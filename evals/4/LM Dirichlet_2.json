{"query": "Bitcoin for beginners", "clip_length": 2, "selected_index": "LM Dirichlet", "results": [{"Clip Text": "You're listening to a purple Radio podcast with me probably share our <mark>for</mark> rights reasons the music in this podcast is shorter than the original version on demand. So a big warm welcome to my guests on the show tonight and a Colgan and loose and Berkeley the InStep presidents your oh, yeah, and of course, we've got a lot of things to talk about We're not gonna get into it just straight away no first. Of all just tell us about yourselves and ye introduce yourself to listeners at home. I know you very well, but obviously people at home though. So yeah. Okay, I'll go first. Hi. I'm Hannah Colgan a second year from Hill bead studying physical geography from London. Yeah, that's it. That's great. That's great. That's perfect. That's what you wanted and you lose it. Hi. I'm Lucy. I said, I'm not sure Sciences. I'm also a second-year student from Hill beard. Me and Hannah live next door to each their last year. Yeah, and and I also support", "Start Time (s)": 0.0, "End Time (s)": 64.2, "Clip Length (min)": 1.07, "show_uri": "spotify:show:1NSJ0oOcYGVRWTKi0uSAd0", "show_name": "Purple Radio on Demand", "show_description": "Purple Radio is Durham University's multi-award-winning student radio station - including a first and second at the 2019 Student Radio Awards.  Host of the Student Radio Association Chart Show 2019 and home to a diverse range of podcasts including music, sport and news amongst many others.  Contact: info@purpleradio.co.uk @PurpleRadioUK on Twitter @purple_radio on Instagram", "publisher": "Purple Radio", "episode_uri": "spotify:episode:0AT7TC6SCHBy6Ov8rRYqhh", "episode_name": "The Robert Leech Gerrard Podcast ", "episode_description": "Join Robert Leech-Gerrard as he sits down with the presidents of Instep, Durham University's dance society, to find out more about their upcoming annual showcase event, Reconnect. ", "score": 5.871055, "explanation": "{\n  \"value\": 5.871055,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11177774,\n      \"description\": \"weight(word_list:for in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11177774,\n          \"description\": \"score(LMDirichletSimilarity, freq=26.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.99554527,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 26.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.7592773,\n      \"description\": \"weight(word_list:beginners in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.7592773,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "your oh, yeah, and of course, we've got a lot of things to talk about We're not gonna get into it just straight away no first. Of all just tell us about yourselves and ye introduce yourself to listeners at home. I know you very well, but obviously people at home though. So yeah. Okay, I'll go first. Hi. I'm Hannah Colgan a second year from Hill bead studying physical geography from London. Yeah, that's it. That's great. That's great. That's perfect. That's what you wanted and you lose it. Hi. I'm Lucy. I said, I'm not sure Sciences. I'm also a second-year student from Hill beard. Me and Hannah live next door to each their last year. Yeah, and and I also support LFC with Rob. Yes hundred percent. That is what we needed to hear that. It's like the little poor thing. Everyone can probably tell from your voice, but it's good to know anyway, so so yeah, so you two, like I said our the InStep dance So basically <mark>for</mark> a lot of people they'll be like what is in Step. So just tell us a little bit about the site. Well, yeah, it's the biggest our society and Durham one of the biggest du societies. It's like <mark>for</mark> dancers of all abilities <mark>beginners</mark> intermediates Advanced people. Yeah and pastors every year and and then we also have do you underneath those? So they're CompTIA him who compete around the UK so competition team so that's yeah I do. Where do you yeah. Okay, so it's a big operation and yeah. Yeah, very big organization. Yeah, well, obviously so five obviously I live with you. So I would like I can see what you're doing at home and somebody just see like an absolute nightmare, but at the same time it's like very rewarding to actually see the good things that happen. When you put in the time you put in the effort stuff like that. Yeah. So I guess the main thing would be that you work into ours is the show but we're going to leave listeners on tenterhooks. Oh, yeah. It's like to share we get another song. I'll give you guys a breather and yeah, we'll get into the main stopping Justice. Can but in the meantime we", "Start Time (s)": 19.0, "End Time (s)": 138.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1NSJ0oOcYGVRWTKi0uSAd0", "show_name": "Purple Radio on Demand", "show_description": "Purple Radio is Durham University's multi-award-winning student radio station - including a first and second at the 2019 Student Radio Awards.  Host of the Student Radio Association Chart Show 2019 and home to a diverse range of podcasts including music, sport and news amongst many others.  Contact: info@purpleradio.co.uk @PurpleRadioUK on Twitter @purple_radio on Instagram", "publisher": "Purple Radio", "episode_uri": "spotify:episode:0AT7TC6SCHBy6Ov8rRYqhh", "episode_name": "The Robert Leech Gerrard Podcast ", "episode_description": "Join Robert Leech-Gerrard as he sits down with the presidents of Instep, Durham University's dance society, to find out more about their upcoming annual showcase event, Reconnect. ", "score": 5.871055, "explanation": "{\n  \"value\": 5.871055,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11177774,\n      \"description\": \"weight(word_list:for in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11177774,\n          \"description\": \"score(LMDirichletSimilarity, freq=26.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.99554527,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 26.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.7592773,\n      \"description\": \"weight(word_list:beginners in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.7592773,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "guests on tonight. And those are the presidents of the Durham InStep Society Hannah and Lucy. Hello. And as we were just talking about earlier you of course, I've got your big annual show coming up this year. So I think it's time to be a little bit of a lie, don't you think? Yeah answer. The name is reconnect. Right? So let's just talk about reconnect because obviously that could mean a lot of different things and Is really like I've always really good name a really good feeling everything. So I just felt like maybe could explain that a little bit Yeah. So it's like the logo is like explains. So reconnect. The Eco is in green. So that's our main General theme of the show. We're trying to raise environmental awareness and trying to help all of us, you know, reconnect nature and being more eco-friendly through the medium of dance, of course, so it's like re Eco necked. Yeah. So I've actually seen the artwork and the visuals and I actually look really good. So I'd encourage anyone who hasn't already seeing their to go and check out the event. You can find on Facebook on yeah Facebook. Yeah. So any other details you like to share <mark>for</mark> now about the show and it's on the 12th and the 13th of March. So on at 7:30 in the Fontaine Ballroom in the DS you right? Okay and can anyone come to it? Yeah, it's five pounds <mark>for</mark> students. Have you show your Durham student ID and then if not seven pints <mark>for</mark> adults, right? Okay, so I mean obviously I'll be there so I mean I went to the show last year as well because it's a come sir. Yeah, and I actually really like I was pleasantly surprised because obviously I was going to come and support you any way but actually turned up and I was like, I know it's a cliche but there's like very much something <mark>for</mark> everyone if you know I'm here because there's so many different genres of dance and <mark>for</mark> me, so <mark>for</mark> example ballet, I would think I'm not too interested in ballet, but then something else would come out and I'd really grabbed my attention by the end of the night. I found myself enjoying the ballet as well. Johnny is why I think the beauty about it because there's so many different themes and so many different ideas going on and I think it's just like the way it's all constructed together. It's just Just like say something <mark>for</mark> everyone to enjoy that's why we love it. Like it's a society <mark>for</mark> everyone like beginners. I everyone's embellish. Oh, yeah, just like showcases", "Start Time (s)": 156.1, "End Time (s)": 275.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1NSJ0oOcYGVRWTKi0uSAd0", "show_name": "Purple Radio on Demand", "show_description": "Purple Radio is Durham University's multi-award-winning student radio station - including a first and second at the 2019 Student Radio Awards.  Host of the Student Radio Association Chart Show 2019 and home to a diverse range of podcasts including music, sport and news amongst many others.  Contact: info@purpleradio.co.uk @PurpleRadioUK on Twitter @purple_radio on Instagram", "publisher": "Purple Radio", "episode_uri": "spotify:episode:0AT7TC6SCHBy6Ov8rRYqhh", "episode_name": "The Robert Leech Gerrard Podcast ", "episode_description": "Join Robert Leech-Gerrard as he sits down with the presidents of Instep, Durham University's dance society, to find out more about their upcoming annual showcase event, Reconnect. ", "score": 5.871055, "explanation": "{\n  \"value\": 5.871055,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11177774,\n      \"description\": \"weight(word_list:for in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11177774,\n          \"description\": \"score(LMDirichletSimilarity, freq=26.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.99554527,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 26.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.7592773,\n      \"description\": \"weight(word_list:beginners in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.7592773,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "good. So I'd encourage anyone who hasn't already seeing their to go and check out the event. You can find on Facebook on yeah Facebook. Yeah. So any other details you like to share <mark>for</mark> now about the show and it's on the 12th and the 13th of March. So on at 7:30 in the Fontaine Ballroom in the DS you right? Okay and can anyone come to it? Yeah, it's five pounds <mark>for</mark> students. Have you show your Durham student ID and then if not seven pints <mark>for</mark> adults, right? Okay, so I mean obviously I'll be there so I mean I went to the show last year as well because it's a come sir. Yeah, and I actually really like I was pleasantly surprised because obviously I was going to come and support you any way but actually turned up and I was like, I know it's a cliche but there's like very much something <mark>for</mark> everyone if you know I'm here because there's so many different genres of dance and <mark>for</mark> me, so <mark>for</mark> example ballet, I would think I'm not too interested in ballet, but then something else would come out and I'd really grabbed my attention by the end of the night. I found myself enjoying the ballet as well. Johnny is why I think the beauty about it because there's so many different themes and so many different ideas going on and I think it's just like the way it's all constructed together. It's just Just like say something <mark>for</mark> everyone to enjoy that's why we love it. Like it's a society <mark>for</mark> everyone like beginners. I everyone's embellish. Oh, yeah, just like showcases everyone. Like it's really ya know and I think he's like you said the reconnect everything that's obviously a strong theme. I like I said, I really liked it and I think it really means something I think the relevant. Yeah exactly. It's like something that's really relevant at this moment in time. And <mark>for</mark> me, I think obviously dance is an art form in itself, but it's amazing. If you can have you know, a piece of art that's nice and itself and nice to look up it actually means something so the These were all going to come and enjoy your dancing, but hopefully everyone could take something about away from the show. Yeah. Yeah. Yeah, and he's like, I mean, obviously I do a radio show so I listen to music but the BET very best music is the music that say something about something and I think if your show can do that and that's what y'all tryin to and fingers crossed fingers crossed. I'm sure it will be amazing. Like I said, I've been last year really enjoyed it so fingers crossed. Hopefully even that is yeah. I mean, I might be great. I'll be great and Yeah, we're going to carry on talking", "Start Time (s)": 207.7, "End Time (s)": 327.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1NSJ0oOcYGVRWTKi0uSAd0", "show_name": "Purple Radio on Demand", "show_description": "Purple Radio is Durham University's multi-award-winning student radio station - including a first and second at the 2019 Student Radio Awards.  Host of the Student Radio Association Chart Show 2019 and home to a diverse range of podcasts including music, sport and news amongst many others.  Contact: info@purpleradio.co.uk @PurpleRadioUK on Twitter @purple_radio on Instagram", "publisher": "Purple Radio", "episode_uri": "spotify:episode:0AT7TC6SCHBy6Ov8rRYqhh", "episode_name": "The Robert Leech Gerrard Podcast ", "episode_description": "Join Robert Leech-Gerrard as he sits down with the presidents of Instep, Durham University's dance society, to find out more about their upcoming annual showcase event, Reconnect. ", "score": 5.871055, "explanation": "{\n  \"value\": 5.871055,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11177774,\n      \"description\": \"weight(word_list:for in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11177774,\n          \"description\": \"score(LMDirichletSimilarity, freq=26.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.99554527,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 26.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.7592773,\n      \"description\": \"weight(word_list:beginners in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.7592773,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "going to carry on talking little bit more about the show a little bit more about Society in just a second. But until then want to get on a bit of Juicy like dude your cat. I think I pronounce that right Lucy wanted this one. So yeah when you get this on hope you enjoy it. Speaking again with the presence of InStep and of course, we just been speaking about the show and I'm very excited about it. We've got two weeks to wait is it two weeks? Yeah 16 days. And of course, we'll just speaking then about the fact that he's got a female's very much about helping the environment. Reconnecting with the environment reconnecting with the planet and so of course that's very much a symbolic thing that you're at is trying to promote but we've just been speaking then during the song about some of the more tangible things that you show might be doing. So you're going to be raising money. I understand <mark>for</mark> a couple of good calls. So I'll to Charities ordering Wildlife trust. So that's a local charity and then our wider charity is the British ecological Society. So the ways of raising money is yeah. So a proportion of our ticket sales are going to go obviously to the Charities and then we've got a bake sale. During the interval. So we're going to try and encourage people to either bring or bake like stuff but make the maybe like vegan or more like organic like so yeah, but are more environmentally kind of friendly then we're designing tote bags with our logos on that which will be organic and like, you know, the cotton will get that organic. Yeah, and then we're having bamboo straws like reusable straws. We're going to sell those as well. We're getting them engraved with like in step on. Wow. I did I suspect that's very smooth. Yeah. Yeah. Yes, that's brand-new lose to me as well. So yeah, that sounds really impressive lots of stash. It's not something that's the main thing as well that you're actually thinking about the environmental impact of what your products are what you are what you are selling because it wouldn't mean much", "Start Time (s)": 327.0, "End Time (s)": 446.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1NSJ0oOcYGVRWTKi0uSAd0", "show_name": "Purple Radio on Demand", "show_description": "Purple Radio is Durham University's multi-award-winning student radio station - including a first and second at the 2019 Student Radio Awards.  Host of the Student Radio Association Chart Show 2019 and home to a diverse range of podcasts including music, sport and news amongst many others.  Contact: info@purpleradio.co.uk @PurpleRadioUK on Twitter @purple_radio on Instagram", "publisher": "Purple Radio", "episode_uri": "spotify:episode:0AT7TC6SCHBy6Ov8rRYqhh", "episode_name": "The Robert Leech Gerrard Podcast ", "episode_description": "Join Robert Leech-Gerrard as he sits down with the presidents of Instep, Durham University's dance society, to find out more about their upcoming annual showcase event, Reconnect. ", "score": 5.871055, "explanation": "{\n  \"value\": 5.871055,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11177774,\n      \"description\": \"weight(word_list:for in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11177774,\n          \"description\": \"score(LMDirichletSimilarity, freq=26.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.99554527,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 26.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.7592773,\n      \"description\": \"weight(word_list:beginners in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.7592773,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and like, you know, the cotton will get that organic. Yeah, and then we're having bamboo straws like reusable straws. We're going to sell those as well. We're getting them engraved with like in step on. Wow. I did I suspect that's very smooth. Yeah. Yeah. Yes, that's brand-new lose to me as well. So yeah, that sounds really impressive lots of stash. It's not something that's the main thing as well that you're actually thinking about the environmental impact of what your products are what you are what you are selling because it wouldn't mean much of a show if you try to be environmentally friendly, but then you were selling things that yeah, we thought let's put a spin on it like yeah make it wanted and the one other thing we're doing as well as trying to reuse costumes that we've already got instead of buying new costumes. And obviously that's yeah again not yeah. Yeah. Yeah, like I said, They were good last year. So why don't you again as well though? The vegan cake say I'm looking forward to it because last night obviously, it's Pancake Day. So I seen you two cooking the vegan pancakes and like the sound of that to me just sounds like well, no, not <mark>for</mark> me, but that I seen you cooking them and I thinking I love about that. I thank you very much. Just drowning golden syrup. Oh, yeah last night was the most sugar I've had in about four years. Absolutely. I didn't know what to do. So get to sleep until 200 tidy room what I found in the mall so golden syrup and then sugar on pancakes feel like my mom will be listening to this and she'll be thinking. Well, it's like a dentist, but I do get my teeth brushing you all know that in my heart loses its Praises you're watching. Yeah. It means to me and just before getting too. Next song I want to give a shout out to a very special someone Connor Redmond again that just that means the world may absolutely means the world. I know knees listen as well. So like that is obviously our power couple.", "Start Time (s)": 420.0, "End Time (s)": 537.5, "Clip Length (min)": 1.96, "show_uri": "spotify:show:1NSJ0oOcYGVRWTKi0uSAd0", "show_name": "Purple Radio on Demand", "show_description": "Purple Radio is Durham University's multi-award-winning student radio station - including a first and second at the 2019 Student Radio Awards.  Host of the Student Radio Association Chart Show 2019 and home to a diverse range of podcasts including music, sport and news amongst many others.  Contact: info@purpleradio.co.uk @PurpleRadioUK on Twitter @purple_radio on Instagram", "publisher": "Purple Radio", "episode_uri": "spotify:episode:0AT7TC6SCHBy6Ov8rRYqhh", "episode_name": "The Robert Leech Gerrard Podcast ", "episode_description": "Join Robert Leech-Gerrard as he sits down with the presidents of Instep, Durham University's dance society, to find out more about their upcoming annual showcase event, Reconnect. ", "score": 5.871055, "explanation": "{\n  \"value\": 5.871055,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11177774,\n      \"description\": \"weight(word_list:for in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11177774,\n          \"description\": \"score(LMDirichletSimilarity, freq=26.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.99554527,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 26.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.7592773,\n      \"description\": \"weight(word_list:beginners in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.7592773,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "then you to just let us know and we'll get it on but in the meantime going to play foals and this is the runner on people radio. And Lucy the presidents of Durham's in step down Society. Yeah. So we've talked I've hit with wax lyrical really about your show that's coming up and hopefully if you people listening wouldn't have known about instead before tonight and hopefully that sort of pique their interest a little bit. And so maybe I was wondering if you could maybe talk about how they could get involved in Step. Yeah. Yeah, we have two different types of memberships. So we have her annual ones. You paid 25 Yeah, I know you can come to any classes any weekend. And then we have a pay-as-you-go. So you pay three pounds of your member and then to pamper class and that's on the DS you yeah, it's all like through the DSU is really good like so exactly every weekend. Yeah, they run on Saturdays and Sundays so and complete <mark>beginners</mark> can get involved in that as well come. Yeah. Absolutely. I this year I teach beginner tap your teacher. You want everyone to know you're a teacher, honey. The teacher if you take one thing away from tonight forget about the show and of the teacher says every weekend class. So people that want to learn tap can all hit up my class. But yes <mark>for</mark> every ability like yeah, we have advanced classes as well. Yeah Amelia as well as beginners. They are the level. I might get involved. I just think third term Darlene might be your like stressful. Yeah. I think I'd be like, I don't know it's cold. I've got South through my head, but I don't know if it is cell so but like proper, you know, really moving the hips. Yeah. I'd be mine. I reckon we have a salsa and bachata class. Yeah, because on a night owl after a couple of drinks. I think the hips go anyway, that's so if they were trained to go that it might it might look a little bit better job. So well, I'd love you to come. Yeah. No, actually, we're all we've got we have a competition in third term. It's the he'll vote ready <mark>for</mark> that, but we", "Start Time (s)": 543.0, "End Time (s)": 660.8, "Clip Length (min)": 1.96, "show_uri": "spotify:show:1NSJ0oOcYGVRWTKi0uSAd0", "show_name": "Purple Radio on Demand", "show_description": "Purple Radio is Durham University's multi-award-winning student radio station - including a first and second at the 2019 Student Radio Awards.  Host of the Student Radio Association Chart Show 2019 and home to a diverse range of podcasts including music, sport and news amongst many others.  Contact: info@purpleradio.co.uk @PurpleRadioUK on Twitter @purple_radio on Instagram", "publisher": "Purple Radio", "episode_uri": "spotify:episode:0AT7TC6SCHBy6Ov8rRYqhh", "episode_name": "The Robert Leech Gerrard Podcast ", "episode_description": "Join Robert Leech-Gerrard as he sits down with the presidents of Instep, Durham University's dance society, to find out more about their upcoming annual showcase event, Reconnect. ", "score": 5.871055, "explanation": "{\n  \"value\": 5.871055,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11177774,\n      \"description\": \"weight(word_list:for in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11177774,\n          \"description\": \"score(LMDirichletSimilarity, freq=26.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.99554527,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 26.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.7592773,\n      \"description\": \"weight(word_list:beginners in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.7592773,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "on Saturdays and Sundays so and complete <mark>beginners</mark> can get involved in that as well come. Yeah. Absolutely. I this year I teach beginner tap your teacher. You want everyone to know you're a teacher, honey. The teacher if you take one thing away from tonight forget about the show and of the teacher says every weekend class. So people that want to learn tap can all hit up my class. But yes <mark>for</mark> every ability like yeah, we have advanced classes as well. Yeah Amelia as well as beginners. They are the level. I might get involved. I just think third term Darlene might be your like stressful. Yeah. I think I'd be like, I don't know it's cold. I've got South through my head, but I don't know if it is cell so but like proper, you know, really moving the hips. Yeah. I'd be mine. I reckon we have a salsa and bachata class. Yeah, because on a night owl after a couple of drinks. I think the hips go anyway, that's so if they were trained to go that it might it might look a little bit better job. So well, I'd love you to come. Yeah. No, actually, we're all we've got we have a competition in third term. It's the he'll vote ready <mark>for</mark> that, but we could be partners. Yeah. So yes, that's the hill versus Bailey competition. Yeah. It's like because our we have another competition in Ember which we run it's called Durham Dance Fusion. So we ran that other Unis Carpentier. Yeah the sales <mark>for</mark> the competition T. But this one in third term is <mark>for</mark> like any InStep. Yes, your member hell or <mark>for</mark> Bailey depend on which college around. Yes, just like within in step back. It's just about finding yeah. Yeah. Yeah. That sounds good as well. That's the that's the third time you say. Yeah. Definitely. It's that one as well because you know food so I mean after your exams are finished you just like got loads of sign. Tellin Ya Live Life, don't you? Instead. Yeah. Yeah. I mean it's too late. That's the slogan actually love life or whatever live life. I've got it wrong already live life Rico get on some T-shirts organically sustainable concerts those t-shirts. You can tell I'm really bad at least Kanye. But yeah, you look", "Start Time (s)": 600.3, "End Time (s)": 719.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1NSJ0oOcYGVRWTKi0uSAd0", "show_name": "Purple Radio on Demand", "show_description": "Purple Radio is Durham University's multi-award-winning student radio station - including a first and second at the 2019 Student Radio Awards.  Host of the Student Radio Association Chart Show 2019 and home to a diverse range of podcasts including music, sport and news amongst many others.  Contact: info@purpleradio.co.uk @PurpleRadioUK on Twitter @purple_radio on Instagram", "publisher": "Purple Radio", "episode_uri": "spotify:episode:0AT7TC6SCHBy6Ov8rRYqhh", "episode_name": "The Robert Leech Gerrard Podcast ", "episode_description": "Join Robert Leech-Gerrard as he sits down with the presidents of Instep, Durham University's dance society, to find out more about their upcoming annual showcase event, Reconnect. ", "score": 5.871055, "explanation": "{\n  \"value\": 5.871055,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11177774,\n      \"description\": \"weight(word_list:for in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11177774,\n          \"description\": \"score(LMDirichletSimilarity, freq=26.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.99554527,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 26.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.7592773,\n      \"description\": \"weight(word_list:beginners in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.7592773,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "which college around. Yes, just like within in step back. It's just about finding yeah. Yeah. Yeah. That sounds good as well. That's the that's the third time you say. Yeah. Definitely. It's that one as well because you know food so I mean after your exams are finished you just like got loads of sign. Tellin Ya Live Life, don't you? Instead. Yeah. Yeah. I mean it's too late. That's the slogan actually love life or whatever live life. I've got it wrong already live life Rico get on some T-shirts organically sustainable concerts those t-shirts. You can tell I'm really bad at least Kanye. But yeah, you look like look like Hannah Lucy who are the presidents of in Stephen not met so they know a lot more about what they're talking about. Yeah, you sound like we know at all. Yeah in between the songs a lot of frantic searching my old we do this through Ooh luck. Exactly. Let's get it. Let's get it. Now you doing a good job. I'm really enjoying it and we're taking a little break and when they get on a song by The 1975, and I know anyone who's listening who knows me thinking. Oh my God, it's taking him <mark>for</mark> three minutes. This is 95 and it's me and you together song and in case you don't know I absolutely love it. Unfortunately, we only got a minute left of our show tonight and it's a great shame because I've really enjoyed having you on the show tonight. Yeah, I really enjoyed it. So like anytime you want to come back just if you want to plug something else just like, you know, what will give it will get will get we need more protein will give you the Hard Sell. So yeah, so yeah, just before you go and just <mark>for</mark> you say goodbye to everyone. Let's remind everyone last time. Why are you actually here? Why are we reconnect? It's happening. Reconnect something loose anything to us and on the 12th and the 13th of March at the Fontaine ballroom and the DSU tickets are on the door. So just bring yourself along you can find the event on Facebook. So if you type in reconnect in the bar, it'll come up click going to give us a call. Yeah, please play along", "Start Time (s)": 683.8, "End Time (s)": 803.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1NSJ0oOcYGVRWTKi0uSAd0", "show_name": "Purple Radio on Demand", "show_description": "Purple Radio is Durham University's multi-award-winning student radio station - including a first and second at the 2019 Student Radio Awards.  Host of the Student Radio Association Chart Show 2019 and home to a diverse range of podcasts including music, sport and news amongst many others.  Contact: info@purpleradio.co.uk @PurpleRadioUK on Twitter @purple_radio on Instagram", "publisher": "Purple Radio", "episode_uri": "spotify:episode:0AT7TC6SCHBy6Ov8rRYqhh", "episode_name": "The Robert Leech Gerrard Podcast ", "episode_description": "Join Robert Leech-Gerrard as he sits down with the presidents of Instep, Durham University's dance society, to find out more about their upcoming annual showcase event, Reconnect. ", "score": 5.871055, "explanation": "{\n  \"value\": 5.871055,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11177774,\n      \"description\": \"weight(word_list:for in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11177774,\n          \"description\": \"score(LMDirichletSimilarity, freq=26.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.99554527,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 26.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.7592773,\n      \"description\": \"weight(word_list:beginners in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.7592773,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Unfortunately, we only got a minute left of our show tonight and it's a great shame because I've really enjoyed having you on the show tonight. Yeah, I really enjoyed it. So like anytime you want to come back just if you want to plug something else just like, you know, what will give it will get will get we need more protein will give you the Hard Sell. So yeah, so yeah, just before you go and just <mark>for</mark> you say goodbye to everyone. Let's remind everyone last time. Why are you actually here? Why are we reconnect? It's happening. Reconnect something loose anything to us and on the 12th and the 13th of March at the Fontaine ballroom and the DSU tickets are on the door. So just bring yourself along you can find the event on Facebook. So if you type in reconnect in the bar, it'll come up click going to give us a call. Yeah, please play along the interval they would just listen to music if you care about the environment you serious? No, it's amazing because like a lot of people see loads of things about the environment if you how can I help him? Stuff but this is so easy because you're making it easy <mark>for</mark> us. Literally what we can bring a fiver whatever and then you do the rest and we can enjoy it don't mean cake in the interview. Yeah, you know very clearly that your cakes down your secure and they see me coming a lot angle. That would be the best day. But so many things are time you had chicken and meat balls. I just I can't The them at the minute but give it time give me time. It looks after everything that models fall. So yeah, it's been an absolute pleasure. Thank you <mark>for</mark> having me. Yeah, really enjoyed it and we've got one last songs players out and this was requested by my brother Mattie. So I am a you all right? Hi. So yeah, this is robbers, and we're going to play it out. I'll see you later and thank you <mark>for</mark> listening. Thanks <mark>for</mark> downloading this purple radio. podcast <mark>for</mark> more great content and", "Start Time (s)": 759.4, "End Time (s)": 878.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1NSJ0oOcYGVRWTKi0uSAd0", "show_name": "Purple Radio on Demand", "show_description": "Purple Radio is Durham University's multi-award-winning student radio station - including a first and second at the 2019 Student Radio Awards.  Host of the Student Radio Association Chart Show 2019 and home to a diverse range of podcasts including music, sport and news amongst many others.  Contact: info@purpleradio.co.uk @PurpleRadioUK on Twitter @purple_radio on Instagram", "publisher": "Purple Radio", "episode_uri": "spotify:episode:0AT7TC6SCHBy6Ov8rRYqhh", "episode_name": "The Robert Leech Gerrard Podcast ", "episode_description": "Join Robert Leech-Gerrard as he sits down with the presidents of Instep, Durham University's dance society, to find out more about their upcoming annual showcase event, Reconnect. ", "score": 5.871055, "explanation": "{\n  \"value\": 5.871055,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11177774,\n      \"description\": \"weight(word_list:for in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11177774,\n          \"description\": \"score(LMDirichletSimilarity, freq=26.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.99554527,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 26.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.7592773,\n      \"description\": \"weight(word_list:beginners in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.7592773,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "serious? No, it's amazing because like a lot of people see loads of things about the environment if you how can I help him? Stuff but this is so easy because you're making it easy <mark>for</mark> us. Literally what we can bring a fiver whatever and then you do the rest and we can enjoy it don't mean cake in the interview. Yeah, you know very clearly that your cakes down your secure and they see me coming a lot angle. That would be the best day. But so many things are time you had chicken and meat balls. I just I can't The them at the minute but give it time give me time. It looks after everything that models fall. So yeah, it's been an absolute pleasure. Thank you <mark>for</mark> having me. Yeah, really enjoyed it and we've got one last songs players out and this was requested by my brother Mattie. So I am a you all right? Hi. So yeah, this is robbers, and we're going to play it out. I'll see you later and thank you <mark>for</mark> listening. Thanks <mark>for</mark> downloading this purple radio. podcast <mark>for</mark> more great content and listen live heads a purple radio dot Co dot U k--", "Start Time (s)": 812.0, "End Time (s)": 882.1, "Clip Length (min)": 1.17, "show_uri": "spotify:show:1NSJ0oOcYGVRWTKi0uSAd0", "show_name": "Purple Radio on Demand", "show_description": "Purple Radio is Durham University's multi-award-winning student radio station - including a first and second at the 2019 Student Radio Awards.  Host of the Student Radio Association Chart Show 2019 and home to a diverse range of podcasts including music, sport and news amongst many others.  Contact: info@purpleradio.co.uk @PurpleRadioUK on Twitter @purple_radio on Instagram", "publisher": "Purple Radio", "episode_uri": "spotify:episode:0AT7TC6SCHBy6Ov8rRYqhh", "episode_name": "The Robert Leech Gerrard Podcast ", "episode_description": "Join Robert Leech-Gerrard as he sits down with the presidents of Instep, Durham University's dance society, to find out more about their upcoming annual showcase event, Reconnect. ", "score": 5.871055, "explanation": "{\n  \"value\": 5.871055,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.11177774,\n      \"description\": \"weight(word_list:for in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11177774,\n          \"description\": \"score(LMDirichletSimilarity, freq=26.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.99554527,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 26.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 5.7592773,\n      \"description\": \"weight(word_list:beginners in 289) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.7592773,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Hello everyone. This is Adam Meister the bitcoinmeister the disrupt Meister. Welcome to the one <mark>Bitcoin</mark> show. Today is March the first 2020 strong hand golden age of the 2020s baby had. Height we're going to talk about that some 80 percenters were talking about it in motion value your wealth in <mark>Bitcoin</mark> be a unique beast on confiscated Bible low my Elite friends marches here. Oh my hey this week in Bitcoin. The last one in February or was legendary ugly old goat was on there and Phil was on there and Brady Swenson. Of a citizen <mark>Bitcoin</mark> fill as of course unchain Capital check it out yesterday. There were two shows. One of them was a caped presentation. I did <mark>for</mark> an Iowa <mark>Bitcoin</mark> group. I did it from here in LA, but they were in Iowa when I", "Start Time (s)": 7.3, "End Time (s)": 83.1, "Clip Length (min)": 1.26, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the disrupt Meister. Welcome to the one <mark>Bitcoin</mark> show. Today is March the first 2020 strong hand golden age of the 2020s baby had. Height we're going to talk about that some 80 percenters were talking about it in motion value your wealth in <mark>Bitcoin</mark> be a unique beast on confiscated Bible low my Elite friends marches here. Oh my hey this week in Bitcoin. The last one in February or was legendary ugly old goat was on there and Phil was on there and Brady Swenson. Of a citizen <mark>Bitcoin</mark> fill as of course unchain Capital check it out yesterday. There were two shows. One of them was a caped presentation. I did <mark>for</mark> an Iowa <mark>Bitcoin</mark> group. I did it from here in LA, but they were in Iowa when I did <mark>for</mark> them on Thursday, it's pretty cool watch it. It's linked to below of course and the be on <mark>bitcoin</mark> show. We were talking about the current events the Panic. Oh my God the people out there. Come on. Mine the Golden Age you guys are just falling into this 80% or mainstream media hype about this. God all right, so I can't even say what I'm talking about. But you all know what's been in the news lately. It's ridiculous. I'm not going to spend on a stuff because of course. This is the one <mark>Bitcoin</mark> show. Oh, yeah, San Francisco. I'll be at the event at the end of the month. That's linked to below Tel Aviv. Oh, yeah. I'm still going to Tel Aviv. Of course. The having party will be made 21st best having party on Earth that's linked to below and We will talk about the having in a second.", "Start Time (s)": 17.0, "End Time (s)": 135.0, "Clip Length (min)": 1.97, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of course and the be on <mark>bitcoin</mark> show. We were talking about the current events the Panic. Oh my God the people out there. Come on. Mine the Golden Age you guys are just falling into this 80% or mainstream media hype about this. God all right, so I can't even say what I'm talking about. But you all know what's been in the news lately. It's ridiculous. I'm not going to spend on a stuff because of course. This is the one <mark>Bitcoin</mark> show. Oh, yeah, San Francisco. I'll be at the event at the end of the month. That's linked to below Tel Aviv. Oh, yeah. I'm still going to Tel Aviv. Of course. The having party will be made 21st best having party on Earth that's linked to below and We will talk about the having in a second. Jay doorman says this stem the stimulus is coming possibly as early as today. What do you think <mark>Bitcoin</mark> does when more insane amounts of free money are created. I've got to say I agree with Jay doorman on this one that the FED may be coordinated with some of the other. Western Nations and rich Asian Nations like Japan will have some coordinated stimulus of some sort lowering rates suddenly. Maybe it won't be coordinated. Maybe it will but I don't think Trump can and it will pump all the markets again including Bitcoin. So be prepared <mark>for</mark> that. Am IA fan of that kind of stuff of the fed. The FED is going to do with the fence going to do it's not my I don't care anymore. That's why I own Bitcoin. I don't care what the think that's that that when you own <mark>Bitcoin</mark> you really don't care what the FED does. I'm just pointing it out.", "Start Time (s)": 86.6, "End Time (s)": 206.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "possibly as early as today. What do you think <mark>Bitcoin</mark> does when more insane amounts of free money are created. I've got to say I agree with Jay doorman on this one that the FED may be coordinated with some of the other. Western Nations and rich Asian Nations like Japan will have some coordinated stimulus of some sort lowering rates suddenly. Maybe it won't be coordinated. Maybe it will but I don't think Trump can and it will pump all the markets again including Bitcoin. So be prepared <mark>for</mark> that. Am IA fan of that kind of stuff of the fed. The FED is going to do with the fence going to do it's not my I don't care anymore. That's why I own Bitcoin. I don't care what the think that's that that when you own <mark>Bitcoin</mark> you really don't care what the FED does. I'm just pointing it out. <mark>For</mark> those of you who think also beginning of a horrible recession. Oh the 2020 is going be so terrible <mark>for</mark> the economy and Ever want to jump back in every when the crack is flowing again when the heroine is Flowing that monetary hair and everyone will be partying it up. Like it's freaking 1999 and it's Prince pound that like button. All right. So Moon capital, what's this? Oh, this is good. Unpopular take <mark>Bitcoin</mark> is so much bigger than <mark>Bitcoin</mark> Twitter. We are a small part of the <mark>Bitcoin</mark> community. And if we all disappeared <mark>Bitcoin</mark> would be fine pound that like button dude. I agree. You can learn a lot from <mark>Bitcoin</mark> Twitter, but 80% of it of course of it is gossip and a waste of time and people screaming at each other and complete nonsense even 20% probably is good.", "Start Time (s)": 142.9, "End Time (s)": 262.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "All right. So Moon capital, what's this? Oh, this is good. Unpopular take <mark>Bitcoin</mark> is so much bigger than <mark>Bitcoin</mark> Twitter. We are a small part of the <mark>Bitcoin</mark> community. And if we all disappeared <mark>Bitcoin</mark> would be fine pound that like button dude. I agree. You can learn a lot from <mark>Bitcoin</mark> Twitter, but 80% of it of course of it is gossip and a waste of time and people screaming at each other and complete nonsense even 20% probably is good. I do encourage people to to read the the Twitter feeds of the people I have on the show and and the Twitter feeds of people that I retweet but not to get into the ludicrous arguments. It's now when you do get into this ludicrous arguments and when you start to put these people on pedestals, you forget that there's so many entities in this Ace who's never been on Twitter before have just bought a lot of <mark>Bitcoin</mark> because it's it's <mark>Bitcoin</mark> because they want to preserve their wealth because they wanted a they want gold 2.0 limited Supply type of monetary. I mean that it's so it's a good reminder. Sometimes you have to get out of a little bubble and it's a thing with YouTube <mark>Bitcoin</mark> YouTubers like me if we all disappeared. It wouldn't matter at all. Would it matter at all <mark>for</mark> <mark>Bitcoin</mark> <mark>Bitcoin</mark> is so much bigger <mark>Bitcoin</mark> is the honey badger. It doesn't matter what the YouTubers do and I'm not a YouTuber. I'm a bit coiner, but you know what? I mean the Twitter people do so if you ever if you ever start to take that don't overreact to social media Okay, there is a benefit to it there. You can learn it does not make Bitcoin. It does not make or bake make-or-break <mark>Bitcoin</mark> it helps you as an individual become a more efficient", "Start Time (s)": 228.1, "End Time (s)": 347.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "many entities in this Ace who's never been on Twitter before have just bought a lot of <mark>Bitcoin</mark> because it's it's <mark>Bitcoin</mark> because they want to preserve their wealth because they wanted a they want gold 2.0 limited Supply type of monetary. I mean that it's so it's a good reminder. Sometimes you have to get out of a little bubble and it's a thing with YouTube <mark>Bitcoin</mark> YouTubers like me if we all disappeared. It wouldn't matter at all. Would it matter at all <mark>for</mark> <mark>Bitcoin</mark> <mark>Bitcoin</mark> is so much bigger <mark>Bitcoin</mark> is the honey badger. It doesn't matter what the YouTubers do and I'm not a YouTuber. I'm a bit coiner, but you know what? I mean the Twitter people do so if you ever if you ever start to take that don't overreact to social media Okay, there is a benefit to it there. You can learn it does not make Bitcoin. It does not make or bake make-or-break <mark>Bitcoin</mark> it helps you as an individual become a more efficient manager of your finances if you properly read and listen to the so shut up in shouting mouth matches waited wasting their time and on Twitter or and comment sections just trolling which is not Being in motion at all now all we got questions here. Hey before we move on to this and I can't say that word there Daniel. That's not a very nice thing. You're a bit coiner riot. You're a big koiner. Not a you not a YouTuber <mark>for</mark> sure. I don't know where I still write it from. Thanks, Daniel. I'm a I'm a big point or not a YouTuber <mark>for</mark> sure. Okay. Good. All right <mark>Bitcoin</mark> or Ted says here on Twitter bitcoiners deserve every single Cent", "Start Time (s)": 282.3, "End Time (s)": 401.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Okay, there is a benefit to it there. You can learn it does not make Bitcoin. It does not make or bake make-or-break <mark>Bitcoin</mark> it helps you as an individual become a more efficient manager of your finances if you properly read and listen to the so shut up in shouting mouth matches waited wasting their time and on Twitter or and comment sections just trolling which is not Being in motion at all now all we got questions here. Hey before we move on to this and I can't say that word there Daniel. That's not a very nice thing. You're a bit coiner riot. You're a big koiner. Not a you not a YouTuber <mark>for</mark> sure. I don't know where I still write it from. Thanks, Daniel. I'm a I'm a big point or not a YouTuber <mark>for</mark> sure. Okay. Good. All right <mark>Bitcoin</mark> or Ted says here on Twitter bitcoiners deserve every single Cent their portfolio appreciates. Your Bitcoins being well-preserved is an effort. Still very few are ready to learn. I agree but it will change over time <mark>Bitcoin</mark> is going to create lesions of cybersecurity experts. Hmm regions of cyber Security Experts. I think it'll make some people more aware of the cybersecurity risk out there when you're dealing with your finances when you're dealing with your private key. I think it's going to send some people to third parties. I think it's going to help some <mark>Bitcoin</mark> Banks out. I would say the bitcoiners do deserve every single cent of their that their portfolio appreciates", "Start Time (s)": 333.4, "End Time (s)": 453.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>for</mark> sure. I don't know where I still write it from. Thanks, Daniel. I'm a I'm a big point or not a YouTuber <mark>for</mark> sure. Okay. Good. All right <mark>Bitcoin</mark> or Ted says here on Twitter bitcoiners deserve every single Cent their portfolio appreciates. Your Bitcoins being well-preserved is an effort. Still very few are ready to learn. I agree but it will change over time <mark>Bitcoin</mark> is going to create lesions of cybersecurity experts. Hmm regions of cyber Security Experts. I think it'll make some people more aware of the cybersecurity risk out there when you're dealing with your finances when you're dealing with your private key. I think it's going to send some people to third parties. I think it's going to help some <mark>Bitcoin</mark> Banks out. I would say the bitcoiners do deserve every single cent of their that their portfolio appreciates if they are properly managing the private key on their treasure on their Ledger or whatever their Hardware device. Okay, but I don't I don't think it's going to wake up everyone to properly controlling their private key. It will wake up some people but you say Legions will become cyber Security Experts. I think it's wishful thinking dude. I think we got a lot of bad stories ahead of us <mark>for</mark> some individuals that do not take personal responsibility. Seriously now on that note. Hello everyone. If you haven't heard about anchor it's the easiest way to make a podcast. That's how I make mine. Let me explain it's free. There's creation tools that allow you to record and edit your podcast right from your phone or your computer like like I do anchor will distribute your podcast <mark>for</mark> you. So it can be", "Start Time (s)": 384.1, "End Time (s)": 504.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "help some <mark>Bitcoin</mark> Banks out. I would say the bitcoiners do deserve every single cent of their that their portfolio appreciates if they are properly managing the private key on their treasure on their Ledger or whatever their Hardware device. Okay, but I don't I don't think it's going to wake up everyone to properly controlling their private key. It will wake up some people but you say Legions will become cyber Security Experts. I think it's wishful thinking dude. I think we got a lot of bad stories ahead of us <mark>for</mark> some individuals that do not take personal responsibility. Seriously now on that note. Hello everyone. If you haven't heard about anchor it's the easiest way to make a podcast. That's how I make mine. Let me explain it's free. There's creation tools that allow you to record and edit your podcast right from your phone or your computer like like I do anchor will distribute your podcast <mark>for</mark> you. So it can be heard on Spotify Apple podcast and many more you can make money just like I do from your podcast with no minimum listenership. It's everything you need to make a podcast in one place. I love the convenience download the free anchor app or go to Anchor dot. F m-- to get started. Anchor dot f m here's a story about a guy. Who's apparently bidding cryptocurrency <mark>for</mark> quite some time and owns a lot of be cash and <mark>Bitcoin</mark> he had $60,000 60,000 bees cash worth around 20 million dollars stolen from his phone. Oh, yes. He wasn't keeping his be cash. He was those cyber security expert was he as the excuse me as the Tweet before Alito alluded to he did become. Um cyber security expert yet. He's been in the space <mark>for</mark> a very long", "Start Time (s)": 442.2, "End Time (s)": 561.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "podcast <mark>for</mark> you. So it can be heard on Spotify Apple podcast and many more you can make money just like I do from your podcast with no minimum listenership. It's everything you need to make a podcast in one place. I love the convenience download the free anchor app or go to Anchor dot. F m-- to get started. Anchor dot f m here's a story about a guy. Who's apparently bidding cryptocurrency <mark>for</mark> quite some time and owns a lot of be cash and <mark>Bitcoin</mark> he had $60,000 60,000 bees cash worth around 20 million dollars stolen from his phone. Oh, yes. He wasn't keeping his be cash. He was those cyber security expert was he as the excuse me as the Tweet before Alito alluded to he did become. Um cyber security expert yet. He's been in the space <mark>for</mark> a very long time. It's linked to below the entire crazy story, but he was either keeping his be cached on a phone or keeping his be cash at blockchain dot info God forbid and it was stolen from him. All we had to do. All he had to do was keep it at a Tresor. I mean if you've got like a million dollars Dude, I can't believe in you have a million dollars worth of be cash or keeping on the phone. Let alone 20 million dollars worth of it. Now some people think well, he he's not a very smart guy because he's got his wealth and be cash. He doesn't understand what bit that <mark>Bitcoin</mark> is the next <mark>Bitcoin</mark> and that you got a value your wealth in <mark>Bitcoin</mark> and not be cash. That's <mark>for</mark> sure. I think it's really unfortunate that he got his fortune stolen from him because Been an honor phone or keeping it on a blockchain done in <mark>for</mark> we're", "Start Time (s)": 501.3, "End Time (s)": 620.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "yet. He's been in the space <mark>for</mark> a very long time. It's linked to below the entire crazy story, but he was either keeping his be cached on a phone or keeping his be cash at blockchain dot info God forbid and it was stolen from him. All we had to do. All he had to do was keep it at a Tresor. I mean if you've got like a million dollars Dude, I can't believe in you have a million dollars worth of be cash or keeping on the phone. Let alone 20 million dollars worth of it. Now some people think well, he he's not a very smart guy because he's got his wealth and be cash. He doesn't understand what bit that <mark>Bitcoin</mark> is the next <mark>Bitcoin</mark> and that you got a value your wealth in <mark>Bitcoin</mark> and not be cash. That's <mark>for</mark> sure. I think it's really unfortunate that he got his fortune stolen from him because Been an honor phone or keeping it on a blockchain done in <mark>for</mark> we're not keeping it on a hardware wallet clearly, but that's linked to below that story a few people are talking about it. Some people some be cashiers are worried because the hacker is going to sell it all and maybe that'll crash damn right? I wouldn't worry about that aspect of it. I'm more so would worry about people who keep that much money on a phone. Or on blockchain that info and somehow by losing access to their phone by getting their phone hacked. Maybe he had some password listed there. Maybe he had some private key listed there. It's not exactly clear but he did something really wrong and you can avoid all of that first and you know, that that's probably reason I don't have a phone. I don't even have a phone if I had a phone I would not keep any of cryptocurrency there at all. No.", "Start Time (s)": 560.3, "End Time (s)": 676.5, "Clip Length (min)": 1.94, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "losing access to their phone by getting their phone hacked. Maybe he had some password listed there. Maybe he had some private key listed there. It's not exactly clear but he did something really wrong and you can avoid all of that first and you know, that that's probably reason I don't have a phone. I don't even have a phone if I had a phone I would not keep any of cryptocurrency there at all. No. What else is he who keeps his kind of money with only a phone as protection never heard of a hardware while and never heard of a hardware while it's when will people learn how to secure their coins. How many horror stories must we see? Well, we're going to see we're going to hear quite quite a few more here. So guys, don't be the next Horror Story and all right. Remember if you guys got questions I can answer. I see people talk in there. You see just type in <mark>Bitcoin</mark> Meister do it super cat. And what is next on the agenda here? Oh, well, let's talk about cash real quick. We're talking about <mark>Bitcoin</mark> which is digital cash digital gold. Whatever you want to call it much better than a bringing that cash in on your in your suitcase. And yes <mark>Bitcoin</mark> fixes the following problem that this on this unfortunate individual has the FED sees $39,000 from this guy's carry-on bags. He sues the get it back when the feds asked where he got the money. He invoked his Fifth Amendment rights against self-incrimination. The sixth Circuit Court says that means he doesn't have standing to challenge the seizure because he can't show it's his money. So yeah, if you got thirty nine thousand dollars laying around in cash. And it can be easily taken away from you. Okay easily", "Start Time (s)": 651.6, "End Time (s)": 770.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "from this guy's carry-on bags. He sues the get it back when the feds asked where he got the money. He invoked his Fifth Amendment rights against self-incrimination. The sixth Circuit Court says that means he doesn't have standing to challenge the seizure because he can't show it's his money. So yeah, if you got thirty nine thousand dollars laying around in cash. And it can be easily taken away from you. Okay easily confiscated. You might think you're getting it back, but you're going to get into some bureaucracy there as as this. Tweet shows. It's his money. He doesn't want to say where he got the money. They stole it from him the TSA stole the money from it was in his possession. He doesn't want to say it is his right not to say where he got the money from but now the court said well, if you can't say where he got it from it's not really his money. So they stole his money. Yeah, <mark>Bitcoin</mark> definitely solves that issue right there because they can't just come at you and take your <mark>Bitcoin</mark> unless you have your freaking private key ring down there. Yeah, if you're like the guy men. Above it. That's pretty bad. But if you've got it on a Tresor if you've got it on a ledger Hardware wallet, they can't just they don't they can take your your Ledger or your treasure, but they can't they can't get it from you right away. They cannot get it from Uruguay. If you've if you know that thing's been stolen you got your private key. You you've first of all you move it at that point and you're in good shape. Now, I doubt if the government stole suddenly stole your treasure at this point, they would have the proper and of course. If you just even if they stole it and they had the proper specialized device and specialized person that could get into your", "Start Time (s)": 741.6, "End Time (s)": 859.9, "Clip Length (min)": 1.97, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "they can't just they don't they can take your your Ledger or your treasure, but they can't they can't get it from you right away. They cannot get it from Uruguay. If you've if you know that thing's been stolen you got your private key. You you've first of all you move it at that point and you're in good shape. Now, I doubt if the government stole suddenly stole your treasure at this point, they would have the proper and of course. If you just even if they stole it and they had the proper specialized device and specialized person that could get into your Treasurer if you had the freaking. The was it the passphrase or whatever not the not the code not your password, but you're special 25th word. Basically you'd be fine <mark>for</mark> a while at least and again you would know if they stole your treasure and you would have your private key. And of course you would move it to a new you would move the <mark>Bitcoin</mark> to a new private key at that point. You'll be fine. But anyway going back to the whole darn point of this it and you. So off moberg ask have you seen Daniel Kravitz talk about fake Toshi and Michael Hudson, it's hilarious. Well II I've unfortunately during its people retweet Daniel Kravitz worship of just blind worship of fake Toshi. So I've seen that I don't know who Michael hugs Hudson is but it's it's really like cringe-worthy that the stuff that Daniel tweets out there. I mean, he's not like The most socially skilled guy out there", "Start Time (s)": 817.8, "End Time (s)": 937.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I know some people like to be entertained by people who are not, you know, the the most socially Who can be socially awkward or whatever, but that dudes a waste your time. You're not learning anything from that guy. It's like the stroke so. Literally talked about the Dead the cash Heist by the government. They don't carry cash in your in your bags when you're going on a plane not a good idea and it's just unfortunate. We live in this world where you you should be able to And there's been a few people that have lost their cash that way. So the lovely a TSA agents. Alright, so here's an interesting trolling example from a woman who likes likes to troll a lot. Her name is Angela watch vault. And this probably shows she doesn't really know too much about <mark>Bitcoin</mark> and that's not the point of me sharing this. I think it again is foreshadowing the next big social attack on <mark>bitcoin</mark> which will create a fork of Bitcoin. She said if tomorrow I submitted a technically sound pull request that would lift the 21 million cap in Bitcoin. What stops it from being included in the next release of <mark>Bitcoin</mark> core All right, so that's it's a pretty ridiculous question. And but and she's probably just trying to stir people up or she wants new followers because it generated a lot of retweets and a lot of people yelling at her. Okay great. But look what she specifically trolled with their the theme or how would you raise it by 21 million? How would you raise the 21 million cap? And it's people like her that", "Start Time (s)": 988.0, "End Time (s)": 1107.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "sound pull request that would lift the 21 million cap in Bitcoin. What stops it from being included in the next release of <mark>Bitcoin</mark> core All right, so that's it's a pretty ridiculous question. And but and she's probably just trying to stir people up or she wants new followers because it generated a lot of retweets and a lot of people yelling at her. Okay great. But look what she specifically trolled with their the theme or how would you raise it by 21 million? How would you raise the 21 million cap? And it's people like her that once that becomes. The more popular little mean among the no coiners or whoever she'll Jump Right In on it and just say yeah, why not? Let's have a big coin with 21 million. And you know what? I will say go ahead make my day create that crypto dividend go <mark>for</mark> it. It's <mark>Bitcoin</mark> is the next big coin. You guys are trying to be the next be cash and please by give up your precious <mark>Bitcoin</mark> to buy this <mark>for</mark> 82 million proposed <mark>Bitcoin</mark> whatever you want to call it's not <mark>Bitcoin</mark> but 42 million proposed altcoin and yeah by what I get <mark>for</mark> free, but she I'm just I'm just throwing this out there. She's trolling with this theme of the future. Let's say this trolling theme of the future. It's a little <mark>for</mark> Shatter there <mark>for</mark> you people. I know I've talked about it quite a bit lately, but this next having period between 2020 and 2024. That's my that's my prediction of the next. Big B cash type of fork off of <mark>Bitcoin</mark> unfriendly <mark>for</mark> one that will involve inflation. <mark>For</mark> the impatient <mark>for</mark> the people <mark>for</mark> the complainers. Okay. What do we got here? All right, so", "Start Time (s)": 1066.4, "End Time (s)": 1186.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "yeah, why not? Let's have a big coin with 21 million. And you know what? I will say go ahead make my day create that crypto dividend go <mark>for</mark> it. It's <mark>Bitcoin</mark> is the next big coin. You guys are trying to be the next be cash and please by give up your precious <mark>Bitcoin</mark> to buy this <mark>for</mark> 82 million proposed <mark>Bitcoin</mark> whatever you want to call it's not <mark>Bitcoin</mark> but 42 million proposed altcoin and yeah by what I get <mark>for</mark> free, but she I'm just I'm just throwing this out there. She's trolling with this theme of the future. Let's say this trolling theme of the future. It's a little <mark>for</mark> Shatter there <mark>for</mark> you people. I know I've talked about it quite a bit lately, but this next having period between 2020 and 2024. That's my that's my prediction of the next. Big B cash type of fork off of <mark>Bitcoin</mark> unfriendly <mark>for</mark> one that will involve inflation. <mark>For</mark> the impatient <mark>for</mark> the people <mark>for</mark> the complainers. Okay. What do we got here? All right, so I still <mark>for</mark> some reason one of my email accounts my numerous email accounts. I don't have a phone but I have numerous email accounts. I gotta get a nice shirt on today. You cannot get shirts like this link to below I still get I still get the Doug Casey. I get some free free newsletter thing from him and occasionally, he'll have someone writes. I usually just erase them because usually the titles are just like gold gold. The or Trump destroying economy or end of world about to happen. You know, it's just there's such clickbait nonsense. But I'll occasionally check the ones that I think Mike deal with <mark>Bitcoin</mark> and sure enough. He's got a he's got a guy who appeals to the 80 percenters writing <mark>for</mark> him talking about the", "Start Time (s)": 1116.7, "End Time (s)": 1236.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of the next. Big B cash type of fork off of <mark>Bitcoin</mark> unfriendly <mark>for</mark> one that will involve inflation. <mark>For</mark> the impatient <mark>for</mark> the people <mark>for</mark> the complainers. Okay. What do we got here? All right, so I still <mark>for</mark> some reason one of my email accounts my numerous email accounts. I don't have a phone but I have numerous email accounts. I gotta get a nice shirt on today. You cannot get shirts like this link to below I still get I still get the Doug Casey. I get some free free newsletter thing from him and occasionally, he'll have someone writes. I usually just erase them because usually the titles are just like gold gold. The or Trump destroying economy or end of world about to happen. You know, it's just there's such clickbait nonsense. But I'll occasionally check the ones that I think Mike deal with <mark>Bitcoin</mark> and sure enough. He's got a he's got a guy who appeals to the 80 percenters writing <mark>for</mark> him talking about the having so anyone hyping the having okay. I like having hype use the hashtag having hype. I think I forgot to in my in the tweet. I forgot to hashtag it up my bad, but here it is. I'm going to read you. Are you prepared? May 20 2011 is a message from our colleagues over at Palm Beach research group that we found particularly interesting. We urge you to continue reading Casey dispatch reader a big event is happening in the world of cryptocurrencies in May. It happens every four years. You could call it the big coil Olympics. If you like this event is called the having those first two bull runs work. Great, and I believe this will happen again with <mark>Bitcoin</mark> and", "Start Time (s)": 1167.6, "End Time (s)": 1287.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Mike deal with <mark>Bitcoin</mark> and sure enough. He's got a he's got a guy who appeals to the 80 percenters writing <mark>for</mark> him talking about the having so anyone hyping the having okay. I like having hype use the hashtag having hype. I think I forgot to in my in the tweet. I forgot to hashtag it up my bad, but here it is. I'm going to read you. Are you prepared? May 20 2011 is a message from our colleagues over at Palm Beach research group that we found particularly interesting. We urge you to continue reading Casey dispatch reader a big event is happening in the world of cryptocurrencies in May. It happens every four years. You could call it the big coil Olympics. If you like this event is called the having those first two bull runs work. Great, and I believe this will happen again with <mark>Bitcoin</mark> and other cryptocurrencies in 2020. That's from teeka tiwari sheath and Analyst at Palm Beach research Group, which of course pumps all sorts of 50 or altcoins again my point in sharing this is that if you think it's hot, if you think it's priced in when this guy is just educate educating his 80% followers about it now. Dead wrong. And yeah, so as I said I predict I predicted in 2016 I predicted in <mark>for</mark> 2020 as we get closer more and more people whether they be sketching individuals like that or the mainstream media are going to be bringing it to the attention of the 80 percenters. It will be fomo etcetera, etc. Etc. Price will go up. Then price will go down and then by the End by the start of 2021, we'll have our I real. Real movement again.", "Start Time (s)": 1226.5, "End Time (s)": 1346.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "followers about it now. Dead wrong. And yeah, so as I said I predict I predicted in 2016 I predicted in <mark>for</mark> 2020 as we get closer more and more people whether they be sketching individuals like that or the mainstream media are going to be bringing it to the attention of the 80 percenters. It will be fomo etcetera, etc. Etc. Price will go up. Then price will go down and then by the End by the start of 2021, we'll have our I real. Real movement again. Okay, but no it's not posting yet because people like that haven't heard about it yet. How many people do you think have at least one Bitcoin? There was an a story I did on this a few weeks ago Jeff. And I forgot the exact numbers the person broke it down by entities. How many entities have at least one <mark>Bitcoin</mark> and now I forgot what it was. It's not that many if you have like 10, you're in such good shape. It's unbelievable, but I don't I don't remember the number now. They have at least one <mark>Bitcoin</mark> it maybe it was like 200,000 or something like that. It's quite a small number. It's quite a small number of entities. You know, what I'll try to do Jeff is I'll link to the video after the show. I'll find the video and it'll be linked to below and we'll say how many entities have at least one <mark>Bitcoin</mark> but very good question and I'd like so I'm going with the this The testicles that I talked about in that video that I cannot remember right now that were in that article, I think that guy wrote the article did a good job of figuring out how many entities have one <mark>Bitcoin</mark> at Penn <mark>Bitcoin</mark> have a hundred", "Start Time (s)": 1311.2, "End Time (s)": 1430.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "How many entities have at least one <mark>Bitcoin</mark> and now I forgot what it was. It's not that many if you have like 10, you're in such good shape. It's unbelievable, but I don't I don't remember the number now. They have at least one <mark>Bitcoin</mark> it maybe it was like 200,000 or something like that. It's quite a small number. It's quite a small number of entities. You know, what I'll try to do Jeff is I'll link to the video after the show. I'll find the video and it'll be linked to below and we'll say how many entities have at least one <mark>Bitcoin</mark> but very good question and I'd like so I'm going with the this The testicles that I talked about in that video that I cannot remember right now that were in that article, I think that guy wrote the article did a good job of figuring out how many entities have one <mark>Bitcoin</mark> at Penn <mark>Bitcoin</mark> have a hundred <mark>Bitcoin</mark> is cetera and because it's some companies that share it there their exchanges that okay. Hello <mark>Bitcoin</mark> presentation people should understand <mark>Bitcoin</mark> if you're a <mark>Bitcoin</mark> ER with an interest in educating Aguilar people about big how <mark>Bitcoin</mark> works and why it's important. They consider giving this intro presentation in your local community and I link to the tweet that links to the presentation. I also link to hello Bitcoin. And I actually went through the entire presentation. I thought it was very good. There was a little there was a couple high level things in there that some people might not get but in terms of talking about scarcity and why it's valuable and what it is. I thought it was a good thing. It had it had fancy sets and Graphics in it. Well not too fancy. But stuff that people can can get a hold of and be happy about and", "Start Time (s)": 1368.8, "End Time (s)": 1488.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "links to the presentation. I also link to hello Bitcoin. And I actually went through the entire presentation. I thought it was very good. There was a little there was a couple high level things in there that some people might not get but in terms of talking about scarcity and why it's valuable and what it is. I thought it was a good thing. It had it had fancy sets and Graphics in it. Well not too fancy. But stuff that people can can get a hold of and be happy about and if you're a if you want to show your Club your church group or whatever. You want to give a little bit coin presentation. There it is these guys at hello bit. When it had made something that you can share with many people so check that out. I thought it was a cool little tool. So in motion that that entity is in motion pound that like fun finally it's happened to me. All right, baby named says You don't wait <mark>for</mark> insurance premiums to go down the buy life insurance. You don't wait <mark>for</mark> insurance premiums to go down the buy fire insurance and you shouldn't wait <mark>for</mark> <mark>Bitcoin</mark> prices to go down to have some insurance again. Socio economic disruptions. Well, that is a good way of looking at things. Mr. Doar David nage actually said that I hope I said they've an aide said that yes, you can consider <mark>Bitcoin</mark> insurance against really horrible situations happening in your country. And so you really shouldn't wait to have that insurance against your your country. Perhaps printing your wealth away, etc, etc. Okay, I'm Adam Meister the bitcoinmeister the disrupt Meister remember to subscribe this channel like this video share this video check out the links below. Pound it", "Start Time (s)": 1459.6, "End Time (s)": 1578.0, "Clip Length (min)": 1.97, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 5.1723456, "explanation": "{\n  \"value\": 5.1723456,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.1599092,\n      \"description\": \"weight(word_list:bitcoin in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.1599092,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.012436601,\n      \"description\": \"weight(word_list:for in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012436601,\n          \"description\": \"score(LMDirichletSimilarity, freq=30.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.0881214,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 30.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "The audible of the best in Bitcoin. This is the crypto Cana me. If you guys have not seen it yet Gigi just recently dropped an article on his medium page and it's another great one about around the concept of <mark>Bitcoin</mark> as a living organism. So let's go ahead and jump into the read and then we'll talk a little bit about it afterward. Bitcoins habitats how <mark>Bitcoin</mark> is surviving and thriving Between Worlds as I have argued previously <mark>Bitcoin</mark> is a living organism. But where does this organism live exactly as with many questions in the world of <mark>Bitcoin</mark> exact answers are hard to come by living things have fuzzy edges beginnings and endings are hard to pinpoint differentiation is more or less arbitrary and what was classified as a wolf today might evolve to be a dog tomorrow. <mark>Bitcoin</mark> has no rigid specification. No absolute finality. No fixed development team. No final security guarantees. No scheduled updates. No Central", "Start Time (s)": 0.6, "End Time (s)": 91.1, "Clip Length (min)": 1.51, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>Bitcoin</mark> is a living organism. But where does this organism live exactly as with many questions in the world of <mark>Bitcoin</mark> exact answers are hard to come by living things have fuzzy edges beginnings and endings are hard to pinpoint differentiation is more or less arbitrary and what was classified as a wolf today might evolve to be a dog tomorrow. <mark>Bitcoin</mark> has no rigid specification. No absolute finality. No fixed development team. No final security guarantees. No scheduled updates. No Central brain, no central vision. No Kings and no rulers. It is a decentralized organism organically evolving without central planners the lack of any centralization is the source of Bitcoins Beauty. Its organic Behavior. and its resilience <mark>Bitcoin</mark> is everywhere and nowhere which makes figuring out where this thing lives a daunting task. However, it turns out that there is a space it lives in multiple spaces as we shall see. the habitats of <mark>Bitcoin</mark> while classifying the habitat of a decentralized organism isn't trivial we can look at the constituents of <mark>Bitcoin</mark> to make the task a bit easier as outlined in the last article of this series The Coin lives across domains with one foot in the purely informational realm ideas and code and one foot in the Physical Realm people and nodes and awareness of Bitcoins environments might help to better understand this new form of life. No, Can be meaningfully studied in isolation and <mark>Bitcoin</mark> is no exception as Alan Watts pointed out one has to be aware of the basic unity every", "Start Time (s)": 51.3, "End Time (s)": 171.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is the source of Bitcoins Beauty. Its organic Behavior. and its resilience <mark>Bitcoin</mark> is everywhere and nowhere which makes figuring out where this thing lives a daunting task. However, it turns out that there is a space it lives in multiple spaces as we shall see. the habitats of <mark>Bitcoin</mark> while classifying the habitat of a decentralized organism isn't trivial we can look at the constituents of <mark>Bitcoin</mark> to make the task a bit easier as outlined in the last article of this series The Coin lives across domains with one foot in the purely informational realm ideas and code and one foot in the Physical Realm people and nodes and awareness of Bitcoins environments might help to better understand this new form of life. No, Can be meaningfully studied in isolation and <mark>Bitcoin</mark> is no exception as Alan Watts pointed out one has to be aware of the basic unity every organism forms with its environment quote <mark>for</mark> the ecologist the biologists and the physicists know but seldom feel that every organism constitutes a single field of behavior or process with its environment. There is no a way of separating what any given organism is doing from what its environment is doing <mark>for</mark> which reason ecologist speak not of organisms in environments, but of organism environments and quote Alan Watts. With that in mind, let's take a closer. Look at the organism environments. We are dealing with as outlined above Bitcoins ideas and code inhabit one realm and Bitcoins people and nodes inhabit another to stick with tradition. Let's", "Start Time (s)": 103.9, "End Time (s)": 223.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>for</mark> the ecologist the biologists and the physicists know but seldom feel that every organism constitutes a single field of behavior or process with its environment. There is no a way of separating what any given organism is doing from what its environment is doing <mark>for</mark> which reason ecologist speak not of organisms in environments, but of organism environments and quote Alan Watts. With that in mind, let's take a closer. Look at the organism environments. We are dealing with as outlined above Bitcoins ideas and code inhabit one realm and Bitcoins people and nodes inhabit another to stick with tradition. Let's call the Physical Realm meet space and the purely informational realm cyberspace. Even if as always the lines might be fuzzy around the edges. The soul of <mark>Bitcoin</mark> so to speak lives in cyberspace. They are <mark>Bitcoin</mark> absorbs useful ideas and incorporates them into its code as with all living things. Something is useful if it helps an organism to survive while <mark>Bitcoin</mark> has various self regulatory mechanisms to react to the environment new ideas may be necessary <mark>for</mark> survival if changes are drastic enough. The quote body of <mark>Bitcoin</mark> like all bodies is living in meatspace nodes hard drives cables and other things come together in an intricate dance pushing around electrons changing zeros to ones and vice versa making sure that Bitcoins heartbeats about a thousand times a week living things have an interest in staying alive and the <mark>Bitcoin</mark> organism is no exception <mark>Bitcoin</mark> found an ingenious way to ensure that it stays alive. If it pays people as Ralph Merkle pointed out people and increasingly", "Start Time (s)": 176.0, "End Time (s)": 294.3, "Clip Length (min)": 1.97, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "purely informational realm cyberspace. Even if as always the lines might be fuzzy around the edges. The soul of <mark>Bitcoin</mark> so to speak lives in cyberspace. They are <mark>Bitcoin</mark> absorbs useful ideas and incorporates them into its code as with all living things. Something is useful if it helps an organism to survive while <mark>Bitcoin</mark> has various self regulatory mechanisms to react to the environment new ideas may be necessary <mark>for</mark> survival if changes are drastic enough. The quote body of <mark>Bitcoin</mark> like all bodies is living in meatspace nodes hard drives cables and other things come together in an intricate dance pushing around electrons changing zeros to ones and vice versa making sure that Bitcoins heartbeats about a thousand times a week living things have an interest in staying alive and the <mark>Bitcoin</mark> organism is no exception <mark>Bitcoin</mark> found an ingenious way to ensure that it stays alive. If it pays people as Ralph Merkle pointed out people and increasingly organizations are incentivized to keep it alive. They shape the physical world to Bitcoins liking feed it energy renew its hardware and update its software to keep it alive. The fact that <mark>Bitcoin</mark> pays us to keep it alive opens up a third space a space of financial transactions value and mutual beneficial exchange. Let's call this space thin space to understand Finn space. We will have to examine the other side of this coin so far. We only examined the side with the uppercase B the <mark>Bitcoin</mark> network, but there is also <mark>Bitcoin</mark> with a lowercase b, which is the unit of value itself. elf brought into existence by every copy of The Ledger These Bitcoins while deeply", "Start Time (s)": 225.4, "End Time (s)": 345.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "are incentivized to keep it alive. They shape the physical world to Bitcoins liking feed it energy renew its hardware and update its software to keep it alive. The fact that <mark>Bitcoin</mark> pays us to keep it alive opens up a third space a space of financial transactions value and mutual beneficial exchange. Let's call this space thin space to understand Finn space. We will have to examine the other side of this coin so far. We only examined the side with the uppercase B the <mark>Bitcoin</mark> network, but there is also <mark>Bitcoin</mark> with a lowercase b, which is the unit of value itself. elf brought into existence by every copy of The Ledger These Bitcoins while deeply embedded in the Amber of The Ledger are traded worldwide on various markets and marketplaces and since these Bitcoins and their value are critical <mark>for</mark> <mark>Bitcoin</mark> survival. We will have to recognize thin space as the third space that this strange Beast lives in note that fin space. Strangely enough is solely inhabited by Bit coin with a lowercase b In total we can identify three distinct environments which the <mark>Bitcoin</mark> organism inhabits cyberspace the world of ideas and code meatspace the world of people and nodes and fin space the world of value and markets the world of dollars and SATs. Understanding these habitats becomes increasingly important especially as the climate in one or more heats up. The climate's They Are A-Changin the three spaces outlined above cyberspace meatspace and fin space have different restrictions different climates. So to speak", "Start Time (s)": 295.5, "End Time (s)": 414.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "space the world of value and markets the world of dollars and SATs. Understanding these habitats becomes increasingly important especially as the climate in one or more heats up. The climate's They Are A-Changin the three spaces outlined above cyberspace meatspace and fin space have different restrictions different climates. So to speak in short, they operate under different rules. Once these rules change drastically enough people will say that quote. The political climate is heating up and reports on the quote coming Financial climate will be written citizens will be unable to speak and act freely. If things change drastically enough people will rise up in protest or if all else fails lie. cyberspace while we don't have precise words <mark>for</mark> it. It is obvious that the climate in cyberspace has changed quite drastically in the last two decades or so, the idealistic utopian ideas, which were the foundation of most of the internet were perverted by the advertisement driven surveillance companies, which are the Giants of today. People and politicians are slowly waking up to the strange reality that we are living in the fact that Facebook can manipulate moods and sway elections is as disturbing as the fact that Google knows you better than you know yourself. Edward Snowden showed that the most paranoid netizens were right all along everyone in cyberspace is under constant surveillance without suspicion by default while the Western world does not immediately feel the repercussions that come with living in a constant state of surveillance. Chinese citizens are gathering first-hand experience with each passing day.", "Start Time (s)": 384.6, "End Time (s)": 503.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of today. People and politicians are slowly waking up to the strange reality that we are living in the fact that Facebook can manipulate moods and sway elections is as disturbing as the fact that Google knows you better than you know yourself. Edward Snowden showed that the most paranoid netizens were right all along everyone in cyberspace is under constant surveillance without suspicion by default while the Western world does not immediately feel the repercussions that come with living in a constant state of surveillance. Chinese citizens are gathering first-hand experience with each passing day. In the Western World, the consequences are advertisements which range from Annoying too spooky in China. The consequences are frozen bank accounts and inability to by train or plane tickets elimination of credit worthiness automated fines <mark>for</mark> trivial offenses and more voicing the wrong opinion quote on quote online or not can lead to restricted access to schools hotels and jobs and after ruining Life with a flip of a bit you will be publicly named as a bad Citizen and the government will even take away your dog. If that doesn't sound dystopian enough <mark>for</mark> your taste, I bet that it will be in a couple of years remind yourself that this is only the beginning. In the quote free world things are more subtle multiple efforts are underway to curb net neutrality. The very Cornerstone of the internet legislation is being passed which is inherently incompatible with the laws of cyberspace. It seems like the last battle of the crypto Wars is yet to be fault as politicians are calling <mark>for</mark> responsible encryption and the ban of certain CAD files.", "Start Time (s)": 460.9, "End Time (s)": 580.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to by train or plane tickets elimination of credit worthiness automated fines <mark>for</mark> trivial offenses and more voicing the wrong opinion quote on quote online or not can lead to restricted access to schools hotels and jobs and after ruining Life with a flip of a bit you will be publicly named as a bad Citizen and the government will even take away your dog. If that doesn't sound dystopian enough <mark>for</mark> your taste, I bet that it will be in a couple of years remind yourself that this is only the beginning. In the quote free world things are more subtle multiple efforts are underway to curb net neutrality. The very Cornerstone of the internet legislation is being passed which is inherently incompatible with the laws of cyberspace. It seems like the last battle of the crypto Wars is yet to be fault as politicians are calling <mark>for</mark> responsible encryption and the ban of certain CAD files. Companies are in charge of the speakers corners of cyberspace and are making arbitrary decisions on what can be uttered by whom and what is off-limits <mark>bitcoin</mark> knows no borders. No jurisdictions. However, it has to conform to the laws of cyberspace and if these laws change or in other words, if large parts of the world block <mark>Bitcoin</mark> traffic and or the usage of tour the <mark>Bitcoin</mark> organism will have to adapt Meatspace meatspace climate differs wildly from jurisdiction to jurisdiction some bastions of Freedom still exist. But once you try to board an international flight, it becomes obvious that you were right to privacy and your freedom to bring a bottle of water with you are null and void protests across the globe indicate that the powerless are fed up with the powerful who do everything", "Start Time (s)": 515.7, "End Time (s)": 635.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "change or in other words, if large parts of the world block <mark>Bitcoin</mark> traffic and or the usage of tour the <mark>Bitcoin</mark> organism will have to adapt Meatspace meatspace climate differs wildly from jurisdiction to jurisdiction some bastions of Freedom still exist. But once you try to board an international flight, it becomes obvious that you were right to privacy and your freedom to bring a bottle of water with you are null and void protests across the globe indicate that the powerless are fed up with the powerful who do everything they can to stay in control and solidified their positions of influence. History shows that governments do not shy away from using their power in 1933 executive order 6102 was signed effectively forcing the whole population of the United States to hand over their gold and gold certificates to the government. Yes, seizing <mark>Bitcoin</mark> is way harder than season gold in some cases even impossible but it would surprise me if those who currently control our money the governments and central banks of this world would simply roll over and let <mark>Bitcoin</mark> march on unhindered governments have a monopoly on violence and they are able and willing to abuse this violence in their own interest with Bitcoin. However, people can flee a country with their wealth intact while this is definitely not easy and not Something I would wish on anyone it is now possible. thin space Where should I even begin the current debt based Financial system has an appetite <mark>for</mark> printing money which is beyond belief quantitative easing negative interest rate policies currency Wars hyperinflations. And a looming recession are just a few of the recipes of the global instability soup, which is currently Brewing The Current financial system", "Start Time (s)": 600.2, "End Time (s)": 719.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "quantitative easing negative interest rate policies currency Wars hyperinflations. And a looming recession are just a few of the recipes of the global instability soup, which is currently Brewing The Current financial system seems so far removed from common sense and reality that all the jargon in the world won't be able Stabilize this house of cards people know that our money is broken, which is why they flee to buying real estate stocks and all kinds of complicated Financial constructs to preserve their wealth in the current system. You have to be an investment expert just to hold your value. And we haven't even talked about the looming recession and the virtual inevitability of the next financial crisis yet. Yes governments might be able to Kick the Can down the road by printing ever more money, but no road is endless and the experiment which is Fiat money will come to an end one way or another how <mark>Bitcoin</mark> will react to a catastrophe in fin space is anyone's guess some people might flee from their failing fiat currency into <mark>Bitcoin</mark> using it as a risk. Off asset others might sell <mark>Bitcoin</mark> to buy something. They consider more stable such as real estate or land a rising number of people will identify <mark>Bitcoin</mark> as the best money. We have ever had shunning other assets and other monies in the quest to stack as many SATs as they can. However, it might play out <mark>Bitcoin</mark> is the cure <mark>for</mark> many of the current systems ills it is hard money, which doesn't devalue over time. It is an Incorruptible system, which forms the basis of a new Financial reality quote. It can't be changed. It can't be argued with it can't be tampered with it can't be corrupted. It can't be stopped. It can't even be interrupted end quote. Ralph", "Start Time (s)": 704.7, "End Time (s)": 824.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "other assets and other monies in the quest to stack as many SATs as they can. However, it might play out <mark>Bitcoin</mark> is the cure <mark>for</mark> many of the current systems ills it is hard money, which doesn't devalue over time. It is an Incorruptible system, which forms the basis of a new Financial reality quote. It can't be changed. It can't be argued with it can't be tampered with it can't be corrupted. It can't be stopped. It can't even be interrupted end quote. Ralph Merkle in addition to the above. It seems to have many indirect effects. It lowers the time preference of those who use it. It incentivizes users to have better personal and operational security. It incentivizes individuals and companies to have better digital hygiene. It propels the development of Chip manufacturing and encryption technology while <mark>Bitcoin</mark> definitely influences is environments and vice versa how <mark>Bitcoin</mark> reacts to drastic changes is yet to be seen migration <mark>Bitcoin</mark> lives on the internet as Ralph Merkle points out the internet however is not a necessary requirement <mark>for</mark> <mark>Bitcoin</mark> to work. <mark>Bitcoin</mark> is text pure information in every system capable of transmitting and storing information is a potential habitat <mark>for</mark> the <mark>Bitcoin</mark> organism. The internet just happens to be the most suitable habitat, which currently exists since it is the most efficient system to transmit information we have to date. cyberspace the <mark>Bitcoin</mark> organism could migrate to other environments and multiple efforts are underway, which enable <mark>Bitcoin</mark> to spread to places where access to Internet infrastructure is limited or non-existent as of this writing <mark>Bitcoin</mark> transactions and", "Start Time (s)": 787.2, "End Time (s)": 906.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and companies to have better digital hygiene. It propels the development of Chip manufacturing and encryption technology while <mark>Bitcoin</mark> definitely influences is environments and vice versa how <mark>Bitcoin</mark> reacts to drastic changes is yet to be seen migration <mark>Bitcoin</mark> lives on the internet as Ralph Merkle points out the internet however is not a necessary requirement <mark>for</mark> <mark>Bitcoin</mark> to work. <mark>Bitcoin</mark> is text pure information in every system capable of transmitting and storing information is a potential habitat <mark>for</mark> the <mark>Bitcoin</mark> organism. The internet just happens to be the most suitable habitat, which currently exists since it is the most efficient system to transmit information we have to date. cyberspace the <mark>Bitcoin</mark> organism could migrate to other environments and multiple efforts are underway, which enable <mark>Bitcoin</mark> to spread to places where access to Internet infrastructure is limited or non-existent as of this writing <mark>Bitcoin</mark> transactions and lightning invoices have been sent via radio waves mesh and satellite networks just to name a few all of these can be seen as <mark>Bitcoin</mark> conservation efforts so to speak Whether we will see the migration of <mark>Bitcoin</mark> to another system in the decades and centuries to come depends in essence on whether the internet will remain a suitable habitat or not. If the online climate changes drastically enough we might see the migration to even more resilient less restrictive environments. Meet space we can already see that mining facilities pop up where energy is cheapest or even stranded in essence mining is done where it makes the most sense economically speaking. The same is true <mark>for</mark> running nodes if people can run nodes at low risk and near zero marginal cost. They will", "Start Time (s)": 838.8, "End Time (s)": 958.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "organism could migrate to other environments and multiple efforts are underway, which enable <mark>Bitcoin</mark> to spread to places where access to Internet infrastructure is limited or non-existent as of this writing <mark>Bitcoin</mark> transactions and lightning invoices have been sent via radio waves mesh and satellite networks just to name a few all of these can be seen as <mark>Bitcoin</mark> conservation efforts so to speak Whether we will see the migration of <mark>Bitcoin</mark> to another system in the decades and centuries to come depends in essence on whether the internet will remain a suitable habitat or not. If the online climate changes drastically enough we might see the migration to even more resilient less restrictive environments. Meet space we can already see that mining facilities pop up where energy is cheapest or even stranded in essence mining is done where it makes the most sense economically speaking. The same is true <mark>for</mark> running nodes if people can run nodes at low risk and near zero marginal cost. They will thus visualizing <mark>Bitcoin</mark> on a map nodes and Mining facilities migrate geographically from unfriendly places to friendlier places over time. Unprofitable mining facilities will shut down profitable mining facilities will go online the same again is true <mark>for</mark> nodes increasingly people will migrate to jurisdictions which are more favorable to their <mark>Bitcoin</mark> Holdings. And if you want to start a <mark>Bitcoin</mark> company, you might also move to a jurisdiction which is more favorable to you and your future business. Thin space in the last 10 years many people decided to buy <mark>Bitcoin</mark> effectively feeding the <mark>Bitcoin</mark> organism by investing in it. This Capital allocation will continue as more people understand the nature of this Beast and the ultimate goal of <mark>Bitcoin</mark> the", "Start Time (s)": 892.5, "End Time (s)": 1011.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "speaking. The same is true <mark>for</mark> running nodes if people can run nodes at low risk and near zero marginal cost. They will thus visualizing <mark>Bitcoin</mark> on a map nodes and Mining facilities migrate geographically from unfriendly places to friendlier places over time. Unprofitable mining facilities will shut down profitable mining facilities will go online the same again is true <mark>for</mark> nodes increasingly people will migrate to jurisdictions which are more favorable to their <mark>Bitcoin</mark> Holdings. And if you want to start a <mark>Bitcoin</mark> company, you might also move to a jurisdiction which is more favorable to you and your future business. Thin space in the last 10 years many people decided to buy <mark>Bitcoin</mark> effectively feeding the <mark>Bitcoin</mark> organism by investing in it. This Capital allocation will continue as more people understand the nature of this Beast and the ultimate goal of <mark>Bitcoin</mark> the separation of money and state what investors described as portfolio balancing and allocation of capital can be seen as a migration of value from worse assets to better. Sets from Bad stores of value to better stores of value <mark>Bitcoin</mark> being the ultimate asset in terms of portability verifiability divisibility scarcity and uncie's ability will continue to suck up value and grow in the process. Conclusion <mark>Bitcoin</mark> lives at the intersection of three spaces meet space cyberspace and fin space these spaces have different laws different rules and different climates to fully understand any organism. We must not only look at the organism itself, but examine the organism environment a listicle e because of its decentralized nature <mark>Bitcoin</mark> is able", "Start Time (s)": 950.5, "End Time (s)": 1070.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "goal of <mark>Bitcoin</mark> the separation of money and state what investors described as portfolio balancing and allocation of capital can be seen as a migration of value from worse assets to better. Sets from Bad stores of value to better stores of value <mark>Bitcoin</mark> being the ultimate asset in terms of portability verifiability divisibility scarcity and uncie's ability will continue to suck up value and grow in the process. Conclusion <mark>Bitcoin</mark> lives at the intersection of three spaces meet space cyberspace and fin space these spaces have different laws different rules and different climates to fully understand any organism. We must not only look at the organism itself, but examine the organism environment a listicle e because of its decentralized nature <mark>Bitcoin</mark> is able to overcome many if not all obstacles in its environment. It's it can migrate to favorable jurisdictions in meatspace use different transportation and storage media in cyberspace and feed on the instability of other asset classes in thin space. Whatever the future may bring <mark>Bitcoin</mark> is equipped to survive and thrive in the various environments it lives in it is remarkably resilient. Well adapted to survive any coming storm. However, perfect it may be and we closed a another great article by GG. Let's go ahead and hit our sponsor and then I want to talk about talk about the habitats of Bitcoin. <mark>For</mark> anyone who has a podcast anchor cannot be beaten particularly <mark>for</mark> trying to get off the ground their entire platform is free. This includes unlimited", "Start Time (s)": 1009.7, "End Time (s)": 1129.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but examine the organism environment a listicle e because of its decentralized nature <mark>Bitcoin</mark> is able to overcome many if not all obstacles in its environment. It's it can migrate to favorable jurisdictions in meatspace use different transportation and storage media in cyberspace and feed on the instability of other asset classes in thin space. Whatever the future may bring <mark>Bitcoin</mark> is equipped to survive and thrive in the various environments it lives in it is remarkably resilient. Well adapted to survive any coming storm. However, perfect it may be and we closed a another great article by GG. Let's go ahead and hit our sponsor and then I want to talk about talk about the habitats of Bitcoin. <mark>For</mark> anyone who has a podcast anchor cannot be beaten particularly <mark>for</mark> trying to get off the ground their entire platform is free. This includes unlimited hosting both in audio that you upload and how much your listeners download. I have uploaded an incredible library of audio now and I've never paid anchor a dime. In fact, they connect me with other sponsors and have run an ad consistently on my show. So they've paid <mark>For</mark> exposure to my audience that's really hard to beat even if we ignore that I can record directly in the app or my browser. I don't need any other software. If I don't want it I can edit at sound effects clips and they automatically published to all of the top podcasting platforms. I never had to do a thing. So if you were thinking of starting a show or already have a podcast, there's no better platform out there check out anchor by downloading the app or go to Anchor dot f FM today So jumping right", "Start Time (s)": 1063.6, "End Time (s)": 1182.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "more control and telling more and more people what to do to a greater and greater degree until there is essentially pushed. In the incentives of the of the nature of government that it is a monopoly on the right to enact violence against peaceful people with the justification that just because they have the Monopoly on violence. They are right by default and you have to defend your case against them. Well that leads to essentially an incredibly High a cost to exit is a great piece by Nick Szabo that we've read on this show called. old exit and freedom from his unenumerated from his blog and it's a wonderful piece just talking about how like incentives and the barrier to exit are such a critical factor in how well one can actually maintain or essentially fight back against you know, the destruction of Liberty and that's one of those things that makes <mark>Bitcoin</mark> such a potent tool on the actually brings up is that now you can actually take value With you you can exit the jurisdiction without necessarily losing your job. Maybe you work remotely maybe you have a business or a productive environment, which is totally in the digital realm which exists almost completely in cyberspace. Maybe the bulk of your savings the more that your savings are in <mark>Bitcoin</mark> the more that you can easily take with you without Without running into some huge hindrance or some fee or some restriction on being able to get back up and running in the new jurisdiction or the new location that you go. So it is <mark>Bitcoin</mark> is one of those tools that massively lowers the the ability and the cost to exit a totalitarian communist or just disliking like like a uncomfortable jurisdiction or a set of rules and you know, like the the incentives", "Start Time (s)": 1263.5, "End Time (s)": 1383.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "environment, which is totally in the digital realm which exists almost completely in cyberspace. Maybe the bulk of your savings the more that your savings are in <mark>Bitcoin</mark> the more that you can easily take with you without Without running into some huge hindrance or some fee or some restriction on being able to get back up and running in the new jurisdiction or the new location that you go. So it is <mark>Bitcoin</mark> is one of those tools that massively lowers the the ability and the cost to exit a totalitarian communist or just disliking like like a uncomfortable jurisdiction or a set of rules and you know, like the the incentives of I meant are such that I compared to the incentives of you know, like a bad DirecTV plan or like cable and internet plan. Is that the barrier there is that you know, if they if they make me wait on hold and I have to call him to customer support five times <mark>for</mark> a problem that's clearly on their side and I can't get help. Well, then my barrier is dealing with you know, having crappy internet <mark>for</mark> a couple of days or having no internet or having to work off my cellular before I get the new company, too. Come in and use a different service or if that's not even possible. Let's say there's a geographic monopoly in my area. Well, then, you know, I'd have to use a hot spot or something and I could pay <mark>for</mark> crazy huge like cellular and that's possible. You know, that's not even like if you do it by one device, I've actually done that <mark>for</mark> multiple weeks. It's a pain but that is not a that is not the barrier to exit of a government system with the Lead to enact violence against people to violently control. What they do at like is something as ridiculous as whether or not you have your dog on your leash. That's what that was alluding to in that article of how China", "Start Time (s)": 1340.4, "End Time (s)": 1459.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "be willing to risk death to risk incredible physical harm in order to even attempt to stand up against it. Well, then that's exactly why corruption totalitarianism why governments essentially all end in a gloriously brutal and violent conclusion There are very few governments that have collapsed that did not pair with genocide and unbelievable corruption and just evil in every sense of the word. So there's nothing quite so empowering to the individual as to lower their barrier to exit and both cyberspace just in general the connectivity of the internet and the ability to exchange with other countries and across jurisdictions the ability <mark>for</mark> a large portion of your livelihood to exist outside of any geographical area and the ability to actually take your wealth. Maybe you're in Your life savings with you across the border in your brain is is something to not be underestimated? And when you think about how bad the Chinese social credit system could get that quote Gigi has a really good quote in this article that says if that doesn't sound dystopian enough <mark>for</mark> your taste, I bet that it will be in a couple of years remind yourself that this is only the beginning end quote and that is so true. What they are doing is they are setting the foundation's up <mark>for</mark> the next genocide and the next quarter rific. Ends of privacy and confiscations of any sort of Liberty or individuality and", "Start Time (s)": 1537.8, "End Time (s)": 1657.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "savings with you across the border in your brain is is something to not be underestimated? And when you think about how bad the Chinese social credit system could get that quote Gigi has a really good quote in this article that says if that doesn't sound dystopian enough <mark>for</mark> your taste, I bet that it will be in a couple of years remind yourself that this is only the beginning end quote and that is so true. What they are doing is they are setting the foundation's up <mark>for</mark> the next genocide and the next quarter rific. Ends of privacy and confiscations of any sort of Liberty or individuality and the Chinese government is not really in any better financial situation. They are in a horrible spot. And obviously this Wuhan virus has not made it any the coronavirus or whatever has not made this any easier <mark>for</mark> them. But when the shit hits the fan when you got to be kidding yourself if you think they're not going to you. use this against their population when things get hairy <mark>for</mark> the political hierarchy when things start to get threatened when people start to challenge them or financial assurances get weaker when those cities and parts of the country that we did are actually the rich ones thus quote-unquote modern side of China, which is actually a small portion and a couple of specks of China really The vast majority of China is incredibly poor, but when the when the Comforts of those who are living in the little Oasis though a through Oasis Of China when that is threatened when their stability is threatened and they have", "Start Time (s)": 1609.7, "End Time (s)": 1729.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "hierarchy when things start to get threatened when people start to challenge them or financial assurances get weaker when those cities and parts of the country that we did are actually the rich ones thus quote-unquote modern side of China, which is actually a small portion and a couple of specks of China really The vast majority of China is incredibly poor, but when the when the Comforts of those who are living in the little Oasis though a through Oasis Of China when that is threatened when their stability is threatened and they have to essentially hit the poor harder when they have to add new restrictions add new taxes add additional confiscations and controls on people. There will be a Breaking Point and they will use the social credit system <mark>for</mark> every horror. They can possibly come up with before there is nothing left to take and before they've done so much damage and caused so much harm that the people are willing to die to get out of it. That is a very sad truth but it is something that history has never really contested that that's just kind of always the case. Government can get away with something and it has the power to do something. It will absolutely abuse the shit out of it and that leads to what the climate of cyberspace is. Like how well can the controls and the costs the barriers of meatspace be re-implemented in cyberspace. How well does the great firewall of China work? And there's an app that actually another interesting quote here. I think this one are you at where are you", "Start Time (s)": 1685.3, "End Time (s)": 1804.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "there is nothing left to take and before they've done so much damage and caused so much harm that the people are willing to die to get out of it. That is a very sad truth but it is something that history has never really contested that that's just kind of always the case. Government can get away with something and it has the power to do something. It will absolutely abuse the shit out of it and that leads to what the climate of cyberspace is. Like how well can the controls and the costs the barriers of meatspace be re-implemented in cyberspace. How well does the great firewall of China work? And there's an app that actually another interesting quote here. I think this one are you at where are you at? Yeah. Okay, and this is in the article obviously <mark>Bitcoin</mark> knows no borders no jurisdictions. However, it has to conform to the laws of cyberspace and if these laws change in other words, if large parts of the world block <mark>Bitcoin</mark> traffic and or the usage of tore the <mark>Bitcoin</mark> organism will have Doubt in quote. This is another crazy thing about Bitcoin. Is it like I love the way he brought up how like <mark>Bitcoin</mark> doesn't exactly live cyberspace or well not cyberspace, but the internet itself is really just the best habitat right now and it could become not the best habitat, but <mark>Bitcoin</mark> does not necessarily have Have to live on the internet. There are a lot of ways information can be transmitted and there could be many alternative networks, but it's very interesting to think about how", "Start Time (s)": 1748.8, "End Time (s)": 1868.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>Bitcoin</mark> knows no borders no jurisdictions. However, it has to conform to the laws of cyberspace and if these laws change in other words, if large parts of the world block <mark>Bitcoin</mark> traffic and or the usage of tore the <mark>Bitcoin</mark> organism will have Doubt in quote. This is another crazy thing about Bitcoin. Is it like I love the way he brought up how like <mark>Bitcoin</mark> doesn't exactly live cyberspace or well not cyberspace, but the internet itself is really just the best habitat right now and it could become not the best habitat, but <mark>Bitcoin</mark> does not necessarily have Have to live on the internet. There are a lot of ways information can be transmitted and there could be many alternative networks, but it's very interesting to think about how <mark>Bitcoin</mark> might adapt. Um how things might have to evolve in order <mark>for</mark> <mark>Bitcoin</mark> to stay alive. And that is another of the billion reasons why as much as painful as it is and as much as I wish this wasn't the case Have to keep the block size small we have to keep the bandwidth to to reach consensus to completely defend the auditability and consensus rules of the <mark>Bitcoin</mark> mechanism as tightly limited as possible. Because we do not necessarily have the internet to use to keep consensus. We do not necessarily have all of the conveniences and bandwidth and capacity that we have at this very moment. This must live in an adversarial environment. Not a welcoming comforting environment. And I think", "Start Time (s)": 1808.6, "End Time (s)": 1928.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that we're probably going to cover on the show because so many shit coins have had have seen some incredible consequences and we have we can learn a lot of lessons from some staking coins and some highly centralized coins that have seen their whole worlds and their foundations of yes, it's quote-unquote decentralized Shake underneath them. I think they are giving us exactly samples of exactly why these things are so important. We're constantly being reinforced that Yep. This is basically the only way whatever limitations and whatever hard truths we have to admit. This is it and we have to figure that out but as centralized quote on quote as block streams satellite network is it's amazing to think that we do have there is a satellite Network that can run and To propagate the information of the <mark>Bitcoin</mark> blockchain entirely external to the internet. It is not needed. The internet is not needed in order to stay in sync and consensus with the <mark>Bitcoin</mark> blockchain. Now, if all of it ended up being a necessary to do over the satellite Network, you know, then we suddenly have a problem, you know, the internet went down there Great Wall of great firewall of China went up and started blocking all <mark>Bitcoin</mark> traffic same with the US. As you know, if every country essentially tried to use every amount of influence possible to stop it. There would be luckily most of it or most of it a lot of traffic of <mark>Bitcoin</mark> goes over tour and that is another incredibly important thing and I don't think they'd be able to absolutely ban the use of tour. This is one of those things where the incentives are so strong because the reason tour exist is because governments use it. Governments want that", "Start Time (s)": 1928.8, "End Time (s)": 2048.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "order to stay in sync and consensus with the <mark>Bitcoin</mark> blockchain. Now, if all of it ended up being a necessary to do over the satellite Network, you know, then we suddenly have a problem, you know, the internet went down there Great Wall of great firewall of China went up and started blocking all <mark>Bitcoin</mark> traffic same with the US. As you know, if every country essentially tried to use every amount of influence possible to stop it. There would be luckily most of it or most of it a lot of traffic of <mark>Bitcoin</mark> goes over tour and that is another incredibly important thing and I don't think they'd be able to absolutely ban the use of tour. This is one of those things where the incentives are so strong because the reason tour exist is because governments use it. Governments want that privacy. They will they would literally need to implement an alternative in some way in order to make it make sense <mark>for</mark> them to actually ban tour. They cut themselves. They you know, they cut off their own foot by getting rid of tour in order to stop the internet. I mean, excuse me in order to stop Bitcoin. So the fact that <mark>Bitcoin</mark> is, you know, hat tip to car Camp it <mark>for</mark> <mark>Bitcoin</mark> is the blockade Honor the fact that <mark>Bitcoin</mark> is Nimble enough that it is a high-capacity enough in value and low capacity enough in bandwidth in digit is it is small it is Speedy. It is Nimble it can get through every single crack the fact that <mark>Bitcoin</mark> can do that and that it can run very well over two were in fact one of my nodes runs entirely over to her as no problem. It is caught up with Threat with my other node just the same. They are always on the same block the fact that it does that well, um is I think a potent", "Start Time (s)": 1996.4, "End Time (s)": 2116.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "by getting rid of tour in order to stop the internet. I mean, excuse me in order to stop Bitcoin. So the fact that <mark>Bitcoin</mark> is, you know, hat tip to car Camp it <mark>for</mark> <mark>Bitcoin</mark> is the blockade Honor the fact that <mark>Bitcoin</mark> is Nimble enough that it is a high-capacity enough in value and low capacity enough in bandwidth in digit is it is small it is Speedy. It is Nimble it can get through every single crack the fact that <mark>Bitcoin</mark> can do that and that it can run very well over two were in fact one of my nodes runs entirely over to her as no problem. It is caught up with Threat with my other node just the same. They are always on the same block the fact that it does that well, um is I think a potent reality to at least a potent characteristic to how we can know that <mark>Bitcoin</mark> will be resilient and I'd be very curious is a very interesting thought experiment to think how could <mark>Bitcoin</mark> run without the major Avenues of the internet? How could we Bridge every jurisdiction? How could we get across every single border? And through every crack in all of these informational networks to keep it going to live in the in the face of truly every government as an adversary. And I think that's the goal. It's not keeping it the most, you know, powerful computer network in the world. I mean, obviously all of those things would be great. But I think just keeping it alive would would push it to that next stage which would make it come back from Um the dead and even if it took one of the hardest hits it's ever taken in its life that all we have to do is keep the heartbeat running. All we have to do is keep the organism alive and", "Start Time (s)": 2062.1, "End Time (s)": 2181.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "if it does it wins? It's not a game of who can have the best features who has the most gadgets. It's a game of who can survive in the face of the greatest challenges because we will have challenges now talking about Vince space speaking of fin space. Um, that is that that was an interesting addition to this because I've always thought of it as a bridge between meet space and cyberspace and I never really thought about Finn space as its own. Part of this puzzle, but truly like if you really could make an argument that fin space really isn't cyber space cyberspace does not really have anything to do with the markets of value in and of itself. Like there is a climate of cyberspace that is totally external to the climate of fin space. But what's funny is there is no there is nothing. That has as much fuel <mark>for</mark> the fire of <mark>Bitcoin</mark> to consume as fin space. They just it is just kindling from like to the Horizon and that is that is one of the craziest the climate of thin space is is a perfect storm <mark>for</mark> <mark>Bitcoin</mark> in some it's in some context like right now, but obviously the the the meats are the fin space response as As to restrictions and Integrations and being able to move Capital back and forth and get into and out of <mark>Bitcoin</mark> could change drastically in very short order. And that is that is a climate that is entirely dependent on The Strokes of a bunch of narcissist hens. So that could easily turn against us but the the underlying climate the real nature of value and those imbalances don't go anywhere those things are still Fuel <mark>for</mark> the fire. Now. They can try to put in Fire", "Start Time (s)": 2189.4, "End Time (s)": 2309.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "That has as much fuel <mark>for</mark> the fire of <mark>Bitcoin</mark> to consume as fin space. They just it is just kindling from like to the Horizon and that is that is one of the craziest the climate of thin space is is a perfect storm <mark>for</mark> <mark>Bitcoin</mark> in some it's in some context like right now, but obviously the the the meats are the fin space response as As to restrictions and Integrations and being able to move Capital back and forth and get into and out of <mark>Bitcoin</mark> could change drastically in very short order. And that is that is a climate that is entirely dependent on The Strokes of a bunch of narcissist hens. So that could easily turn against us but the the underlying climate the real nature of value and those imbalances don't go anywhere those things are still Fuel <mark>for</mark> the fire. Now. They can try to put in Fire breaks. They can try to you know stamp it out every single place that you know, people try to start it back up essentially to fight against this thing as it spreads through the economy, but the more the worse they try to control the more Capital controls in the more restrictions on value. The the better <mark>Bitcoin</mark> looks just like we did in just like we talked about in yesterday's article with the distrust of Inez banks that they tried to resell the freedoms and privileges that they already had in the banking institution that were just stripped from them and dub it fresh money like the arrogance of that is unbelievable. But in that situation they've lost trust completely like it's gone like nobody's going to get fresh money and think. Oh thank God I got it back there. It was taken it was sold to them by the very people who took it from them and the greater those restrictions are the greater the Lee", "Start Time (s)": 2246.9, "End Time (s)": 2366.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "single place that you know, people try to start it back up essentially to fight against this thing as it spreads through the economy, but the more the worse they try to control the more Capital controls in the more restrictions on value. The the better <mark>Bitcoin</mark> looks just like we did in just like we talked about in yesterday's article with the distrust of Inez banks that they tried to resell the freedoms and privileges that they already had in the banking institution that were just stripped from them and dub it fresh money like the arrogance of that is unbelievable. But in that situation they've lost trust completely like it's gone like nobody's going to get fresh money and think. Oh thank God I got it back there. It was taken it was sold to them by the very people who took it from them and the greater those restrictions are the greater the Lee of the financial system of thin space of the fin space climate the less <mark>Bitcoin</mark> is any sort of a trade-off it's like well I got volatility just awful down just just horrific plummeting chaotic volatility on the one hand or I've got like just Bitcoins just average volatility mostly goes up. And if on the left hand, they've got you know Capital controls. They've got I can't integrate with any apps all the shit stopped working. Nothing. They get her just the whole thing is just crumbling apart. Everybody is reaching <mark>for</mark> every ounce of control every government and major player in the financial system is reaching <mark>for</mark> every ounce of control and restriction that they can put on people so that they don't save value so that they cannot escape the the to that barrier of exit all the inconveniences and costs of <mark>Bitcoin</mark> look super", "Start Time (s)": 2312.9, "End Time (s)": 2432.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of the fin space climate the less <mark>Bitcoin</mark> is any sort of a trade-off it's like well I got volatility just awful down just just horrific plummeting chaotic volatility on the one hand or I've got like just Bitcoins just average volatility mostly goes up. And if on the left hand, they've got you know Capital controls. They've got I can't integrate with any apps all the shit stopped working. Nothing. They get her just the whole thing is just crumbling apart. Everybody is reaching <mark>for</mark> every ounce of control every government and major player in the financial system is reaching <mark>for</mark> every ounce of control and restriction that they can put on people so that they don't save value so that they cannot escape the the to that barrier of exit all the inconveniences and costs of <mark>Bitcoin</mark> look super easy to deal with in comparison. And I truly I truly hope that doesn't come to this that you know, like there is some sense in these people left. But you know when it's their livelihoods versus our livelihoods, what do you think? They're going to choose? And Gigi even brings up that in 1934 They confiscated all gold all gold from the citizens of their own country during the height of a group of the Great Depression. How insane is that? And the country was a whole lot Freer and a whole lot more independent than it is now. People are way more obedient and subservient than they were then we've had another 70 years of conditioning. And if they", "Start Time (s)": 2369.6, "End Time (s)": 2488.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "easy to deal with in comparison. And I truly I truly hope that doesn't come to this that you know, like there is some sense in these people left. But you know when it's their livelihoods versus our livelihoods, what do you think? They're going to choose? And Gigi even brings up that in 1934 They confiscated all gold all gold from the citizens of their own country during the height of a group of the Great Depression. How insane is that? And the country was a whole lot Freer and a whole lot more independent than it is now. People are way more obedient and subservient than they were then we've had another 70 years of conditioning. And if they you know, they crack down the start. I'm confiscating <mark>Bitcoin</mark> and stuff. I'm put it as flat as possible. I'm already making plans to get the fuck out of Dodge. Like I'm not staying here. Then I get in my Bitcoin. If anything if I can do anything to prevent that from happening, I'm gonna do it. No way in hell. I'm letting the same corrupt arrogant machine that has absolutely destroyed the American economy that has driven the entire the entire population into impossible deaths and has destroyed an entire money rip up my life vest and the life vest of my family. The last thing that we've actually got to possibly weather the storm that is clearly on the horizon. Hell, no. I am not playing that game. So thank thy Lord Satoshi <mark>for</mark>", "Start Time (s)": 2432.5, "End Time (s)": 2551.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I'm confiscating <mark>Bitcoin</mark> and stuff. I'm put it as flat as possible. I'm already making plans to get the fuck out of Dodge. Like I'm not staying here. Then I get in my Bitcoin. If anything if I can do anything to prevent that from happening, I'm gonna do it. No way in hell. I'm letting the same corrupt arrogant machine that has absolutely destroyed the American economy that has driven the entire the entire population into impossible deaths and has destroyed an entire money rip up my life vest and the life vest of my family. The last thing that we've actually got to possibly weather the storm that is clearly on the horizon. Hell, no. I am not playing that game. So thank thy Lord Satoshi <mark>for</mark> bringing this tool onto us to lower the barrier to exit and hopefully put enough pressure. That's that's another actually thing. Oh, actually, let me let me go ahead and hit that <mark>for</mark> we close this episode out. There is recommended reading at the end of this first he's got proof of life, which is Gigi's other article and we've done it on the show. So I'll be sure to link to that then the sovereign individual by James Dale Davidson and whoa, whoa William Rees MOG. I have listened to that. I'm probably going to listen to it again, but they actually talked about in that art at that article in that very long book, which is brilliant, by the way about how just lowering. Hmm. Excuse me. Just lowering the barrier to exit. is often enough to restrict their", "Start Time (s)": 2491.6, "End Time (s)": 2610.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "out a whole lot easier than they used to be able to the the sort of the the spread the unbelievable spread of the coronavirus virus is massive evidence of this 40 50 years ago. Do not have this level of travel globally like and now in a matter of days the coronavirus is basically everywhere in the world. I mean, that's scary and it sucks, but it's also A powerful demonstration of how much we are a global economy. We are a global Community now where we were not in the past. So the faster people are able to leave to jump jurisdictions and the lower those restrictions are the the faster the power to actually enact those controls to actually create that violence the state actually holds Because all they have is mercenaries. They have paid soldiers. Those soldiers will not fight <mark>for</mark> free most of the people who go into police military and all of that stuff. They go because of a job they go because good benefits. The state's power to enact violence against its own population is dependent on its purchasing power. It's dependent on the wealth of its economy the stability and the to the trust the believability of their nonsense narratives are entirely dependent on the wealth of the economy if the wealthy and the truly productive the ones that are being bled dry right now and still propping up this Giant machine start leaving the purchasing power the control and the narrative will break apart very very quickly. And as they proposed in the sovereign individual that could actually lead to all of these what we think of these huge", "Start Time (s)": 2654.7, "End Time (s)": 2774.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to play out should happen much much. Quicker and should basically escalate to a much lesser degree in this day and age because of the movement on that is available to us. But then again, you know caveat to that. We also have one of the not not one of we have the largest financial imbalance and the largest state institutions that have ever existed so Hopefully hopefully it still good news and a Davidson and William Reese mogs thesis plays out as they explained in that book on the that is a amazing book and I highly highly recommend it. I will link to both of those further reading that Gigi gave in the article. Both of those will be available in the show notes and on the website. All right. Thank you guys so much <mark>for</mark> listening. I'll actually direct Ohio. Yeah holidays. We have <mark>Bitcoin</mark> holidays today is gold parody day. So I had a hard time trying to name these holidays because there's gold parity day and then there's gold market cap day or gold is greater than <mark>Bitcoin</mark> day. I'm not not sure exactly maybe maybe we can crowdsource the naming of this holiday, but gold parody day was March 3rd, 2017 and One <mark>Bitcoin</mark> past the price of one ounce of gold and that was the first time that happened. I think it crashed back down underneath it <mark>for</mark> a little while before on its way back up but it basically passed it and stayed past it since then I'll but in the not too distant future. I expect to see a new gold parody day where the entire market cap of the <mark>Bitcoin</mark> system matches the market cap of the entire world's gold Supply. And that is", "Start Time (s)": 2780.2, "End Time (s)": 2899.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Both of those will be available in the show notes and on the website. All right. Thank you guys so much <mark>for</mark> listening. I'll actually direct Ohio. Yeah holidays. We have <mark>Bitcoin</mark> holidays today is gold parody day. So I had a hard time trying to name these holidays because there's gold parity day and then there's gold market cap day or gold is greater than <mark>Bitcoin</mark> day. I'm not not sure exactly maybe maybe we can crowdsource the naming of this holiday, but gold parody day was March 3rd, 2017 and One <mark>Bitcoin</mark> past the price of one ounce of gold and that was the first time that happened. I think it crashed back down underneath it <mark>for</mark> a little while before on its way back up but it basically passed it and stayed past it since then I'll but in the not too distant future. I expect to see a new gold parody day where the entire market cap of the <mark>Bitcoin</mark> system matches the market cap of the entire world's gold Supply. And that is going to be a crazy and exciting time. But yeah, that's that is today March 3rd is gold parody day and I recommend celebrating with a little bit of Goldschlager and also your backup ritual whatever you do to back up your keys do it today. That is what <mark>Bitcoin</mark> holidays are <mark>for</mark> is so that we are constantly reminded to keep our <mark>Bitcoin</mark> safe to keep our <mark>Bitcoin</mark> safe from thieves. You keep them on our Hardware wallet to make sure that we are holding our keys and to make sure our keys will not be lost in the case of disaster. So take a show take a shot of Goldschlager and backup your keys. If you would like to check out the entire list of <mark>Bitcoin</mark> holidays that I have pulled together, you can find that on the crypto Kana me.com and up", "Start Time (s)": 2832.7, "End Time (s)": 2952.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I expect to see a new gold parody day where the entire market cap of the <mark>Bitcoin</mark> system matches the market cap of the entire world's gold Supply. And that is going to be a crazy and exciting time. But yeah, that's that is today March 3rd is gold parody day and I recommend celebrating with a little bit of Goldschlager and also your backup ritual whatever you do to back up your keys do it today. That is what <mark>Bitcoin</mark> holidays are <mark>for</mark> is so that we are constantly reminded to keep our <mark>Bitcoin</mark> safe to keep our <mark>Bitcoin</mark> safe from thieves. You keep them on our Hardware wallet to make sure that we are holding our keys and to make sure our keys will not be lost in the case of disaster. So take a show take a shot of Goldschlager and backup your keys. If you would like to check out the entire list of <mark>Bitcoin</mark> holidays that I have pulled together, you can find that on the crypto Kana me.com and up the top bar. It says holidays. It's hard to miss. So check that out. All right guys, thank you to my patrons. I've had a number of new people added to the crew and it is awesome to have everybody. Thank you guys <mark>for</mark> supporting the show. It makes a world of difference and I couldn't do this without you. So I You all thank you so much <mark>for</mark> listening. This is the crypto economy. I am guys swung and until next time take it easy everybody.", "Start Time (s)": 2887.2, "End Time (s)": 2981.8, "Clip Length (min)": 1.58, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.156553, "explanation": "{\n  \"value\": 5.156553,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 5.156553,\n      \"description\": \"weight(word_list:bitcoin in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 5.156553,\n          \"description\": \"score(LMDirichletSimilarity, freq=93.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.624427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 93.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=43.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3407193,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 43.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Hello and welcome to episode 12 of the how to become a personal trainer podcast with your host Michael piccante. My name is Jordan sigh it and in this episode we talk about the pyramid that you need to know <mark>for</mark> muscle gain, essentially the order of importance <mark>for</mark> you and your clients to make sure that they're building muscle as quickly and efficiently as possible. Enjoy the episode. Hello, Jordan. Hello, Michael. This is not a one-take show. This is the first-ever. We were one minute into the podcast and then I realized that we have a little bit of a new setup here and our audio engineer extraordinaire David has certain rules and regulations around the set up and I realized that I hadn't set it up properly to par. But now we are good to go. We're only 45 seconds in but you were saying Just go back to what you're talking about. I think that was a good discussion. You're saying that you actually I don't remember how you phrase it. How about you start off? Basically just that. Well, you asked me if when I'm fasted like if I haven't eaten", "Start Time (s)": 5.0, "End Time (s)": 75.7, "Clip Length (min)": 1.18, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "This is the first-ever. We were one minute into the podcast and then I realized that we have a little bit of a new setup here and our audio engineer extraordinaire David has certain rules and regulations around the set up and I realized that I hadn't set it up properly to par. But now we are good to go. We're only 45 seconds in but you were saying Just go back to what you're talking about. I think that was a good discussion. You're saying that you actually I don't remember how you phrase it. How about you start off? Basically just that. Well, you asked me if when I'm fasted like if I haven't eaten anything in the morning do I think about that do I think of it in those terms like? Oh I'm fasted right now, right you because you were saying you didn't eat this morning and I was like does that pop up in your mind is like something that even think about or do you just not even consider it? I consider it from the perspective of meal timing and if I have a specific Fitness goal usually fat loss all fast <mark>for</mark> a few hours in the morning just <mark>for</mark> that purpose. But this morning I realized that because I was able to sustain Focus <mark>for</mark> longer. I was I was less distracted. I had more concentration and after eating a meal and particularly a large meal but really most times that I eat. I'm less focused <mark>for</mark> some amount of time after the meal. And so yeah, I do notice it. Interesting and you're saying that there's a point where when you're fasted. You have better concentration usually until there's a point of diminishing returns. Like it doesn't go like all right. I'm going too fast <mark>for</mark> four days. And because by the end of day 4 I will have maximum Focus right right, hunger eventually just kicks in and outweighs whatever cognitive upside. I was deriving right which I'm going to theorize is related to something", "Start Time (s)": 38.0, "End Time (s)": 157.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "intake because with your basically zero carb experience, you know tag along Jobs here and there in some dairy product but really with your carnivore experiment you've had almost exclusively proteins and fats and your physical energy hasn't been great. But your mental energy has been that's been one of the surprising parts of it is like In weightlifting. I've been awful like strength training. Absolutely. Terrible Jiu-Jitsu. My energy has been abominable but in terms of mental focus and Clarity I think is a really good word to use like It's interesting, you know sort of how sometimes people will talk about if they go from eating relatively unhealthy junk food all the time to cleaning up their diet the be like, oh my God, I feel so much better and they're like, I didn't know how bad I felt until I started eating healthier. It's been very interesting <mark>for</mark> me to be like, oh, I didn't even realize like that. There was a certain amount of almost brain fog. Now this brings up the whole discussion of people. Are you going to keep doing carnivore because you feel so No, I'm definitely not going to keep doing carnivore because I think the mental Clarity is only one subset of many that we have to consider and number one. I think the most important part is it is completely and utterly unsustainable <mark>for</mark> me. Like that's just like that's the and like you and I have spoken about and we talk about fat loss when you talk about whatever sustainability and consistency are the kings of everything. Hmm, so it doesn't If I mental focus is great if I can't sustain a long term not to mention. I just don't like it. I just don't like it from an injury. I've had in three diarrhea's today. And I'm this is Dane Dane. Nine. Is this day nine Tuesday? Yeah,", "Start Time (s)": 158.4, "End Time (s)": 277.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of people. Are you going to keep doing carnivore because you feel so No, I'm definitely not going to keep doing carnivore because I think the mental Clarity is only one subset of many that we have to consider and number one. I think the most important part is it is completely and utterly unsustainable <mark>for</mark> me. Like that's just like that's the and like you and I have spoken about and we talk about fat loss when you talk about whatever sustainability and consistency are the kings of everything. Hmm, so it doesn't If I mental focus is great if I can't sustain a long term not to mention. I just don't like it. I just don't like it from an injury. I've had in three diarrhea's today. And I'm this is Dane Dane. Nine. Is this day nine Tuesday? Yeah, Dana. Yeah, it's day nine today. I'm still having diarrhea. There's only been two days where I haven't had it and I had three today my butthole just <mark>for</mark> just going to say it. It's here. It's burning in this moment. That's not comfortable. I'm sorry. It is. So unenjoyable. Yeah walking walking to your spot terrible. Just walking around the apartment. What are some of the other factors move away from the from the bowel movement? You just it's just so graphic. I just like really wanna I want to make it very clear but it wasn't clear enough the the physical performance which I think one of the the main critiques that will come out of it is people being like well, you know, you only did it <mark>for</mark> 14 days. Now, here's the interesting part and I was thinking about this you always have your best ideas in the shower. At least I do. Yeah I was thinking about how can I start the video? It's the best way to start the final YouTube video and I was thinking <mark>for</mark> whatever reason the idea came to me.", "Start Time (s)": 228.0, "End Time (s)": 347.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "my butthole just <mark>for</mark> just going to say it. It's here. It's burning in this moment. That's not comfortable. I'm sorry. It is. So unenjoyable. Yeah walking walking to your spot terrible. Just walking around the apartment. What are some of the other factors move away from the from the bowel movement? You just it's just so graphic. I just like really wanna I want to make it very clear but it wasn't clear enough the the physical performance which I think one of the the main critiques that will come out of it is people being like well, you know, you only did it <mark>for</mark> 14 days. Now, here's the interesting part and I was thinking about this you always have your best ideas in the shower. At least I do. Yeah I was thinking about how can I start the video? It's the best way to start the final YouTube video and I was thinking <mark>for</mark> whatever reason the idea came to me. Really coming up like right up close to the camera being like here's the deal. If you're a carnivore person and I say I don't like this diet then at the end of the video. You're going to leave a stupid comment being like yeah. Well, you only did it <mark>for</mark> 14 days and I was like, but if you're Moore, if you're not a carnivore person and that the end of the video I say, you know, I actually really like this diet. You're going to be like, oh, you know what you'll need it <mark>for</mark> 14 days. Try doing it <mark>for</mark> a long time. It's like listen. I understand. This is only a 14-day experiment relax. I'm just giving you my experience with It and that comes with its own limitations, but take it <mark>for</mark> what it is. So I understand that in order to reach the level of higher performance with this type of diet. You have to take the time to become fat adapted like that's obvious. Like we're very well aware of that that being said carbs over ketones a hundred percent carved it. We need to make that t-shirt. Absolutely and even", "Start Time (s)": 286.1, "End Time (s)": 405.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So I think that's interesting but more durable was your fearless leader. He said if you want coffee, you can have some he recommended I don't have it. But the reason I did continue to drink it is because I didn't want there to be negative side effects of not having coffee in. Her mangled what with the carnivore and I didn't wouldn't be able to tell which one was which so I solely made sure that I only switch that one variable which was my nutrition everything else to State exactly the same smart. But yeah, then the other thing and I think I'll probably talk about this in a video or something is the reduce sugar Cravings which has been actually tremendous. I will say the first thing I'm going to have when I'm done with this is a big watermelon. Like I just I just want fruit. I just really want fruit, but the Desire to just snack the desire to just pick on random things, whatever even when they're right in front of me in my apartment. It's not even there my I've been so full throughout this whole thing. It's been very difficult <mark>for</mark> me to I want there's so many possible factors that could be causing reduced craving liking reduce psychological craving as a result of knowing you knowing <mark>for</mark> 14 days. It's just completely off-limits in you you have boxed that. Else mentally physiologically, you just haven't really consumed carbohydrates or basically any sugar <mark>for</mark> days and and how quickly whatever kind of hunger cues result from that hmm ain't the massively high fat and protein intake. Oh and that's the other thing is just yeah, you're satiated from the number of calories and specifically fat and protein you're eating and I think think really the <mark>for</mark> me the point of experiments like this <mark>for</mark> like listen, what can we take from this that will then actually help people and the number one thing is <mark>for</mark> me, especially from the mitigating", "Start Time (s)": 451.3, "End Time (s)": 570.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to just pick on random things, whatever even when they're right in front of me in my apartment. It's not even there my I've been so full throughout this whole thing. It's been very difficult <mark>for</mark> me to I want there's so many possible factors that could be causing reduced craving liking reduce psychological craving as a result of knowing you knowing <mark>for</mark> 14 days. It's just completely off-limits in you you have boxed that. Else mentally physiologically, you just haven't really consumed carbohydrates or basically any sugar <mark>for</mark> days and and how quickly whatever kind of hunger cues result from that hmm ain't the massively high fat and protein intake. Oh and that's the other thing is just yeah, you're satiated from the number of calories and specifically fat and protein you're eating and I think think really the <mark>for</mark> me the point of experiments like this <mark>for</mark> like listen, what can we take from this that will then actually help people and the number one thing is <mark>for</mark> me, especially from the mitigating snacking reducing sugar Cravings is okay, make sure that you're eating a ton of protein as often as you can and <mark>for</mark> me, it's almost like if you have a grilled chicken breast, you're not going to be craving something sweet right after it and so from this has been an interesting mindset <mark>for</mark> me as Coach be like cool. So how can I improve my guideline to improve my coaching to help people who say well, how can I deal with sugar cravings and the same way? I've always been like listen if you're struggling with binge eating cool binge, but just wait 20 minutes and oftentimes that will mitigate the desire then need to binge. So if you're having a sugar craving cool in 20 minutes, if you want sugar go <mark>for</mark> it, but first have Greek yogurt first have cotton sheets. First have chicken first have what every protein shake whatever it is if you still want to have sugar after that great, but Have protein first that really I think that could help a lot. Yeah, I", "Start Time (s)": 502.0, "End Time (s)": 621.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "reducing sugar Cravings is okay, make sure that you're eating a ton of protein as often as you can and <mark>for</mark> me, it's almost like if you have a grilled chicken breast, you're not going to be craving something sweet right after it and so from this has been an interesting mindset <mark>for</mark> me as Coach be like cool. So how can I improve my guideline to improve my coaching to help people who say well, how can I deal with sugar cravings and the same way? I've always been like listen if you're struggling with binge eating cool binge, but just wait 20 minutes and oftentimes that will mitigate the desire then need to binge. So if you're having a sugar craving cool in 20 minutes, if you want sugar go <mark>for</mark> it, but first have Greek yogurt first have cotton sheets. First have chicken first have what every protein shake whatever it is if you still want to have sugar after that great, but Have protein first that really I think that could help a lot. Yeah, I mean I'm going on like 24 years of eating protein first and every single meal career not actually but it is just a good strategy <mark>for</mark> one getting enough protein in the day. We will struggle to get enough protein. If you start every meal with the protein entree, yeah that's going to help and it's going to help blend hunger. It's harder to over eat chicken breasts than it is to overeat way harder any other And it doesn't go to the extreme of saying don't have it because as soon as you tell someone not to have it, they're like screw you and it allows them to it's essentially the cotton the the concept of adding rather than subtracting read. Like we're going to remove this remove this remove. This is like no you can still have that but we're just going to add this and through that it's sort of like instead of a saying well don't need this <mark>for</mark> me this cool. I have a big salad every day. Yeah to add that. That and just through doing that you end up eating less instead of constantly focusing on losing those last 10 pounds focus on getting stronger. Exactly. Yeah, it's funny. I posted a this patch on my chin the", "Start Time (s)": 571.5, "End Time (s)": 690.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and they're like, that's why and it was so interesting to see how quickly they came up being like. That's why that's why and I have no idea. Maybe they're right. They couldn't be it'll be interesting to see what happens in the month after you come off of it that I'm there and that's I'm excited to see because I'm going to document the week after as well and if the hair goes away or whatever it is, it'll be actually very interesting to see what happens here because all the hair is white, but it's the first time there's actually a hair there and I was speaking my dermatologist. She was like The hair will come back. It might come back hairless or colorless at first, but after that old it will pigment again. It will retake its normal form interesting. Yeah, it's very interesting. We'll see the cognitive focus is still the biggest like the thing. I'm most fascinated by because anytime I you know, I haven't done full carnivore. But anytime I fasted or the couple times. I've done ketogenic experiments my Need <mark>for</mark> caffeine is down. And my ability to focus is up. Oh, I didn't know that. I didn't know that. Hmm. That's super interesting. Yeah mental Clarity is the best way to put it that has never outweighed my desire <mark>for</mark> an enjoyment of carbohydrates as well as the positive effect. They have on my training and like happiness, but I can definitely see myself adopting some kind of similar diet at some point and this is coming from someone who like yesterday I had 525 grams of carbs. Where did those come from yesterday wasn't the best? I had had a lot of Wheat Thins before bed. Those are so good because they were just in the cupboard here. I haven't had those in a years. They're so good. They're delicious oatmeal. I think I had two bananas yesterday. I don't remember exactly a long as I've been tracking recently didn't have any ice cream", "Start Time (s)": 724.0, "End Time (s)": 843.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "525 grams of carbs. Where did those come from yesterday wasn't the best? I had had a lot of Wheat Thins before bed. Those are so good because they were just in the cupboard here. I haven't had those in a years. They're so good. They're delicious oatmeal. I think I had two bananas yesterday. I don't remember exactly a long as I've been tracking recently didn't have any ice cream yesterday add some white rice. I actually got mango and blackberries from the like hot bar and fruit area. Yeah. Yeah. Stuff so it could have been better could have been worse but coming from someone who am trying to get over 500 grams of carbs per day right now, which is related to my muscle building goals, which is something we're going to talk about in this podcast. I can see myself intentionally having periods where I go, very low carb <mark>for</mark> the mental upside part of me wonders. Obviously you wouldn't be in ketosis. If you're doing this on a day-to-day basis, but part of me wonders if there would be any benefit to essentially most of your morning early afternoon being zero carb high fat high protein and then saving your carbs <mark>for</mark> night right before you go to bed if you wanted to include carbs and see if you get the cognitive benefits of that type of a diet earlier in the day. I don't know if that would work. I don't know if you have to be in ketosis in order to This happen or if it's more of like an acute, you don't have any cards in your system. You don't have any blood shirt not very little blood sugar elevations. So is that why you have the cognitive benefits? I don't know. Yeah. Tested find out we'll see should we talk and make a given to video? I only ate carbs after 6 p.m. <mark>For</mark> 30 days. Here's what happened part of I Love It I would click on it", "Start Time (s)": 813.8, "End Time (s)": 933.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I can see myself intentionally having periods where I go, very low carb <mark>for</mark> the mental upside part of me wonders. Obviously you wouldn't be in ketosis. If you're doing this on a day-to-day basis, but part of me wonders if there would be any benefit to essentially most of your morning early afternoon being zero carb high fat high protein and then saving your carbs <mark>for</mark> night right before you go to bed if you wanted to include carbs and see if you get the cognitive benefits of that type of a diet earlier in the day. I don't know if that would work. I don't know if you have to be in ketosis in order to This happen or if it's more of like an acute, you don't have any cards in your system. You don't have any blood shirt not very little blood sugar elevations. So is that why you have the cognitive benefits? I don't know. Yeah. Tested find out we'll see should we talk and make a given to video? I only ate carbs after 6 p.m. <mark>For</mark> 30 days. Here's what happened part of I Love It I would click on it part of and I think a lot of trainers will be able to relate to this part of my concern is this type of lesson is so far down on the important stuff pyramid that even I'm hesitant to even voice. My interest in going to very low to no carbs because I know that a handful of coaching clients of mine if they caught wind of that would want to go zero car and I do not want those individuals going to your old car. Yeah <mark>for</mark> psychological and physical reasons. Yeah. I think I very much understand that when I did the Big Mac challenge, I got a fair few clients being like I want to do this with you and I was like, absolutely not What is wrong? It's like no way and that's why you can see like I still have", "Start Time (s)": 869.2, "End Time (s)": 987.4, "Clip Length (min)": 1.97, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "after I started ahead to be like do not do this with me. Do not try this. This is purely made and so it's funny how people sort of tag along and want to try and do it with you, but I still think it's funny. I was actually going over my YouTube channel with Rico this morning and we're looking at what videos we want to do next and I want to I actually want to get away from doing weight loss stuff because we've done so many Weight Loss things. But the point is we've covered all of the questions that you could ask about weight loss. They're all there. Hmm. So it's like what next how do we continue to make new content that is educational and providing people with high quality information is going to help improve their their them on their journey to whatever it is. Their goals are without repeating myself over and over again and without just doing The same message over and over again. So I like these challenges from that perspective because it it adds a new component to education and to content creation that also makes it fun <mark>for</mark> me and ideally fun <mark>for</mark> them. But definitely I mean that type of thing is so low on the totem pole of like what people need to know <mark>for</mark> sure. Yeah. Sock muscle building. Let's do it. We got a whole pyramid we get the we did we got a great response to the the programming <mark>for</mark> fat loss episode. So we wanted to do a programming <mark>for</mark> muscle gain episode. So we made a whole big pyramid. This is probably going to be a longer discussion than the fat loss programming depending on depending on how long this goes. We might make it a two-parter, but we're really excited about this. And if you enjoyed the Fat Loss Program episode you think you're going to like this. If you have please leave a five star review, they've been helping a lot and seriously, we really appreciate it and all the comments you've been leaving as well have been really amazing and it makes doing this podcast so worth it. So thank you absolutely. So at the base", "Start Time (s)": 990.8, "End Time (s)": 1110.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "The vat and the base of this pyramid really outlines why so much of our content is based around getting people consistent because most people just aren't that they're not hitting the base. I'll never forget when I when I pulled my YouTube and realize that over 50% of the people watching my videos weren't working out or doing any really work out. Yeah. Wow. How did you pull them? I don't remember if I if I asked to leave. Comments and I'm on a video below or you like actual link. Yeah, I SurveyMonkey. It was at least three or four years ago. I might have done a Survey Monkey. But but I work really well I've done those. Yeah, but getting people on something that they will consistently do is it's just necessary, right? If you can have the absolute best most optimized program that the best coaches in the world agree on and do it <mark>for</mark> a month. And if you hate it take the net take months to and three off so you only worked out one out of three months compared to a mediocre even like somewhat bottom of the barrel training program that you do <mark>for</mark> three consecutive months all else equal. You're going to build more muscle on the letter and <mark>for</mark> me personally, I'll never forget this workout that I did in at Gold's Gym Venice where I should have been like, you know, like psychologically amped up to the I love training there. This is maybe five years ago with Vince Del Monte's younger brother. Mikey was a really good videographer Canadian really good dude. He was doing a program that was it had to have been 40 to 50 sets per muscle group per week. So the workout we were doing was I think it took over two hours and they were all super sets and try sets without rest.", "Start Time (s)": 1194.8, "End Time (s)": 1313.1, "Clip Length (min)": 1.97, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "group per week. So the workout we were doing was I think it took over two hours and they were all super sets and try sets without rest. It wasn't full body. Like it was a split. So I think we hit the entire upper body in this workout. I didn't even make it through the whole workout because I was so dead. I hated it so much. Like I hadn't even done half of the biceps work and I love currently like I can curl forever and and my biceps were so done upper traps were completely engaged constantly. My neck was starting to cramp up on me. I just I didn't enjoy it so that could I mean that's Too much volume, which is something that we're going to get to later in the podcast, but regardless of how perfect quote unquote that programming was I wasn't going to do a second work out of it and that just goes to show that doing something because some people love high volume and great <mark>for</mark> those people being on the higher end of the spectrum <mark>for</mark> volume is awesome. But if you're not going to do it consistently you can't build muscle. I love that. I love the the message. the takeaway from that which is What we all know in terms of you have to find something that you enjoy but I think a lot of coaches will ask their clients. Well, what do you like but a lot of times they don't know what they like they have no idea. So well, what kind of program you like? What kind of exercise do you like? Do you want higher volume low volume like what and they're like, I don't know and I think one of the best things that coach can do is give your clients different styles of programming and gauge their what they're enjoying most and also, Track their consistency. If you give them a basic strength program that is lower volume higher intensity lower frequency and heavier lifting and they all of a sudden start reducing their consistency. They're not liking it as", "Start Time (s)": 1302.7, "End Time (s)": 1422.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and you can ask your client if because oftentimes a client will say I love this phase say, that's great. I'm so happy. What do you like about him? What are a couple things you really enjoy? Make a note and put use that information in your future programming whether you're catering to their wants in every training phase or not. Knowing that will let you put something together that is going to increase your clients consistency hundred percent. What do we got next on the pyramid intensity? You want to take this one first? I'll start on this one. So what we mean by training intensity is the number the how close Individual is to failure on a given working set and this is so important and we ranked it so high partly because one of the reasons that many individuals trained consistently <mark>for</mark> long periods of time and don't see much progress, maybe maybe in their first six months or first year. They got stronger and they started to see certain muscles develop but then after maybe the one year mark, they started plateauing and they really haven't seen much difference in their body in the three or four years since despite consistently working out it's usually because that person is not trying to increase the amount of weight they are using and is Too far away from failure or another way to put that is using too low a percent of their one rep max in most exercises that they're doing. I think the part that you said that really needs to be emphasized here is this is not <mark>for</mark> people who are <mark>beginners</mark> you're talking about people who have already been Lifting <mark>for</mark> a considerable period of time", "Start Time (s)": 1457.1, "End Time (s)": 1576.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "one of the reasons that many individuals trained consistently <mark>for</mark> long periods of time and don't see much progress, maybe maybe in their first six months or first year. They got stronger and they started to see certain muscles develop but then after maybe the one year mark, they started plateauing and they really haven't seen much difference in their body in the three or four years since despite consistently working out it's usually because that person is not trying to increase the amount of weight they are using and is Too far away from failure or another way to put that is using too low a percent of their one rep max in most exercises that they're doing. I think the part that you said that really needs to be emphasized here is this is not <mark>for</mark> people who are <mark>beginners</mark> you're talking about people who have already been Lifting <mark>for</mark> a considerable period of time they've already taken advantage of the new be gained. And then they aren't seeing the results that they should that they would expect to see in. No way shape or form. Are we recommending you take someone on day one of their workout experience? Maybe they have 50 pounds to lose or whatever it is. And you're all right. We're going <mark>for</mark> a 1rm here like that stupid. That's not what we're saying <mark>beginners</mark> can get stronger with as little as 40 percent 1rm, and there's also we have to make the distinction between strength and muscle gain, which are two different things. They're intertwined, but they're different. When you're working with beginners, they'll get stronger and build muscle if they're in a calorie deficit if they're not eating enough protein as long as they're just lifting weight. It's not optimal, but they will just because they're making those adaptations as you reach a higher level trainee. Then you have to make sure your training intensity is high. Your consistency", "Start Time (s)": 1511.2, "End Time (s)": 1629.5, "Clip Length (min)": 1.97, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Your consistency is deficient. Your protein is enough you want it we'll talk about nutrition in this as well. But as you get to be more advanced if you're not LIF your Not consistently getting to a point where your muscles are Contracting at the highest possible intensity your leave. You're not going to get the best results and that doesn't mean Contracting at the expense of technique and we'll discuss that later. That's further up the of the pyramid but one of the reasons that we put intensity here is because you could have you could have really high intensity but if your Technique Is off then it's not going to get the best results. You could have very you can have perfect technique. But if your intensity is too low, you're not going to get the best results intensity is the constant here where if you're not hitting a high enough intensity, then you're going to be not getting the best results that you could be getting <mark>for</mark> yourself or <mark>for</mark> your clients. Yep. That's exactly right. I don't even know how much more necessarily we need to say here obviously varying. Overtime is important and the the point you drove home, which is <mark>beginners</mark> will build muscle on Lower intensity. So we're not suggesting that every set needs to be one rep shy of complete and total total failure <mark>for</mark> beginner. But once you're beyond that point, you need to be within five reps and and I say 1 to 4 on working sets to build muscle hard. It sets quote-unquote. So I worked with Paul Carter <mark>for</mark> the better part of the last year and I look at him as a very as basically one of the leading experts in muscle growth and I hired him because I wanted to learn a lot from him and he's spoken and taught me a lot about why you'd want to go", "Start Time (s)": 1628.7, "End Time (s)": 1748.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to do four five six sets of something you can do 2 to 3 sets and be done sometimes Paul has been doing this one set. Like I'll work up to one top set of as high intensity as I can and done. Psychologically, this is super helpful from the perspective of if you have if you see six sets of squats in front of you if you see five sets of rows, whatever it is, you just get drained immediately and immediately you'll start to conserve your energy to not go all out knowing you have so much and when you do that you immediately drop the level of intensity that you bring to each set. So oftentimes you're never reaching your maximum level of intensity then when you look at how Total reps you are at your maximum level intensity over the course of the five six sense. It actually might be less than the total number of reps. You're at your maximum intensity. If you just did one or two sets, which is a super important point that I hadn't considered until Paul spoke to me about it was like if you do two sets at your maximum intensity <mark>for</mark> 12 reps oftentimes those like last four five six reps. That's where you're really hitting your maximum intensity. That's where it's like the most important. But if you're doing five sets of 10 or whatever it is, you might get so fatigued and you might just be trying to conserve so much energy that you the total might be four or five reps at that. Whereas if you did two sets you'd have about 10 to 12 reps at that high intensity. And so that's where you really don't need to start looking at the global picture of your programming and thinking like what's the point of programming five sets? If they're never going to reach a point in those five sets of where they're really giving it their all yeah and that plays into consistency. Hmm because if I see the five by five or six by six To start the workout. I am so much less. I mean unless I'm in a certain mood or certain that period of my life where I'm really amped up <mark>for</mark> that. But normally I'm just much less excited about that. And so Tapering", "Start Time (s)": 1773.0, "End Time (s)": 1892.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "which is a super important point that I hadn't considered until Paul spoke to me about it was like if you do two sets at your maximum intensity <mark>for</mark> 12 reps oftentimes those like last four five six reps. That's where you're really hitting your maximum intensity. That's where it's like the most important. But if you're doing five sets of 10 or whatever it is, you might get so fatigued and you might just be trying to conserve so much energy that you the total might be four or five reps at that. Whereas if you did two sets you'd have about 10 to 12 reps at that high intensity. And so that's where you really don't need to start looking at the global picture of your programming and thinking like what's the point of programming five sets? If they're never going to reach a point in those five sets of where they're really giving it their all yeah and that plays into consistency. Hmm because if I see the five by five or six by six To start the workout. I am so much less. I mean unless I'm in a certain mood or certain that period of my life where I'm really amped up <mark>for</mark> that. But normally I'm just much less excited about that. And so Tapering volume down a bit so that you can have maximum intensity in that workout is going to help with adherence and then obviously even at a high level of intensity. There's going to be a certain amount of muscle that you can build on X volume and over time that volume is going to have to increase to continue to make more muscle gain <mark>for</mark> an individual. Mmm, I think One of the aspects of of why intensity is so important in terms of how much weight you're lifting. How have your living we spoke about this yesterday is that If you're looking from a progressive overload perspective getting stronger adding more weight over time your volume will increase simply by lifting more weight. Mmm your", "Start Time (s)": 1825.6, "End Time (s)": 1945.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "example of how volume can sort of be misleading and I feel like we all know that someone's if you just look at someone's body weight. You don't know much about them. But if you look at their body fat percentage, you will get a much better picture of that individual volume. Just total volume doesn't tell you very much. But when you look at volume from the perspective of high-quality volume of volume where you actually were working your muscles at the higher the highest level of intensity. Now, you're starting to get a better picture of that work out how effective that workout might have been and how effective it will be over the long term. That's exactly right. Anything else on intensity do we want to have any guidelines? Are we going to talk about sets and Reps in this one? I feel we're going to have to make this a two-parter. I think we are too. I think that will probably go in the next session rep recommendations got it. So and those will tie into intensity and volume and how you should structure sets and Reps <mark>for</mark> muscle gain. We're going to go more in detail on that. It's already over 30 minutes and we know this is going to be we want it. We don't want to skimp on anything. So we're Make this a two-part episode. So <mark>for</mark> now <mark>for</mark> intensity, I think we're good. Is there anything you want to add to that important clarifications? Because I guess we'll clarify as we go up the pyramid right because next one is technique right? Correct? Yeah, and I actually <mark>for</mark> a second made half an argument that technique should have been at the bottom of the pyramid below consistency. And then I was until Jordan pointed out that he's seen many. Big dudes bad technique in which I had to concede my my hopeful aspirational argument. It was it was a good argument we could talk about why right like why might we have because I was on board <mark>for</mark> a second before I thought about all the massive dudes. I've seen a terrible technique. So why might", "Start Time (s)": 2070.2, "End Time (s)": 2189.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and those will tie into intensity and volume and how you should structure sets and Reps <mark>for</mark> muscle gain. We're going to go more in detail on that. It's already over 30 minutes and we know this is going to be we want it. We don't want to skimp on anything. So we're Make this a two-part episode. So <mark>for</mark> now <mark>for</mark> intensity, I think we're good. Is there anything you want to add to that important clarifications? Because I guess we'll clarify as we go up the pyramid right because next one is technique right? Correct? Yeah, and I actually <mark>for</mark> a second made half an argument that technique should have been at the bottom of the pyramid below consistency. And then I was until Jordan pointed out that he's seen many. Big dudes bad technique in which I had to concede my my hopeful aspirational argument. It was it was a good argument we could talk about why right like why might we have because I was on board <mark>for</mark> a second before I thought about all the massive dudes. I've seen a terrible technique. So why might technique why is technique so important aside from the blowing your back at it blowing your spine ideas? That's my that's my number one reason by far there are Reasons that one is is by far the first because good technique is the best thing you can do to prevent injury. Mmm. And if you are injured you can't consistently train was was my thought process. Yep. The other benefit of technique is proper technique with a full range of motion. Yes going to increase muscle fiber recruitment. Yes, which is going to lead to not just a little bit more muscle gain, but if two individuals completed the exact same program in one literally completed the top half of the range of motion every single move they did. Yeah, and the other person did a full repetition on every single move <mark>for</mark> 12 phases <mark>for</mark> an entire year.", "Start Time (s)": 2124.2, "End Time (s)": 2243.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "right like why might we have because I was on board <mark>for</mark> a second before I thought about all the massive dudes. I've seen a terrible technique. So why might technique why is technique so important aside from the blowing your back at it blowing your spine ideas? That's my that's my number one reason by far there are Reasons that one is is by far the first because good technique is the best thing you can do to prevent injury. Mmm. And if you are injured you can't consistently train was was my thought process. Yep. The other benefit of technique is proper technique with a full range of motion. Yes going to increase muscle fiber recruitment. Yes, which is going to lead to not just a little bit more muscle gain, but if two individuals completed the exact same program in one literally completed the top half of the range of motion every single move they did. Yeah, and the other person did a full repetition on every single move <mark>for</mark> 12 phases <mark>for</mark> an entire year. I'm just pulling a number out here. But I would say the person who completes full reps will gain three to four times as much muscle. I have zero basis to corroborate that but I would agree that definitively they'll get better results and they'll get injured less. It'll be more a more consistent. They'll have better in assuming neither of them get injured but they consistently trained guarantee to get better results and that the research showing that is obvious the total much the muscle fiber recruitment. Much actual muscle they're actually using it's going to be way more beneficial over the long term interestingly though. And here's why I was so intent on talking about muscle fiber recruitment. Is it because if you tell a client hey, I want you to really lower the weight and use better technique because you could hurt yourself. I found they're far less likely to do it. Whereas if you say hey if you lower the weight and use better technique, you're", "Start Time (s)": 2181.2, "End Time (s)": 2300.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "they'll get better results and they'll get injured less. It'll be more a more consistent. They'll have better in assuming neither of them get injured but they consistently trained guarantee to get better results and that the research showing that is obvious the total much the muscle fiber recruitment. Much actual muscle they're actually using it's going to be way more beneficial over the long term interestingly though. And here's why I was so intent on talking about muscle fiber recruitment. Is it because if you tell a client hey, I want you to really lower the weight and use better technique because you could hurt yourself. I found they're far less likely to do it. Whereas if you say hey if you lower the weight and use better technique, you're actually going to get better results because you're using more muscle. The fibers you're going to get more muscle involvement and that will lead to bigger stronger muscles. That's when they'll actually do it not because they're afraid of getting injured but because oh I'll get better results. If I do this which to me is funny. It is has it's good to know to <mark>for</mark> coaches to frame it <mark>for</mark> the exact see better adherence to it. It's so interesting to me people generally speaking tend to not be as worried about getting injured as they are about not getting ideal results where and but The unfortunate part is most people will end up getting injured because they're not using good technique and that will end up being the reason why they're not getting good results and they think that there's wolves programming thing or it's an exercise selection thing. It's like no. No, it's like you're training like an idiot and you're using too much weight. Your Technique is off. What are your training too? Much frequency is too high. Your duration is too high your volume is too high because they're doing stupid stuff rather than toning it down a little bit so they can be more consistent and us bringing. In this back to consistency over and over and over again is very deliberate and on purpose because again, you can have the perfect program the perfect volume that perfect intensity perfect exercise selection perfect technique, but if you're not consistent <mark>for</mark> whatever reason whether it's", "Start Time (s)": 2258.1, "End Time (s)": 2377.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to know to <mark>for</mark> coaches to frame it <mark>for</mark> the exact see better adherence to it. It's so interesting to me people generally speaking tend to not be as worried about getting injured as they are about not getting ideal results where and but The unfortunate part is most people will end up getting injured because they're not using good technique and that will end up being the reason why they're not getting good results and they think that there's wolves programming thing or it's an exercise selection thing. It's like no. No, it's like you're training like an idiot and you're using too much weight. Your Technique is off. What are your training too? Much frequency is too high. Your duration is too high your volume is too high because they're doing stupid stuff rather than toning it down a little bit so they can be more consistent and us bringing. In this back to consistency over and over and over again is very deliberate and on purpose because again, you can have the perfect program the perfect volume that perfect intensity perfect exercise selection perfect technique, but if you're not consistent <mark>for</mark> whatever reason whether it's injury whether it's you're just not doing it <mark>for</mark> whatever reason if you're not consistent, it's not going to work. So always finding a way to help your clients be more consistent will be the number one factor in getting them success. So by all means let them know they're more likely to injure themselves, but even From more importantly in my experience tell them they'll get better results because of more muscle muscle recruitment by getting a full technique in with lighter weight. That's smart. Yeah. Gary responded well to that. Yeah, Gary always respond well to that type of so it's interesting how like things that he responds well to in terms of like even something as simple as getting more protein in like he responded very well to the this is going to help you build more muscle rather than like this. This is going to keep you more full type of yeah, this is going to keep you more full. I'll be fine because in his mind, it's the same as not getting hurt. Right? No. No, I'll be fine. Yep, but if you put it in the", "Start Time (s)": 2316.4, "End Time (s)": 2435.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "results because of more muscle muscle recruitment by getting a full technique in with lighter weight. That's smart. Yeah. Gary responded well to that. Yeah, Gary always respond well to that type of so it's interesting how like things that he responds well to in terms of like even something as simple as getting more protein in like he responded very well to the this is going to help you build more muscle rather than like this. This is going to keep you more full type of yeah, this is going to keep you more full. I'll be fine because in his mind, it's the same as not getting hurt. Right? No. No, I'll be fine. Yep, but if you put it in the context of you're going to see greater progress as a result of this. Yes, he'll do it. Absolutely. Yeah, that's really funny anything else on technique. I mean, I know it sounds self-explanatory. I'm wondering if there's maybe just there are other this is obvious <mark>for</mark> most of us, but there are other aspects of technique. I know I touched on range of motion but proper time under tension right controlling The Eccentric and not bouncing the bar off of your chest technique specific queuing is going to be different <mark>for</mark> every single exercise. So that's obviously Ali something that we will cover over the duration of the podcast if you're interested in hearing about that and definitely let us know but it's not something will drill down on today, you know, it might be worth talking about is how to correct your clients technique properly in a in a good way so they don't get upset. Mmm. And the reason I say this I don't think I've told the story on this podcast I might and tell me if I have I had a client. His coaching client years ago years and years and years ago before I even really started charging <mark>for</mark> doing that stuff and he had just started doing online", "Start Time (s)": 2396.6, "End Time (s)": 2516.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I'm wondering if there's maybe just there are other this is obvious <mark>for</mark> most of us, but there are other aspects of technique. I know I touched on range of motion but proper time under tension right controlling The Eccentric and not bouncing the bar off of your chest technique specific queuing is going to be different <mark>for</mark> every single exercise. So that's obviously Ali something that we will cover over the duration of the podcast if you're interested in hearing about that and definitely let us know but it's not something will drill down on today, you know, it might be worth talking about is how to correct your clients technique properly in a in a good way so they don't get upset. Mmm. And the reason I say this I don't think I've told the story on this podcast I might and tell me if I have I had a client. His coaching client years ago years and years and years ago before I even really started charging <mark>for</mark> doing that stuff and he had just started doing online coaching and I'll never forget you told me I'm super excited. I got a new one like coaching client amazing all the stuff. I was like, oh dude, that's awesome and within a couple days, he was like dude you just canceled on me. I don't know where I don't know what happened and I was like well walk me through the interactions in the process of what happened and we'll figure out where he might have gone wrong. And he's like, all right. Well, so we gave him the whole program you super excited about it and I told him to send me videos. He was like, okay cool. This is great. He sent me videos and this guy sent sent him videos him bench pressing and I've never heard the start. I've never told you this story. Oh man. He sent he sent this his coach my client videos of him bench pressing and and he's like I corrected his technique and then you cancel. And I was like send me the emails that you sent me and I look", "Start Time (s)": 2450.9, "End Time (s)": 2570.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "coaching and I'll never forget you told me I'm super excited. I got a new one like coaching client amazing all the stuff. I was like, oh dude, that's awesome and within a couple days, he was like dude you just canceled on me. I don't know where I don't know what happened and I was like well walk me through the interactions in the process of what happened and we'll figure out where he might have gone wrong. And he's like, all right. Well, so we gave him the whole program you super excited about it and I told him to send me videos. He was like, okay cool. This is great. He sent me videos and this guy sent sent him videos him bench pressing and I've never heard the start. I've never told you this story. Oh man. He sent he sent this his coach my client videos of him bench pressing and and he's like I corrected his technique and then you cancel. And I was like send me the emails that you sent me and I look at the emails and it was so funny because it was so <mark>for</mark> me. It was just common sense the way to approach this but I think some people they just don't even think about it. When I read the emails that he wrote to his client about his technique he sent the videos and he just goes right into me and I say all right, we got a lot of work to do and so he started it out. He was like your range of motion is way too short. He's like and he's going on a list of all of the things that this guy is doing wrong and he says send me another video and that was it. He didn't say anything positive about it. He didn't say anything like this is normal. There was no there was no Any type of comforting at all? Mmm and this obviously differs on your clients and who you're working with and your personality is a coach but that being said <mark>for</mark> the vast majority of people especially with a brand new client, especially with someone who doesn't know you especially with someone who this is a new experience <mark>for</mark> them. I like to number one. You should always try and find your find a", "Start Time (s)": 2516.0, "End Time (s)": 2635.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "look at the emails and it was so funny because it was so <mark>for</mark> me. It was just common sense the way to approach this but I think some people they just don't even think about it. When I read the emails that he wrote to his client about his technique he sent the videos and he just goes right into me and I say all right, we got a lot of work to do and so he started it out. He was like your range of motion is way too short. He's like and he's going on a list of all of the things that this guy is doing wrong and he says send me another video and that was it. He didn't say anything positive about it. He didn't say anything like this is normal. There was no there was no Any type of comforting at all? Mmm and this obviously differs on your clients and who you're working with and your personality is a coach but that being said <mark>for</mark> the vast majority of people especially with a brand new client, especially with someone who doesn't know you especially with someone who this is a new experience <mark>for</mark> them. I like to number one. You should always try and find your find a way to compliment someone genuinely and before you say this because I know what you're going to say and I Of it one helpful thing to think about when writing this email is pretend you're telling this person this what you're saying to their face. Yes pretend it's in an actual conversation. The reason I love that you said that is because it goes back to what we said in the episode where we spoke about what what certifications to get as a personal trainer which by the way if you haven't listened to that, I think it's the first or second one or stuff is definitely go listen to that. It was one of the most well-received ones so far one of the things we spoke. About is the importance of coaching in person. And if you just go from coaching nobody in person to coaching online, you are at a serious disadvantage coaching people in person will teach you how to be a better Coach online. It does not work the other way around so like you're saying think about being in person with them what you would say to their face what you'd say to an in-person client", "Start Time (s)": 2570.2, "End Time (s)": 2690.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I think a lot of coaches will might just compliment sandwich may feel that was a great point, but you're going over look he didn't say but there's just good. I think I think I truly think a lot of coaches will feel like they are doing their client a disgruntled. This service and Jordan and I are on the same page with this but say someone is dead lifting back is just rounded like I've everything wrong with it that could be wrong with it. Like if someone walked into the gym you'd be like, I hope they're not looking at this right now. I think a lot of coaches would feel like by leaving certain parts of the exercise uncorrected. They might not be doing their job as a coach, but that's incorrect. Because you can finish it. I'm sorry point. I'm not I don't want to steal it. I just wanted to drive home like this is important. I think you should I agree with you. It's going well first. It's going to be very discouraging <mark>for</mark> someone even if you compliment sandwich them you find one thing that you genuinely believe is good about it and compliment and then you list nine things that need to be changed and then throw and you know pretty good control decentralized. come most of the Reps, but you're overwhelming the person you're it's too much to change too much in a single interaction. Like they can't go back and apply all that. So instead of taking one or two things that they can actually take that Q take that piece of advice and make the change and send you a video back. It's zero because putting all nine into play isn't going to happen. I mean the way that I would explain it is imagine if you're listening to this podcast and you want to build your Fitness business. And maybe you're just starting out or you're at the beginning. You don't really know where to go and and Mike and I were just like art listen to here's what you need to do. First. You get an email list. You need to email that list four times a week. At least you need to", "Start Time (s)": 2775.5, "End Time (s)": 2895.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "at a time like learn over the Over the process of time you'll learn you'll figure it out. Is it optimal to only post on one platform at a time and only like one time a day? No, I'm probably not probably not optimal. But we also know you have a lot of other stuff going on your coaching other people you're trying to build your business. You have a family you have other things going on. So if we overloaded you with unrealistic expectations, you'd be able screw this I'm just not going to do it same thing with your clients when they're doing technique, especially in a gym with people that they don't know. They don't feel comfortable around they're already self-conscious. They don't feel like they should be there. They're nervous about getting Injured if you're if you're correcting them and you're giving them 27 different things. All right, so you want to bring your feet a little bit closer together. You want to get your hands a little wider apart. You want to make sure your chest is up back is flat hips up a little bit higher Squeeze In Breathe base your belly good aren't perfect. And then you do it again. They're like, alright, that was awful and you try it again. Like oh my god what the hell just happened. So if you list all the things and you need to do in one to fix all their technique, you're screwing them over you're actually going to make it not only longer <mark>for</mark> them to fix their technique, but likely they'll quit So going to the compliment sandwich actually in before we even discussed that I said earlier might compliment sandwich me what she did half the sandwich. He complimented me then said what I had to fix then there was no further comment at the end. But one thing that is open-faced below. It was a carnival. Let us wrap on top. I said something I just soon as I said, I was like, oh we need to talk about that. Mike did not say the word but I said the word but I was like, Mike said, oh, that was great. But that's he or she didn't say but which was good if you say but and keep in mind this goes <mark>for</mark> every conversation you have in your life. Not just <mark>for</mark> clients when you give someone a compliment and then you say but afterwards doesn't everything was just erased everything there. If you're going to give someone a compliment followed up with and or just followed up with whatever you have to say without saying the word but or although are on the other hand because any", "Start Time (s)": 2912.6, "End Time (s)": 3032.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that I said earlier might compliment sandwich me what she did half the sandwich. He complimented me then said what I had to fix then there was no further comment at the end. But one thing that is open-faced below. It was a carnival. Let us wrap on top. I said something I just soon as I said, I was like, oh we need to talk about that. Mike did not say the word but I said the word but I was like, Mike said, oh, that was great. But that's he or she didn't say but which was good if you say but and keep in mind this goes <mark>for</mark> every conversation you have in your life. Not just <mark>for</mark> clients when you give someone a compliment and then you say but afterwards doesn't everything was just erased everything there. If you're going to give someone a compliment followed up with and or just followed up with whatever you have to say without saying the word but or although are on the other hand because any time you have one of these words, whatever. Came before it doesn't count. Yep. It is. It's kind of like small talk before asking <mark>for</mark> a favor. Why did you just waste my time <mark>for</mark> two and a half minutes? Hey, how are you doing? Yeah. Yeah, how's it work? Good good. Yeah, and you think you could share my article on your page? It's it's obnoxious. So so <mark>for</mark> the compliment sandwich number one in terms of giving a good compliment sandwich and a good compliment sandwich is one. That's actually Even this is an and a lot of people I will what if their technique just sucked. What if their technique was awful you can find something good about it. You can either find something good about the technique or just say start off by saying awesome. Thank you so much <mark>for</mark> sending me these technique videos a lot of clients and maybe even most don't even do that. So I really appreciate you sending me these I can already tell we're off to a good start. Boom. Yeah complement and that's a genuine one because most clients don't do that. So cool. Then you go through or if something is going to the technique. It's like awesome. I love how you got up to the bar your setup was perfect. Now what I want you to pay attention to and", "Start Time (s)": 2979.4, "End Time (s)": 3099.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "two things. I'm doing really well. I'm doing I'm feeling pretty Any good about myself so really really focus on that and again, this isn't really if we think about it going all back to consistency because if you send an email or you tell a client that like all the things they suck at they're not going to be consistent. They're gonna literally the guy canceled his payment and didn't coach him with him anymore. That was that's a great story quintessence of he's not gonna be consistent. He's gonna stop going to the gym or and definitely not work with you anymore and this happens. So when you're working on technique, yes, tell them it's going to be better. So they don't injure themselves. Tell them it's going to be It gets more better muscle fiber recruitment. So better results over the long term, but very very very very much focused on how you communicate as a coach and make sure that when you're done correcting them they feel more confident in themselves not less confident. That's exactly right. The last point that I think when there's almost nothing good technically about a form video the example Jordan gave <mark>for</mark> the compliments are good go Go to like when you feel like there really isn't a lot. You can say positively about it. Those are good examples when there is something good about their form that you want to reinforce so that they continue to do that. Those are good compliments to give those are good types of compliments to give intensity funny enough something we spoke about is one that often use meaning if someone's form breaks down because they were s of in the weight they selected and they were really trying hard they're bringing a lot of intensity to the set I'll compliment that because I don't want my form correction to lead to them swinging too far in the other direction so this is amazing you're really working hard I love that that is what it's going to lead to amazing progress over time keep it up one thing to pay attention to though that one thing that I was literally in my head just thinking like the", "Start Time (s)": 3152.1, "End Time (s)": 3272.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "intensity funny enough something we spoke about is one that often use meaning if someone's form breaks down because they were s of in the weight they selected and they were really trying hard they're bringing a lot of intensity to the set I'll compliment that because I don't want my form correction to lead to them swinging too far in the other direction so this is amazing you're really working hard I love that that is what it's going to lead to amazing progress over time keep it up one thing to pay attention to though that one thing that I was literally in my head just thinking like the one thing it makes it so much more more easy to overcome yeah the one thing that I want you to work on is this rather make our we got four things to work on the one thing it's sort of like when you want your client to you just want someone to do more walking you say all right so I want you to do an extra like 20 minutes of walking versus I just want you to walk around your local high school perimeter one time it's a very different thing <mark>for</mark> them to overcome one time a walk around High School versus 20 minutes it might actually take them longer to walk around the high school perimeter but because it's only one time it seems easier to overcome Something else to consider and and this just sort of popped into my mind when I've been working with clients who are somewhat more dance. They don't have to be very Advanced to intermediate or there are super passionate about this out. They love it. They love learning about it. One of the things I've done that has both made my job easier and also increased their increased the in their enjoyment of the program, but also made my job. Easier from the perspective of I didn't have to tell them they're doing something wrong is I would ask them when they sent me a video I'd say do me a favor. Tell me one thing. You think you can improve from your Technique then I'll tell you what, I think the reason I like that and I wouldn't do this with a complete beginner who's nervous because they don't know I'm there to tell them and give them support and be the stability <mark>for</mark>", "Start Time (s)": 3236.0, "End Time (s)": 3356.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>for</mark> them to overcome one time a walk around High School versus 20 minutes it might actually take them longer to walk around the high school perimeter but because it's only one time it seems easier to overcome Something else to consider and and this just sort of popped into my mind when I've been working with clients who are somewhat more dance. They don't have to be very Advanced to intermediate or there are super passionate about this out. They love it. They love learning about it. One of the things I've done that has both made my job easier and also increased their increased the in their enjoyment of the program, but also made my job. Easier from the perspective of I didn't have to tell them they're doing something wrong is I would ask them when they sent me a video I'd say do me a favor. Tell me one thing. You think you can improve from your Technique then I'll tell you what, I think the reason I like that and I wouldn't do this with a complete beginner who's nervous because they don't know I'm there to tell them and give them support and be the stability <mark>for</mark> them so they don't have to think about it, but <mark>for</mark> someone who maybe is a little bit intermediate to Advanced they might have a little bit of an ego surrounding their technique, especially if they're new the what I'm thinking about in my mind a squat technique I see this all the time and it's super important you get side view of squat technique so you can really see their depth if I have a relatively intermediate to Advanced lifter who comes in they're relatively strong and they love this stuff they might have a little bit of an ego around what they're doing I don't want to be like Hey listen this is great your Technique is awesome your squat depth is a little bit short so I'd like you to go deeper let's remove some weight and go deeper a lot of times we don't really give me defense any labor really because I've had coaches before and they said it was great and like my immediate response would be like are so go work with those coaches so I have to remove that from the from the possibility of discussion so I say hey looking at the side view specifically what do you think one thing might be to improve and then nine times out of ten eight and a half nine times out of ten that person will", "Start Time (s)": 3296.0, "End Time (s)": 3415.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that they continue to put that practice into play in the future is that it feels like the idea Came From Within yeah I got to be honest man like one of my favorite Parts about doing this podcast has been these coaching tactics like that you know we see all these other people with coaching programs to build your Fitness business but they've never actually coached anybody online I don't I mean let's be honest anyone make this pyramid of building muscle and we're super excited about it but just because you know the pyramid building muscle doesn't mean know how to get someone actually be consistent with it and develop a good relationship with the client I love these conversations of client communication because I would be shocked if anybody in the world has had as much client communication as you and I you just can't fake this conversation because it comes as a result of hundreds /hello thousands of interactions with clients online a hundred and online fitness coaching has only been around so long and we both did it consistently <mark>for</mark> most of that time period yeah yeah I agree I'm having fun too I like it's great to talk about what intensity means and why consistency is important but having these as these discussions around client communication specifically and how to structure client communication to increase consistency to improve their intensity to decrease the risk of getting injured that's I'm really loving like that's probably the least expected Part of this that I'm enjoying the most good. I'm glad yeah, man. Do we want to make a part two to want to stop here? Keep going I think so. We are almost an hour in and we have 1 2 3 4 like six to seven more things to cover and some of them will be shorter and kind of group together, but I think that will make <mark>for</mark> a really good part 2 of this podcast perfect. So in this podcast you covered the base, which Was consistency followed going up to intensity", "Start Time (s)": 3459.2, "End Time (s)": 3578.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of interactions with clients online a hundred and online fitness coaching has only been around so long and we both did it consistently <mark>for</mark> most of that time period yeah yeah I agree I'm having fun too I like it's great to talk about what intensity means and why consistency is important but having these as these discussions around client communication specifically and how to structure client communication to increase consistency to improve their intensity to decrease the risk of getting injured that's I'm really loving like that's probably the least expected Part of this that I'm enjoying the most good. I'm glad yeah, man. Do we want to make a part two to want to stop here? Keep going I think so. We are almost an hour in and we have 1 2 3 4 like six to seven more things to cover and some of them will be shorter and kind of group together, but I think that will make <mark>for</mark> a really good part 2 of this podcast perfect. So in this podcast you covered the base, which Was consistency followed going up to intensity followed up by technique and that's where we just cut it off. I was perfect. I think that the strong the strong base that's like the power base of building muscle. Then we're going to go up we'll discuss things like volume will discuss that's not good. We will give a teaser but not in any particular order. Oh, I like that. So in no specific order. This is what we'll talk about next week exercise selection volume rest and Recovery. training frequency rep range nutrition and rest time I like that I like that so what might be fun <mark>for</mark> you is to make your own pyramid and you know consistency intensity and technique are the bottom three in that order consistency intensity technique try and figure out where you would arrange the orders of", "Start Time (s)": 3510.3, "End Time (s)": 3629.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and that's where we just cut it off. I was perfect. I think that the strong the strong base that's like the power base of building muscle. Then we're going to go up we'll discuss things like volume will discuss that's not good. We will give a teaser but not in any particular order. Oh, I like that. So in no specific order. This is what we'll talk about next week exercise selection volume rest and Recovery. training frequency rep range nutrition and rest time I like that I like that so what might be fun <mark>for</mark> you is to make your own pyramid and you know consistency intensity and technique are the bottom three in that order consistency intensity technique try and figure out where you would arrange the orders of importance and then listen to the podcast next week and see how you did compared to us and see if Either you like yours better you like ours better and we'll go from there. Awesome. Thank you <mark>for</mark> listening. If you enjoyed this episode, we would really appreciate it. If you left a five star review or one star if you hated the episode, we also really appreciate the feedback the compliments feel good obviously, so if you want to leave one of those but we also really like the what you want to hear more of on the podcast because as much enjoyment is Jordan and I are getting out of this we're doing it <mark>for</mark> use So let us know and thank you <mark>for</mark> listening. Thank you so much.", "Start Time (s)": 3580.4, "End Time (s)": 3668.4, "Clip Length (min)": 1.47, "show_uri": "spotify:show:10k3vxLOFhZHfciP4k5Ar7", "show_name": "How To Become A Personal Trainer", "show_description": "Practical tips to help you become a better coach so you can help more people.", "publisher": "Mike Vacanti | Jordan Syatt", "episode_uri": "spotify:episode:7vfnLgfVgyoKW1fx2ABk3t", "episode_name": "Workout Design For Muscle Growth", "episode_description": "In this episode we discuss...\u00a0  -The most important factors to stimulate muscle growth (and their order of importance).\u00a0 -Why proper technique is essential for muscle growth (outside of risking blowing your spine out of your back).\u00a0 -Whether you should focus more on intensity or volume for the best muscle growth stimulus.\u00a0 -And more...\u00a0  Want to help thousands of people all over the world and build your own successful online fitness business? Join us in The Fitness Business Mentorship: https://www.fitnessbusinessmentorship.com/\u00a0 Download the FREE 30 Ways To Build A Successful Online Coaching Business Manual: http://bit.ly/30O2l6p\u00a0 If you liked this episode please subscribe to the podcast and leave us a rating: https://apple.co/35ATwyf\u00a0  ----\u00a0  Post-Production by: David Margittai | In Post Media Website: https://www.inpostmedia.com/ Email: david@inpostmedia.com\u00a0  \u00a9 2020 Michael Vacanti & Jordan Syatt ", "score": 4.938857, "explanation": "{\n  \"value\": 4.938857,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.109332904,\n      \"description\": \"weight(word_list:for in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.109332904,\n          \"description\": \"score(LMDirichletSimilarity, freq=89.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9228538,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 89.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.829524,\n      \"description\": \"weight(word_list:beginners in 157) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.829524,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.643045,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Well, either freaks, it's your boy Marty been here to introduce this flash episode of Tales from the Crypt sat down with our good friend <mark>Bitcoin</mark> Tina to talk about the perfect storm of things that are happening in the world that are bullish <mark>for</mark> <mark>Bitcoin</mark> a lot going on right now particularly this week in American markets globally with the coronavirus reading I think you guys are gonna like it quick one always bullish bullish as always with our good friend Tina. This episode is brought to you by the cash yet freaks are null. Um, I was actually had a friend reach out to me the yesterday the other not the other day yesterday. He was like, ah, let's see easiest way to buy Bitcoin. Remember you told me download that what was it the cash yet? That's what I said. It's the easiest way to buy Bitcoin. He had to be refreshed his memory had to be refreshed yesterday did a little video on my cell phone showing them how to buy Bitcoin. I did that thing where you record your screen went to the cash app scroll over to the squiggly line the art over to <mark>bitcoin</mark> hit it up about $50 hit $50 wanna buy $50", "Start Time (s)": 0.5, "End Time (s)": 66.2, "Clip Length (min)": 1.09, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it's your boy Marty been here to introduce this flash episode of Tales from the Crypt sat down with our good friend <mark>Bitcoin</mark> Tina to talk about the perfect storm of things that are happening in the world that are bullish <mark>for</mark> <mark>Bitcoin</mark> a lot going on right now particularly this week in American markets globally with the coronavirus reading I think you guys are gonna like it quick one always bullish bullish as always with our good friend Tina. This episode is brought to you by the cash yet freaks are null. Um, I was actually had a friend reach out to me the yesterday the other not the other day yesterday. He was like, ah, let's see easiest way to buy Bitcoin. Remember you told me download that what was it the cash yet? That's what I said. It's the easiest way to buy Bitcoin. He had to be refreshed his memory had to be refreshed yesterday did a little video on my cell phone showing them how to buy Bitcoin. I did that thing where you record your screen went to the cash app scroll over to the squiggly line the art over to <mark>bitcoin</mark> hit it up about $50 hit $50 wanna buy $50 hit by help my fingerprint down hit confirm. Boom $50 worth of <mark>bitcoin</mark> in my cash app was able to send it right off to a hardware wallet and basically get my financial sovereignty in less than 30 seconds. It was crazy. All right, so they're letting Stacks at still letting you send SATs receive sets and then on top of that the links tax live with us. If you want to you guys have heard about it already, but if you haven't catch up investing is now here if you have a stock that you want to invest in a stock you can buy as little as one dollar with it. If it's a little too expensive. You don't have to buy the whole thing by a sliver of a stock now because your account is connected to your bank account your cash app account is directly connected to your bank account. You want to wait four to five days. You start investing today cash up investing is a subsidiary Square remember s IPC as Always use the code", "Start Time (s)": 1.1, "End Time (s)": 120.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "with it. If it's a little too expensive. You don't have to buy the whole thing by a sliver of a stock now because your account is connected to your bank account your cash app account is directly connected to your bank account. You want to wait four to five days. You start investing today cash up investing is a subsidiary Square remember s IPC as Always use the code stacking sets. You're going to get $10 when you sign up and ten dollars going to go to our good friends at owls lacrosse. That's owls lacrosse. Enjoy this episode with a good friend Tina. I know I certainly did. Okay. You've had a dynamic where money has become Freer than free. Can you talk about a Fed just gone nuts? All the central bank's going nuts. So it's all acting like Safe Haven. I believe that in a world where central Bankers are tripping over themselves to devalue their currency <mark>Bitcoin</mark> wins in the world of Fiat currencies <mark>Bitcoin</mark> is the Victor remember? Part of the bull case <mark>for</mark> Bitcoin. You're not paying attention. You probably should be. What is a freaks welcome back to Tales from the Crypt at your boy Marty bent here? The flash episode had her good friend repeat guests reach out to me over DMS and say hey, we need to talk. I'd like to introduce you freaks again to <mark>bitcoin</mark> Tina Tina. How are we great everyday is a good day in Bitcoin. Ha ha that's what you're saying. Every all news is good news <mark>for</mark> Bitcoin. Well news is good news <mark>for</mark> Bitcoin. All obstacles are overcome by the social layer of the Point because <mark>Bitcoin</mark> is by its nature antifragile. Yes, and to preface this episode. We're not fear mongering. All right. This is an optimistic episode. We were just laying the land giving a lay of the land and explaining how it may or may not affect", "Start Time (s)": 102.3, "End Time (s)": 222.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>Bitcoin</mark> wins in the world of Fiat currencies <mark>Bitcoin</mark> is the Victor remember? Part of the bull case <mark>for</mark> Bitcoin. You're not paying attention. You probably should be. What is a freaks welcome back to Tales from the Crypt at your boy Marty bent here? The flash episode had her good friend repeat guests reach out to me over DMS and say hey, we need to talk. I'd like to introduce you freaks again to <mark>bitcoin</mark> Tina Tina. How are we great everyday is a good day in Bitcoin. Ha ha that's what you're saying. Every all news is good news <mark>for</mark> Bitcoin. Well news is good news <mark>for</mark> Bitcoin. All obstacles are overcome by the social layer of the Point because <mark>Bitcoin</mark> is by its nature antifragile. Yes, and to preface this episode. We're not fear mongering. All right. This is an optimistic episode. We were just laying the land giving a lay of the land and explaining how it may or may not affect <mark>Bitcoin</mark> going to the Future. So it's been a pretty chaotic week in the markets in the world coronavirus you are describing is the perfect storm <mark>for</mark> <mark>Bitcoin</mark> as gonna be the title of this episode. Why do you think this? Okay, this is the perfect storm <mark>for</mark> Bitcoin. Now. First of all <mark>Bitcoin</mark> is not there a risk on Nora risk-off asset <mark>Bitcoin</mark> is the core to an emerging economic Paradigm in my opinion <mark>for</mark> what it's worth. I had believed and continue to believe that in the 2020s will see negative rates at a minimum will see Zero rates and we'll see massive government spending. I believe that there's a very good chance. There's a very good chance that the coronavirus may have accelerated this timetable. I don't know how corrupt plays out. It's", "Start Time (s)": 162.2, "End Time (s)": 282.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Why do you think this? Okay, this is the perfect storm <mark>for</mark> Bitcoin. Now. First of all <mark>Bitcoin</mark> is not there a risk on Nora risk-off asset <mark>Bitcoin</mark> is the core to an emerging economic Paradigm in my opinion <mark>for</mark> what it's worth. I had believed and continue to believe that in the 2020s will see negative rates at a minimum will see Zero rates and we'll see massive government spending. I believe that there's a very good chance. There's a very good chance that the coronavirus may have accelerated this timetable. I don't know how corrupt plays out. It's very hard to say. There's a lot of data. We don't know yet and I don't know exactly how it will play out, but I think that It becomes an excuse <mark>for</mark> government spending that governments want to do anyway, because governments like to spend money. So it becomes a very easy excuse to spend it becomes very easy excuse <mark>for</mark> central banks to cut rates because they kind of want to cut rates. Anyway, regardless of what they say, they still like to cut rates and they know they need to so it's not even their fault <mark>for</mark> cutting rates so they don't even have to take the blame because there are always the Entities who want to go after them saying they shouldn't cut rates. Central banks can throw up his hands it when we we can't control this thing. Now some will say that cutting rates doesn't help. Deal with a virus and no cutting rates doesn't but the thing is if markets were to crash and I don't know if markets will crash or Not Crash. I am very up in the air on that.", "Start Time (s)": 236.1, "End Time (s)": 354.3, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it becomes very easy excuse <mark>for</mark> central banks to cut rates because they kind of want to cut rates. Anyway, regardless of what they say, they still like to cut rates and they know they need to so it's not even their fault <mark>for</mark> cutting rates so they don't even have to take the blame because there are always the Entities who want to go after them saying they shouldn't cut rates. Central banks can throw up his hands it when we we can't control this thing. Now some will say that cutting rates doesn't help. Deal with a virus and no cutting rates doesn't but the thing is if markets were to crash and I don't know if markets will crash or Not Crash. I am very up in the air on that. I had set a while ago. That I expect stocks to be essentially flat <mark>for</mark> a decade. I continue to feel that way. I was somewhat doubtful of that view not that long ago when things were just soaring but it seems that events have taken a turn that has reeled in that possibility again that we may be flat essentially <mark>for</mark> a decade and I think we're sort of in this push-me pull-you environment where it's tug of war. Or between what gets done so even though maybe stock should decline because of events if governments spend like crazy and central banks by assets. Then things don't go down. We have certain things which are immutable and demographics is immutable. Although some told me today that who knows. Maybe this thing is a A plan to get rid of Aging Boomers. I don't know if that's true or not.", "Start Time (s)": 302.6, "End Time (s)": 421.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>for</mark> a decade and I think we're sort of in this push-me pull-you environment where it's tug of war. Or between what gets done so even though maybe stock should decline because of events if governments spend like crazy and central banks by assets. Then things don't go down. We have certain things which are immutable and demographics is immutable. Although some told me today that who knows. Maybe this thing is a A plan to get rid of Aging Boomers. I don't know if that's true or not. I certainly hope not but I actually don't think it's a plan to get rid of Adrian Boomers and those who are older than Boomers. I think if I had to guess that Nobody planned this thing. This one's completely unplanned and I don't know if it's nature or anything else but not <mark>for</mark> your sake too. Huh said I would offer my stick to thanks. I appreciate that. Well the problem is that even even if you don't die from it. I heard recently that. You could wind up with permanent lung damage. So, you know, even if you're 25 years old permanent lung damage <mark>for</mark> the rest of your life. It's really not something to look forward to so you really don't want to get sick and I don't know that's you know, the band strain or the not bad strain, but I think because it becomes this event which will encourage massive governmental spending and I think you know, I think we're going to have huge spending regardless. I don't think it would matter who's in office. I that you'd see spending either an infrastructure project or green deal or any different ways that you would see just enormous spending and I think that the central bank's the", "Start Time (s)": 380.9, "End Time (s)": 500.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "It's really not something to look forward to so you really don't want to get sick and I don't know that's you know, the band strain or the not bad strain, but I think because it becomes this event which will encourage massive governmental spending and I think you know, I think we're going to have huge spending regardless. I don't think it would matter who's in office. I that you'd see spending either an infrastructure project or green deal or any different ways that you would see just enormous spending and I think that the central bank's the FED would will expand their balance sheet to keep that spending and the debt issuance from driving rates much higher. It's a very weird. It's a very weird environment. But if that view is correct on my part, it becomes incredibly bullish <mark>for</mark> <mark>Bitcoin</mark> crashing stocks at the end of the day is not bullish <mark>for</mark> Bitcoin. I mean if the water in the bathtub goes down your little sailboat that you have floating on the top of the water is likely to go down with it. It's not going to be helpful to have stocks. Let's say get cut in half so Could it happen sure could happen. I don't know whether or not stocks will get hit dramatically, but I think that you will see. Actions taken by Central government's actions taken by central banks that will look to prevent that whereas in Prior periods. These various entities were always reactive. I think they're going to be far more proactive because we've been living in an environment <mark>for</mark> the last decade where Everything is Bubblicious out there. So if Capital markets come down very hard namely", "Start Time (s)": 460.7, "End Time (s)": 580.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "stocks at the end of the day is not bullish <mark>for</mark> Bitcoin. I mean if the water in the bathtub goes down your little sailboat that you have floating on the top of the water is likely to go down with it. It's not going to be helpful to have stocks. Let's say get cut in half so Could it happen sure could happen. I don't know whether or not stocks will get hit dramatically, but I think that you will see. Actions taken by Central government's actions taken by central banks that will look to prevent that whereas in Prior periods. These various entities were always reactive. I think they're going to be far more proactive because we've been living in an environment <mark>for</mark> the last decade where Everything is Bubblicious out there. So if Capital markets come down very hard namely stocks that becomes a pretty big problem <mark>for</mark> everybody because money conditions get tight when money conditions get tight credit conditions get tight and that becomes very hard <mark>for</mark> the real economy. So, net net I mean this may be a crazy point of view, but I think that we will see an environment that becomes perfect <mark>for</mark> <mark>Bitcoin</mark> when you throw in the having with what I think will be the backdrop <mark>for</mark> Very easy money. Additionally there may be things happening like you saw with Germany, and now may be announced today with France and India you have a lot of you have a positive backdrop <mark>for</mark> Bitcoin. And so to me, this becomes The Perfect Storm by Perfect Storm. I mean like a really great thing that you're going to see all kinds of forces come together that", "Start Time (s)": 523.5, "End Time (s)": 643.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a lot of you have a positive backdrop <mark>for</mark> Bitcoin. And so to me, this becomes The Perfect Storm by Perfect Storm. I mean like a really great thing that you're going to see all kinds of forces come together that cause this thing to go possibly higher than numbers that I have said I have guessed that you see a massive overshoot. The overshoot comes related to stock to flow with the projection is $100,000 and I have always thought that from a psychological perspective getting to $100,000 causes a lot of people who are highly skeptical and critical. To change their mind and look at this thing very differently and want to jump on board. You know, you get a guy who listened to Jamie dimon listen to Warren Buffett listen to whoever was critical and negative on <mark>bitcoin</mark> and they look at a price of 50 60 70 80 $100,000. They said themselves. Oh I thought this thing was going to go away and then it's sitting at prices that they think are crazy and they start to say I gotta get me some of that and I think you're going to hear a lot of people saying I got to own me some of that and I have said <mark>for</mark> a while and I continue to say just by 1% You know, it's 1% won't hurt you. Now, that's not Financial advice but realistically If you fall off the curb on the sidewalk and it's only like an inch or two. It's really hard to get really hurt. I mean sure you could fall down and break your hip if you're really old or really clumsy, but that's not going to happen to most people and it's really hard to do with one percent. It's only one percent of your net worth", "Start Time (s)": 625.7, "End Time (s)": 744.0, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and they start to say I gotta get me some of that and I think you're going to hear a lot of people saying I got to own me some of that and I have said <mark>for</mark> a while and I continue to say just by 1% You know, it's 1% won't hurt you. Now, that's not Financial advice but realistically If you fall off the curb on the sidewalk and it's only like an inch or two. It's really hard to get really hurt. I mean sure you could fall down and break your hip if you're really old or really clumsy, but that's not going to happen to most people and it's really hard to do with one percent. It's only one percent of your net worth and I think it's a highly reasonable thing. I think by the end of this decade we can see truly insane numbers and so the risk reward profile on that. Is just outstanding. So if I'm at all right about the backdrop <mark>for</mark> this thing. Then it's just become a much much better investment. And all of these things are coming together. Hence the term The Perfect Storm again, not in a bad way, but in a really good way it really optimistic really positive way and let me think about that governments starting to become more accepting. Really easy money. And what was the other thing that I said? Stagnant stock markets <mark>for</mark> no. No - yeah, you know really easy money governments coming together and the government's becoming more accepting now. I forgot what I said some OS so my letters fomo after certain level but no no that was the backdrop. I have to go listen to what I said remember interest rates", "Start Time (s)": 702.0, "End Time (s)": 821.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Stagnant stock markets <mark>for</mark> no. No - yeah, you know really easy money governments coming together and the government's becoming more accepting now. I forgot what I said some OS so my letters fomo after certain level but no no that was the backdrop. I have to go listen to what I said remember interest rates falling below zero. Well that relates to the easy money. Well that and that will push people into wanting to own Bitcoin. So listen what I said remember what I said well, but it creates it creates a very positive backdrop though. Those those various those various things that are happening. And so one thing you haven't you got that you having you have very easy money, which I think is very likely plus you have growing acceptance. Governments, I mean what more could you ask <mark>for</mark> to me? That's what you call an absolutely perfect environment. And I think that people really underestimate this I have said <mark>for</mark> a long time all surprises and <mark>Bitcoin</mark> will be on the upside and I think people who try to get cute with this the try to trade it and try to sell it. Oh, one of the things that really have a lot of impact on me recently is as having conversation. Without of the <mark>Bitcoin</mark> or who was trading TLT options because he wanted to make a bet on long-dated paper long-dated treasuries. And you know, I told him I was a little concerned. I thought it was a great idea. I think we took a lot lower but he he owns some April paper and some a papers if you know who knows it could take a while and then race were like 150 at the time and the 10-year yield as we speak is point seven four five. So it just got cut in half. In like a little more", "Start Time (s)": 797.2, "End Time (s)": 916.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "virus is it's really highlighting the the pain points and our supply chain and and the pain points are Global is goal of globalization and sort of the the Situation America has put itself in particularly. Can you print your way out of this or do you think there's a chance that there's a total and this is something I'm sort of leaning towards there's a total crisis of confidence in the institutions mainly the FED that they're able to control this stuff. I don't disagree with anything. You just said but I do think that cutting rates will be supportive of markets. I do think if markets were to simply just crash that that can create the environment that makes it a self-fulfilling prophecy if markets just get taken down very hard. I believe that we are in a world and have been in a world <mark>for</mark> a long time. Are the real economy has become the tail and the markets have become dog. And so I think that if the stock market crashes at the global stock markets crash he wind up with overall tighter Financial conditions and Tighter Financial conditions make <mark>for</mark> a more difficult environment. I think these were bad policies from the beginning but it doesn't matter what I think it matters where we are. It doesn't matter how we got here. It matters that we're here now. It doesn't matter if the rock breaks the glass pitcher or the pitcher hits the rock. It's going to be bad <mark>for</mark> the picture. It doesn't matter if the stocks crater. If they do it's going to be bad <mark>for</mark> the real economy and it's going to be a problem. I agree with you that there's a lot of weakness and Supply chains. There are a lot of fragilities in the", "Start Time (s)": 962.9, "End Time (s)": 1082.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "hard. I believe that we are in a world and have been in a world <mark>for</mark> a long time. Are the real economy has become the tail and the markets have become dog. And so I think that if the stock market crashes at the global stock markets crash he wind up with overall tighter Financial conditions and Tighter Financial conditions make <mark>for</mark> a more difficult environment. I think these were bad policies from the beginning but it doesn't matter what I think it matters where we are. It doesn't matter how we got here. It matters that we're here now. It doesn't matter if the rock breaks the glass pitcher or the pitcher hits the rock. It's going to be bad <mark>for</mark> the picture. It doesn't matter if the stocks crater. If they do it's going to be bad <mark>for</mark> the real economy and it's going to be a problem. I agree with you that there's a lot of weakness and Supply chains. There are a lot of fragilities in the economy, but adding one more problem to the mixture doesn't make it better. So no cutting rates in and of themselves. does not fix the underlying problems, but if stocks crashed in conjunction with the other problems happening It doesn't make that cocktail a better cocktail <mark>for</mark> solving these problems at this point. It probably makes it worse and I don't think these good policies. I haven't thought these were good policies <mark>for</mark> many many many many years, but it's where we are. Now. I'm not trying to say that you believe that no, no answer that. I don't think you're trying to say that I do you do you envision a possibility in which the policies are completely ineffective. this time around like", "Start Time (s)": 1015.5, "End Time (s)": 1134.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "these problems at this point. It probably makes it worse and I don't think these good policies. I haven't thought these were good policies <mark>for</mark> many many many many years, but it's where we are. Now. I'm not trying to say that you believe that no, no answer that. I don't think you're trying to say that I do you do you envision a possibility in which the policies are completely ineffective. this time around like they pump a bunch of money in but not even that can keep stock market stasis. markets are dependent on earnings as well as price earnings multiples. I don't know if multiples can expand. That's why I kind of believe that you're going to see this push-me pull-you because you could have a tough earnings environment and it can be a tough earnings environment <mark>for</mark> a while which keeps pressure on stocks. But the same time you get all kinds of support from fiscal policies that become supportive of those earnings and if you have Central Looking to control the shape of the curve and keeping rates. Down by keeping bond prices from selling off then you create an environment where multiples can remain high. So that's why you wind up with this really strange environment of being able to maintain relatively high prices, even though maybe it shouldn't be I think we're in a world today which is different from the world of the last 90 years because I think that we having been through these crises already. The response has become far more activist rather than reactive and so", "Start Time (s)": 1108.2, "End Time (s)": 1226.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that become supportive of those earnings and if you have Central Looking to control the shape of the curve and keeping rates. Down by keeping bond prices from selling off then you create an environment where multiples can remain high. So that's why you wind up with this really strange environment of being able to maintain relatively high prices, even though maybe it shouldn't be I think we're in a world today which is different from the world of the last 90 years because I think that we having been through these crises already. The response has become far more activist rather than reactive and so it's not good that we got here. But we're going to do more of the same to keep the thing going and that becomes very positive <mark>for</mark> <mark>Bitcoin</mark> and ultimately in my view <mark>Bitcoin</mark> will be the thing that takes us to that next economic Paradigm and it has to become a lot bigger <mark>for</mark> that to happen. And I think we're in that environment where <mark>Bitcoin</mark> is going to become enormous in the course of the 2020s, and I think it's going to go to levels that people. Cannot possibly imagine I'd be very reluctant to part with my <mark>Bitcoin</mark> if I were if I were whoever's listening to this, I'd be very reluctant to part with it. You're not margin trading it right now. Now I never margin trade it I sit with fully owned and sit with fully on bitcoin. I also own gbtc and that I do have <mark>for</mark> the purpose of selling because I do have to pay my bills and and I like to eat and I like to have a roof over my head. So I do have gbtc who's whose sole purpose is to sell because I will need to sell some but I'm hopeful that I'll have some", "Start Time (s)": 1176.2, "End Time (s)": 1295.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I don't think enough people really understand why this asset will benefit from the environment there weren't looking worst case scenario. when we saw Cyprus in when we saw Cyprus in 2011-12 2011-2012, you know 2012 you don't own your money in the bank. You don't own the money at your brokerages. Those are held by the institutions. We saw that with MF Global if these institutions go belly-up and I'm not suggesting that they do but if they do go belly-up they can do whatever they want your money. Essentially if you hold your own private Keys, you actually control your own money. If you have an extremely aggressive inflation, I believe and I'm not suggesting. We have a very extremely aggressive inflation. Although I think we're setting the stage <mark>for</mark> that to happen down. The one that could take three four five six seven years. I don't know how long that takes but that could take a while, but it can be a very aggressive inflation having an asset which is Fixed and Supply as well as Supply inelastic. is very much a beneficiary of of an inflating the money supply where money will chase that asset because of its natural qualities in addition to its scarcity. Becomes an asset that you want to own so I think it becomes the ideal thing to own <mark>for</mark> the 2020s and I think this is a really interesting kickoff and this really started with a bang right in January of 2020. And I think I'd have thought <mark>for</mark> a while. The 2020s are going to be a", "Start Time (s)": 1300.4, "End Time (s)": 1420.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I think we're setting the stage <mark>for</mark> that to happen down. The one that could take three four five six seven years. I don't know how long that takes but that could take a while, but it can be a very aggressive inflation having an asset which is Fixed and Supply as well as Supply inelastic. is very much a beneficiary of of an inflating the money supply where money will chase that asset because of its natural qualities in addition to its scarcity. Becomes an asset that you want to own so I think it becomes the ideal thing to own <mark>for</mark> the 2020s and I think this is a really interesting kickoff and this really started with a bang right in January of 2020. And I think I'd have thought <mark>for</mark> a while. The 2020s are going to be a truly spectacular decade. I would not be surprised to see <mark>Bitcoin</mark> up in the three to five million dollars. Inch by 2030 somewhere between 2020 and 2030 to so I'm that my guess is a 300 to 500 x return from $10,000 would be higher from $7,000. I think the numbers will be absolutely spectacular and I think today's dollars something really insane. But by 5 to 8 million dollars in today's dollars three to five million three to five you bit three If you bid me up money, I'll take the loads out of that the three to five million. I think it's going to be some really crazy stuff and I think that I'd actually would like most people think that's completely off the charts nuts.", "Start Time (s)": 1357.9, "End Time (s)": 1477.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to 8 million dollars in today's dollars three to five million three to five you bit three If you bid me up money, I'll take the loads out of that the three to five million. I think it's going to be some really crazy stuff and I think that I'd actually would like most people think that's completely off the charts nuts. I'd really prefer they think that rather than thinking it's possible. So probably do I'm going to I think I'm comfortable enough to say that they probably do people listen as the guy you're actually a lot of people listening was probably believe you but Outsiders definitely they totally think I'm crazy and I'm really okay with that. I think, you know, they're crazy numbers, but I think that If the world is yes, I think in today's I think in today's buying power. I think if you have a very resident place in the numbers would just be whatever. No I think in today's buying power if you had one <mark>Bitcoin</mark> today, it'll buy you what three million dollars would buy you today. That's what's going to happen to the value of that <mark>for</mark> five million dollars what it buys you today, which means if you have 10 Bitcoin, you know, you're talking about being like a A small whale and if you have a hundred coin you are well and I think a lot of I think a lot of the oh jeez. A lot of them I think will lose their <mark>Bitcoin</mark> along the way which I'm really happy about it because I think many of them underestimate the asset that they have they've held it what <mark>for</mark> them feels like so long, they're like all all nervous. You're not using this as a medium of exchange yet. And oh my God, it's not going to really work out. You got to push it <mark>for</mark> me to exchange their they feel like these 11 years is like this eternity and I look at the 11 years like it's nothing and the thing Grew From from 0 to today. What are we at a hundred and seventy hundred eight? We are we today", "Start Time (s)": 1452.5, "End Time (s)": 1571.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "as big as from zero to a hundred sixty billion. No, I'm in but In absolute dollars. The numbers are going to be off the charts spectacular and and it's going to be really big really huge money and everything is pushing it that way. No, I agree. I mean the world is insane right now and I think at least to me I tweeted it out this morning Bitcoins engaged in a war of attrition. Just gotta Outlast the incumbent Financial system and then comment Financial Paradigm old us to do is keep producing blocks and it's a good segue into another ingredient of The Perfect Storm. They were talking about again the regulation and countries around the world. You mentioned France Germany India Rabbit Hole recap yesterday. Matt and I were talking about How we think the German and I believe similarly the French regulations or new laws are bearish but you're saying it's bullish even though it may be restrictive <mark>for</mark> companies to start. This is overall good <mark>for</mark> <mark>Bitcoin</mark> along run. Why do you think that it's bullish as can be because the key to <mark>bitcoin</mark> ultimately becoming the money that we use is being large enough to be able to grow and create an internal Market that enables us to do things that whirring, you know, you hide in the crowd. Let's face facts. We live in a world where lots of people use cash to do things that They don't pay taxes on so how many times have you heard? Somebody say, you know give you cash <mark>for</mark> a discount and they get the discount. So everybody knows what they're going to do and if the crowd is large enough and if the techniques are there, they're going to be too many transactions to to keep track of so, I am not bothered by these regulations. I think that when you have", "Start Time (s)": 1586.5, "End Time (s)": 1706.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "they're going to be too many transactions to to keep track of so, I am not bothered by these regulations. I think that when you have 50 million people 70 million people in America 70 million Americans using it some people will coin and some people will use lightning will Pro years lightning probably pretty much everywhere coin or many many will will do it you end up hiding a crowd. I think what you'll end up seeing at some point along the way is the tax laws will get changed because bitcoiners will be smart and they will create political action committees. They will donate two Pax Pax will donate two congressmen and senators and we'll end up getting favorable laws passed at $500,000 Bitcoin. Are we going to be people who should be giving some money to support politicians who support our point of view who support favorable tax laws <mark>for</mark> Bitcoin? I think it'd be crazy not to UPenn Bitcoin. It's half a million dollars that's five million dollars. That's a lot of money. So you can afford to give a few thousand dollars to politicians and you do it with, you know, another 50,000 bitcoiners becomes a lot of money and politicians will speak, you know will do will support your point of view when you give the money. That's how this works. We live in a world where where money talks and I think that it will be a very positive - I'm not at all Disturbed. We just need to see number go up and anything which promotes number go up and enables people to come into <mark>Bitcoin</mark> is positive. So even though regulation so that this regulation means you're not Banning it. Regulating it. You don't ban it if you're going to ban it you ban it he don't regulate it to ban it", "Start Time (s)": 1698.0, "End Time (s)": 1816.8, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a few thousand dollars to politicians and you do it with, you know, another 50,000 bitcoiners becomes a lot of money and politicians will speak, you know will do will support your point of view when you give the money. That's how this works. We live in a world where where money talks and I think that it will be a very positive - I'm not at all Disturbed. We just need to see number go up and anything which promotes number go up and enables people to come into <mark>Bitcoin</mark> is positive. So even though regulation so that this regulation means you're not Banning it. Regulating it. You don't ban it if you're going to ban it you ban it he don't regulate it to ban it because you just ban it. So regulation is positive. It's not negative regulation enables people who look at this and say I don't want to buy <mark>Bitcoin</mark> because the government's are going to ban it and say well dummy they just regulated it. So they're obviously not Banning it so you can now invest in this thing. You can be comfortable. This is just like what you're comfortable with so when you can can say to people who have a lot more money than we do guys who may be in my age of people that this is regulated and you can feel comfortable owning this they watch it going up. What are they going to do? They're going to buy it and they're going to help Drive the price higher so you let something like that, huh, that's going to say let's hone in on that. What do you think? A lot of boomers are thinking right now, especially this week in the stock market a lot of people your rager. There are they not thinking about <mark>Bitcoin</mark> are they worried about the retirement funds and they're worried about their retirement funds right now everybody worries about their money in the stock market when the stock market goes down unless they're short who doesn't worry about the", "Start Time (s)": 1766.3, "End Time (s)": 1885.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you bought stocks the S&P it seven or eight hundred and the SP is now at 2,900 how much can you be hurting? You're still all right, you're not happy that it's down I mean, but but but you're up. Multiples and depending on stocks you own you could be up an awful lot. So it depends on who we're talking about. I think it's hard to generalize. I think people like to generalize there's some people where the average retirement amounts are in the neighborhood of 200 thousand dollars. There have been people speaking of late that the using those kinds of numbers. $200,000 is probably not enough to retire on at the age of 65 how much they own in stocks? I don't know. I think that even a retiree who 65 should today own 1% in Bitcoin, even if you had only $200,000 1% in <mark>Bitcoin</mark> will make sense. The odds of them buying it under 20,000. I think are close to zero the odds and buying it under a hundred thousand. I think are not much more than zero. And people tend to chase price. That's just how we are. Most bitcoiners come to <mark>bitcoin</mark> they get inoculated the first time they hear about <mark>Bitcoin</mark> they say, oh that that's crap. They don't do anything and then the prices up 5 or 10 X or some number from where they first heard about it and they say, oh, yeah. I think I'm interested in I don't want to buy it. This happens all the time. This happens with probably most people in <mark>Bitcoin</mark> there. There's only a handful of people who heard about it and bought it right away. at least that's from the stories that I hear and people can correct that if they know different but I think that the upside is enormous and even if you pay $100,000", "Start Time (s)": 1919.8, "End Time (s)": 2039.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "if I'm right on the numbers and I believe that I will be then your slope tremendous upside. So that's really going to be okay. So people will come into this in the course of the next few years. I think this will be the first mainstream bull market and there's a good chance that like that first big bull market you had early on not who won in 2016 and 2017. That this will be quite surprising to where it goes because there's a global tsunami of money that's going to start coming into Bitcoin. It's going to come in as a trickle everything in economics seems to be Gradually, then suddenly that's how markets tend to work gradually than sudden and I gradually takes a while exponential curves look linear in the early stages. That's the gradually part. They hit a critical point and then suddenly happens and I think <mark>Bitcoin</mark> will be no different. I think we'll go through a series of these things and I think the next year to three possibly four years or quite shocking take us two numbers that are really Like crazy. I don't know what the next they are Market looks like I think the next bull market, which we may be in the early stages of will end up being quite spectacular because the psychology which is set up and that's a big factor to so you have all these positive force is happening and you have this massive buildup of negative psychology. It'll be like a dam bursting as people know what they heard about Bitcoin. They know about the negative you I mean how many people I talk to people and they think I'm crazy. I talked to a lot of Yabba. No not if people think you're crazy. Yeah. No, I'm not really I'm not interested in nothing. Don't don't bother me. Oh the <mark>Bitcoin</mark> guy. Oh my God Gotta Get Away gotta get", "Start Time (s)": 2039.8, "End Time (s)": 2159.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "They hit a critical point and then suddenly happens and I think <mark>Bitcoin</mark> will be no different. I think we'll go through a series of these things and I think the next year to three possibly four years or quite shocking take us two numbers that are really Like crazy. I don't know what the next they are Market looks like I think the next bull market, which we may be in the early stages of will end up being quite spectacular because the psychology which is set up and that's a big factor to so you have all these positive force is happening and you have this massive buildup of negative psychology. It'll be like a dam bursting as people know what they heard about Bitcoin. They know about the negative you I mean how many people I talk to people and they think I'm crazy. I talked to a lot of Yabba. No not if people think you're crazy. Yeah. No, I'm not really I'm not interested in nothing. Don't don't bother me. Oh the <mark>Bitcoin</mark> guy. Oh my God Gotta Get Away gotta get away from that guy. It's a <mark>Bitcoin</mark> guy. He's nothing but trouble I mean people make jokes about this, but it's true. We're annoying. I'm really annoying. I don't say that. Oh, I'm sure. Like that, but well you're touching on something that I'm very interested in and something I think about a lot to is after the next bull market or x amount of bull markets. What is the the correction look like is it as intense and psychologically what is a threshold at which people are like? All right. This is serious isn't going anywhere and we don't see an 80 to 90% crash again after maybe we Plateau fall 50% Okay, so you have misquoted me from from our first podcast. In January of 2019 you have misquoted make when I said that volatility will subdue IE downside volatility will become less and but upside volatility will remain insane. So I think that there's a good", "Start Time (s)": 2095.1, "End Time (s)": 2214.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but well you're touching on something that I'm very interested in and something I think about a lot to is after the next bull market or x amount of bull markets. What is the the correction look like is it as intense and psychologically what is a threshold at which people are like? All right. This is serious isn't going anywhere and we don't see an 80 to 90% crash again after maybe we Plateau fall 50% Okay, so you have misquoted me from from our first podcast. In January of 2019 you have misquoted make when I said that volatility will subdue IE downside volatility will become less and but upside volatility will remain insane. So I think that there's a good likelihood that at some point maybe the next bear Market more than likely definitely the one after that that the downside will be greatly diminished from what we've seen now. I'll give you a caveat. If we were to go to a million-dollar <mark>Bitcoin</mark> in the next four years, I don't know what it looks like. Thanks <mark>for</mark> if <mark>Bitcoin</mark> were to go from where it is now <mark>for</mark> a series of moves up to a million dollars. I don't know what crash would or would not look like. It's very hard to guess if we really overshoot where I think we should go and I think we should go to that to or $400,000 range which people think it's crazy. But we really overshoot could we crash down to one or two? Thousand dollars maybe and I actually don't want to see million dollar <mark>Bitcoin</mark> in the next three or four years. I'd rather only see. I know people think that's crazy <mark>Bitcoin</mark> going to you know to to $400,000 because if you if you if you dropped from a peak of 400,000 to 150, which is not nearly as bad as what we've seen then lots of people feel comfortable coming in at 150. If you went to a million in this massive Spike, we're like in the last month", "Start Time (s)": 2172.1, "End Time (s)": 2292.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "three or four years. I'd rather only see. I know people think that's crazy <mark>Bitcoin</mark> going to you know to to $400,000 because if you if you if you dropped from a peak of 400,000 to 150, which is not nearly as bad as what we've seen then lots of people feel comfortable coming in at 150. If you went to a million in this massive Spike, we're like in the last month or two you went from five hundred thousand dollars up to a million. You potentially have a lot of people who just got blown out. Really high prices. So how long that takes to correct? It could take a really long time to correct? I don't want to see something like that. Could we see it? It's possible. We could see it. I don't want to see it. I think that would be incredibly hard environment. I think it'd be very hard to trade. I think it'd be very hard to sell. I think the chain would become probably heavily bogged down. We'd have a hard time moving <mark>Bitcoin</mark> to sell because I don't want to see that. I don't want to see that and actually it brings up a good point. I forget who said it core developer recently said that the the pace of development at the protocol level is pacing nicely with the price right now. So <mark>Bitcoin</mark> is usable at this price at this. Option level and it'll be interesting to see how development Paces with the price going forward. Especially if markets continue doing what they're doing an animal spirits take over. Do you think the protocol is better position <mark>for</mark> a bull run moving forward? Is better position than what than it was three years ago 27th the protocol like the the technology. I'm not I'm not an expert on the protocol. I'm not going to I'm not going to speculate on that. I'm not knowledgeable enough there. I think there's a lot of great things happening, but that's really a question of other people not <mark>for</mark>", "Start Time (s)": 2265.5, "End Time (s)": 2384.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>Bitcoin</mark> to sell because I don't want to see that. I don't want to see that and actually it brings up a good point. I forget who said it core developer recently said that the the pace of development at the protocol level is pacing nicely with the price right now. So <mark>Bitcoin</mark> is usable at this price at this. Option level and it'll be interesting to see how development Paces with the price going forward. Especially if markets continue doing what they're doing an animal spirits take over. Do you think the protocol is better position <mark>for</mark> a bull run moving forward? Is better position than what than it was three years ago 27th the protocol like the the technology. I'm not I'm not an expert on the protocol. I'm not going to I'm not going to speculate on that. I'm not knowledgeable enough there. I think there's a lot of great things happening, but that's really a question of other people not <mark>for</mark> me. I think that the infrastructure background is is friendly or towards massive amounts of money coming in and will continue to accelerate and we'll see More money coming into developing potential scaling layers and businesses trying to find their way. Look we see that with somebody like square a company like square that is supporting core developers that is doing a lot of really really positive things. I would expect with Rising prices will see at least. I hope we do more companies that are like Square we have delta T that's doing stuff. I think that we'll see a lot of investment where companies are trying to build their own businesses and benefit from from using <mark>Bitcoin</mark> and are supportive of the values of <mark>Bitcoin</mark> and I'm hopeful that we'll see that as far as the protocol goes that", "Start Time (s)": 2325.0, "End Time (s)": 2444.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to speculate on that. I'm not knowledgeable enough there. I think there's a lot of great things happening, but that's really a question of other people not <mark>for</mark> me. I think that the infrastructure background is is friendly or towards massive amounts of money coming in and will continue to accelerate and we'll see More money coming into developing potential scaling layers and businesses trying to find their way. Look we see that with somebody like square a company like square that is supporting core developers that is doing a lot of really really positive things. I would expect with Rising prices will see at least. I hope we do more companies that are like Square we have delta T that's doing stuff. I think that we'll see a lot of investment where companies are trying to build their own businesses and benefit from from using <mark>Bitcoin</mark> and are supportive of the values of <mark>Bitcoin</mark> and I'm hopeful that we'll see that as far as the protocol goes that was over and above my head and I'm not an expert in that I won't comment I think <mark>for</mark> the infrastructure, I think we've built a lot of infrastructure in the last few years and I think that will continue to happen. Will allow <mark>for</mark> more money flows come in was the cash app around in 2017. Towards the tail end I believe they started were where anybody using it not as many people as they're using it today. So people always losing it widely. So cash app is is phenomenal on board on boarding tool and so there are there are a lot of things that I'm going to you've got give <mark>Bitcoin</mark> out there that becomes a number there are a lot of things that are out there that are building their a lot of things that were not there in 2017, which would be supportive. If things become truly crazy and you're dealing with a very", "Start Time (s)": 2376.8, "End Time (s)": 2496.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "This thing can really happen the banking system can actually shut down. So when I say, I don't believe what I say, I say it but then it's like oh, I don't go load up on Golden 2000 2002 2003 when I showed up in doing that. So I thought rates are going to go down and then like two weeks later they get cut in half. So yeah, I think rates can go down but I don't think rates are gonna go down in two weeks. So when I say, I don't believe what I say aye I can be right about something but yet I'm also surprised at how aggressive it is and how right I might be in something so Your ideas write the timings off a little bit. Well, it's just like You believe it but it's like it's when you're talking about things which are really hard to believe. It's sometimes even hard to believe it yourself that. If <mark>Bitcoin</mark> is sitting at $400,000, I'm going to be like I said, I'm gonna $400,000 but man I didn't think it would really go to $400,000 this fast and and we won't it's going to be hard to believe. I promise you because to $400,000 you will not believe it and neither one most other people and if it goes higher we're going to be really Bonkers and the whole world will be Bonkers. They're very we can say these things but actually watching it happen. You still sad. You still stand there with your mouth open just in astonishment and I think it should happen but actually watching the thing actually happen. I'm astonished that the tenure paper is at point. Seven four eight right. Now. I'm astonished I look at the yield curve. The curve is all on pretty much not not the 30-year all under one percent. These are astonishing numbers. I did not live in a world like this. I mean I saw sure post post 2000.", "Start Time (s)": 2560.3, "End Time (s)": 2677.6, "Clip Length (min)": 1.95, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and they Can't you can't deny your your human instinct? Right or everybody has a hard time imagining a world that's different from the one they know and that includes me. It's very hard to imagine a world that you don't know yet and yet yes, I believe it. Yes. I think it's going to happen. But when it happens, it will be astonishing. It will astonish even those of us who believe it will happen. Does that make any sense? I know I know you look at you. You got really nervous when I said that you got really nervous. I can see the line across him is like what the hell is this? I thought you were going to contradict yourself, but I completely understand what you're saying. I felt that way in 2017. Like I couldn't believe it got the 20,000 when I got there and like you I've been I've been saying that I think it will hit millions of dollars one day. What year did you buy Bitcoin? That's a very personal question right approximately. Okay, I'm approximately what price did you buy <mark>Bitcoin</mark> approximate range my do not I bought it to the height of the last bubble before the A bubble, but did you buy lower than that to? Yes, I did. Okay. So when you bought lower than that, did you really think I was going to hit 20,000? I mean I thought so yes, but when it had were you amazed when I got there? Yeah having it like this is a PSA at all. You freaks out there like make sure you have especially stuff that you have in your own custody down like lockdown because that that treasure this Hardware while it's get very heavy when that price starts to rise. I'm no but my point is my point is if you see something if you're buying Bitcoins at $300 and you see it at ten thousand dollars and it's not that many years later. It's pretty astonishing.", "Start Time (s)": 2734.8, "End Time (s)": 2853.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "do not I bought it to the height of the last bubble before the A bubble, but did you buy lower than that to? Yes, I did. Okay. So when you bought lower than that, did you really think I was going to hit 20,000? I mean I thought so yes, but when it had were you amazed when I got there? Yeah having it like this is a PSA at all. You freaks out there like make sure you have especially stuff that you have in your own custody down like lockdown because that that treasure this Hardware while it's get very heavy when that price starts to rise. I'm no but my point is my point is if you see something if you're buying Bitcoins at $300 and you see it at ten thousand dollars and it's not that many years later. It's pretty astonishing. I have to add this one thing before we go <mark>Bitcoin</mark> is the key to a long life. Why do you say this? Because it may not be any longer but watching it every day. It sure seems like it's a lot longer, right? Yeah. Yeah, it's been a very long two years. Well her it's going too far as long as it's been a fun two years. I didn't say it isn't fun. I just as long we watch this thing 24/7 right even everything about say they don't look huh? You ever think about taking a vacation from watching this stuff? 24/7 how do you take a vacation from it? It's everywhere. You can't you can't help yourself. I like to walk it I didn't but I don't but I don't trade it. I just sit and watch it. Is that drive you crazy at all? I mean, you're already crazy. Not really. Not really. No. I look I'd be happier right now of <mark>Bitcoin</mark> was sitting at 25,000. I think it's dumb at this price. I think", "Start Time (s)": 2799.6, "End Time (s)": 2917.5, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I have to add this one thing before we go <mark>Bitcoin</mark> is the key to a long life. Why do you say this? Because it may not be any longer but watching it every day. It sure seems like it's a lot longer, right? Yeah. Yeah, it's been a very long two years. Well her it's going too far as long as it's been a fun two years. I didn't say it isn't fun. I just as long we watch this thing 24/7 right even everything about say they don't look huh? You ever think about taking a vacation from watching this stuff? 24/7 how do you take a vacation from it? It's everywhere. You can't you can't help yourself. I like to walk it I didn't but I don't but I don't trade it. I just sit and watch it. Is that drive you crazy at all? I mean, you're already crazy. Not really. Not really. No. I look I'd be happier right now of <mark>Bitcoin</mark> was sitting at 25,000. I think it's dumb at this price. I think $9,000 is stupid cheap. I mean I did not think <mark>Bitcoin</mark> was going to get rekt from six to three thousand. I just didn't think that was going to happen. I wasn't happy when it happened. I felt when it got wrecked to People saying what's going on 1000 that was just stupid, and that's why I wanted to talk to you back in January 2019. I think this is just a very large base that we're tracing out that will give us an enormous. What's-her-name Levine's amount of says the bigger the base the higher in space. So we just have this huge thing that we're tracing out here that we're only people who really believe in this thing and holding onto it because they ride through", "Start Time (s)": 2854.9, "End Time (s)": 2973.1, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "did not think <mark>Bitcoin</mark> was going to get rekt from six to three thousand. I just didn't think that was going to happen. I wasn't happy when it happened. I felt when it got wrecked to People saying what's going on 1000 that was just stupid, and that's why I wanted to talk to you back in January 2019. I think this is just a very large base that we're tracing out that will give us an enormous. What's-her-name Levine's amount of says the bigger the base the higher in space. So we just have this huge thing that we're tracing out here that we're only people who really believe in this thing and holding onto it because they ride through the ups and downs, which this has been very beneficial <mark>for</mark> the class of 2017 to 2020. It's been a very beneficial time <mark>for</mark> them to load up on on bitcoin. And I think that they'll be people who are our dollar cost averaging into it today who if they are able to hold on to what they have if you're 25 or 30 years old when you're 50 or 60 years old. You're going to be very very rich. I think even one <mark>Bitcoin</mark> will make you very very very rich. I talked to a guy the other day told me you only has 53 million SATs and he's trying know trying to become a whole corner. And I said, you know keep keep keep doing that keep working on that. I think even 53 million sets will be a staggering amount of money many people will have sold well before the numbers that I think it will get to in 20 to 30 years,", "Start Time (s)": 2922.6, "End Time (s)": 3040.3, "Clip Length (min)": 1.96, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "be people who are our dollar cost averaging into it today who if they are able to hold on to what they have if you're 25 or 30 years old when you're 50 or 60 years old. You're going to be very very rich. I think even one <mark>Bitcoin</mark> will make you very very very rich. I talked to a guy the other day told me you only has 53 million SATs and he's trying know trying to become a whole corner. And I said, you know keep keep keep doing that keep working on that. I think even 53 million sets will be a staggering amount of money many people will have sold well before the numbers that I think it will get to in 20 to 30 years, but if you're able to hold on to that Million sites will be a lot of money and that seems crazy and we think oh my God, how can that possibly be? But if you bought <mark>Bitcoin</mark> at a dollar and you bought 10,000 of them, it's only $10,000 which is not a lot of money. I mean ten thousand dollars just in the world of investing is nothing. It may be a lot of money to do certain things with but that today is how much is that today? Which is 10,000. It's 90 million dollars. How much is that? 10,000 Bitcoins. I mean, it's 90 million, right? Yeah. We don't we don't want to make that steak that woman made ten MSNBC who said that who said that million dollars and everyone could have had a million dollars from that little bit. We don't want to make that mistake right here. I'll look it up right now 10,000 Times nine million nine hundred ninety million dollars. So who the fuck $10,000 could become 90 million dollars. That's crazy. And I think that you know, I think that", "Start Time (s)": 2992.0, "End Time (s)": 3111.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "$10,000 which is not a lot of money. I mean ten thousand dollars just in the world of investing is nothing. It may be a lot of money to do certain things with but that today is how much is that today? Which is 10,000. It's 90 million dollars. How much is that? 10,000 Bitcoins. I mean, it's 90 million, right? Yeah. We don't we don't want to make that steak that woman made ten MSNBC who said that who said that million dollars and everyone could have had a million dollars from that little bit. We don't want to make that mistake right here. I'll look it up right now 10,000 Times nine million nine hundred ninety million dollars. So who the fuck $10,000 could become 90 million dollars. That's crazy. And I think that you know, I think that 30 years and that's a long time 30 years from now 20 years from now that one <mark>Bitcoin</mark> at $9,000 today who will be worth an enormous amount of money. So because a lot of people will sell they'll end up Distributing out that <mark>Bitcoin</mark> to other people the gini coefficient will keep You growing the be very few people are able to really hold on as these things go up. If we watch it go to two three four hundred thousand dollars. If you own 10 <mark>Bitcoin</mark> today, you gotta go no care. We don't end the coin today and it's at $300,000. That's three million dollars. So that's a lot of money and it's a lot of money goes to 3 million dollars in 10 years and Bitcoin. Is 30 million dollars that's an enormous amount of money. So it'll be hard to hold on to our stash because we'll always be scared of how it trades. It's going to be difficult people will spend and people have to live, you know, you got to pay your expenses. So if you", "Start Time (s)": 3057.1, "End Time (s)": 3176.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "no care. We don't end the coin today and it's at $300,000. That's three million dollars. So that's a lot of money and it's a lot of money goes to 3 million dollars in 10 years and Bitcoin. Is 30 million dollars that's an enormous amount of money. So it'll be hard to hold on to our stash because we'll always be scared of how it trades. It's going to be difficult people will spend and people have to live, you know, you got to pay your expenses. So if you have a job, you'll be earning an income. But your stash may become worth a lot of money and you want to you want to take nice vacations. You want to buy a car you want to do things with so people All do things but they will also want to enjoy that money as well. So people will probably spend some of it some will spend more than others. A lot of people won't hold anywhere near the amount of <mark>Bitcoin</mark> the number of <mark>Bitcoin</mark> that they have in 10 and 20 and 30 years. I agree. I see I mean we've seen it happen time and time again already. That's all I'm saying. Yeah, and I guess we can end it with talking about like the perfect storm. And another thing that I thought was very very one thing. I thought was very interesting this week again playing into fundamentals and then going back to your comments earlier about getting Capitol Hill involved in lobbyist involved is <mark>Bitcoin</mark> mining becoming a function of power plants and we're seeing more oil and gas companies get into it too. So a lot of people are depending on the coin centers and you were describing like a bitcoiners pack in the future. I think we were able to Trojan Horse our way in through the energy sector particularly oil and", "Start Time (s)": 3144.0, "End Time (s)": 3263.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "we've seen it happen time and time again already. That's all I'm saying. Yeah, and I guess we can end it with talking about like the perfect storm. And another thing that I thought was very very one thing. I thought was very interesting this week again playing into fundamentals and then going back to your comments earlier about getting Capitol Hill involved in lobbyist involved is <mark>Bitcoin</mark> mining becoming a function of power plants and we're seeing more oil and gas companies get into it too. So a lot of people are depending on the coin centers and you were describing like a bitcoiners pack in the future. I think we were able to Trojan Horse our way in through the energy sector particularly oil and gas companies that I think that's actually brilliant. I think that taking people might be negative on this, but think about out <mark>Bitcoin</mark> has tremendous incentives built into it <mark>for</mark> energy Innovation Energy Efficiency. Some people complain that utilities mining bitcoins and negative but one of the things I believe and so I'm not an expert here. So give me a little leeway. One of the things I believe is that energy producers like utilities Electric utilities have a problem with is Peak load issues and stabilizing their production of power. If you're mining <mark>Bitcoin</mark> and you can say, okay, we'll turn the <mark>Bitcoin</mark> off the power level is whatever you can better predict the loads. You're operating at because that becomes a variable item that you can either", "Start Time (s)": 3213.4, "End Time (s)": 3333.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "energy with less Solutions. That you know, I think that's yeah and get some music going on in the background there. I don't know what it was. I trying to figure out what it was. It could be. No, I didn't sell I could be an ad going off one year when your tabs it's open or something like that. I have multiple computers here can't find the mouse. That's weird. Anyway, so I think that it becomes very beneficial to the utility sector. I think it tends to draw I think will tend to drive Innovation. And I think that that will be a very very good thing and I think that we'll see a lot of positive stuff. Come from that. I completely agree. That's like one of the things I'm most passionate about right now. The <mark>Bitcoin</mark> narrative is trying to change that energy narrative particularly. I think it is changing in it will become more obvious that <mark>Bitcoin</mark> really helps fix in efficiencies in the energy sector particularly and in a glaringly obvious way once you once you actually see like this this power plant that went live and up. New York are consuming 40 megawatts a day. That's insane. Well, if being able to have a stable amount of production, I believe and you'll need somebody who knows more about this than I do, but I think that's actually a really positive thing <mark>for</mark> an energy producer rather than having this huge fluctuation. And I think you wind up with fluctuations on the basis of on the basis of the time of day as well as seasonality in the year, but I think it's those shorter", "Start Time (s)": 3375.2, "End Time (s)": 3494.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I think it is changing in it will become more obvious that <mark>Bitcoin</mark> really helps fix in efficiencies in the energy sector particularly and in a glaringly obvious way once you once you actually see like this this power plant that went live and up. New York are consuming 40 megawatts a day. That's insane. Well, if being able to have a stable amount of production, I believe and you'll need somebody who knows more about this than I do, but I think that's actually a really positive thing <mark>for</mark> an energy producer rather than having this huge fluctuation. And I think you wind up with fluctuations on the basis of on the basis of the time of day as well as seasonality in the year, but I think it's those shorter term production Cycles which become difficult <mark>for</mark> utilities and being able to smooth that out. Probably is very beneficial to running those utilities, but you'll need to talk to somebody knows a lot more about it than I do. Well, I actually one of the First episodes we had on this podcast is with somebody who works at an energy company at a facility and he Saying Joe Luna Charles djou loony, he was saying I don't know if it was his particular facility or another around him, but they were basically putting water in like train cars and pushing it up a hill and dropping it down the hill which then had turbines that would pick up the water and sort of reproduce the energy so they had like a net zero energy consumption overnight when the load was later. So they keep the factory on but now just being able to use that energy to mind <mark>Bitcoin</mark> instead. You can make money that", "Start Time (s)": 3439.6, "End Time (s)": 3558.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "term production Cycles which become difficult <mark>for</mark> utilities and being able to smooth that out. Probably is very beneficial to running those utilities, but you'll need to talk to somebody knows a lot more about it than I do. Well, I actually one of the First episodes we had on this podcast is with somebody who works at an energy company at a facility and he Saying Joe Luna Charles djou loony, he was saying I don't know if it was his particular facility or another around him, but they were basically putting water in like train cars and pushing it up a hill and dropping it down the hill which then had turbines that would pick up the water and sort of reproduce the energy so they had like a net zero energy consumption overnight when the load was later. So they keep the factory on but now just being able to use that energy to mind <mark>Bitcoin</mark> instead. You can make money that way and not have to do that redundant useless task. So just it just makes a lot of sense there would be fantastic. Yeah, and then good really be fantastic Oil and Gas Energy Lobby seems to be one of the biggest in the world. Like we may not even have to depend on coin Center. It may help them out so much that they go to bat <mark>for</mark> <mark>Bitcoin</mark> on Capitol Hill. That'd be great. That would be really great. And and and I think we'll see a lot of innovation. In the space. I don't I'm not an expert in energy and so incentives are really economic incentives are better ways to drive Behavior than our regulation or moral imperatives. You may think something is going to court the right thing to do. But if", "Start Time (s)": 3494.9, "End Time (s)": 3614.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Oil and Gas Energy Lobby seems to be one of the biggest in the world. Like we may not even have to depend on coin Center. It may help them out so much that they go to bat <mark>for</mark> <mark>Bitcoin</mark> on Capitol Hill. That'd be great. That would be really great. And and and I think we'll see a lot of innovation. In the space. I don't I'm not an expert in energy and so incentives are really economic incentives are better ways to drive Behavior than our regulation or moral imperatives. You may think something is going to court the right thing to do. But if you benefit from it economically by doing it you really tend to want to do it anyway, so That just I think you can economic incentives are very powerful drivers <mark>for</mark> human behavior many of My Views around <mark>Bitcoin</mark> all revolve around price. And what price does and price is incredibly important maybe the most important thing in an economy price causes consumers and producers to make choices and if price drives Individuals and entities to do things that are net positives then that becomes a good thing. So <mark>Bitcoin</mark> becomes something which creates incentives to drive behavior that is is beneficial. That probably sounds what's up. Yeah, that's beautiful know I've I wholeheartedly believe that the incentives are such this are at second third order incentives outside of the direct Network are are beneficial as well. And people are just", "Start Time (s)": 3569.2, "End Time (s)": 3687.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and price is incredibly important maybe the most important thing in an economy price causes consumers and producers to make choices and if price drives Individuals and entities to do things that are net positives then that becomes a good thing. So <mark>Bitcoin</mark> becomes something which creates incentives to drive behavior that is is beneficial. That probably sounds what's up. Yeah, that's beautiful know I've I wholeheartedly believe that the incentives are such this are at second third order incentives outside of the direct Network are are beneficial as well. And people are just starting to notice this it's a perfect storm. It seems like it's all coming together. Everything was good <mark>for</mark> Bitcoin. All bad news. All good news is good <mark>for</mark> Bitcoin. Obstacles are nothing but things to be overcome by the social layer of Bitcoin. Bitcoins inevitable party I think so as well and I guess let's end it last note. How strong is the social layer <mark>Bitcoin</mark> right now? It's gotten stronger in this bear Market. I think so. But I mean, I'm just one person. I mean I only see what's on Twitter and I think that maybe it may just be a limited window but The social are is created by the incentives of Bitcoin. So turns out Marty that you don't change <mark>Bitcoin</mark> <mark>Bitcoin</mark> changes you. And we're going to add that on that peace and love freaks.", "Start Time (s)": 3637.4, "End Time (s)": 3753.5, "Clip Length (min)": 1.93, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "And people are just starting to notice this it's a perfect storm. It seems like it's all coming together. Everything was good <mark>for</mark> Bitcoin. All bad news. All good news is good <mark>for</mark> Bitcoin. Obstacles are nothing but things to be overcome by the social layer of Bitcoin. Bitcoins inevitable party I think so as well and I guess let's end it last note. How strong is the social layer <mark>Bitcoin</mark> right now? It's gotten stronger in this bear Market. I think so. But I mean, I'm just one person. I mean I only see what's on Twitter and I think that maybe it may just be a limited window but The social are is created by the incentives of Bitcoin. So turns out Marty that you don't change <mark>Bitcoin</mark> <mark>Bitcoin</mark> changes you. And we're going to add that on that peace and love freaks.", "Start Time (s)": 3687.2, "End Time (s)": 3753.5, "Clip Length (min)": 1.11, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.9298024, "explanation": "{\n  \"value\": 4.9298024,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.9298024,\n      \"description\": \"weight(word_list:bitcoin in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.9298024,\n          \"description\": \"score(LMDirichletSimilarity, freq=96.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.656134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 96.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=62.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6230705,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 62.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Really quickly, we recommend listening to this show on Spotify where you can listen to all of our favorite artists and podcasts in one place <mark>for</mark> free without a premium account Spotify has a huge catalogue of podcasts on every imaginable topic plus you can follow your favorite podcast. So you never miss an episode premium users can download episodes to listen to offline wherever and whenever and easily share what you're listening to with your friends on Instagram, so if you haven't done so already Ready, be sure to download the Spotify app search <mark>for</mark> Optimal Health daily on Spotify or browse podcasts in the your library tab. Also, make sure to follow me. So you never miss an episode of Optimal Health daily. This is Optimal Health daily episode 949 mechanical advantage drop sets the smart way to build muscle fast by John. Romanello of Roman Fitness systems.com. And I'm dr. Neal Malik reading you some of the most popular health and fitness blogs out there with permission from the websites, of course. Oh man. I am a big fan of drop set so I can't wait to read this to you. But really", "Start Time (s)": 0.2, "End Time (s)": 67.8, "Clip Length (min)": 1.13, "show_uri": "spotify:show:7bAET7ZZKgml8AI0jUg8oY", "show_name": "Optimal Health Daily", "show_description": "Why bother searching for the best blogs about health & fitness when it can be found and read for you? Think of Optimal Health Daily as an audioblog or blogcast. Support this podcast: https://anchor.fm/optimal-health-daily/support", "publisher": "Dr. Neal Malik", "episode_uri": "spotify:episode:5KNJcwdo2eSDR5Est1Jw2l", "episode_name": "949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems", "episode_description": "John Romaniello of Roman Fitness Systems on mechanical advantage drop sets. Episode 949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems RFS originally began as a personal training company servicing the NYC Metro area back in 2003. Through that company, Roman coached everyone from professional athletes to actors to regular folks. In 2009, John Romaniello started the site to more conveniently merge his love of fitness and writing. While it was \u201cjust a blog\u201d at first, it quickly became much, much more. Slowly but surely, writing articles, blog posts and books became the priority. Today, RFS continues to be one of the most respected sites for high quality fitness and lifestyle information around. The original post is located here: http://romanfitnesssystems.com/articles/mechanical-advantage-drop-sets/ Please Rate & Review the Show! Visit Me Online at OLDPodcast.com and in The O.L.D. Facebook Group  ---   Support this podcast: https://anchor.fm/optimal-health-daily/support", "score": 4.834836, "explanation": "{\n  \"value\": 4.834836,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.22023965,\n      \"description\": \"weight(word_list:for in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.22023965,\n          \"description\": \"score(LMDirichletSimilarity, freq=21.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.8662952,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 21.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.6145964,\n      \"description\": \"weight(word_list:beginners in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.6145964,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "whenever and easily share what you're listening to with your friends on Instagram, so if you haven't done so already Ready, be sure to download the Spotify app search <mark>for</mark> Optimal Health daily on Spotify or browse podcasts in the your library tab. Also, make sure to follow me. So you never miss an episode of Optimal Health daily. This is Optimal Health daily episode 949 mechanical advantage drop sets the smart way to build muscle fast by John. Romanello of Roman Fitness systems.com. And I'm dr. Neal Malik reading you some of the most popular health and fitness blogs out there with permission from the websites, of course. Oh man. I am a big fan of drop set so I can't wait to read this to you. But really quickly before I get to it. If you want to see pictures of us hosts of the optimal shows plus get some quotes. Quotes and see some behind-the-scenes stuff and lots more come follow us on Instagram. You can find us at Old podcast. We would of course love to see you there. But <mark>for</mark> now, I'm excited to read to you this post. So let's get right to it as we optimize your life. Mechanical advantage drop sets the smart way to build muscle fast by John Rowe. Mennella of Roman Fitness systems.com when you're training to build muscle you learn quickly that everything works, but that nothing works forever the basic 3 by 10 approach from your high school football days probably hasn't been effective since well when you played High School football as you progress you learn that every aspect of a given workout is but a single piece of the strength training puzzle. That each of those pieces can be modified individually to achieve a different effect and greater results, whether it's increasing the weight adjusting volume or switching exercises, you'll undoubtedly begin to see what works <mark>for</mark> you. But as you advance in your training this gets harder and harder so it becomes important that you include more advanced", "Start Time (s)": 23.3, "End Time (s)": 143.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:7bAET7ZZKgml8AI0jUg8oY", "show_name": "Optimal Health Daily", "show_description": "Why bother searching for the best blogs about health & fitness when it can be found and read for you? Think of Optimal Health Daily as an audioblog or blogcast. Support this podcast: https://anchor.fm/optimal-health-daily/support", "publisher": "Dr. Neal Malik", "episode_uri": "spotify:episode:5KNJcwdo2eSDR5Est1Jw2l", "episode_name": "949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems", "episode_description": "John Romaniello of Roman Fitness Systems on mechanical advantage drop sets. Episode 949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems RFS originally began as a personal training company servicing the NYC Metro area back in 2003. Through that company, Roman coached everyone from professional athletes to actors to regular folks. In 2009, John Romaniello started the site to more conveniently merge his love of fitness and writing. While it was \u201cjust a blog\u201d at first, it quickly became much, much more. Slowly but surely, writing articles, blog posts and books became the priority. Today, RFS continues to be one of the most respected sites for high quality fitness and lifestyle information around. The original post is located here: http://romanfitnesssystems.com/articles/mechanical-advantage-drop-sets/ Please Rate & Review the Show! Visit Me Online at OLDPodcast.com and in The O.L.D. Facebook Group  ---   Support this podcast: https://anchor.fm/optimal-health-daily/support", "score": 4.834836, "explanation": "{\n  \"value\": 4.834836,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.22023965,\n      \"description\": \"weight(word_list:for in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.22023965,\n          \"description\": \"score(LMDirichletSimilarity, freq=21.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.8662952,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 21.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.6145964,\n      \"description\": \"weight(word_list:beginners in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.6145964,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and lots more come follow us on Instagram. You can find us at Old podcast. We would of course love to see you there. But <mark>for</mark> now, I'm excited to read to you this post. So let's get right to it as we optimize your life. Mechanical advantage drop sets the smart way to build muscle fast by John Rowe. Mennella of Roman Fitness systems.com when you're training to build muscle you learn quickly that everything works, but that nothing works forever the basic 3 by 10 approach from your high school football days probably hasn't been effective since well when you played High School football as you progress you learn that every aspect of a given workout is but a single piece of the strength training puzzle. That each of those pieces can be modified individually to achieve a different effect and greater results, whether it's increasing the weight adjusting volume or switching exercises, you'll undoubtedly begin to see what works <mark>for</mark> you. But as you advance in your training this gets harder and harder so it becomes important that you include more advanced training techniques. So you can keep progressing one of those Advanced Techniques is called drop sets a drop set is when you perform a set of a given exercise. He's to the point of fatigue or failure and then change a variable in a way that allows you to continue performing the set. Keep in mind. Everything can be treated as a variable in this equation in traditional drop sets. The variable is the weight itself. You reduce or drop the weight. Once you reach fatigue allowing yourself to perform a few more reps with a lighter load. These are also known as strip sets because you're stripping the weight off the bar all told this is a decent technique and The results but it can be made better in so many ways, but first you need to look at the way that the weight affects the muscle without falling too far down the rabbit hole of muscle research. It's enough to say that in most cases", "Start Time (s)": 76.1, "End Time (s)": 196.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:7bAET7ZZKgml8AI0jUg8oY", "show_name": "Optimal Health Daily", "show_description": "Why bother searching for the best blogs about health & fitness when it can be found and read for you? Think of Optimal Health Daily as an audioblog or blogcast. Support this podcast: https://anchor.fm/optimal-health-daily/support", "publisher": "Dr. Neal Malik", "episode_uri": "spotify:episode:5KNJcwdo2eSDR5Est1Jw2l", "episode_name": "949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems", "episode_description": "John Romaniello of Roman Fitness Systems on mechanical advantage drop sets. Episode 949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems RFS originally began as a personal training company servicing the NYC Metro area back in 2003. Through that company, Roman coached everyone from professional athletes to actors to regular folks. In 2009, John Romaniello started the site to more conveniently merge his love of fitness and writing. While it was \u201cjust a blog\u201d at first, it quickly became much, much more. Slowly but surely, writing articles, blog posts and books became the priority. Today, RFS continues to be one of the most respected sites for high quality fitness and lifestyle information around. The original post is located here: http://romanfitnesssystems.com/articles/mechanical-advantage-drop-sets/ Please Rate & Review the Show! Visit Me Online at OLDPodcast.com and in The O.L.D. Facebook Group  ---   Support this podcast: https://anchor.fm/optimal-health-daily/support", "score": 4.834836, "explanation": "{\n  \"value\": 4.834836,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.22023965,\n      \"description\": \"weight(word_list:for in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.22023965,\n          \"description\": \"score(LMDirichletSimilarity, freq=21.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.8662952,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 21.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.6145964,\n      \"description\": \"weight(word_list:beginners in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.6145964,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "built. Therefore while drop sets are great. They suffer from the inherent issue of forcing you to use lighter weight as you progress deeper with each subsequent, drop your decreasing load. Why? You're still doing more work and getting closer to failure than traditional sets allow. You're not making the best of the heavyweight in order to eliminate that deficiency the goal would obviously be to keep using heavy weight. But how can you manage that if your fatiguing further and further with each rep what are mechanical advantage drop sets when we talk about mechanics and training we're really discussing positional adjustments as they apply to increasing or decreasing the leverage you're using to lift the weight and therefore the ease or Culty with which you can perform the exercise. This leads us to mechanical advantage drop sets or mads a type of drop set in which the variable is not the weight, but the exercises you perform with that weight as an example. You probably notice that it's easier <mark>for</mark> you to perform a bench press with a lower incline and harder to perform it with a higher incline as you increase the incline muscular leverage changes on favorably as does recruitment of individual muscles. Or more specifically as you increase the angle and the incline gets higher you place less emphasis on the chest and more on the smaller weaker muscles of the shoulders put in terms more relevant to this article. The higher incline is mechanically harder to set this up into a mechanical advantage drop set. You would start the chest press at a high incline work to failure fatigue, then drop the incline a bit that is with each successive set you lower the And continue to work you'll wind up being able to perform several more reps despite being fatigued. This is because you're stronger in that position of the lower incline, then you were in the previous ones the higher inclines, of course, this can be done with any body part and with nearly any", "Start Time (s)": 200.4, "End Time (s)": 320.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:7bAET7ZZKgml8AI0jUg8oY", "show_name": "Optimal Health Daily", "show_description": "Why bother searching for the best blogs about health & fitness when it can be found and read for you? Think of Optimal Health Daily as an audioblog or blogcast. Support this podcast: https://anchor.fm/optimal-health-daily/support", "publisher": "Dr. Neal Malik", "episode_uri": "spotify:episode:5KNJcwdo2eSDR5Est1Jw2l", "episode_name": "949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems", "episode_description": "John Romaniello of Roman Fitness Systems on mechanical advantage drop sets. Episode 949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems RFS originally began as a personal training company servicing the NYC Metro area back in 2003. Through that company, Roman coached everyone from professional athletes to actors to regular folks. In 2009, John Romaniello started the site to more conveniently merge his love of fitness and writing. While it was \u201cjust a blog\u201d at first, it quickly became much, much more. Slowly but surely, writing articles, blog posts and books became the priority. Today, RFS continues to be one of the most respected sites for high quality fitness and lifestyle information around. The original post is located here: http://romanfitnesssystems.com/articles/mechanical-advantage-drop-sets/ Please Rate & Review the Show! Visit Me Online at OLDPodcast.com and in The O.L.D. Facebook Group  ---   Support this podcast: https://anchor.fm/optimal-health-daily/support", "score": 4.834836, "explanation": "{\n  \"value\": 4.834836,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.22023965,\n      \"description\": \"weight(word_list:for in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.22023965,\n          \"description\": \"score(LMDirichletSimilarity, freq=21.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.8662952,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 21.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.6145964,\n      \"description\": \"weight(word_list:beginners in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.6145964,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "with a higher incline as you increase the incline muscular leverage changes on favorably as does recruitment of individual muscles. Or more specifically as you increase the angle and the incline gets higher you place less emphasis on the chest and more on the smaller weaker muscles of the shoulders put in terms more relevant to this article. The higher incline is mechanically harder to set this up into a mechanical advantage drop set. You would start the chest press at a high incline work to failure fatigue, then drop the incline a bit that is with each successive set you lower the And continue to work you'll wind up being able to perform several more reps despite being fatigued. This is because you're stronger in that position of the lower incline, then you were in the previous ones the higher inclines, of course, this can be done with any body part and with nearly any exercise. Let's flip it and let's look at back training. You can start <mark>for</mark> example with a wide grip pull up with your hands pronated and your arms splayed out. This is the weakest mechanical position based on On which muscles will be at work in the exercise as well as how The Leverage of your arms will come into play. But by changing your hand and arm position from the weakest to ones that are more mechanically advantageous. You can perform more reps with each successive change, even though it's obvious that you've gone to failure on the previous set now despite the fact that you're going to be fatiguing throughout the entire ordeal by moving from weaker to Stronger positions. You can complete an impressive number of reps allowing. Increased time under tension without a decrease in weight. You could apply this another way using a bent over row start with a wide grip overhand row, then move to a narrow grip and finally finish with an underhand row. So mechanical advantage drop sets are better than traditional drop sets because the load doesn't change as I mentioned", "Start Time (s)": 264.3, "End Time (s)": 384.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:7bAET7ZZKgml8AI0jUg8oY", "show_name": "Optimal Health Daily", "show_description": "Why bother searching for the best blogs about health & fitness when it can be found and read for you? Think of Optimal Health Daily as an audioblog or blogcast. Support this podcast: https://anchor.fm/optimal-health-daily/support", "publisher": "Dr. Neal Malik", "episode_uri": "spotify:episode:5KNJcwdo2eSDR5Est1Jw2l", "episode_name": "949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems", "episode_description": "John Romaniello of Roman Fitness Systems on mechanical advantage drop sets. Episode 949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems RFS originally began as a personal training company servicing the NYC Metro area back in 2003. Through that company, Roman coached everyone from professional athletes to actors to regular folks. In 2009, John Romaniello started the site to more conveniently merge his love of fitness and writing. While it was \u201cjust a blog\u201d at first, it quickly became much, much more. Slowly but surely, writing articles, blog posts and books became the priority. Today, RFS continues to be one of the most respected sites for high quality fitness and lifestyle information around. The original post is located here: http://romanfitnesssystems.com/articles/mechanical-advantage-drop-sets/ Please Rate & Review the Show! Visit Me Online at OLDPodcast.com and in The O.L.D. Facebook Group  ---   Support this podcast: https://anchor.fm/optimal-health-daily/support", "score": 4.834836, "explanation": "{\n  \"value\": 4.834836,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.22023965,\n      \"description\": \"weight(word_list:for in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.22023965,\n          \"description\": \"score(LMDirichletSimilarity, freq=21.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.8662952,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 21.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.6145964,\n      \"description\": \"weight(word_list:beginners in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.6145964,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "drop sets are better than traditional drop sets because the load doesn't change as I mentioned previously with traditional drop sets. You're keeping your position static and decreasing the weight to perform more reps, but with mads the weight stays the same. The entire time the entire set is done with heavy weight. Now as any body builder will tell you there are certainly some Merit in training with lighter weights at least in the sense that doing so allows you to train with high volume and frequency without impeding recovery too much but speaking generally most people are going to get a lot more out of consistently using more challenging weights. Not only will you get stronger but lifting heavy weights also has more applicability to relative strength and two sports. Finally with mechanical advantage drop sets your weight is consistently heavy and you get to push to fatigue and Beyond forcing more and more muscle fibers to be recruited with each rep and each mechanical change if an advanced method and certainly isn't easy, but if you're looking <mark>for</mark> a way to challenge yourself and force your body to grow I think you just found it. You just listen to The Post titled mechanical advantage drop sets the smart way to build muscle fast by John. Romanello of Roman Fitness systems.com a real quick. Thanks to anchor <mark>for</mark> hosting this podcast. Anchor is the easiest way to make a podcast. They'll distribute your podcast <mark>for</mark> you. So can be heard everywhere Spotify Apple podcasts Google podcasts and many more you can easily make money from your podcast to with no minimum listenership. Anchor You everything you need in one place <mark>for</mark> free which you can use right from your phone or computer creation tools allow you to record and edit your podcast. So it sounds great download the anchor app or go to Anchor dot f m-- to get started. Dr. Neil here <mark>for</mark> my commentary. Now I've talked about so called drop", "Start Time (s)": 379.0, "End Time (s)": 498.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:7bAET7ZZKgml8AI0jUg8oY", "show_name": "Optimal Health Daily", "show_description": "Why bother searching for the best blogs about health & fitness when it can be found and read for you? Think of Optimal Health Daily as an audioblog or blogcast. Support this podcast: https://anchor.fm/optimal-health-daily/support", "publisher": "Dr. Neal Malik", "episode_uri": "spotify:episode:5KNJcwdo2eSDR5Est1Jw2l", "episode_name": "949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems", "episode_description": "John Romaniello of Roman Fitness Systems on mechanical advantage drop sets. Episode 949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems RFS originally began as a personal training company servicing the NYC Metro area back in 2003. Through that company, Roman coached everyone from professional athletes to actors to regular folks. In 2009, John Romaniello started the site to more conveniently merge his love of fitness and writing. While it was \u201cjust a blog\u201d at first, it quickly became much, much more. Slowly but surely, writing articles, blog posts and books became the priority. Today, RFS continues to be one of the most respected sites for high quality fitness and lifestyle information around. The original post is located here: http://romanfitnesssystems.com/articles/mechanical-advantage-drop-sets/ Please Rate & Review the Show! Visit Me Online at OLDPodcast.com and in The O.L.D. Facebook Group  ---   Support this podcast: https://anchor.fm/optimal-health-daily/support", "score": 4.834836, "explanation": "{\n  \"value\": 4.834836,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.22023965,\n      \"description\": \"weight(word_list:for in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.22023965,\n          \"description\": \"score(LMDirichletSimilarity, freq=21.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.8662952,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 21.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.6145964,\n      \"description\": \"weight(word_list:beginners in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.6145964,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "if an advanced method and certainly isn't easy, but if you're looking <mark>for</mark> a way to challenge yourself and force your body to grow I think you just found it. You just listen to The Post titled mechanical advantage drop sets the smart way to build muscle fast by John. Romanello of Roman Fitness systems.com a real quick. Thanks to anchor <mark>for</mark> hosting this podcast. Anchor is the easiest way to make a podcast. They'll distribute your podcast <mark>for</mark> you. So can be heard everywhere Spotify Apple podcasts Google podcasts and many more you can easily make money from your podcast to with no minimum listenership. Anchor You everything you need in one place <mark>for</mark> free which you can use right from your phone or computer creation tools allow you to record and edit your podcast. So it sounds great download the anchor app or go to Anchor dot f m-- to get started. Dr. Neil here <mark>for</mark> my commentary. Now I've talked about so called drop sets before on this show many times before sometimes I would call them pyramids. You may also have heard them called ladders, but what John has just added to the equation is genius. He's right in that lifting with heavy weights is one of the best ways to build muscle fast. And so I love the idea of instead of dropping the weight, which I talked about before when doing pyramids or ladders instead here you keep The same heavyweight you just maybe change the angle or change your hand position you start with a more difficult position and with the same weight. You make it a little easier on yourself with each set. And to me that sounds super smart. And as John mentioned you want to be sure that you're kind of an advanced lifter in the sense that you've been lifting weights <mark>for</mark> a little while. Maybe you've received some personal training before you attempt this this would not be a great technique <mark>for</mark> beginners. And if you can is probably a good Good idea to have someone", "Start Time (s)": 436.0, "End Time (s)": 555.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:7bAET7ZZKgml8AI0jUg8oY", "show_name": "Optimal Health Daily", "show_description": "Why bother searching for the best blogs about health & fitness when it can be found and read for you? Think of Optimal Health Daily as an audioblog or blogcast. Support this podcast: https://anchor.fm/optimal-health-daily/support", "publisher": "Dr. Neal Malik", "episode_uri": "spotify:episode:5KNJcwdo2eSDR5Est1Jw2l", "episode_name": "949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems", "episode_description": "John Romaniello of Roman Fitness Systems on mechanical advantage drop sets. Episode 949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems RFS originally began as a personal training company servicing the NYC Metro area back in 2003. Through that company, Roman coached everyone from professional athletes to actors to regular folks. In 2009, John Romaniello started the site to more conveniently merge his love of fitness and writing. While it was \u201cjust a blog\u201d at first, it quickly became much, much more. Slowly but surely, writing articles, blog posts and books became the priority. Today, RFS continues to be one of the most respected sites for high quality fitness and lifestyle information around. The original post is located here: http://romanfitnesssystems.com/articles/mechanical-advantage-drop-sets/ Please Rate & Review the Show! Visit Me Online at OLDPodcast.com and in The O.L.D. Facebook Group  ---   Support this podcast: https://anchor.fm/optimal-health-daily/support", "score": 4.834836, "explanation": "{\n  \"value\": 4.834836,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.22023965,\n      \"description\": \"weight(word_list:for in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.22023965,\n          \"description\": \"score(LMDirichletSimilarity, freq=21.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.8662952,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 21.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.6145964,\n      \"description\": \"weight(word_list:beginners in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.6145964,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and edit your podcast. So it sounds great download the anchor app or go to Anchor dot f m-- to get started. Dr. Neil here <mark>for</mark> my commentary. Now I've talked about so called drop sets before on this show many times before sometimes I would call them pyramids. You may also have heard them called ladders, but what John has just added to the equation is genius. He's right in that lifting with heavy weights is one of the best ways to build muscle fast. And so I love the idea of instead of dropping the weight, which I talked about before when doing pyramids or ladders instead here you keep The same heavyweight you just maybe change the angle or change your hand position you start with a more difficult position and with the same weight. You make it a little easier on yourself with each set. And to me that sounds super smart. And as John mentioned you want to be sure that you're kind of an advanced lifter in the sense that you've been lifting weights <mark>for</mark> a little while. Maybe you've received some personal training before you attempt this this would not be a great technique <mark>for</mark> beginners. And if you can is probably a good Good idea to have someone spot you because again, you're going to be lifting heavy weights. You may not know how your muscles are going to respond to doing that kind of load. So you don't want the weights to fall on you. But again if you're at that level and it's safe <mark>for</mark> you to do so, I'm a huge fan of these mechanical advantage drop sets. All right, that'll do it from me <mark>for</mark> today. I'll be back here tomorrow <mark>for</mark> a usual Friday QA. So stay tuned <mark>for</mark> that. We are optimal life. Oh wait. Hello life Optimizer. This is just a moloch creator and producer of this show and optimal living daily, the brother podcast of this one literally have dr. Nils brother. If you like the format of this show, you'll love optimal living daily to where I also read to you from blogs, but cover other topics like personal development finance and minimalism from bloggers like Derek severs the minimalist Zen habits and many", "Start Time (s)": 485.5, "End Time (s)": 604.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:7bAET7ZZKgml8AI0jUg8oY", "show_name": "Optimal Health Daily", "show_description": "Why bother searching for the best blogs about health & fitness when it can be found and read for you? Think of Optimal Health Daily as an audioblog or blogcast. Support this podcast: https://anchor.fm/optimal-health-daily/support", "publisher": "Dr. Neal Malik", "episode_uri": "spotify:episode:5KNJcwdo2eSDR5Est1Jw2l", "episode_name": "949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems", "episode_description": "John Romaniello of Roman Fitness Systems on mechanical advantage drop sets. Episode 949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems RFS originally began as a personal training company servicing the NYC Metro area back in 2003. Through that company, Roman coached everyone from professional athletes to actors to regular folks. In 2009, John Romaniello started the site to more conveniently merge his love of fitness and writing. While it was \u201cjust a blog\u201d at first, it quickly became much, much more. Slowly but surely, writing articles, blog posts and books became the priority. Today, RFS continues to be one of the most respected sites for high quality fitness and lifestyle information around. The original post is located here: http://romanfitnesssystems.com/articles/mechanical-advantage-drop-sets/ Please Rate & Review the Show! Visit Me Online at OLDPodcast.com and in The O.L.D. Facebook Group  ---   Support this podcast: https://anchor.fm/optimal-health-daily/support", "score": 4.834836, "explanation": "{\n  \"value\": 4.834836,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.22023965,\n      \"description\": \"weight(word_list:for in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.22023965,\n          \"description\": \"score(LMDirichletSimilarity, freq=21.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.8662952,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 21.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.6145964,\n      \"description\": \"weight(word_list:beginners in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.6145964,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "while. Maybe you've received some personal training before you attempt this this would not be a great technique <mark>for</mark> beginners. And if you can is probably a good Good idea to have someone spot you because again, you're going to be lifting heavy weights. You may not know how your muscles are going to respond to doing that kind of load. So you don't want the weights to fall on you. But again if you're at that level and it's safe <mark>for</mark> you to do so, I'm a huge fan of these mechanical advantage drop sets. All right, that'll do it from me <mark>for</mark> today. I'll be back here tomorrow <mark>for</mark> a usual Friday QA. So stay tuned <mark>for</mark> that. We are optimal life. Oh wait. Hello life Optimizer. This is just a moloch creator and producer of this show and optimal living daily, the brother podcast of this one literally have dr. Nils brother. If you like the format of this show, you'll love optimal living daily to where I also read to you from blogs, but cover other topics like personal development finance and minimalism from bloggers like Derek severs the minimalist Zen habits and many more. So <mark>for</mark> more amazing content read to you <mark>for</mark> free come subscribe to Living daily two and together will optimize your life. to Optimal Health Data be sure to hit the Subscribe button to stay up to date on each new episode and head to old podcast.com that's oold podcast.com <mark>for</mark> a free gift as well as more actionable tips and resources to help you maximize your potential. Thanks <mark>for</mark> joining us and remember your optimal life awaits.", "Start Time (s)": 545.8, "End Time (s)": 638.7, "Clip Length (min)": 1.55, "show_uri": "spotify:show:7bAET7ZZKgml8AI0jUg8oY", "show_name": "Optimal Health Daily", "show_description": "Why bother searching for the best blogs about health & fitness when it can be found and read for you? Think of Optimal Health Daily as an audioblog or blogcast. Support this podcast: https://anchor.fm/optimal-health-daily/support", "publisher": "Dr. Neal Malik", "episode_uri": "spotify:episode:5KNJcwdo2eSDR5Est1Jw2l", "episode_name": "949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems", "episode_description": "John Romaniello of Roman Fitness Systems on mechanical advantage drop sets. Episode 949: Mechanical Advantage Drop Sets: The Smart Way to Build Muscle Fast by John Romaniello of Roman Fitness Systems RFS originally began as a personal training company servicing the NYC Metro area back in 2003. Through that company, Roman coached everyone from professional athletes to actors to regular folks. In 2009, John Romaniello started the site to more conveniently merge his love of fitness and writing. While it was \u201cjust a blog\u201d at first, it quickly became much, much more. Slowly but surely, writing articles, blog posts and books became the priority. Today, RFS continues to be one of the most respected sites for high quality fitness and lifestyle information around. The original post is located here: http://romanfitnesssystems.com/articles/mechanical-advantage-drop-sets/ Please Rate & Review the Show! Visit Me Online at OLDPodcast.com and in The O.L.D. Facebook Group  ---   Support this podcast: https://anchor.fm/optimal-health-daily/support", "score": 4.834836, "explanation": "{\n  \"value\": 4.834836,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.22023965,\n      \"description\": \"weight(word_list:for in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.22023965,\n          \"description\": \"score(LMDirichletSimilarity, freq=21.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.8662952,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 21.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.6145964,\n      \"description\": \"weight(word_list:beginners in 44) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.6145964,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Hello everyone. This is Adam Meister the bitcoinmeister the disrupt Meister. Welcome to the one <mark>Bitcoin</mark> show. Today is March the 5th 20/20 strong hand long-term. Thinking <mark>Bitcoin</mark> is the <mark>Bitcoin</mark> in motion five-digit realm now. You're welcome Bitcoin. We're going to talk about that today Relentless. This is your home <mark>for</mark> <mark>Bitcoin</mark> Insider information. I'm offended by selling don't fomo on alts. Hello my Elite friends. How you doing today, baby beautiful day as you two would say hey. Hey, so if you've got questions, I've got answers type in <mark>Bitcoin</mark> Meister. Or do a super chat remember this Friday, which is tomorrow and less than 24 hours at 2 p.m. Baltimore time. It's this week in <mark>Bitcoin</mark> as usual you get that every Friday best guest in the freaking space one Galt.", "Start Time (s)": 7.8, "End Time (s)": 84.0, "Clip Length (min)": 1.27, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the disrupt Meister. Welcome to the one <mark>Bitcoin</mark> show. Today is March the 5th 20/20 strong hand long-term. Thinking <mark>Bitcoin</mark> is the <mark>Bitcoin</mark> in motion five-digit realm now. You're welcome Bitcoin. We're going to talk about that today Relentless. This is your home <mark>for</mark> <mark>Bitcoin</mark> Insider information. I'm offended by selling don't fomo on alts. Hello my Elite friends. How you doing today, baby beautiful day as you two would say hey. Hey, so if you've got questions, I've got answers type in <mark>Bitcoin</mark> Meister. Or do a super chat remember this Friday, which is tomorrow and less than 24 hours at 2 p.m. Baltimore time. It's this week in <mark>Bitcoin</mark> as usual you get that every Friday best guest in the freaking space one Galt. Hey, I'm you're going to get offended by tomorrow, but there's a lot to talk about and yeah, so it's a great time tomorrow Friday this week in Bitcoin. Follow me on Twitter at kickball people. Seriously. I've been cleaning all day retweeting. You mentioned me. I recruit you. If it's a good thing which most of the time it is when people mention meet eech be alt and disrupt Meister economy can watch all 1600 over 1600 and you too. You too. Videos I've been in that deal with Bitcoin. All right. so let's talk about the what is this here where we talked about like this shirt, by the way, it's linked to below. I got this at Las Vegas tone base conference. You can get one like it. It's hot a little something or", "Start Time (s)": 18.2, "End Time (s)": 137.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "F course everything I talked about in this video is linked to below Whirlpool stats.com. It gives you some statistics about this coin stop and the month of February that just which is a short month. Even though it's a little longer than usually was is the most popular Samurai Whirlpool month of all time. Now that that haven't been that many but it beats it by a lot so fancy sets and Graphics at that at that site at that tweet. If you want to know more about this kind of thing, it's getting more popular clearly. It's definitely getting more popular and we'll see how it progresses. So there must not be that hard if that many people are doing with their Bitcoin. All right, or that many Bitcoins are it's happening to them now. All right. Yes, I'm offended by that to cast what you just said. I can't say that word. Remember if you have questions type in <mark>Bitcoin</mark> Meister, so I see them and pound that like button right now strong hand 2024 make that one of your sayings <mark>for</mark> the next four years learn how to hold if you're new to this because a lot of you weren't around in. Teen when I was seeing strong hand 2020 now we got us a strong hand 2024. Let's go over too. Well stick in the United States, then we'll go to Asia <mark>for</mark> a second here. This just is a reminder text season. I guess we're in tax season when I'm running. I see people dressed up with like the Statue of Liberty like rolling around sign saying well do your taxes or whatever so it must be time <mark>for</mark> that. and now although I wonder the guy that they are paying the hold the sign I want value and yeah, whatever, you know, I'm anyway so value about the <mark>Bitcoin</mark> is what I'm about to talk", "Start Time (s)": 190.4, "End Time (s)": 309.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Remember if you have questions type in <mark>Bitcoin</mark> Meister, so I see them and pound that like button right now strong hand 2024 make that one of your sayings <mark>for</mark> the next four years learn how to hold if you're new to this because a lot of you weren't around in. Teen when I was seeing strong hand 2020 now we got us a strong hand 2024. Let's go over too. Well stick in the United States, then we'll go to Asia <mark>for</mark> a second here. This just is a reminder text season. I guess we're in tax season when I'm running. I see people dressed up with like the Statue of Liberty like rolling around sign saying well do your taxes or whatever so it must be time <mark>for</mark> that. and now although I wonder the guy that they are paying the hold the sign I want value and yeah, whatever, you know, I'm anyway so value about the <mark>Bitcoin</mark> is what I'm about to talk about here when we're coming because this this quote here reminds us that if you play in the Fiat realm, you got to play by their rules and they are rules are nasty when it comes and when I say they I mean the United States government the rules are nasty when it comes to taxes because they Take a time to clarify it yet. Now time is a keyword from when I just in that sentence. I just said in time. It's going to be a lot easier these crypto taxes. It's going to be a lot easier. We're very early on so you can take your chances and Val your wealth and Fiat and offend me and sell your <mark>Bitcoin</mark> and then have to deal with this nightmare. Hello everyone if you haven't heard about an anchor It's the easiest way to make a podcast. That's how I make mine. Let me explain it's free. There's creation tools that allow you to record and edit your podcast right from your", "Start Time (s)": 248.2, "End Time (s)": 368.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "us that if you play in the Fiat realm, you got to play by their rules and they are rules are nasty when it comes and when I say they I mean the United States government the rules are nasty when it comes to taxes because they Take a time to clarify it yet. Now time is a keyword from when I just in that sentence. I just said in time. It's going to be a lot easier these crypto taxes. It's going to be a lot easier. We're very early on so you can take your chances and Val your wealth and Fiat and offend me and sell your <mark>Bitcoin</mark> and then have to deal with this nightmare. Hello everyone if you haven't heard about an anchor It's the easiest way to make a podcast. That's how I make mine. Let me explain it's free. There's creation tools that allow you to record and edit your podcast right from your phone or your computer. Like I do anchor will distribute your podcast <mark>for</mark> you. So it can be heard on Spotify Apple podcast and many more you can make money just like I do from your podcast with no minimum listenership. It's everything you need to make a podcast in one place. I love the convenience download the free anchor app or go to Anchor dot. F m-- to get started. Anchor dot f m or you'll wait it out. You have a strong hand and it will be easier one day God forbid you ever have to turn it into Fiats. All right into Beyond 2020 <mark>for</mark> but let's read the quote during the United States Congressional meeting titled. This is just happened building blocks of challenge the benefits of blockchain technology <mark>for</mark> small businesses the participants discuss the effect of blockchain to small businesses at the Gathering protocol Labs General council member Marvin", "Start Time (s)": 314.2, "End Time (s)": 432.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Spotify Apple podcast and many more you can make money just like I do from your podcast with no minimum listenership. It's everything you need to make a podcast in one place. I love the convenience download the free anchor app or go to Anchor dot. F m-- to get started. Anchor dot f m or you'll wait it out. You have a strong hand and it will be easier one day God forbid you ever have to turn it into Fiats. All right into Beyond 2020 <mark>for</mark> but let's read the quote during the United States Congressional meeting titled. This is just happened building blocks of challenge the benefits of blockchain technology <mark>for</mark> small businesses the participants discuss the effect of blockchain to small businesses at the Gathering protocol Labs General council member Marvin Amore said that doing your taxes <mark>for</mark> crypto is the worst nightmare when asked tax treatment is very complicated. It's not ready <mark>for</mark> prime time yet, but in time in time dudes, so hey if you want to play in the Fiat realm you're offending me, but you'll have to deal with it. So don't say you weren't warned when like stacking set. So this who is this dude. He says bitcoinmeister beware the <mark>Bitcoin</mark> Inquisition. Oh, no, I you know, I'm not worried about things like that. All those fitting in is overrated. People want to do those virtue sing if they want to that's that Purity purity test people they're wasting their time with the Meister bring on the Inquisition to me. Oh, look who is in the house? I was thinking about you lately Shane. All Rick. I was", "Start Time (s)": 376.1, "End Time (s)": 495.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "when asked tax treatment is very complicated. It's not ready <mark>for</mark> prime time yet, but in time in time dudes, so hey if you want to play in the Fiat realm you're offending me, but you'll have to deal with it. So don't say you weren't warned when like stacking set. So this who is this dude. He says bitcoinmeister beware the <mark>Bitcoin</mark> Inquisition. Oh, no, I you know, I'm not worried about things like that. All those fitting in is overrated. People want to do those virtue sing if they want to that's that Purity purity test people they're wasting their time with the Meister bring on the Inquisition to me. Oh, look who is in the house? I was thinking about you lately Shane. All Rick. I was wondering where you are. I made a live show. Thank you <mark>for</mark> helping me have strong hands. I'm so excited <mark>for</mark> the next 5 to 10 years, dude. You should be and you got a beautiful family. A out there they're going to be really happy about but Shane did you think the NWC by the way, I felt I felt like we talked about and wc and one point. I don't know he did did you I hope you did mwc because your family want to thank you in the future you I don't know. You said send me e-mail about that if you did that <mark>for</mark> I wanted to I wanted to send you an email about it. But I hope everything is going well up there and people are not panicking like they are in Seattle or making a big deal. I don't know what's going on in your neck of the Northwest but Pray, I want to get to the North best us soon. Well this year hopefully maybe later this year. You never know. Alright, long live the Pacific Northwest beautiful. So moving on. Let's go to South Korea here know before we go to South Korea. Let's go to Vortex talking about this. Let's go to New", "Start Time (s)": 439.6, "End Time (s)": 559.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you got a beautiful family. A out there they're going to be really happy about but Shane did you think the NWC by the way, I felt I felt like we talked about and wc and one point. I don't know he did did you I hope you did mwc because your family want to thank you in the future you I don't know. You said send me e-mail about that if you did that <mark>for</mark> I wanted to I wanted to send you an email about it. But I hope everything is going well up there and people are not panicking like they are in Seattle or making a big deal. I don't know what's going on in your neck of the Northwest but Pray, I want to get to the North best us soon. Well this year hopefully maybe later this year. You never know. Alright, long live the Pacific Northwest beautiful. So moving on. Let's go to South Korea here know before we go to South Korea. Let's go to Vortex talking about this. Let's go to New York state where a mining. Power company is mining <mark>Bitcoin</mark> every day. This is great stuff Vortex points out to ramp up at X. Then too long a power plant in New York sets up it in. This is what he's talking about a power plant new its own <mark>Bitcoin</mark> mining operation using the electricity it produces to generate about $50,000 worth of cryptocurrency everyday. And of course, of course if you're familiar, If this channel I have been talking about Steve Barber who's been doing this in Canada. I've been talking about him since early 2018 so <mark>for</mark> two years, so this should not be a shock to you that other power related entities are doing this. He does it with excess natural gas. It's the same type of same same base layer deal there. Okay, using extra capacity to create <mark>Bitcoin</mark> through mining now the another statistic something. From Bloomberg who wrote about this.", "Start Time (s)": 506.0, "End Time (s)": 625.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "this. Let's go to New York state where a mining. Power company is mining <mark>Bitcoin</mark> every day. This is great stuff Vortex points out to ramp up at X. Then too long a power plant in New York sets up it in. This is what he's talking about a power plant new its own <mark>Bitcoin</mark> mining operation using the electricity it produces to generate about $50,000 worth of cryptocurrency everyday. And of course, of course if you're familiar, If this channel I have been talking about Steve Barber who's been doing this in Canada. I've been talking about him since early 2018 so <mark>for</mark> two years, so this should not be a shock to you that other power related entities are doing this. He does it with excess natural gas. It's the same type of same same base layer deal there. Okay, using extra capacity to create <mark>Bitcoin</mark> through mining now the another statistic something. From Bloomberg who wrote about this. No Marty bent also wrote about this the latest operation coming to you live from upstate New York, where a power plant pushing natural gas to their local grid as decide to fit their operation with some supplement guide to fit their operation with some supplementary remaining it the harness untapped energy during times when there isn't that much demand from the grid allowing the power plant. Stay open longer than otherwise would be possible helping to keep people employed and even out the energy load over the course of the whole year instead of just Peak Seasons. So dude, they're employing people. They're using extra capacity. It's great. If this is a beautiful thing <mark>for</mark> all the haters of Bitcoin, you show them this And probably still probably hate", "Start Time (s)": 557.8, "End Time (s)": 677.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "type of same same base layer deal there. Okay, using extra capacity to create <mark>Bitcoin</mark> through mining now the another statistic something. From Bloomberg who wrote about this. No Marty bent also wrote about this the latest operation coming to you live from upstate New York, where a power plant pushing natural gas to their local grid as decide to fit their operation with some supplement guide to fit their operation with some supplementary remaining it the harness untapped energy during times when there isn't that much demand from the grid allowing the power plant. Stay open longer than otherwise would be possible helping to keep people employed and even out the energy load over the course of the whole year instead of just Peak Seasons. So dude, they're employing people. They're using extra capacity. It's great. If this is a beautiful thing <mark>for</mark> all the haters of Bitcoin, you show them this And probably still probably hate it Palin that like button. Okay. Now that we're going to South Korea and people from they 2017 remember when it was wild and wacky in South Korea. I even got the visit South Korea. Thanks to a very awesome dude out there and hang out in I was in Busan most of the time but thanks to the very awesome dude out there. I got to go to Seoul also, which was freezing at that time but now and it was wild and wacky. Yeah. Then they they went the complete other direction and scared people and well now today we got new South Koreans amendment to special Reporting Act passes cryptocurrency now fully legal in South Korea. Awesome, but there's one not awesome part of it. The reason it's legal is because now the exchanges and all sorts of third parties that you may have to deal with in South", "Start Time (s)": 611.6, "End Time (s)": 731.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "dude I heard your stories you really let those ladies with you around sometime. Not all but some you know who I'm talking to dude. But anyway, there's different cultures in this world. It's a lovely place to visit even with all that Panic out there. Now, I would have visit now if you know the United States would let me back in. Hey watch yesterday's show. By the way. If you want to hear me talk about all these panic. The prison's everyone is throwing themselves in okay yesterday show I talked about the situation with travel going on and I think is ridiculous. And what just watch yesterday's the end of yesterday's show the end of yes, it was a good one pound that like button and also watch the Tuesday show. I talked about Brad Mills and the survey that he did. I don't know how anyone everyone should be tweeting about this brand Mill survey. Okay. It's a real survey of what Think about <mark>Bitcoin</mark> a scientific nothing not just a Twitter. Is that a Twitter survey? Not a Twitter poll. He paid <mark>for</mark> this. Okay, so go to Tuesday's show right now watch it will probably talk about it on tomorrow's show. I'll prop Brad back on this week in <mark>Bitcoin</mark> in one to two weeks because I have a 10-week rotation and he was on like eight to nine weeks ago. He's a good got a good podcast out there. So let's talk about lightning Network <mark>for</mark> you lightning Network freaks. Very interesting article about the future here. I don't know if this will pick up. I don't know. This will be a killer app how the lightning Network could improve encrypted messages. So lightning Network encrypted messages combo, you tech-heads can read it tell me how realistic it is if it's going to really happen if it's and if it's can make a big difference, I still hesitate with some of these Technologies is I just know with simplify things. <mark>For</mark> the Common Man and this seems kind of complicated but who knows but read it. So", "Start Time (s)": 759.2, "End Time (s)": 878.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "everyone should be tweeting about this brand Mill survey. Okay. It's a real survey of what Think about <mark>Bitcoin</mark> a scientific nothing not just a Twitter. Is that a Twitter survey? Not a Twitter poll. He paid <mark>for</mark> this. Okay, so go to Tuesday's show right now watch it will probably talk about it on tomorrow's show. I'll prop Brad back on this week in <mark>Bitcoin</mark> in one to two weeks because I have a 10-week rotation and he was on like eight to nine weeks ago. He's a good got a good podcast out there. So let's talk about lightning Network <mark>for</mark> you lightning Network freaks. Very interesting article about the future here. I don't know if this will pick up. I don't know. This will be a killer app how the lightning Network could improve encrypted messages. So lightning Network encrypted messages combo, you tech-heads can read it tell me how realistic it is if it's going to really happen if it's and if it's can make a big difference, I still hesitate with some of these Technologies is I just know with simplify things. <mark>For</mark> the Common Man and this seems kind of complicated but who knows but read it. So if you're a Tech head if you're not Tech head and don't read it because I did, you know, you can only do so much during a game now. ZDNet has an article about malicious Chrome extension caught stealing Ledger wallet recovery seeds Okay, let your wallet people. You don't need a Chrome extension. So why the heck didn't even download it in the first place. Don't do that. Don't don't frivolously never put in your freaking recovery seeds, dude. So it looks like you have to type in your recovery seeped into the keyboard. You can just type it in to the treasurer and then you know, it's all good. I think you're not getting fooled by something malicious like this, but they're going to keep on trying people out there from the", "Start Time (s)": 812.7, "End Time (s)": 932.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "seems kind of complicated but who knows but read it. So if you're a Tech head if you're not Tech head and don't read it because I did, you know, you can only do so much during a game now. ZDNet has an article about malicious Chrome extension caught stealing Ledger wallet recovery seeds Okay, let your wallet people. You don't need a Chrome extension. So why the heck didn't even download it in the first place. Don't do that. Don't don't frivolously never put in your freaking recovery seeds, dude. So it looks like you have to type in your recovery seeped into the keyboard. You can just type it in to the treasurer and then you know, it's all good. I think you're not getting fooled by something malicious like this, but they're going to keep on trying people out there from the Ukraine from Asia from where it <mark>for</mark> the United States everywhere. There are those are scams. Okay. Those are true stands we abuse that They're gonna be a lot of people out there. They're just trying to rob you all the time and you just got to be very very careful. And so the best thing to do is never get it into your Ledger never have to get into your treasure. Why do you have to get into there? Anyway, the only reason you need to get into their well, there's one good reason signing a message <mark>for</mark> your airdrop Crypt of dividend that's freaking awesome because we love to get free crypto dividends that we turn in the Bitcoin, but otherwise The only read the other reasons get in. There's the move <mark>Bitcoin</mark> around to God forbid send it to him exchanged it to sell it. No, you took to the cool thing about having her. Your own a hardware wallet, you can create as many receive addresses as you want to save them all somewhere. And then", "Start Time (s)": 873.8, "End Time (s)": 993.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "those are scams. Okay. Those are true stands we abuse that They're gonna be a lot of people out there. They're just trying to rob you all the time and you just got to be very very careful. And so the best thing to do is never get it into your Ledger never have to get into your treasure. Why do you have to get into there? Anyway, the only reason you need to get into their well, there's one good reason signing a message <mark>for</mark> your airdrop Crypt of dividend that's freaking awesome because we love to get free crypto dividends that we turn in the Bitcoin, but otherwise The only read the other reasons get in. There's the move <mark>Bitcoin</mark> around to God forbid send it to him exchanged it to sell it. No, you took to the cool thing about having her. Your own a hardware wallet, you can create as many receive addresses as you want to save them all somewhere. And then when you someone needs to send you busy or you need to send yourself <mark>Bitcoin</mark> <mark>for</mark> some reason you just all you do is you send it to that address. You don't have to get in here Tresor to create new ones as you already created. A lot of them. You don't need to get into your Treasurer ledger to receive Bitcoin. Some of these don't know that some newbies don't know that at all, but eight It's a growing space. So I will state the obvious sometimes because the obvious is not obvious <mark>for</mark> everybody now. The always entertaining <mark>Bitcoin</mark> Rabbi has a tweet out there that is a <mark>for</mark> in honor of Purim which is next Tuesday where we read the megillah, but he made a <mark>Bitcoin</mark> talmud tractate now. I'm not too sure when it says I know it says <mark>Bitcoin</mark> and Hebrew in the middle of the tractate. Hopefully he'll give a translation a to it. But he's a funny guy that's linked to below get his book will. See what he does <mark>for</mark> Purim in terms of Bitcoin. It should be", "Start Time (s)": 937.0, "End Time (s)": 1056.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you someone needs to send you busy or you need to send yourself <mark>Bitcoin</mark> <mark>for</mark> some reason you just all you do is you send it to that address. You don't have to get in here Tresor to create new ones as you already created. A lot of them. You don't need to get into your Treasurer ledger to receive Bitcoin. Some of these don't know that some newbies don't know that at all, but eight It's a growing space. So I will state the obvious sometimes because the obvious is not obvious <mark>for</mark> everybody now. The always entertaining <mark>Bitcoin</mark> Rabbi has a tweet out there that is a <mark>for</mark> in honor of Purim which is next Tuesday where we read the megillah, but he made a <mark>Bitcoin</mark> talmud tractate now. I'm not too sure when it says I know it says <mark>Bitcoin</mark> and Hebrew in the middle of the tractate. Hopefully he'll give a translation a to it. But he's a funny guy that's linked to below get his book will. See what he does <mark>for</mark> Purim in terms of Bitcoin. It should be fun <mark>for</mark> everyone who celebrates pour em on Tuesday. It's coming up. Well time is time is flying by and on Saturday show. By the way. I will talk about the real tell mood because we're going Beyond <mark>Bitcoin</mark> on Saturday show and some other Jewish topics life after death type of stuff. But that's Saturday show. You never know what you're going to get. You do know. It's going to be Beyond Bitcoin. And I showed this shirt already. Can you see it? I don't know because I'm not even looking at the screen right now. But does anyone else have any other questions? No, they do not. All right. That is the end of the show then. end Going once going twice. Sold we're at the end of the show. Oh, yeah, let me show the shirt. He was in motion. He gave it to me at the that", "Start Time (s)": 993.9, "End Time (s)": 1113.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and some other Jewish topics life after death type of stuff. But that's Saturday show. You never know what you're going to get. You do know. It's going to be Beyond Bitcoin. And I showed this shirt already. Can you see it? I don't know because I'm not even looking at the screen right now. But does anyone else have any other questions? No, they do not. All right. That is the end of the show then. end Going once going twice. Sold we're at the end of the show. Oh, yeah, let me show the shirt. He was in motion. He gave it to me at the that legendary event. Yes you go. You should see the video where I last wore this shirt. We had a two special guests on be some of you might remember that show it kind of sure it it made a lot of people get the gossip mode in it. All right. I'm Adam Meister. Don't be a <mark>Bitcoin</mark> yenta. I'm Adam Meister the Bitcoin. Somebody just threw up Meister tune in Saturday. I mean Friday tomorrow 2 p.m. This week in <mark>Bitcoin</mark> to PMI Baltimore time 7 p.m. London time 11:00 a.m. Los Angeles time want Galt atomizer will be the host. It's Ken bozak making a great return and crisp like, so see you guys tomorrow pound that like button. I feel like I forgot something, but I probably didn't bye-bye.", "Start Time (s)": 1072.9, "End Time (s)": 1164.8, "Clip Length (min)": 1.53, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:2heyDaTfMQQx3uXnJlpR9V", "episode_name": "The 1 Bitcoin Show- BTC power plant mining in NY! Lots of coinjoining! Fiat realm tax nightmare, South Korea, BTC Talmud, Q&A!", "episode_description": "Welcome to the 1 Bitcoin Show! Amazing coinjoin statistic! More power plants to get into BTC mining? Don't play in the fiat realm! Taxes are a nightmare! An attempt by hackers to steal from ledgers! Lightning network, BTC talmud, much more! \u00a0Recorded in Los Angeles, CA! Watch the show here- https://www.youtube.com/watch?v=694JBiZapqI Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 4.769042, "explanation": "{\n  \"value\": 4.769042,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.7069783,\n      \"description\": \"weight(word_list:bitcoin in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.7069783,\n          \"description\": \"score(LMDirichletSimilarity, freq=33.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.590746,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 33.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.062063914,\n      \"description\": \"weight(word_list:for in 42) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.062063914,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.9458315,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.88376755,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 2840.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Hello and welcome to MHS podcast celebrating International Women's Day 2020. Our podcast is based on Elizabeth days podcast how to fail which is a celebration of things going wrong and what we can learn from that Elizabeth interviews the celebrity <mark>for</mark> them to discuss failings in their life both in their personal life and in their career showing how much you can grow from things that maybe haven't gone to plan. So, my name's Beth Wilson, I'm marketing comes officer at mha and I'm the host <mark>for</mark> this episode today. I have the lovely off Neil Blake with me who is the newly-appointed campaigns manager at NHA. So let's get to it. So your first finger is okay. So my first failure would be in my first management career first management role. Sorry. So it's more of a career failure. Totally thought that once you become a manager the aim of that is to overwork yourself. All right, I like work as hard as you can or", "Start Time (s)": 6.5, "End Time (s)": 81.0, "Clip Length (min)": 1.24, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but totally had a knock-on effect in my outputs and on your well-being on your well-being absolutely lacquered completely never switching off like you would be watching a movie with your family when you're not watching it. I'm on my laptop like doing it like not taking the time to look after myself and realizing that that was important in order to do really good job until I Spend out until I literally was like I can't do this anymore. Like this is killing me and it just takes away Health. It takes away just your capacity in general or what you're able to give to you people you love or equal to given your role. Like he's just can't do any of that my biggest learning from it as a hundred percent, but never to do that again that it that I remember someone said to me during my career Journey. Someone said if it doesn't get done today, There's nothing wrong with it being done tomorrow and it was one of the guys like keenest things. I needed to hear because I was a big person <mark>for</mark> finish it today. Don't leave anything <mark>for</mark> tomorrow, you know clear less kind of policy, but like actually realized I wasn't working <mark>for</mark> anyone give things the time at they need manage expectations. So you don't get it done properly and the world to not be going around. It's really not like it's not going to end with a lot doing brain surgery here. Like it's it can be handled as long as you handle it. I think so that was like a huge learning curve <mark>for</mark> me. And I think a lot of people can probably take something from that and maybe recognized something in them. Even if they're not management. You know, I think there's times when if you take your work phone home or your laptop, you can just end up naturally just like I'll just check it. Oh, yeah all the time. Yeah, especially if you like if you have any kind of social media in your role as well that yeah, I'm staying like I remember applying some people's messages. I like it's really about like nah. Nonsense like yeah, it was it woke me up. And I was like, well, I need to keep that that green button from", "Start Time (s)": 94.2, "End Time (s)": 213.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that we were apply under like a certain amount of time. So I'd reply and what I'd stay and then go back to bed like that since saying like what are you doing? Like at some point? I just go. No. Yeah, especially doesn't matter what I'm half asleep. Yeah. Yeah. No, I think sometimes and focusing on Things there is that Essence to prove yourself even more. I don't want to let anybody down you don't want to like so if it takes you five minutes to do something they feel like needs to be done and you kind of want to do it. But actually it's realizing that I don't have to do that and I'm proving myself and what I actually deliver not in those little things that are wasting my time, I really unproductive. Yeah. Yeah, cool. So that's your first one. So, what would you say? Say is your second feel you had written down so I wrote down because I thought about this <mark>for</mark> a while. Yeah, so I think a biggest failure of mine was not asking <mark>for</mark> the things I needed when I needed them, right and especially when I thought I deserved them typical like typical example pay Rises. So you like not walking into the room and having the conversation that you know, Well needs to be had and you've worked hard enough you the time in fact, you're probably under are in my situation. I wasn't the paid prior to that. Ask. This wasn't here. Mha. This was somewhere else and I knew that I was already been underpaid I thought well, let me show them what I can do that. I liked my review. I let them know that you under yeah, but it was so difficult. I can't like minimize just how difficult it was to walk in. Skinned alive. Yes.", "Start Time (s)": 214.5, "End Time (s)": 329.2, "Clip Length (min)": 1.91, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "right and especially when I thought I deserved them typical like typical example pay Rises. So you like not walking into the room and having the conversation that you know, Well needs to be had and you've worked hard enough you the time in fact, you're probably under are in my situation. I wasn't the paid prior to that. Ask. This wasn't here. Mha. This was somewhere else and I knew that I was already been underpaid I thought well, let me show them what I can do that. I liked my review. I let them know that you under yeah, but it was so difficult. I can't like minimize just how difficult it was to walk in. Skinned alive. Yes. I think there's this men have no issue doing it. And when I turn to my like guy friends and I'm like, yeah, do you like just that? I don't get like every six months. I'll go and ask <mark>for</mark> a pay rise. I know somebody that every time he gets a new task added to his role he goes and asks <mark>for</mark> it to be married in his pay rise. Wow, and and that is the time to do that and he's fine with that and he's like, well I have to you can't fuck. Fight <mark>for</mark> our skin like it's sorta like great attitude. Yeah. It's not intrinsic in me. I don't know if the no I think no not until it's like let me like do everything I can <mark>for</mark> you on till I ask <mark>for</mark> a penny like do you know what I mean? It's find it awkward is so awkward, but then I realized that actually the value of what we value in ourselves isn't based on what we paid actually what we values being able to pay <mark>for</mark> the things that make cuz quite Happy yeah, everything and if you're doing the roll and you know that you can match that payment somewhere else and you know that actually you deserve that then what what harm is it in asking like truly. I really it's that big thing of if you don't ask you don't get and if they don't know they're not going to go ahead we", "Start Time (s)": 286.0, "End Time (s)": 405.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Fight <mark>for</mark> our skin like it's sorta like great attitude. Yeah. It's not intrinsic in me. I don't know if the no I think no not until it's like let me like do everything I can <mark>for</mark> you on till I ask <mark>for</mark> a penny like do you know what I mean? It's find it awkward is so awkward, but then I realized that actually the value of what we value in ourselves isn't based on what we paid actually what we values being able to pay <mark>for</mark> the things that make cuz quite Happy yeah, everything and if you're doing the roll and you know that you can match that payment somewhere else and you know that actually you deserve that then what what harm is it in asking like truly. I really it's that big thing of if you don't ask you don't get and if they don't know they're not going to go ahead we think you deserve more money like at the end of the day their profit business. Like why would they turn to me and say we want to pay you more? I mean some organizations do Foster that culture but on most times. Yeah. Whoo. <mark>For</mark> a moment. Yeah, you know, I mean, so I think I think most of the time managers do know. Yeah, they do know when you weren't actually deserve more money, but sometimes they just wait <mark>for</mark> you to come to them and I think that realization of well, it's either gonna stay the same and I've asked or it does get better. Yeah, and at least then, you know, if you do have a know you can decide, you know to take stock and think of it somewhere you want to stay or not kind of stuff have to ask the question first. Yeah. So that was one of my biggest things where I just I just was God. I like worked myself up so much to do it. Like oh my God what they say not to be just found that it was really easy conversation and sometimes conversations. They've had before. Yeah, it's not the first time I've had someone else picked it up in your head under here and then such a big deal because it affects you more than that. Of course it does, you know of interpret that it affects you all the time. Yeah. Yeah.", "Start Time (s)": 357.9, "End Time (s)": 477.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know to take stock and think of it somewhere you want to stay or not kind of stuff have to ask the question first. Yeah. So that was one of my biggest things where I just I just was God. I like worked myself up so much to do it. Like oh my God what they say not to be just found that it was really easy conversation and sometimes conversations. They've had before. Yeah, it's not the first time I've had someone else picked it up in your head under here and then such a big deal because it affects you more than that. Of course it does, you know of interpret that it affects you all the time. Yeah. Yeah. I think I do think that. If you are driven by money that you're probably more likely to ask I think if you're driven by what you do, you're not you're actually more likely to be more deserving of it because you actually really care about yeah outputs are great. So like they're the people that should be asking but tend to be the don't because they're driven <mark>for</mark> me driven by what we do. Yeah, and I enjoy it. Yeah, and I just doing a good job in general as well. Yeah, it's how you feel good at work. Yeah. It's interesting. Said about the difference in your you know in your guy weighs a hundred percent. They like it's brilliant like so Brazen, but the whole like it's not a bad thing. They have they are not scared by asking that question and it may it does make me think is that is that because it's not tall is it just all those things like their life experiences that kind of accumulate them together like, you know, is it what is it social conditioning? I don't know like a they always been told like ask <mark>for</mark> what you want. Yeah, I'm go go <mark>for</mark> it kind of thing and to not worry bother ya told his woman to go the status quo go over the phone. Don't push too much. Don't ruffle any feathers. Yeah, because at the end of the day, there's so many more woman's woman so many words <mark>for</mark> women when they do things like", "Start Time (s)": 441.6, "End Time (s)": 561.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "because they're driven <mark>for</mark> me driven by what we do. Yeah, and I enjoy it. Yeah, and I just doing a good job in general as well. Yeah, it's how you feel good at work. Yeah. It's interesting. Said about the difference in your you know in your guy weighs a hundred percent. They like it's brilliant like so Brazen, but the whole like it's not a bad thing. They have they are not scared by asking that question and it may it does make me think is that is that because it's not tall is it just all those things like their life experiences that kind of accumulate them together like, you know, is it what is it social conditioning? I don't know like a they always been told like ask <mark>for</mark> what you want. Yeah, I'm go go <mark>for</mark> it kind of thing and to not worry bother ya told his woman to go the status quo go over the phone. Don't push too much. Don't ruffle any feathers. Yeah, because at the end of the day, there's so many more woman's woman so many words <mark>for</mark> women when they do things like that would become like she's quite aggressive. And yeah, she's quite the b word it starts. I think I'm people don't be caught that. So it all comes back to how people view was doesn't it, which is really shameful because actually it's nothing to do with that. You've done the journey. And anyone else in your old would have asked <mark>for</mark> it. So it's rare. I mean obviously there's times when you shouldn't but if you really believed that you should get one them. Yeah, I think we've got I know I've gotta get better at having those conversations and I do feel like the I understand do I have develops loads from that time where I had to first ask <mark>for</mark> one, but it is so So terrifying. Yeah, it is so totally yeah. Yeah, it shouldn't be but it is it is kind of like actuate it all until it until it just becomes normal own the more you do it the more normally as I guess. In fact, it's just fostering those conversations in general that are yeah and I suppose", "Start Time (s)": 499.8, "End Time (s)": 619.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is really shameful because actually it's nothing to do with that. You've done the journey. And anyone else in your old would have asked <mark>for</mark> it. So it's rare. I mean obviously there's times when you shouldn't but if you really believed that you should get one them. Yeah, I think we've got I know I've gotta get better at having those conversations and I do feel like the I understand do I have develops loads from that time where I had to first ask <mark>for</mark> one, but it is so So terrifying. Yeah, it is so totally yeah. Yeah, it shouldn't be but it is it is kind of like actuate it all until it until it just becomes normal own the more you do it the more normally as I guess. In fact, it's just fostering those conversations in general that are yeah and I suppose like if you have an honest and open conversation with your manager quite regularly about things like that. Yeah, then it won't come as a surprise and all that kinda thing like yeah just be easier to speak about if you've already spoken. Three we got a ninja may be exactly I totally agree, but I do think as well. There's something to be said <mark>for</mark> we go she ate in an interview. I think yeah, there's a percentage somewhere. I hate that don't have it. But there's plenty of somewhere about the fact that men are more likely to negotiate that interview salary and I'm okay that first time we are offered most of the time in most organizations, they're expecting you to negotiate so it's actually just a bit under like a bit like a sales pitch or whatever. Oh and then our there's a setup <mark>for</mark> a doubt. We have to find it. Maybe put it on the captions <mark>for</mark> this but they are way more likely to go. She ate that price and what kinda cake offered the role <mark>for</mark> his women are way more likely to say. Yeah, it's advertisers that I'll take it. Thank you exactly. I'm just happy just like what is what is That woman we think that oh my gosh, that's the final thoughts which is sad. I'll pay it. You can negotiate a", "Start Time (s)": 577.1, "End Time (s)": 696.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "an interview. I think yeah, there's a percentage somewhere. I hate that don't have it. But there's plenty of somewhere about the fact that men are more likely to negotiate that interview salary and I'm okay that first time we are offered most of the time in most organizations, they're expecting you to negotiate so it's actually just a bit under like a bit like a sales pitch or whatever. Oh and then our there's a setup <mark>for</mark> a doubt. We have to find it. Maybe put it on the captions <mark>for</mark> this but they are way more likely to go. She ate that price and what kinda cake offered the role <mark>for</mark> his women are way more likely to say. Yeah, it's advertisers that I'll take it. Thank you exactly. I'm just happy just like what is what is That woman we think that oh my gosh, that's the final thoughts which is sad. I'll pay it. You can negotiate a market broad you <mark>beginners</mark> you your house like anything that's a big purchase in your life and a big investment which like a job is a big investment in your life and into your time. We don't feel like we can just say thank you. Yeah, that's kind of what I'm on now. So yeah. Yeah, I'm just grateful just so grateful. Thank you so much. Yeah. Yeah, I'll take it. Having radical conversations with friends. Yeah, like so it's more of a personal failure think <mark>for</mark> a long time. I was a very good giving friend. Really good at giving I think if you are like a heart person few highly empathetic you can show that by being a giving person and like showing your friends how much you care", "Start Time (s)": 638.9, "End Time (s)": 758.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "now. So yeah. Yeah, I'm just grateful just so grateful. Thank you so much. Yeah. Yeah, I'll take it. Having radical conversations with friends. Yeah, like so it's more of a personal failure think <mark>for</mark> a long time. I was a very good giving friend. Really good at giving I think if you are like a heart person few highly empathetic you can show that by being a giving person and like showing your friends how much you care about them and stuff, but I was rubbing my friends of like their own growth by not having really radical conversation that actually need to come here. So have you got an example that may be? Okay, so one friend <mark>for</mark> example, it's just trivial thing. So she was dating this guy that was so awful <mark>for</mark> her. Awful, my nothing we've all been there we've opened and I could see outside looking in that he was totally use and that's a conversation. I should have had my friends right? I was well partly right in the sense of we all need to work our own things out sometimes sometimes the best at that it is today. Yeah <mark>for</mark> yourself. However to not even have like gone. I'm not sure our yeah. Are you sure this is what I'm seeing. What do you think and like having that conversation? That robbed her and actually in the end. It's exactly what he did. He did use our he'd completely left and like she was left with no preparation <mark>for</mark> it. She could have been better prepared <mark>for</mark> that. Even if she decided not to take my advice. Yeah, she could have just known you were right. I suppose it's hard. It's really hard. Isn't it? Yes is to stand up to that friend. Yeah and be open about something that she's obviously investing. I'd like it's miming and can say", "Start Time (s)": 713.2, "End Time (s)": 832.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "could have just known you were right. I suppose it's hard. It's really hard. Isn't it? Yes is to stand up to that friend. Yeah and be open about something that she's obviously investing. I'd like it's miming and can say yeah. Yeah. Yeah, it's hard completely. It was a so I It often but there is a podcast could radical Candor and it's an American podcasts fantastic and it's basically about having canned really radical conversations to get the desires you want. It's based on Career rolls and stuff like that and like how to have radical conversations with your manager. But there's a real key bit in it about feedback and how feedback actually helps all of us to give feedback helps the person giving it and to get feedback helps you become better when we have such a resistance against feedback as a question. Like what is your feedback trying to actually say to me. Are you telling me I'm not good enough. Yeah, and this whole like constructive criticism thing. Is that kind of threw it out the window just feels like this is mm. Yeah, but like actually feedback to be helpful <mark>for</mark> everyone involved especially if it's positioned, right? Obviously, you have to be nice about it. But to have like now looking back that key part that I've learned and applied to my rolls. I didn't apply it kind of to my relationships just because actually we that The best thing about friendship developing each other growing together and being honest and trust. Yeah. Yeah, and now I would say I'm competing not afraid to have those conversations with friends, but I do think it's so so important. It's really important to just be able to it's not about being that I think he's awful and yeah ever date that guy but that's not that's yeah back to the hell. No, she just feels now there's just about friendship. Actually. It's about be like I love you, and I really want the best <mark>for</mark> you. Yeah, I'm seeing this. Yeah, can you help me understand it? Yeah, I mean and then just be like, oh cool I get you and I hope I'm wrong we go problem.", "Start Time (s)": 820.8, "End Time (s)": 940.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "say to me. Are you telling me I'm not good enough. Yeah, and this whole like constructive criticism thing. Is that kind of threw it out the window just feels like this is mm. Yeah, but like actually feedback to be helpful <mark>for</mark> everyone involved especially if it's positioned, right? Obviously, you have to be nice about it. But to have like now looking back that key part that I've learned and applied to my rolls. I didn't apply it kind of to my relationships just because actually we that The best thing about friendship developing each other growing together and being honest and trust. Yeah. Yeah, and now I would say I'm competing not afraid to have those conversations with friends, but I do think it's so so important. It's really important to just be able to it's not about being that I think he's awful and yeah ever date that guy but that's not that's yeah back to the hell. No, she just feels now there's just about friendship. Actually. It's about be like I love you, and I really want the best <mark>for</mark> you. Yeah, I'm seeing this. Yeah, can you help me understand it? Yeah, I mean and then just be like, oh cool I get you and I hope I'm wrong we go problem. Yeah, this is what I'm seeing but I'm here <mark>for</mark> you. Yeah, it's about checking in I suppose as well and asking those questions whole life. Are you happy? You know, you see it like this. Sometimes they might see it but they're like, yeah, but I'm helping them and maybe there's a reason they see that you're not privy to because it's their private relationship. So Even in that sense. Yeah, like and it really like really looking back like even more so it she was so hurt and she was really hurt because she thought as well I didn't like him right as she thought I wasn't happy <mark>for</mark> her like that. That's why I never had the conversation. You just sensing that there was some off nurse and she's like and like and then after all came by and you know, we had the conversation she was at our be I wish you'd just told me. It's like and I do", "Start Time (s)": 871.1, "End Time (s)": 989.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you. Yeah, it's about checking in I suppose as well and asking those questions whole life. Are you happy? You know, you see it like this. Sometimes they might see it but they're like, yeah, but I'm helping them and maybe there's a reason they see that you're not privy to because it's their private relationship. So Even in that sense. Yeah, like and it really like really looking back like even more so it she was so hurt and she was really hurt because she thought as well I didn't like him right as she thought I wasn't happy <mark>for</mark> her like that. That's why I never had the conversation. You just sensing that there was some off nurse and she's like and like and then after all came by and you know, we had the conversation she was at our be I wish you'd just told me. It's like and I do your feelings and it's all fine. But actually not having the conversation left more to be said the actually I was saying that wasn't it at all course. I'm happy. I want to be super happy <mark>for</mark> ya. One of the things <mark>for</mark> you and I think there's something really powerful in like women being there <mark>for</mark> other women over a hundred percent, you know, and and seeing that in someone or in someone's relationship or in another friendship or something hundred and and going on your own experiences of like all of a sudden If you would like another friend or happened to me or yeah, whatever and you can kind of you know, go back on that and be like, oh, well, I'm not saying this is exactly the same situation, but, you know see this. Yes. Yeah and sort of, you know, we can grow from learning from other people said, I think once we relinquish the idea that people only have bad intentions and that once we relinquish that we just think okay. Let me just listen to what they're saying. Actually there's so much. Learning to be done at your server and at the end of the day, there are true friend. Yeah, you know, it should come from a bad place. Anyway, you know should be coming from a really good place of like like you said before I love you nervous <mark>for</mark> you. So kind of", "Start Time (s)": 942.3, "End Time (s)": 1062.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I'm happy. I want to be super happy <mark>for</mark> ya. One of the things <mark>for</mark> you and I think there's something really powerful in like women being there <mark>for</mark> other women over a hundred percent, you know, and and seeing that in someone or in someone's relationship or in another friendship or something hundred and and going on your own experiences of like all of a sudden If you would like another friend or happened to me or yeah, whatever and you can kind of you know, go back on that and be like, oh, well, I'm not saying this is exactly the same situation, but, you know see this. Yes. Yeah and sort of, you know, we can grow from learning from other people said, I think once we relinquish the idea that people only have bad intentions and that once we relinquish that we just think okay. Let me just listen to what they're saying. Actually there's so much. Learning to be done at your server and at the end of the day, there are true friend. Yeah, you know, it should come from a bad place. Anyway, you know should be coming from a really good place of like like you said before I love you nervous <mark>for</mark> you. So kind of just telling you now because I don't want you to be her exactly I like it's fostering that in everyone's life. I think like as as children there is this kind of like, you know, you have this kind of Middle Ground I suppose where everything's fine. We can talk about everything and everyone just agree. Again, it's really agreeable life knowing people disagree with you or your parents. And as I hate them like but like then as we mature, I think sometimes we forget that our conversations need to mature sometimes as well. So we like talk about things. We kind of want our friends to be like a great idea. Yeah, I like but actually it's not a great idea. That's really a great idea because we don't want to be like a tyrant. Fred want to be the person people can fund where the night we don't want to be on people's backs. But actually those are some of the most healthiest relationships anybody could ever have had their the things people value you look at", "Start Time (s)": 1000.8, "End Time (s)": 1120.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a great idea because we don't want to be like a tyrant. Fred want to be the person people can fund where the night we don't want to be on people's backs. But actually those are some of the most healthiest relationships anybody could ever have had their the things people value you look at especially mha when we look at people who talk well of their life growing up they talk about the people they surrounded themselves where they talk about great like true friends they had and that they're not true friends because they just sailed through life and it's because they kept going through to yeah and coming out the other end. So I think absolutely actually the best thing we can do. Is happening really difficult conversations honesty is the best policy is absolutely so yeah, I guess there are my three failure stroke learning curve. Yeah, and I'm sure people listening would be able to relate to a lot of that as well. So absolutely like we're all human wrong cigarette or mix exactly and I think it's really nice <mark>for</mark> what this the kind of world. We're in now is woman. Yeah, although there's no has to be done. There's just so much we have done. It's so impressive to see all the women at the table like the different people to see like The Advocates across the across. Mha let alone my other organizations and governments globally. It's great and I think think conversations like this is a bit of makers really better and yeah, it starts with others and bit my bit about picking people up is known about being there <mark>for</mark> each other. Yeah. Yeah even Realizing <mark>for</mark> example that when people are in new roles that that's a little difficult and having someone's going. Hey, how's things and how are you finding it? And don't be afraid to have those conversations nestling, you know, like those conversations are really important because the way we shouldn't shy away from sharing those skills and seeing it in other women to go out. I know it's in your a bit like afraid to put back some, you know to say that one should be said say it make sure you get in", "Start Time (s)": 1105.4, "End Time (s)": 1224.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "think conversations like this is a bit of makers really better and yeah, it starts with others and bit my bit about picking people up is known about being there <mark>for</mark> each other. Yeah. Yeah even Realizing <mark>for</mark> example that when people are in new roles that that's a little difficult and having someone's going. Hey, how's things and how are you finding it? And don't be afraid to have those conversations nestling, you know, like those conversations are really important because the way we shouldn't shy away from sharing those skills and seeing it in other women to go out. I know it's in your a bit like afraid to put back some, you know to say that one should be said say it make sure you get in there and I think Foster and those conversations and encouraging each other to do the things that because maybe a little variable is really good thing to do. Absolutely. So I hope this starts that so and we're going to wrap up. Thank you so much with Neil. Thank you <mark>for</mark> being so honest and open. So this is the end of the first episode but check this space <mark>for</mark> the other ones. Thank you.", "Start Time (s)": 1187.9, "End Time (s)": 1256.3, "Clip Length (min)": 1.14, "show_uri": "spotify:show:1eVQ1SXVyZJ44uGoqg1x5I", "show_name": "MHA | International Women's Day 2020", "show_description": "Our podcast is based on Journalist and Author, Elizabeth Day\u2019s \u2018How to Fail\u2019 podcast and book. If you are unfamiliar with this, Elizabeth Day explores the notion of how we can learn from our own failings, in our personal lives and in our careers. In turn, listeners can learn and feel inspired from hearing about other people\u2019s life stories and how they overcame life\u2019s difficult situations. ", "publisher": "Methodist Homes (MHA)", "episode_uri": "spotify:episode:5kurfyBmPZnOTMvmGVOVqS", "episode_name": "International Women's Day 2020 MHA podcast episode 1 - Othnielle Blake", "episode_description": "Welcome to MHA\u2019s podcast celebrating International Women\u2019s Day 2020. Our podcast is based on Elizabeth Day\u2019s podcast, \u2018How to Fail\u2019 which is a celebration of things going wrong and what we learn from things that maybe haven\u2019t gone to plan. This episode is hosted by Beth Wilson, with guest Othnielle Blake.\u00a0 mha.org.uk ", "score": 4.5730424, "explanation": "{\n  \"value\": 4.5730424,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34343734,\n      \"description\": \"weight(word_list:for in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34343734,\n          \"description\": \"score(LMDirichletSimilarity, freq=45.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3744843,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 45.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.229605,\n      \"description\": \"weight(word_list:beginners in 30) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.229605,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.260652,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.031047,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3608.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "What's up, everyone? Welcome back. This is a bit of a different episode today. This is actually an interview that I did with cave on Divani on his total <mark>Bitcoin</mark> show. So I was a guest on his show and cave-ins super nice guy been putting out a lot of great content around <mark>Bitcoin</mark> a lot of great people on a show really interesting format and had a great conversation with them. So I thought I'd share with you guys here as well just to note the first half there was I think we had some bandwidth issues. So the the audio was spotty in places, but hopefully it's not too disruptive. If you want to follow cave on his podcast is called the total <mark>Bitcoin</mark> podcast and his Twitter handle is at ke y VA en DAV a and I and that's it. Enjoy the show. Let's do it. Hey, John, welcome to the show to the tone Pitkin podcast show. How you doing man? Thanks <mark>for</mark> coming on Jimmy. I'm doing great cave on. Thanks <mark>for</mark> having me man. This little little impromptu this morning, but it's a great way to start my day. Yes, but spontaneous is everything. So listen, John is really funny", "Start Time (s)": 8.1, "End Time (s)": 77.0, "Clip Length (min)": 1.15, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of great content around <mark>Bitcoin</mark> a lot of great people on a show really interesting format and had a great conversation with them. So I thought I'd share with you guys here as well just to note the first half there was I think we had some bandwidth issues. So the the audio was spotty in places, but hopefully it's not too disruptive. If you want to follow cave on his podcast is called the total <mark>Bitcoin</mark> podcast and his Twitter handle is at ke y VA en DAV a and I and that's it. Enjoy the show. Let's do it. Hey, John, welcome to the show to the tone Pitkin podcast show. How you doing man? Thanks <mark>for</mark> coming on Jimmy. I'm doing great cave on. Thanks <mark>for</mark> having me man. This little little impromptu this morning, but it's a great way to start my day. Yes, but spontaneous is everything. So listen, John is really funny because yesterday I was like God I could talks about so many things with you about, you know, related to <mark>bitcoin</mark> and we're going to talk Bitcoin, but then you know, I me and my girlfriend went pretty early to sleep or I don't know we fell asleep. So let me tell his because it's so funny. So hilarious the whole story is so I had a dream where you you and me and another friend. I don't know who it was was we're driving in a car and we started talking and I had my podcasting, you know in the backseat running and I thought okay, you know, it's just recorded. It just have a talk and and then we start talking about <mark>Bitcoin</mark> a while and then after a while, I don't know. Time lapses in my dream. So we start talking about psychedelics and I don't know why is it all about like psychedelic experiences? I have wash. I don't know why you know, maybe the idea was how could we was sort of the context was like, how can we open up people to comprehend or you know to be more receptive to <mark>bitcoin</mark> and so we went to another restaurant, you know, we had to squeeze ourselves into this bench with a lot of other people and with you know, continue", "Start Time (s)": 23.7, "End Time (s)": 143.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So listen, John is really funny because yesterday I was like God I could talks about so many things with you about, you know, related to <mark>bitcoin</mark> and we're going to talk Bitcoin, but then you know, I me and my girlfriend went pretty early to sleep or I don't know we fell asleep. So let me tell his because it's so funny. So hilarious the whole story is so I had a dream where you you and me and another friend. I don't know who it was was we're driving in a car and we started talking and I had my podcasting, you know in the backseat running and I thought okay, you know, it's just recorded. It just have a talk and and then we start talking about <mark>Bitcoin</mark> a while and then after a while, I don't know. Time lapses in my dream. So we start talking about psychedelics and I don't know why is it all about like psychedelic experiences? I have wash. I don't know why you know, maybe the idea was how could we was sort of the context was like, how can we open up people to comprehend or you know to be more receptive to <mark>bitcoin</mark> and so we went to another restaurant, you know, we had to squeeze ourselves into this bench with a lot of other people and with you know, continue talking about <mark>Bitcoin</mark> and psychedelics and I talked about you know about this. Lady friend, I have who's like 65 years old who reminds me of this Matrix lady you little Scamp. So he's so hilarious. So and make a great car. Right? I'm telling you this because afterwards today and I said, I told my girlfriend, you know, I got this interview at 6:00 p.m. Which I thought I would you know, I'd agree but that it was my mistake. And I said, well, you can check him out, you know, check out his body is a real big families podcast is like you know, right? Fire <mark>Bitcoin</mark> so she takes you out and she finds YouTube channel, which I never had, you know check and she and I we know we go through the topics. I'm like God it's like totally open minded, you know, like spiritual martial art yoga psychedelics, I think even is that true or", "Start Time (s)": 75.2, "End Time (s)": 195.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "lady you little Scamp. So he's so hilarious. So and make a great car. Right? I'm telling you this because afterwards today and I said, I told my girlfriend, you know, I got this interview at 6:00 p.m. Which I thought I would you know, I'd agree but that it was my mistake. And I said, well, you can check him out, you know, check out his body is a real big families podcast is like you know, right? Fire <mark>Bitcoin</mark> so she takes you out and she finds YouTube channel, which I never had, you know check and she and I we know we go through the topics. I'm like God it's like totally open minded, you know, like spiritual martial art yoga psychedelics, I think even is that true or no? Yeah. Yeah. Well, you know the YouTube channel was just something that you know, I don't I don't I like recording conversations with people that are you know interested. In similar things to me and so that was just the YouTube channel is just a repository really <mark>for</mark> these conversations. I was having which was part of the RV trip that I mentioned to you before we started but but yeah, you know, I whether it's psychic tell, you know, I've been into fitness and health my whole life been in the psychedelics <mark>for</mark> the last 10 or 15 years, you know <mark>Bitcoin</mark> <mark>for</mark> a number of years and like I don't know I'm just curious and I guess I'm drawn to things that I think are, you know have Potential to be tremendously beneficial in people's lives and in my life and allowing me to be the person and have the life that I want to have so, you know in Bitcoin, of course, as you know, you know it there's such a huge eight asymmetry between what people know about it what they think it is and what it actually could represent the impact that it could have in the future and that's why we're all so passionate about it. But I think you know psychedelics is another one in a very similar vein where people think it's one thing there's you know a lot of Misperception about what it is and it's actually something else and that something else", "Start Time (s)": 152.0, "End Time (s)": 271.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I mentioned to you before we started but but yeah, you know, I whether it's psychic tell, you know, I've been into fitness and health my whole life been in the psychedelics <mark>for</mark> the last 10 or 15 years, you know <mark>Bitcoin</mark> <mark>for</mark> a number of years and like I don't know I'm just curious and I guess I'm drawn to things that I think are, you know have Potential to be tremendously beneficial in people's lives and in my life and allowing me to be the person and have the life that I want to have so, you know in Bitcoin, of course, as you know, you know it there's such a huge eight asymmetry between what people know about it what they think it is and what it actually could represent the impact that it could have in the future and that's why we're all so passionate about it. But I think you know psychedelics is another one in a very similar vein where people think it's one thing there's you know a lot of Misperception about what it is and it's actually something else and that something else is has such huge potential in my opinion <mark>for</mark> <mark>for</mark> positive impact and development and change and positive change in the individual that it like there's a lot of overlap between the two actually and so, you know, I'm I'm interested in those two things <mark>for</mark> that reason. Yeah the YouTube channel just <mark>for</mark> fun way to explore things. I'm interested in. So what's the connection that I meant? Tell me a little bit about your yours Journey your story about how do you what's your background? And how did you get to into Bitcoin? What's your rabbit hole story? My rabbit hole story. Well, I'm mean the first part is I've always been very very curious about everything, you know, just always wanted to see and think as clearly as possible and just pursue truth wherever I could find it. I know that's a bit, you know cliche but you know, that's I think we're all a lot of us in the <mark>Bitcoin</mark> community at least have somewhat of a bent towards pursuing the truth and finding clarity about things.", "Start Time (s)": 215.3, "End Time (s)": 335.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and it's actually something else and that something else is has such huge potential in my opinion <mark>for</mark> <mark>for</mark> positive impact and development and change and positive change in the individual that it like there's a lot of overlap between the two actually and so, you know, I'm I'm interested in those two things <mark>for</mark> that reason. Yeah the YouTube channel just <mark>for</mark> fun way to explore things. I'm interested in. So what's the connection that I meant? Tell me a little bit about your yours Journey your story about how do you what's your background? And how did you get to into Bitcoin? What's your rabbit hole story? My rabbit hole story. Well, I'm mean the first part is I've always been very very curious about everything, you know, just always wanted to see and think as clearly as possible and just pursue truth wherever I could find it. I know that's a bit, you know cliche but you know, that's I think we're all a lot of us in the <mark>Bitcoin</mark> community at least have somewhat of a bent towards pursuing the truth and finding clarity about things. not accepting what we've been told or what we've been taught but the thing that I thought about this the other day actually and I hadn't thought about it in a while but like the so when I was in high school, I was very interested in like the stock market and reading about you know, Benjamin Graham security analysis and Warren Buffett like really trying to absorb what these guys were saying because I wanted to be Filthy Rich when I was older right this this was the goal and but I was also simultaneously, you know, I was Like I love smoking weed when I was high. I love working out. I was in high school. So like all those things were pretty there was fertile soil <mark>for</mark> sure. And then so Marc Emery he was a Canadian marijuana Advocate and he sold seeds like marijuana seeds all over the world and", "Start Time (s)": 268.9, "End Time (s)": 388.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "like all those things were pretty there was fertile soil <mark>for</mark> sure. And then so Marc Emery he was a Canadian marijuana Advocate and he sold seeds like marijuana seeds all over the world and the u.s. Actually, you know, actually invited him and charged him with like distribution of marijuana. He was like number One of the most wanted list or something absurd like that and he in like before when he was fighting the extradition and he actually was extradited and he spent a number of years in prison. He's out now, but when he was arguing his case, he was wearing a Ron Paul t-shirt one day and so I watched a YouTube video and I saw him like arguing his case and I thought well, who's this Ron? Who's this person on his T-shirt? Like why is he wearing a t-shirt with some guy's name on it? And so I looked into Ron Paul. All and then that led me down the you know Federal Reserve rabbit hole and all that kind of stuff and so <mark>for</mark> the longest while before when I was a gold like I was like, oh my God, the system is fucked, you know, you know the Fiat money system is such a you know, it's such a manipulated bullshit game. How do I protect myself and <mark>for</mark> me at the time, you know gold was the answer but as you know, I'm sure you've discussed with many people as well like You know, I was really disheartened when I started to see quote unquote the truth about what was going on and like, you know gold didn't give me that much didn't make me feel that much better about things. It was just a hedge against what might happen, you know, but I still you know, I found my way of moving forward and positively and trying to make the best of a bad situation but like many of us, I just didn't see how this whole thing would get turned around in a positive way. Thought it would keep going in the same negative Direction, excuse me, and And so then when <mark>Bitcoin</mark> came on the scene, I had you know, I got very early introduction to", "Start Time (s)": 371.7, "End Time (s)": 491.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that led me down the you know Federal Reserve rabbit hole and all that kind of stuff and so <mark>for</mark> the longest while before when I was a gold like I was like, oh my God, the system is fucked, you know, you know the Fiat money system is such a you know, it's such a manipulated bullshit game. How do I protect myself and <mark>for</mark> me at the time, you know gold was the answer but as you know, I'm sure you've discussed with many people as well like You know, I was really disheartened when I started to see quote unquote the truth about what was going on and like, you know gold didn't give me that much didn't make me feel that much better about things. It was just a hedge against what might happen, you know, but I still you know, I found my way of moving forward and positively and trying to make the best of a bad situation but like many of us, I just didn't see how this whole thing would get turned around in a positive way. Thought it would keep going in the same negative Direction, excuse me, and And so then when <mark>Bitcoin</mark> came on the scene, I had you know, I got very early introduction to it. But I just I didn't see it <mark>for</mark> what it was right as so so many people I was right right, but I was interested enough to like pursue it intellectually whenever I had the opportunity so, you know, I watched Andreas is videos early on and you know, this this is going to sound bad because I like Andreas and he's done so much <mark>for</mark> this. Base and he's just he's an amazing asset but in the early days, he was always like don't go out and buy it learn about it and like that kind of stuff and I you know, I wish the early guys were like fuck that get some skin in the game by it and then let you know learn about it afterwards. But anyways, so I just kept my eye on it. And then I did my first interview in 2015 with Bobby Lee cuz we were both living in Shanghai at the time and not just kick started it. All and then you know, I've", "Start Time (s)": 426.2, "End Time (s)": 545.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "right right, but I was interested enough to like pursue it intellectually whenever I had the opportunity so, you know, I watched Andreas is videos early on and you know, this this is going to sound bad because I like Andreas and he's done so much <mark>for</mark> this. Base and he's just he's an amazing asset but in the early days, he was always like don't go out and buy it learn about it and like that kind of stuff and I you know, I wish the early guys were like fuck that get some skin in the game by it and then let you know learn about it afterwards. But anyways, so I just kept my eye on it. And then I did my first interview in 2015 with Bobby Lee cuz we were both living in Shanghai at the time and not just kick started it. All and then you know, I've been observing it closely ever since so that's kind of the short version in the reason why I was in Shanghai the first part of my career there I was in finance and I was in wealth management. So I worked <mark>for</mark> a few years there. And then that was you know, soul-destroying didn't like it at all didn't like the people the industry anything like that. So I went back to school <mark>for</mark> three years and I did a degree in natural medicine kind of in line with the you know, pursuing health. all this <mark>for</mark> my whole life independently and then I went back to Shanghai and I work <mark>for</mark> two years in a clinic there in that capacity and then you know, and then I didn't like that either, you know, just far too much emphasis on revenue and greed and you know didn't like the owners and just wasn't a great situation all around and so I left in April 18 went to Amsterdam bought the RV and drove around Europe <mark>for</mark> a little while and then I met my girlfriend in Land and spent the last year in Thailand just you know, kind of living in training started the podcast in late August, I think in last year late August", "Start Time (s)": 498.1, "End Time (s)": 617.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that was you know, soul-destroying didn't like it at all didn't like the people the industry anything like that. So I went back to school <mark>for</mark> three years and I did a degree in natural medicine kind of in line with the you know, pursuing health. all this <mark>for</mark> my whole life independently and then I went back to Shanghai and I work <mark>for</mark> two years in a clinic there in that capacity and then you know, and then I didn't like that either, you know, just far too much emphasis on revenue and greed and you know didn't like the owners and just wasn't a great situation all around and so I left in April 18 went to Amsterdam bought the RV and drove around Europe <mark>for</mark> a little while and then I met my girlfriend in Land and spent the last year in Thailand just you know, kind of living in training started the podcast in late August, I think in last year late August 2019, and now I'm back in Canada. I came home <mark>for</mark> Christmas, but My family's in the restaurant business here. And so I you know, there's certain things that they wanted some help with and I thought I could help. So right now I'm floating around Canada and doing some stuff with them but I suspect I'll be back in Thailand in the not-too-distant future really okay <mark>for</mark> like permanent or like more or less or yeah. I mean, I hate to be ambiguous, but you know, I don't know right now, I I love it. Are it's amazing and my girl is there and you know, we have a great situation there. But yeah, I mean, I'm kind of just floating around at the moment. I don't feel compelled to go back to China. You know, Shanghai you have always loved Shanghai and I spent you know, almost a decade there and it's a great City super modern its Cosmopolitan. There's lots of people there there's a ton of opportunity of course, but the China story is starting to you", "Start Time (s)": 560.2, "End Time (s)": 679.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "like more or less or yeah. I mean, I hate to be ambiguous, but you know, I don't know right now, I I love it. Are it's amazing and my girl is there and you know, we have a great situation there. But yeah, I mean, I'm kind of just floating around at the moment. I don't feel compelled to go back to China. You know, Shanghai you have always loved Shanghai and I spent you know, almost a decade there and it's a great City super modern its Cosmopolitan. There's lots of people there there's a ton of opportunity of course, but the China story is starting to you know unfold in a Action that I'm less and less comfortable with and then of course, you know with the current situation with the virus. It's not a time where many people are clamoring to get back to China a lot of the people I know are actually leaving. So yeah, I'm actually concerned a little bit to now because everything you know, he's booked and I'm going to Hanoi the Crypt economic conference organized by Eric boscorelli <mark>Bitcoin</mark> conference at Summit. So, I don't know, you know what to make of it, but I heard in Hanoi. There's not one single case of in of infection, you know. So yeah, I don't know how to think about the whole virus thing. You know, you hear so much stuff on Twitter and stuff like oh my God, it's good pandemic. The world is fucked or it's like a that's not then, you know, it's less than the common cold in terms of debt or common loon terms of s and stuff so thick. I think it's always great to exercise costs kind of stuff because it can get out of hand rapidly. Obviously with the way the world is today, but, you know down in Thailand and Vietnam and stuff at least right now. It doesn't I don't It's a really a serious threat. It's probably just an inconvenience more than anything because you'll probably have maybe get checked the checkpoints and stuff like that. But so far wrong, it's yeah, the problem is the incubation period now that we're talking about current what do you think is the what's going to be the impact <mark>for</mark> you know, the chain reaction of if it you know gets out of", "Start Time (s)": 641.3, "End Time (s)": 760.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know, he's booked and I'm going to Hanoi the Crypt economic conference organized by Eric boscorelli <mark>Bitcoin</mark> conference at Summit. So, I don't know, you know what to make of it, but I heard in Hanoi. There's not one single case of in of infection, you know. So yeah, I don't know how to think about the whole virus thing. You know, you hear so much stuff on Twitter and stuff like oh my God, it's good pandemic. The world is fucked or it's like a that's not then, you know, it's less than the common cold in terms of debt or common loon terms of s and stuff so thick. I think it's always great to exercise costs kind of stuff because it can get out of hand rapidly. Obviously with the way the world is today, but, you know down in Thailand and Vietnam and stuff at least right now. It doesn't I don't It's a really a serious threat. It's probably just an inconvenience more than anything because you'll probably have maybe get checked the checkpoints and stuff like that. But so far wrong, it's yeah, the problem is the incubation period now that we're talking about current what do you think is the what's going to be the impact <mark>for</mark> you know, the chain reaction of if it you know gets out of control and <mark>for</mark> you know trade Supply chains economies and everything is going on, you know with well, man. China's been pretty mum on the economic impact, you know, and that's just the way they get down there always like that. They don't you know, they don't share a lot of bad news over there. But I mean it's got to be substantial right factories are shut down people aren't people aren't working restaurants are closed like, you know, Shanghai, which is a city that hasn't really been that affected by the virus is shut down. Like I have friends they're sending me pictures and like downtown at 6 p.m. On a Friday night is a ghost town. So you It's and you know at people like apple companies like apple have come out and said this been disruptions in the supply chain and stuff. So, I think it's probably going to have a real big economic impact on China, but also the rest of the world, you know down in Thailand. There's way fewer Chinese", "Start Time (s)": 695.7, "End Time (s)": 815.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "people aren't working restaurants are closed like, you know, Shanghai, which is a city that hasn't really been that affected by the virus is shut down. Like I have friends they're sending me pictures and like downtown at 6 p.m. On a Friday night is a ghost town. So you It's and you know at people like apple companies like apple have come out and said this been disruptions in the supply chain and stuff. So, I think it's probably going to have a real big economic impact on China, but also the rest of the world, you know down in Thailand. There's way fewer Chinese tourists there, you know coming down right now and that's a huge impact on their economy. So I think it'll be pretty substantial and but the longer it draws out, of course the worse it'll be so I guess we'll have to wait and see until like the end of the quarter to see what real impacts our have. Ben hmm. Well if this scenario of a West Coast scenario continues, I mean, it's horrendous it would be horrendous and tragic and you know and really disturbing but on the other hand I'm like this could be like the triggering turning point <mark>for</mark> <mark>Bitcoin</mark> to go, you know on a trajectory. What is what do you think? Yeah. I mean you could make the case that you know, the run-up in January was may be partially motivated by that in the first place. It's like to stay for. And you know what looks to be the came in as many variables of course, but China is going to stimulate the economy <mark>for</mark> sure when this settles down or even even during and so there's going to be a lot more money sloshing around and you know, every other economy in the world is going to keep probably doing the same thing that they've been doing the interventions that they've been doing. So, I mean at this stage, you know, <mark>Bitcoin</mark> obviously has a mind of its own and it you know, it cigs when you think it's gonna zag and all this kind of stuff but there's just so many Variables that are you know on a you know mid to long-term time Horizon that are incredibly bullish <mark>for</mark> <mark>Bitcoin</mark> like so, you know so many from its on its own technical attributes and development <mark>for</mark> the", "Start Time (s)": 786.4, "End Time (s)": 906.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "disturbing but on the other hand I'm like this could be like the triggering turning point <mark>for</mark> <mark>Bitcoin</mark> to go, you know on a trajectory. What is what do you think? Yeah. I mean you could make the case that you know, the run-up in January was may be partially motivated by that in the first place. It's like to stay for. And you know what looks to be the came in as many variables of course, but China is going to stimulate the economy <mark>for</mark> sure when this settles down or even even during and so there's going to be a lot more money sloshing around and you know, every other economy in the world is going to keep probably doing the same thing that they've been doing the interventions that they've been doing. So, I mean at this stage, you know, <mark>Bitcoin</mark> obviously has a mind of its own and it you know, it cigs when you think it's gonna zag and all this kind of stuff but there's just so many Variables that are you know on a you know mid to long-term time Horizon that are incredibly bullish <mark>for</mark> <mark>Bitcoin</mark> like so, you know so many from its on its own technical attributes and development <mark>for</mark> the community to little later microclimate around the world. So, you know, it's always that case where he like you think it's gonna pull back and then you can you know, stack more with whatever whatever be devoting to or or Yeah, I mean so <mark>for</mark> me, it's bullish. I don't know how it's going to play out. I don't know the ups and downs. I don't know if the virus or the stimulus or you know, if there's a big if there's a big global economic downturn either as a result of this or just there as a result of the fact that you know, we're in the longest bull market in history right now. So most people think maybe after the election because Trump will do everything he can to prop things up before that. Yeah, but you know after I've got to be a retraction and you No got to be pretty bad because we're way worse State than we were in 2008, you know in terms of debt and all the rest so,", "Start Time (s)": 839.8, "End Time (s)": 959.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the community to little later microclimate around the world. So, you know, it's always that case where he like you think it's gonna pull back and then you can you know, stack more with whatever whatever be devoting to or or Yeah, I mean so <mark>for</mark> me, it's bullish. I don't know how it's going to play out. I don't know the ups and downs. I don't know if the virus or the stimulus or you know, if there's a big if there's a big global economic downturn either as a result of this or just there as a result of the fact that you know, we're in the longest bull market in history right now. So most people think maybe after the election because Trump will do everything he can to prop things up before that. Yeah, but you know after I've got to be a retraction and you No got to be pretty bad because we're way worse State than we were in 2008, you know in terms of debt and all the rest so, you know will in that environment Bitcoins never been tested in that kind of environment, you know, obviously <mark>Bitcoin</mark> was born out of last financial crisis. And so does liquidity dry up and to people, you know, pull back from the riskier sort of assets. And does that is that negative <mark>for</mark> <mark>Bitcoin</mark> or is there a massive flight too? Certainty and you know <mark>Bitcoin</mark> provides certainty obviously it's volatile, but you it's certainty is in its monetary policy. You know, how much is going to be when they're going to be issued all that kind of stuff and in a climate where in a chaotic climate where certainty is hard to find and the Global Financial system whether we're talking about currencies or stocks or whatever maybe the flight to safety to <mark>bitcoin</mark> will be Amplified in a scenario like that. And if that's the case man, I mean things could get really crazy. Yeah. Yeah. Have you been able to a little bit listen to the was pretty cool actually panel discussions on the on confiscate herbal event, which I would have loved to go. But you know was like, you know, so Feelin the mood. Yeah, come on Zuko trace my all", "Start Time (s)": 906.0, "End Time (s)": 1026.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "all that kind of stuff and in a climate where in a chaotic climate where certainty is hard to find and the Global Financial system whether we're talking about currencies or stocks or whatever maybe the flight to safety to <mark>bitcoin</mark> will be Amplified in a scenario like that. And if that's the case man, I mean things could get really crazy. Yeah. Yeah. Have you been able to a little bit listen to the was pretty cool actually panel discussions on the on confiscate herbal event, which I would have loved to go. But you know was like, you know, so Feelin the mood. Yeah, come on Zuko trace my all these people discussing cope. If you have any chance you should check out their discussions. It's you know, Anton ways Channel and maybe on some other channels, too. I didn't see it. But what did they say? What did they say about all that? Well, they have different, you know topics talk about like one topic also Max Keiser with Stacy Herbert weather. So, you know, they talk about traditional finance and and you know, how <mark>for</mark> what that's the reason I wanted to ask you like because you were also in the wealth management business. Do you think like alternate? Hi, we call an alternate worse. People are you know more more waking up to <mark>bitcoin</mark> and secretly sort of stacking sets in millions of you know, when I was in when I was in the game, you know, <mark>Bitcoin</mark> just wasn't on the radar. So I don't know from that perspective. You know, I know Andy hedstrom, he just released his book why buy <mark>Bitcoin</mark> so he would be probably more insightful on that. And from what I've heard from him. It's starting to trickle in now and then you've got people like Al pal. Who says you know, like the infrastructure may not be ready <mark>for</mark> a lot of funds to get their clients into Bitcoin. Although that's obviously happening now as well, but he's you know, according to him a", "Start Time (s)": 990.8, "End Time (s)": 1110.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "industry like the fund managers. They're all invested in it, you know, so it's you know, I think it's it's starting to get there and what I think a lot of people have been noticing even in the last, you know, three to six months is that you know, mainstream retail attention is starting to like perk up again, you know, like whether that's coverage on the news or whether that's your friends asking you about it again, or whether that's Google Trends or that kind of stuff but it just seems like it like the interest is starting to pick back up again and people are looking at it through a bit of a Front lens right 2017 was let's get rich quick and then it popped and oh, it's a bubble. It's tulips it's forget about it. It's bullshit and now people like noticing. Oh, it's still here and oh it's bounced back up to 10 and oh, it's it's not it's not tulips. It's a new Financial system. It's a digital gold its trust Network. It's this and that that like, oh that's interesting. And now there's so many more resources <mark>for</mark> noobs like it seems like there's a new book coming out every day. There's a shitload of podcast as a ton of great. The content online there's all these different sites that are curating content now, you know <mark>Bitcoin</mark> only and <mark>Bitcoin</mark> best and the work that they're Gigi has done the coin resources, like, you know, there's there's tons of stuff out there now. So if you're a new coming into the space, I mean people are still going to fall <mark>for</mark> the the normal pitfalls of you know, trying to make faster money on all coins or whatever bullshit is the flavor of the month, but but there's just, you know, there's a lot more resources out there and that's a good thing. So when interest Peaks up, hopefully people can skip over some of the bullshit right and you know, the fundamentals of <mark>Bitcoin</mark> I think are more and more and deeper deeper understood now with it. It's the average person or let's say, you know macro investors traditional whatever investors the monetary properties of Bitcoin, I think are now finally, you know, it's it's", "Start Time (s)": 1114.6, "End Time (s)": 1233.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "online there's all these different sites that are curating content now, you know <mark>Bitcoin</mark> only and <mark>Bitcoin</mark> best and the work that they're Gigi has done the coin resources, like, you know, there's there's tons of stuff out there now. So if you're a new coming into the space, I mean people are still going to fall <mark>for</mark> the the normal pitfalls of you know, trying to make faster money on all coins or whatever bullshit is the flavor of the month, but but there's just, you know, there's a lot more resources out there and that's a good thing. So when interest Peaks up, hopefully people can skip over some of the bullshit right and you know, the fundamentals of <mark>Bitcoin</mark> I think are more and more and deeper deeper understood now with it. It's the average person or let's say, you know macro investors traditional whatever investors the monetary properties of Bitcoin, I think are now finally, you know, it's it's it's like going through the layers of the brain like, okay, this is really this is absolute scarcity when did You first <mark>for</mark> the first time like understand the principle of the fundamentals of absolute scars it because it took me a long time actually. Yeah, I agree and to address your first comment is you know, when I first started, you know, when I went down the rabbit hole with Ron Paul initially, right? Nope. The word Fiat was not in the public really, you know lexicon, you know, you wouldn't hear people on CNBC or anything like that use that word and now it's everywhere, you know, people are you know people that have those people on CNBC They're using that word Fiat and money printing is like also in the public lexicon people start to like people people most people don't understand the implications of that. But many people if you watch the financial news or if you pick up any of the political news or whatever, you'll probably hear the term money Printing and Fiat and that just that starting to seep in and that obviously creates more fertile ground when you encounter <mark>Bitcoin</mark> <mark>for</mark> it to sink in a bit more to understand that the impact of gravity e of", "Start Time (s)": 1181.2, "End Time (s)": 1300.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "like, okay, this is really this is absolute scarcity when did You first <mark>for</mark> the first time like understand the principle of the fundamentals of absolute scars it because it took me a long time actually. Yeah, I agree and to address your first comment is you know, when I first started, you know, when I went down the rabbit hole with Ron Paul initially, right? Nope. The word Fiat was not in the public really, you know lexicon, you know, you wouldn't hear people on CNBC or anything like that use that word and now it's everywhere, you know, people are you know people that have those people on CNBC They're using that word Fiat and money printing is like also in the public lexicon people start to like people people most people don't understand the implications of that. But many people if you watch the financial news or if you pick up any of the political news or whatever, you'll probably hear the term money Printing and Fiat and that just that starting to seep in and that obviously creates more fertile ground when you encounter <mark>Bitcoin</mark> <mark>for</mark> it to sink in a bit more to understand that the impact of gravity e of it a bit more but yeah answer your second question. I didn't get it's funny a mean looking back on one's <mark>Bitcoin</mark> journey is always I mean, it's it's it's somewhat aggravating. It's funny. It's like you just you look back and notice how many things you missed and of course, you're always learning. So that's always going to be the case. And that's one of the wonderful things about it. But you know, the 21 million Supply cap was always I understood it. I was like, wow, this is Being a campy can't be manipulated. You can't just say I want more and create inflation and that kind of stuff and that's part of the reason why I saw value in it, but I didn't understand the term or the idea of absolute scarcity and particu. No just didn't sink in until I read safes book and after I read saves book it just it coalesced much more clearly <mark>for</mark> me. It's like much more impactful because they're really the same knowing that you know, it can", "Start Time (s)": 1236.4, "End Time (s)": 1356.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "just that starting to seep in and that obviously creates more fertile ground when you encounter <mark>Bitcoin</mark> <mark>for</mark> it to sink in a bit more to understand that the impact of gravity e of it a bit more but yeah answer your second question. I didn't get it's funny a mean looking back on one's <mark>Bitcoin</mark> journey is always I mean, it's it's it's somewhat aggravating. It's funny. It's like you just you look back and notice how many things you missed and of course, you're always learning. So that's always going to be the case. And that's one of the wonderful things about it. But you know, the 21 million Supply cap was always I understood it. I was like, wow, this is Being a campy can't be manipulated. You can't just say I want more and create inflation and that kind of stuff and that's part of the reason why I saw value in it, but I didn't understand the term or the idea of absolute scarcity and particu. No just didn't sink in until I read safes book and after I read saves book it just it coalesced much more clearly <mark>for</mark> me. It's like much more impactful because they're really the same knowing that you know, it can will only ever be 21 million and Nevermore is this same as kind of understanding absolute scarcity, but it didn't there was a gap there in the understanding didn't sink in in such a way. And so when it did and when I finish safes book, I was just like oh shit Mike, you know, this this one aspect of this Tech this technology and this phenomenon. I didn't fully appreciate and I guess I'm sorry. I started to fully appreciate it then and yeah, so, you know again like The rabbit hole always goes deeper and your conviction usually increases with every step you take down there. Yeah, this process of you know, being having to not only the belief but I always say that trust like trust is beyond belief or conviction. But yeah, it's the same thing, you know, having the conviction to", "Start Time (s)": 1290.4, "End Time (s)": 1410.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the same knowing that you know, it can will only ever be 21 million and Nevermore is this same as kind of understanding absolute scarcity, but it didn't there was a gap there in the understanding didn't sink in in such a way. And so when it did and when I finish safes book, I was just like oh shit Mike, you know, this this one aspect of this Tech this technology and this phenomenon. I didn't fully appreciate and I guess I'm sorry. I started to fully appreciate it then and yeah, so, you know again like The rabbit hole always goes deeper and your conviction usually increases with every step you take down there. Yeah, this process of you know, being having to not only the belief but I always say that trust like trust is beyond belief or conviction. But yeah, it's the same thing, you know, having the conviction to comprehension then then there's no more room <mark>for</mark> doubts of Skeptics or Seth Seth self-doubt self-sabotage, so, You know, right man, and yeah, one of the one of the things that looking back on it I can say hindered me in that regard was early on when I looked at it just you know looked at how it was distributed and the hard cap and everything about it. I was like, yes, this is awesome. But I didn't realize till later that you you mentioned like self-sabotage. I'm an aspect of it <mark>for</mark> me was I didn't Like and I don't think I'm I don't think it's entirely unreasonable to have thought this way because this is such a paradigm shift that like, you know, it's her you need my igniting it let myself believe found like that. I stumbled across like I World Inge future changing absolute paradigm-shifting technology like", "Start Time (s)": 1354.2, "End Time (s)": 1473.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So it kind of makes sense that there be another roughly 20 around the world. Yeah. So I'm like, you know, if it with it it you know, it's the average person or the you know, the big alternate High worth. Vidual it's like what do you have to lose like like even if you have like 0.28 Bitcoin, which is allegedly the average thing that is that puts you in the top whatever one or 10% of the you know, wealthiest bitcoiners. So I'm like, you know, this is like whether you call it like a hedge or you know, a savings technology or whatever. I think this is something that people have to grasp eventually that what do you Toulouse right if you allocate minimal, you know percentage of it a hundred percent and I think the fact that we've just was the first decade of its existence is probably going to be a big like psychological thing <mark>for</mark> a lot of those people because you just the best performing asset over the past decade you it's way harder to just dismiss it and say well it's not a real thing. It's a geek money. It's nerd money. It's Internet. It's tulips like you know. Oh, you're going to have a much harder time casting it aside from from now on just because it's got a decade under its belt and it kicked everybody's asses during that time. And so I think people are going to have to start looking at it more seriously and to your point. I mean what what is allocating Point 5 or 1 percent of your portfolio to it? It's nothing you're taking on almost no risk and the upside is tremendous. So I think again another reason why that's just another reason <mark>for</mark> <mark>For</mark> being bullish because when that really clicks and the kind of flood gates open <mark>for</mark> people in those positions and that industry. It's a no-brainer maybe like half course, we should allocate one percent as a hedge to everything else and probably more. You know, I", "Start Time (s)": 1525.9, "End Time (s)": 1645.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you just the best performing asset over the past decade you it's way harder to just dismiss it and say well it's not a real thing. It's a geek money. It's nerd money. It's Internet. It's tulips like you know. Oh, you're going to have a much harder time casting it aside from from now on just because it's got a decade under its belt and it kicked everybody's asses during that time. And so I think people are going to have to start looking at it more seriously and to your point. I mean what what is allocating Point 5 or 1 percent of your portfolio to it? It's nothing you're taking on almost no risk and the upside is tremendous. So I think again another reason why that's just another reason <mark>for</mark> <mark>For</mark> being bullish because when that really clicks and the kind of flood gates open <mark>for</mark> people in those positions and that industry. It's a no-brainer maybe like half course, we should allocate one percent as a hedge to everything else and probably more. You know, I mean, we're all were Psychopaths <mark>for</mark> Bitcoins. We've allocated way more than one percent. I assumed like people more conservative and that apps the consider other factors and professionals and blah blah blah, you know, 1% would is Possibly still very conservative, maybe two or three or four or five wood is would be the case and if that's the case again, there's just there's not enough of these things to go around. So the price is going to have to adjust upward. Do you see like the next one or two years the once the lightning thing I'm going to do this, you know, the this new development what's going on in lightning space? Especially when what Jack mahler's is like, I'm really excited with Jack. This is crazy because that would that would put something, you know a tool into the hands of people without the people having you to think about Bitcoin. I mean if then we've got finally these this the satisfaction of the outcry <mark>for</mark> like, oh, you know, it's got no utility. It's not a medium of exchange. You cannot pay your coffee with that.", "Start Time (s)": 1587.1, "End Time (s)": 1706.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to everything else and probably more. You know, I mean, we're all were Psychopaths <mark>for</mark> Bitcoins. We've allocated way more than one percent. I assumed like people more conservative and that apps the consider other factors and professionals and blah blah blah, you know, 1% would is Possibly still very conservative, maybe two or three or four or five wood is would be the case and if that's the case again, there's just there's not enough of these things to go around. So the price is going to have to adjust upward. Do you see like the next one or two years the once the lightning thing I'm going to do this, you know, the this new development what's going on in lightning space? Especially when what Jack mahler's is like, I'm really excited with Jack. This is crazy because that would that would put something, you know a tool into the hands of people without the people having you to think about Bitcoin. I mean if then we've got finally these this the satisfaction of the outcry <mark>for</mark> like, oh, you know, it's got no utility. It's not a medium of exchange. You cannot pay your coffee with that. But then after you know, once you have like millions and hundred millions of transactions per second with the lightning Network, I think this is going to you know, just just you know, put it into it. A totally different dimension. What do you think? Yeah. I mean first first of all Jack is a total gangster. I mean, he's launching world changing Technologies bouquet shins from his like pewter room in his fucking boxers. You know, like I I smile when I think about how this history will be told, you know, in 20 30 40 a hundred years when when you know, because like will study the history of money right now and we'll look at gold right and we'll look at the Orion and we'll look at you know, what happened in Constantinople and you know, we'll we'll try to understand how these monetary instruments emerged and what happened to them and how they may be went away or devolved or whatever", "Start Time (s)": 1642.2, "End Time (s)": 1761.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "after a decade was you know, the lightning Network and here's one of the one of the you know, people that contributed like Okay, you're back John. Yeah, sorry. Yeah, maybe maybe I got my bandwidth problem. I don't know what's happening right now, but I don't know maybe sole eruption. So so yeah, that's where did you go? Where did you go? Did you let me let me lose my video. I'm going to turn off both of our videos. And so we have a little bit more bandwidth. All right. Where did where did I lose you? Where did you lose me? Yeah. Yeah, you were talking about Jack Mallards. It's like totally groundbreaking revolutionary who we're going to continue with that. Yeah, so I was just I was just want to say first of all Jack's a gangster and I think it'll be really funny. When we look back on the history of this, you know, what's happening now and him being one of the like the main figures at least in the development of lightning and <mark>for</mark> like people who are studying it at Time to look back and see this kid up and videos in his boxers about like these groundbreaking technological advancements. I think it's going to be pretty funny, you know lightning. I feel like lightning is a whole other universe that I am, you know going to need to explore because the implications of it. I think I still don't I don't fully grasp. I mean look how long it's taken us to understand, you know, a lot of the implications if not the full implications of the base. Layer that I think when we dive, you know, when the implications of lightning become more apparent it's you know, it's going to open up a universe of financial services and economic interaction and all sorts of stuff that right now, we just can't you know, we can't project our minds that far out into the future. I think it's awesome the work that's going on the it's awesome the work that Jack has done. I don't know enough about strike to really comment on it yet. Like it it it's an awesome service.", "Start Time (s)": 1769.0, "End Time (s)": 1888.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of stuff that right now, we just can't you know, we can't project our minds that far out into the future. I think it's awesome the work that's going on the it's awesome the work that Jack has done. I don't know enough about strike to really comment on it yet. Like it it it's an awesome service. I think it seems to me at least. Because and I'll have to talk to hopefully get a chance to talk to Jack about it. But you know, there's obvious connections to the That you know, if if it ever needed to or want it to be shut down by the forces that the powers that be it probably could be but still as a bridge right now to allow bitcoiners to act interact with no corners and no corners track interact with bitcoiners in a seamless way. I mean, it's awesome. Yeah, exactly. So I'm going to not going to not take too much time of you John because I know you don't have much time, but let's wrap it up because might you know, my internet connection could be, you know to become more. Asterisk. I'm good. I'm good on time <mark>for</mark> yeah a half an hour. So it's totally up to you. Okay? Okay now because I don't wanna you know mess with my maybe I'll have you back in a new future because this would I don't want to have like a low-quality bought a podcast. So John I wanted to ask you when you not not Beyond, you know, the monetary economical forces and potential Bitcoin. Where do you see like our society? This is something I II would love to you know, share more thoughts and because you know as a feed on the most talked about this in his book and I know I repeat myself sometimes in my interviews, but this is one of the most fascinating aspects that once we have this, you know Andreas Antonopoulos talks about the architectural foundation. So once we have this decentralized monetary system, you know, I call it the monitor root layer of Bitcoin. Where do you see our society or maybe I thought the educational wise would Which people may be become have PP more", "Start Time (s)": 1872.0, "End Time (s)": 1991.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Okay now because I don't wanna you know mess with my maybe I'll have you back in a new future because this would I don't want to have like a low-quality bought a podcast. So John I wanted to ask you when you not not Beyond, you know, the monetary economical forces and potential Bitcoin. Where do you see like our society? This is something I II would love to you know, share more thoughts and because you know as a feed on the most talked about this in his book and I know I repeat myself sometimes in my interviews, but this is one of the most fascinating aspects that once we have this, you know Andreas Antonopoulos talks about the architectural foundation. So once we have this decentralized monetary system, you know, I call it the monitor root layer of Bitcoin. Where do you see our society or maybe I thought the educational wise would Which people may be become have PP more open-minded and more respect and receptive to additional ideas of what <mark>Bitcoin</mark> can enable facilitates in their daily lives in 10-15 years. Let's say to come, you know, I'm saying like how would people see people's lives change, you know, is it going to be more comfortable are going to be people, you know work less retire earlier have more free space free time more Innovative Technologies. You know that Zero to one Technologies. That's a feed animals talks about in his low time preference, you know gold standard versus Fiat standard. Do you know where I'm going with this a question? Like what's the vision? I do know where you're going and it's you know, it's one of the big questions often debated about Bitcoin, you know, and of course, it's all just speculation on the one hand, you know, first of all, of course interacting with <mark>Bitcoin</mark> changes, you know, your behavior and how you see the world and all of that and you Nine, everybody else that falls into this rabbit hole is proof of that some of a more primed.", "Start Time (s)": 1936.1, "End Time (s)": 2055.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "years. Let's say to come, you know, I'm saying like how would people see people's lives change, you know, is it going to be more comfortable are going to be people, you know work less retire earlier have more free space free time more Innovative Technologies. You know that Zero to one Technologies. That's a feed animals talks about in his low time preference, you know gold standard versus Fiat standard. Do you know where I'm going with this a question? Like what's the vision? I do know where you're going and it's you know, it's one of the big questions often debated about Bitcoin, you know, and of course, it's all just speculation on the one hand, you know, first of all, of course interacting with <mark>Bitcoin</mark> changes, you know, your behavior and how you see the world and all of that and you Nine, everybody else that falls into this rabbit hole is proof of that some of a more primed. Do you know get it sooner but you know, I haven't met a <mark>Bitcoin</mark> or yet who is into space and has been in space <mark>for</mark> a while and hasn't you know change some aspect of their life or their behavior. So I think yes change is inevitable and it seems to be that change moving toward taking greater personal responsibility <mark>for</mark> you know nearly every aspect. Effect of your life whether it be Financial or health or familial or any other area is a is a pretty common Hallmark of that change. And so, you know, I think if <mark>Bitcoin</mark> were to become, you know, a global monetary standard or the global monetary standard, then we would probably see similar changes inspired in people that are interacting with it all over the world and that is awesome. I mean, I think that is sorely needed in In a global culture and civilization today and you know, it'll happen in pockets and spurts and you know, some people will just kind of remain luddites and their heads will", "Start Time (s)": 2001.3, "End Time (s)": 2120.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is a is a pretty common Hallmark of that change. And so, you know, I think if <mark>Bitcoin</mark> were to become, you know, a global monetary standard or the global monetary standard, then we would probably see similar changes inspired in people that are interacting with it all over the world and that is awesome. I mean, I think that is sorely needed in In a global culture and civilization today and you know, it'll happen in pockets and spurts and you know, some people will just kind of remain luddites and their heads will stay in the sand. I mean, there's many examples today of like world changing technologies that we all engage in that a lot of people have just decided not to adopt. So there's going to be that it'll be interesting to see how it plays out. I mean if there's a like a bifurcation of humanity to the ones that benefit from you know, Oh engaging in using a far different monetary standard and organizing mechanism <mark>for</mark> human interaction then and versus ones that kind of stay in the old world. Then you know this whole concept of civil those and stuff may actually play out because you know, there's going to be one group that's far and away ahead of the other one and so that could play but and you know the transition probably going to be messy and I don't like thinking about you know, how The current state of affairs plays out. I'm extremely grateful that <mark>Bitcoin</mark> exists as kind of like a picture up truck driving next to the train that's about to roll off the tracks, you know, and you people can jump off onto the pickup truck and and save themselves, you know that it's definitely good that that is here. But the transition will probably still be a bit messy and I don't look forward to that but you know a hundred years from now or whatever period in the future, I just see, you know, far more peaceful far fairer far more", "Start Time (s)": 2084.6, "End Time (s)": 2203.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "old world. Then you know this whole concept of civil those and stuff may actually play out because you know, there's going to be one group that's far and away ahead of the other one and so that could play but and you know the transition probably going to be messy and I don't like thinking about you know, how The current state of affairs plays out. I'm extremely grateful that <mark>Bitcoin</mark> exists as kind of like a picture up truck driving next to the train that's about to roll off the tracks, you know, and you people can jump off onto the pickup truck and and save themselves, you know that it's definitely good that that is here. But the transition will probably still be a bit messy and I don't look forward to that but you know a hundred years from now or whatever period in the future, I just see, you know, far more peaceful far fairer far more prosperous. society as a result of using something like <mark>Bitcoin</mark> is as the global monetary instrument because you know in this space there's a lot of talk about different economic philosophies, you know, Austrian economics and libertarianism and socialism and all this kind of stuff and these are you know, perfectly fine and entertaining arguments to have I just published a podcast today with Jeff Van Drew, and you know, he Not a free market capitalist, even though he's a <mark>Bitcoin</mark> supporter. So we had a you know, nice friendly little back and forth and disagreements and it was fun. But I just tend to think that this Society we get, you know, so the behavior of the people in that society and then the greater sort of emerged structures that emerge in society as a result or that that result is is primarily predicated on the instrument that's used to organize human economic interaction aka the and so I think that if we're", "Start Time (s)": 2149.7, "End Time (s)": 2269.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "this Society we get, you know, so the behavior of the people in that society and then the greater sort of emerged structures that emerge in society as a result or that that result is is primarily predicated on the instrument that's used to organize human economic interaction aka the and so I think that if we're finding that we're not organizing as a species as optimally as we see your Socialism or you know capitalism as it's been tried before or crony the you know, like whatever our issue is with how we're organizing and interacting I think instead of looking at a philosophy or theory of organizing to try to resolve that and I think we should look at the mechanism or the inch. On which all of that organization is predicated and that is the monetary instruments. Oh, there will come a time. You know, let's say let's say in the future that <mark>Bitcoin</mark> is the global monetary instrument. I suspect there will come a time whether it's a hundred years or 500 years or 50 years or whatever where we'll say, you know, the problems that were noticing in the world, you know, there will obviously be problems and I think the smarter It's resolving them won't be like what kind of political philosophy can we conjure up? But rather? Okay, let's look at the attributes of <mark>Bitcoin</mark> and let's determine what those attributes manifest in terms of social behavior and you know and culture and let's see if tweaking any of the others can ameliorate the issues that were seeing, you know, so that's why we're all so hyped up on <mark>bitcoin</mark> because we can see how this might using this monitoring instrument not only has affected us in our personal lives, but would do so much <mark>for</mark> you know, removing inefficiency and you know, reducing", "Start Time (s)": 2247.7, "End Time (s)": 2366.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and that is the monetary instruments. Oh, there will come a time. You know, let's say let's say in the future that <mark>Bitcoin</mark> is the global monetary instrument. I suspect there will come a time whether it's a hundred years or 500 years or 50 years or whatever where we'll say, you know, the problems that were noticing in the world, you know, there will obviously be problems and I think the smarter It's resolving them won't be like what kind of political philosophy can we conjure up? But rather? Okay, let's look at the attributes of <mark>Bitcoin</mark> and let's determine what those attributes manifest in terms of social behavior and you know and culture and let's see if tweaking any of the others can ameliorate the issues that were seeing, you know, so that's why we're all so hyped up on <mark>bitcoin</mark> because we can see how this might using this monitoring instrument not only has affected us in our personal lives, but would do so much <mark>for</mark> you know, removing inefficiency and you know, reducing corruption and and and like far reducing e incentive <mark>for</mark> reward and promoting peace and all that kind of stuff. So that will always be the case and I instead of getting bogged down in these political Theory arguments. I just think it's it's almost always going to be about that monetary instrument upon which Society is based and if we're still seeing problems in society, we should look at that instead of you know, some Theory to layer on top of it. I think yeah, so we're on the same page John that's good. Yeah. Yeah, that's beautifully said no, you know, why because the most exciting of course, you know, we all want to become more, you know, it's all about the fundamental. It's about a fundamental human right? It's about Freedom. It's it's about, you know, being really in every on every level we can imagine. We are we Are definitely not free at this moment and right", "Start Time (s)": 2299.8, "End Time (s)": 2419.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "we should look at that instead of you know, some Theory to layer on top of it. I think yeah, so we're on the same page John that's good. Yeah. Yeah, that's beautifully said no, you know, why because the most exciting of course, you know, we all want to become more, you know, it's all about the fundamental. It's about a fundamental human right? It's about Freedom. It's it's about, you know, being really in every on every level we can imagine. We are we Are definitely not free at this moment and right and if you if you we questioned, you know, the essence of the legitimacy of the nation state the governor any nation state any government any you know, Central Bank, so the whole centralized structures it just it I mean what could work could think you know, this is a dystopian nightmare, but it's reality. So yeah, once we have this, you know decentralized free architecture. Which you know, a lot of Bitcoins are prominent <mark>Bitcoin</mark> is a preaching about this could eventually this is the most exciting aspect. This could read like facilitate the release disclosure and development and and mass production, you know of of totally Innovative Technologies, which could eventually no serve Humanity serve us and this is what I couldn't I see I couldn't agree more I couldn't agree more man, and I you know, we all think we live in the soup. Super modern world today and like, you know progress has been made obviously, but I do think you know, what would what would have been the case if we had just you know, well, I mean you can't do these what is right because the reason why we have Fiat money right now is because of the failings of gold, right so we can't say like, oh wouldn't it be great if we're still on harder monetary standard but so two years to your point. I just I totally agree. I think that you know Global adoption of <mark>Bitcoin</mark> as the you know primary monetary standard. We'll just mean", "Start Time (s)": 2389.5, "End Time (s)": 2507.5, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "free architecture. Which you know, a lot of Bitcoins are prominent <mark>Bitcoin</mark> is a preaching about this could eventually this is the most exciting aspect. This could read like facilitate the release disclosure and development and and mass production, you know of of totally Innovative Technologies, which could eventually no serve Humanity serve us and this is what I couldn't I see I couldn't agree more I couldn't agree more man, and I you know, we all think we live in the soup. Super modern world today and like, you know progress has been made obviously, but I do think you know, what would what would have been the case if we had just you know, well, I mean you can't do these what is right because the reason why we have Fiat money right now is because of the failings of gold, right so we can't say like, oh wouldn't it be great if we're still on harder monetary standard but so two years to your point. I just I totally agree. I think that you know Global adoption of <mark>Bitcoin</mark> as the you know primary monetary standard. We'll just mean complete unlocking or unleashing a human potential and we will see development and interaction and exploration and technology and prosperity and peace the likes of which we can't even really imagine match Alex. I know that sounds like super exaggerated. But if we're if we're where we at right now where we are right now based on the monies that we've used in the past. I mean, I was such a profound. Upgrade in the money and you know people really need. I know you appreciate this and most bitcoiners listening to the people in the you know, the normal world really need to appreciate the role that money plays in a society. I mean it's so it's foundational and when when that money is has been upgraded to to the extent that <mark>Bitcoin</mark> represents. I just it's hard to imagine how", "Start Time (s)": 2443.7, "End Time (s)": 2563.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I totally agree. I think that you know Global adoption of <mark>Bitcoin</mark> as the you know primary monetary standard. We'll just mean complete unlocking or unleashing a human potential and we will see development and interaction and exploration and technology and prosperity and peace the likes of which we can't even really imagine match Alex. I know that sounds like super exaggerated. But if we're if we're where we at right now where we are right now based on the monies that we've used in the past. I mean, I was such a profound. Upgrade in the money and you know people really need. I know you appreciate this and most bitcoiners listening to the people in the you know, the normal world really need to appreciate the role that money plays in a society. I mean it's so it's foundational and when when that money is has been upgraded to to the extent that <mark>Bitcoin</mark> represents. I just it's hard to imagine how that's going to the benefits that are going to manifest in the world as a result of that. So I'm super pumped. Yeah. And you know you one of the few people John, I mean, I know that I you know, I listen to your parties and I know you've been deep in the rabbit hole. So I think most people have a hard time understanding comprehending how much time and potential we have lost because all these technologies have been either suppress. I mean, whatever started with Nikola Tesla, you know, and this whole thing with JPMorgan, you know, it doesn't matter but I mean, there's so many inventors scientists. There's so much potential out there. That has been you know with it be the patent system or you know, I'm like we could have a totally different civilization. This is what I'm saying. You know and <mark>Bitcoin</mark> is the ultimate tool it we have no other choice than to have this decentralized money hardest", "Start Time (s)": 2498.7, "End Time (s)": 2618.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I mean it's so it's foundational and when when that money is has been upgraded to to the extent that <mark>Bitcoin</mark> represents. I just it's hard to imagine how that's going to the benefits that are going to manifest in the world as a result of that. So I'm super pumped. Yeah. And you know you one of the few people John, I mean, I know that I you know, I listen to your parties and I know you've been deep in the rabbit hole. So I think most people have a hard time understanding comprehending how much time and potential we have lost because all these technologies have been either suppress. I mean, whatever started with Nikola Tesla, you know, and this whole thing with JPMorgan, you know, it doesn't matter but I mean, there's so many inventors scientists. There's so much potential out there. That has been you know with it be the patent system or you know, I'm like we could have a totally different civilization. This is what I'm saying. You know and <mark>Bitcoin</mark> is the ultimate tool it we have no other choice than to have this decentralized money hardest descartes's money with all the monitor properties we can dream of and you know, I'm sometimes you know, how can we communicate this vision? The reactive reality of this Vision to you know to the masses out there it's real and it's possible, you know, well you're doing it man. I mean, that's what that's what this kind of stuff is about podcasting writing books articles talking on Twitter like it's happening before our eyes and sometimes it's difficult to see things when you're in the eye of the storm as it were but, you know these sorts of conversations that you know, we all have our blind spots of course, and we All our scope of knowledge on things is always incomplete, but what you know, what is what pervades the <mark>Bitcoin</mark> quote-unquote Community", "Start Time (s)": 2550.1, "End Time (s)": 2669.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "different civilization. This is what I'm saying. You know and <mark>Bitcoin</mark> is the ultimate tool it we have no other choice than to have this decentralized money hardest descartes's money with all the monitor properties we can dream of and you know, I'm sometimes you know, how can we communicate this vision? The reactive reality of this Vision to you know to the masses out there it's real and it's possible, you know, well you're doing it man. I mean, that's what that's what this kind of stuff is about podcasting writing books articles talking on Twitter like it's happening before our eyes and sometimes it's difficult to see things when you're in the eye of the storm as it were but, you know these sorts of conversations that you know, we all have our blind spots of course, and we All our scope of knowledge on things is always incomplete, but what you know, what is what pervades the <mark>Bitcoin</mark> quote-unquote Community is, a lot of people that you know have humbled themselves enough to go down a rabbit hole of learning about something that is very complex and has wide reaching implications in order to understand it in its totality. You have to understand you have to study history. You have to study economics. You have to study, you know. you know politics to some degree human behavior technology all of that kind of stuff and I My Hope Is and I think this is the case, but when people interact with these sorts of conversations if they're at all open-minded enough to have a you know, or if they're at all able to have an open mind and not just and presumably if they've if they've sought out these conversations and they have enough of an open mind they're going to they're going to see people that seem very very genuine and seem reasonably well, Well formed and seem to be having good-natured and well-intentioned discourse about this stuff and that in", "Start Time (s)": 2607.8, "End Time (s)": 2727.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "reaching implications in order to understand it in its totality. You have to understand you have to study history. You have to study economics. You have to study, you know. you know politics to some degree human behavior technology all of that kind of stuff and I My Hope Is and I think this is the case, but when people interact with these sorts of conversations if they're at all open-minded enough to have a you know, or if they're at all able to have an open mind and not just and presumably if they've if they've sought out these conversations and they have enough of an open mind they're going to they're going to see people that seem very very genuine and seem reasonably well, Well formed and seem to be having good-natured and well-intentioned discourse about this stuff and that in itself has an impact. I remember when I was first listening to Andreas like there was some things I was like, I don't know what the fuck he's talking about. Like I didn't the content. I wasn't Landing <mark>for</mark> me, but I could see I could see how genuine and truthful he was being. Yeah, I could see the passion that he had <mark>for</mark> it. I mean not many people can get up on stage and just kind of stream of Consciousness talk about something that's So complex and has so many different angles from which to look at it and Andreas could do that. And so when I was observing him, I was like, okay, you know not sold on the actual fun the objective attributes because I don't have the context enough time to appreciate them all yet, but I can see a guy who's clearly genuine and passionate and informed and that was you know, that inspired me as well to look further because there's so much out there today on so many things and there's so much Bullshit out there and so much fake shit and so much disingenuine behavior that when you can counter genuineness and authenticity. You're like, all right, there's this is there something going on here. Like is it worth my while to investigate it? Yes or no. That's the decision. We all have to make but like, you know, so I think these", "Start Time (s)": 2679.1, "End Time (s)": 2798.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "on so many things and there's so much Bullshit out there and so much fake shit and so much disingenuine behavior that when you can counter genuineness and authenticity. You're like, all right, there's this is there something going on here. Like is it worth my while to investigate it? Yes or no. That's the decision. We all have to make but like, you know, so I think these conversations and you know as many of them as possible and I'm you know, I haven't done any speaking yet publicly but it's definitely something I'd like to do because like you sure it's okay. It's okay. It's okay. It's okay. if if you get up and you don't know the answer to the questions okay if you miss State something it's okay if you said something one week and a week later you changed it a bit like people people aren't going to hold you to strictly to being perfectly accurate and everything you're saying people are going to hold you to being genuine and authentic and having the right intent and if you can do that and share some of that enthusiasm and this is something that I've said on a bunch of my pods is like and I know like if you're in the <mark>Bitcoin</mark> space and you want to remain anonymous Amos totally respect that and you know it's all good but you know I'm a fan of sharing enthusiasm because people respond to enthusiasm so if you can talk about this subject Manner and show that enthusiasm and authenticity I mean people are going to be drawn to that and then they start their own Journey about you know gaining more information and heading on down the rabbit hole but you know I just think more and more and more everywhere everyone not that not that it requires us I mean this thing is going to Impose its will on the world whether we're involved or not, but you know one I enjoy it. It's fun. I think it's tremendously important and the reality is is like if we connect Here then that's probably a worthwhile goal because because of the positive effects that it probably will have and you know being historically accurate. It's not going to I'm not going to lose sleep over that either, you know, of course the risk is being not", "Start Time (s)": 2778.3, "End Time (s)": 2897.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "they start their own Journey about you know gaining more information and heading on down the rabbit hole but you know I just think more and more and more everywhere everyone not that not that it requires us I mean this thing is going to Impose its will on the world whether we're involved or not, but you know one I enjoy it. It's fun. I think it's tremendously important and the reality is is like if we connect Here then that's probably a worthwhile goal because because of the positive effects that it probably will have and you know being historically accurate. It's not going to I'm not going to lose sleep over that either, you know, of course the risk is being not historically accurate, but if I can look back in 10 to 20 years of my life and say yeah, I was like there at that time and I was you know, I was trying to contribute in my small way then you know, I think I'll I'll be comfortable data in the future. Yeah, yeah. Well patience is a bitch. I know it <mark>for</mark> my self impatient because I know you know it we can we can Mass accelerate this I know we we just need the critical adoption rate with its two three or five percent of the Earth's population and it's just it's just going to take off. I just know that but maybe it has a purpose in built purpose or there's a sense to that whole thing why it's taking the process as it's you know as it's going right so Yeah, but you know, you know, it's interesting is is like the thing that I guess I sometimes have to remind myself. It's like there's no end here. Right like, you know <mark>Bitcoin</mark> being adopted by 10% 20% 30% a hundred percent of the global population like things don't stop then like we will Move the goalposts and we'll find something else that needs our passion and our effort and our articulation and I had a chat with <mark>Bitcoin</mark> Sign guy and you know his one of the things he said in our", "Start Time (s)": 2855.7, "End Time (s)": 2975.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in the future. Yeah, yeah. Well patience is a bitch. I know it <mark>for</mark> my self impatient because I know you know it we can we can Mass accelerate this I know we we just need the critical adoption rate with its two three or five percent of the Earth's population and it's just it's just going to take off. I just know that but maybe it has a purpose in built purpose or there's a sense to that whole thing why it's taking the process as it's you know as it's going right so Yeah, but you know, you know, it's interesting is is like the thing that I guess I sometimes have to remind myself. It's like there's no end here. Right like, you know <mark>Bitcoin</mark> being adopted by 10% 20% 30% a hundred percent of the global population like things don't stop then like we will Move the goalposts and we'll find something else that needs our passion and our effort and our articulation and I had a chat with <mark>Bitcoin</mark> Sign guy and you know his one of the things he said in our discussion was <mark>Bitcoin</mark> can't be an end. You know, it has to be a means right? So it is it is a means to an end and there's no you know like you of course, I want to see you know, rapid and total adoption, but I kind of hold back on having that as an objective because that will just be another stage in the journey and you know, who knows what comes after that but but you know, so I I'm impatient to but on the other on the flipside, I'm not because I have you know, I feel like it's going to unfold as it should and also I got no problem with the Chiefs ass she you know, stack and cheap SATs, but but yeah. It's it's interesting man. I mean who knows where all this is going to wind up but one of the things I'm grateful <mark>for</mark> is actually this, you know having these conversations like", "Start Time (s)": 2911.4, "End Time (s)": 3031.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and I had a chat with <mark>Bitcoin</mark> Sign guy and you know his one of the things he said in our discussion was <mark>Bitcoin</mark> can't be an end. You know, it has to be a means right? So it is it is a means to an end and there's no you know like you of course, I want to see you know, rapid and total adoption, but I kind of hold back on having that as an objective because that will just be another stage in the journey and you know, who knows what comes after that but but you know, so I I'm impatient to but on the other on the flipside, I'm not because I have you know, I feel like it's going to unfold as it should and also I got no problem with the Chiefs ass she you know, stack and cheap SATs, but but yeah. It's it's interesting man. I mean who knows where all this is going to wind up but one of the things I'm grateful <mark>for</mark> is actually this, you know having these conversations like we are right now because the in will ever future manifest in 10 or 20 years. Like I'm just going to be super stoked to have made these connections with people like you right now because I'm sure you know, we'll meet in meatspace one day and we'll have a beer and we'll talk about this stuff and it's just it's just a it's such an awesome Community. I know some people are averse to that. Term, but you know, I'm not so I use it pretty liberally but I just think this is such an awesome community of people and if you can if you can get through the vent, it's such a you know, like a super Spectrum, you know of people from all around the world from different, you know, let's just call it. I don't know, you know schools of thoughts and and philosophies and and perspectives and vision. It's really amazing, you know, totally and if you can get past the veneer Liu Shen of you know toxicity then what opens up is just the most", "Start Time (s)": 2969.0, "End Time (s)": 3089.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a beer and we'll talk about this stuff and it's just it's just a it's such an awesome Community. I know some people are averse to that. Term, but you know, I'm not so I use it pretty liberally but I just think this is such an awesome community of people and if you can if you can get through the vent, it's such a you know, like a super Spectrum, you know of people from all around the world from different, you know, let's just call it. I don't know, you know schools of thoughts and and philosophies and and perspectives and vision. It's really amazing, you know, totally and if you can get past the veneer Liu Shen of you know toxicity then what opens up is just the most stimulating, you know satisfying community that you could you know that I've ever come across so it's it's a I mean, I'm just lucky. I don't know how it all you know how this all happened. You know, I guess there's a certain degree of luck and a lot of us who came across <mark>Bitcoin</mark> and had the background to appreciate it to some degree early on but it's incredible man. I It just I was saying at the very beginning of this that when I was like when I became a gold bug because I saw the extent of the problems in the world. It was pretty disheartening and I kind of had to just you know, regroup and figure out how to move forward in life positively and this community and this, you know technology phenomenon, whatever you want to call it makes that a lot easier because it's this big giant, you know, Ray of Hope on the horizon. That's just shot, you know. Brightly. That's, you know, Rising on the horizon and shines more D-Day and You know that just gives you that boost that energy that excitement to to pursue, you know things that you think are worthwhile and not and not be so cynical and check out of life and just think everything is fucked and you know, there's never going to be better. I mean this radical change absolutely important. Yeah the intention, you know, like how do you think how that that that itself is,", "Start Time (s)": 3045.1, "End Time (s)": 3165.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I mean this radical change absolutely important. Yeah the intention, you know, like how do you think how that that that itself is, you know has an impact on our environment. You know, how we think what's your intention right a hundred percent man. I mean how many people in the world? Wake up? I mean I was this place before but how many people wake up at a job they hate and just like put their feet on the floor oh my God I know read a big sigh yeah yeah you know fill your body with crap and watch shit TV and just like just kind of hate the whole routine of life and you know I've joked a bunch of times on my show but like I think you know obviously we have Rising rates of depression and anxiety and this kind of stuff in the world today like I think the point should be any part of like a sensible protocol of someone who's like dealing with a mental health professional like yes you get your Psychotherapy and maybe a Sprinkle in a little bit of the emerging therapies around Academics and stuff but like maybe a bit of <mark>Bitcoin</mark> education was just that final little unlock to say hey because a lot of people of course it's personal issues. But we like our perception of ourselves obviously in reference to the world around us. So if we see the world around us, as you know, just a dark, you know storm clouds on the horizon. We can't see any way that the things we see that our problems can get turned around and that's going to affect us greatly. But if we have this little thing that That shines a ray of Hope on all that then that's going to impact our sense of Happiness content Miss opportunity positivity like all that stuff. So I do joke about it, but I feel like I can't wait <mark>for</mark> the first like psychologist or whatever to include that in their protocol like you've got Fitness and you know waking up every morning and having a good workout and doing the cold showers and eating well and you know psychedelic Psychotherapy and then a little bit <mark>Bitcoin</mark> is the cherry on the top and down. Seems like a pretty fine protocol that turns somebody's life", "Start Time (s)": 3158.0, "End Time (s)": 3277.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a Sprinkle in a little bit of the emerging therapies around Academics and stuff but like maybe a bit of <mark>Bitcoin</mark> education was just that final little unlock to say hey because a lot of people of course it's personal issues. But we like our perception of ourselves obviously in reference to the world around us. So if we see the world around us, as you know, just a dark, you know storm clouds on the horizon. We can't see any way that the things we see that our problems can get turned around and that's going to affect us greatly. But if we have this little thing that That shines a ray of Hope on all that then that's going to impact our sense of Happiness content Miss opportunity positivity like all that stuff. So I do joke about it, but I feel like I can't wait <mark>for</mark> the first like psychologist or whatever to include that in their protocol like you've got Fitness and you know waking up every morning and having a good workout and doing the cold showers and eating well and you know psychedelic Psychotherapy and then a little bit <mark>Bitcoin</mark> is the cherry on the top and down. Seems like a pretty fine protocol that turns somebody's life around. That's the same release the resort program and we should open up a recited on I'm thinking about it. I'm working. Honestly, I think people are ready is seriously John. I think people are now finally, you know it now with its diet and you know, I used to be vegan myself as <mark>for</mark> six or seven years. So, you know, there's a reason I changed my diet again, but you know, I think people really more conscious more self-conscious more, you know. self-reflective and I think this is the the pulse of our times, you know, 100% I couldn't agree more and again, like we always look out on the world to see if there's any evidence of this way that we're thinking but like we are the evidence like we like were the person that other people were waiting <mark>for</mark> like the person who who knew all this that what we're discussing and was this kind of mindset like 15 years ago where the people they were waiting <mark>for</mark>", "Start Time (s)": 3213.4, "End Time (s)": 3333.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Fitness and you know waking up every morning and having a good workout and doing the cold showers and eating well and you know psychedelic Psychotherapy and then a little bit <mark>Bitcoin</mark> is the cherry on the top and down. Seems like a pretty fine protocol that turns somebody's life around. That's the same release the resort program and we should open up a recited on I'm thinking about it. I'm working. Honestly, I think people are ready is seriously John. I think people are now finally, you know it now with its diet and you know, I used to be vegan myself as <mark>for</mark> six or seven years. So, you know, there's a reason I changed my diet again, but you know, I think people really more conscious more self-conscious more, you know. self-reflective and I think this is the the pulse of our times, you know, 100% I couldn't agree more and again, like we always look out on the world to see if there's any evidence of this way that we're thinking but like we are the evidence like we like were the person that other people were waiting <mark>for</mark> like the person who who knew all this that what we're discussing and was this kind of mindset like 15 years ago where the people they were waiting <mark>for</mark> example good and so there's going to be you know, there's going to be people in 10 years that were the people that we were waiting <mark>for</mark> and so this change is happening because it is us and I you know I like I discussed my background at the beginning of the show like you know always been into you know Health and Fitness and Wellness and obviously the Psychedelic stuff so yeah man I'd love to get groups of people together and and explore some of these Pursuits and these areas you know subject matter and perhaps In the future, like help people get a little taste or sample of them so that they can see if it has any benefit in their lives and then and then go on from there, but there does seem to be and it has <mark>for</mark> a while seem to be pretty dramatic shift in in mindsets around the world. Obviously", "Start Time (s)": 3263.6, "End Time (s)": 3383.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of this way that we're thinking but like we are the evidence like we like were the person that other people were waiting <mark>for</mark> like the person who who knew all this that what we're discussing and was this kind of mindset like 15 years ago where the people they were waiting <mark>for</mark> example good and so there's going to be you know, there's going to be people in 10 years that were the people that we were waiting <mark>for</mark> and so this change is happening because it is us and I you know I like I discussed my background at the beginning of the show like you know always been into you know Health and Fitness and Wellness and obviously the Psychedelic stuff so yeah man I'd love to get groups of people together and and explore some of these Pursuits and these areas you know subject matter and perhaps In the future, like help people get a little taste or sample of them so that they can see if it has any benefit in their lives and then and then go on from there, but there does seem to be and it has <mark>for</mark> a while seem to be pretty dramatic shift in in mindsets around the world. Obviously particularly in the younger generation now. announcing that is still like an accelerating amounts of crazy shit to which is you know is always concerning but look maybe that's always the way of the world and you know, we just have to <mark>for</mark> me it's all about not trying not to focus about on the the crazy shit that's going on in the world, but just being and building the change you want to see as cliches as it sounds but if you're engaging in the things that you think are beneficial in your life and have a Broader beneficial impact and continuously working to understand yourself as well as you can and working to improve yourself as much as you can then look that's the best you can ask <mark>for</mark> you gotta let the chips fall where they may if you do that. Yeah, and you know, I'm right now I'm thinking okay some of my listeners going to think what's got get got that to do, you know with", "Start Time (s)": 3316.8, "End Time (s)": 3436.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "help people get a little taste or sample of them so that they can see if it has any benefit in their lives and then and then go on from there, but there does seem to be and it has <mark>for</mark> a while seem to be pretty dramatic shift in in mindsets around the world. Obviously particularly in the younger generation now. announcing that is still like an accelerating amounts of crazy shit to which is you know is always concerning but look maybe that's always the way of the world and you know, we just have to <mark>for</mark> me it's all about not trying not to focus about on the the crazy shit that's going on in the world, but just being and building the change you want to see as cliches as it sounds but if you're engaging in the things that you think are beneficial in your life and have a Broader beneficial impact and continuously working to understand yourself as well as you can and working to improve yourself as much as you can then look that's the best you can ask <mark>for</mark> you gotta let the chips fall where they may if you do that. Yeah, and you know, I'm right now I'm thinking okay some of my listeners going to think what's got get got that to do, you know with Bitcoin. So so what it does it does, I mean, it's I wish we got to see Italy really in a holistic, you know perspective <mark>for</mark> holistic perspective and comprehension. Level because it will it will real unimaginably and radically, you know change every facet of Our Lives sooner or later. So it was to be honest with you Jon. This is one of my favorite talks I've had with you because it goes real to the essence of why Bitcoin, you know, why we doing why why are we striving? Why are we trying, you know doing whatever it takes to educate to open up to you know, and I love you open-minded, you know. if I may call it you know scientific spiritual open-mindedness and yeah mean hope you know you're going to come to Austria I'll see you sometime in person because we could do", "Start Time (s)": 3367.3, "End Time (s)": 3487.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "sooner or later. So it was to be honest with you Jon. This is one of my favorite talks I've had with you because it goes real to the essence of why Bitcoin, you know, why we doing why why are we striving? Why are we trying, you know doing whatever it takes to educate to open up to you know, and I love you open-minded, you know. if I may call it you know scientific spiritual open-mindedness and yeah mean hope you know you're going to come to Austria I'll see you sometime in person because we could do a special episode on you know obvious psychedelic stuff well then I'm sure you know when we get together I'm sure we'll have like a several hour long conversation over some some beers or something like that but absolutely but yeah like I said man I I've always you ever since you launched your show I thought the format was awesome I loved how you initially got you know several different people on the like a three-way or four-way calls <mark>for</mark> thing and I've used your interviews to prepare me <mark>for</mark> <mark>for</mark> some of the guests that I've had on my show so I'm and let's say the same about you my really recently I think your questions are like awesome it's like on spot you know like super sharp minded questions that really cut to the chase you know and really make the your guests really Reflect thinks you know totally differently as as as if they you know would have just been in a normal conversation. It's really awesome. Are you study interviews? You know? Well, I really appreciate that man, and I'm as perhaps it's the same with you, but it's funny like, you know, I started this because I enjoy having these conversations and like, you know, sometimes you can fall into the Trap of like starting to You like her thinking more about like oh what do people want to hear and maybe I should do that <mark>for</mark> that and like I always come back to no. No. No this this is from me like that. These conversations are from me and you", "Start Time (s)": 3456.5, "End Time (s)": 3575.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "was awesome I loved how you initially got you know several different people on the like a three-way or four-way calls <mark>for</mark> thing and I've used your interviews to prepare me <mark>for</mark> <mark>for</mark> some of the guests that I've had on my show so I'm and let's say the same about you my really recently I think your questions are like awesome it's like on spot you know like super sharp minded questions that really cut to the chase you know and really make the your guests really Reflect thinks you know totally differently as as as if they you know would have just been in a normal conversation. It's really awesome. Are you study interviews? You know? Well, I really appreciate that man, and I'm as perhaps it's the same with you, but it's funny like, you know, I started this because I enjoy having these conversations and like, you know, sometimes you can fall into the Trap of like starting to You like her thinking more about like oh what do people want to hear and maybe I should do that <mark>for</mark> that and like I always come back to no. No. No this this is from me like that. These conversations are from me and you know, I published them just in case anybody else wants to listen in but like, you know, this is because I want to have these conversations and I want to connect with these people, you know as genuinely as possible over a shared shared interest, but still, you know you sometimes I record my listen to it back. I'm like the fuck was that like if ya just We're always our worst critics I guess but so it's nice. Nice. Nice to hear those those words man. I appreciate the kind of so, yeah, let's wrap it up John and hope to you know, get you back soon. You know, I'd love real to see you in person. Your Twitter handle is John Kay valise and you got your <mark>Bitcoin</mark> podcasts <mark>Bitcoin</mark> rapid fire. And we also what I found fascinating your YouTube channel. Yeah, the YouTube channels got a bunch of sprinkling of a bunch of different stuff as", "Start Time (s)": 3510.0, "End Time (s)": 3629.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "awesome. And he was like, what about and I was like, I don't know we'll just roll the camera and talk and he was like, yeah, ok, cool. So so, you know, there's a bunch of conversations like that in there. So yeah a little bit of everything. I'm going to check check some of these out of your videos out with my girlfriend cuz she was pretty impressed if the topics you cover, you know on your YouTube channel by that's so funny. I just had a dream last night about psychedelics with John but basis. Weird and if you want to I got the only one that from Earth direct you towards it. Yeah. The very first one I did was that the on psychedelics conference in Prague in 18 thinking June maybe and it's with dr. Bill Richards. Okay, so it's which one which one is it there? Let me see if I can find it that one. Number one psychedelic medicine doctor Bill Richards the second. Well, yeah got it. I've got a chance so he's the he's The Clinical Director <mark>for</mark> States Of Consciousness research at Johns Hopkins school of medicine and he's been around since the early days with Tim Leary and Richard Alpert and all the way through and he and two other guys at Johns Hopkins and 99 start like restarted the academic research into psychedelics and over the last 20 years they've really formed the basis <mark>for</mark> all the the research that's now being used to change the policies and get these substances integrated into the medical system so and he's such a lovely man he's got such great stories so I talked to him <mark>for</mark> a looks like about an hour there at that conference and you know if you're kind of even if you're new to psychedelics or psilocybin or even if you're not I mean I think that was my best work that was my eyes it was all downhill from there that was my best interview and then it all got worse from there but I just he's such an amazing man So if you're interested in that subject matter, that's a good place to definitely I'm a huge", "Start Time (s)": 3657.9, "End Time (s)": 3777.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0i4SJwrYjxs3Bd5Yqx4Pbw", "show_name": "Bitcoin Rapid-Fire", "show_description": "Bitcoin is the future of money, that is my firm belief. In this show, I speak with the amazing people who are building and contributing to this revolutionary new industry. The 'rapid-fire' episodes give you some concise info and insights, the 'further discussion' episodes let you listen in on a more casual and open dialogue with each guest.   Hey hey hey, stack sats everyday:)", "publisher": "John Vallis", "episode_uri": "spotify:episode:4Au2TYKBkgjoKI1NSAbJ2X", "episode_name": "Guest on Keyvan Davani's 'Total Bitcoin' Podcast", "episode_description": "I was recently invited on to Keyvan Danvani's 'Total bitcoin' Podcast for a chat. Keyvan has been putting out some awesome content with great guests and an interesting format, and it was super fun to get the chance to speak with him. Note: We had some bandwidth issues it seems, so the audio is a bit spotty in places. It's the worst during the first half of the show.  More from Keyvan: WEBSITE: http://thetotalconnector.com/ TWITTER: https://twitter.com/keyvandavani APPLE: https://apple.co/2IA2dhV SPOTIFY: https://spoti.fi/2wOfq1k  More from me: TWITTER:\u00a0http://bit.ly/2P7PUjA YOUTUBE:\u00a0http://bit.ly/2TDeMy9 MEDIUM: http://bit.ly/2Zk0Dex INSTAGRAM:\u00a0http://bit.ly/30r7IqY ", "score": 4.34188, "explanation": "{\n  \"value\": 4.34188,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 4.34188,\n      \"description\": \"weight(word_list:bitcoin in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.34188,\n          \"description\": \"score(LMDirichletSimilarity, freq=63.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.2355943,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 63.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 6.181271e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.181271e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:for in 27) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=72.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7448182,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 72.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Hello and welcome to whatever number episode this is episode number four, but it's confusing because we release the last two episodes out of order. When one one three two. Oh, how will how will they trust how will our fans? How are we gonna get through this as a group? I think I think that all hate mail to at Monday. No, you have to it's more of like an avant-garde movie where they Least like where it's like they don't show you the current timeline like Witcher. I've hurt I would watch which I've heard. It's out of order. I'm playing would you right now? It's ruining my life. It is ruining your life. Yeah, you get so addicted to video games. Yeah. Yes, you do. Wait. So what are your biggest Skyrim breath of the wild and now which are you like medieval don't you I do. What about war? What about like like guns big fan of shooter games? I guess think since you were there were a lot of the Rings girl was Do they have a name <mark>for</mark> the personal Matthew? You know, this is great. That's an interesting thing about you. I feel like you should talk about on stage because everyone's a Harry Potter nerd. Everyone's a Pokemon nerd not like I said deep nerdom. It was a pretty deep nerdom. It's also hard Colbert hard to find. Yeah, so, it's me Stephen Colbert. We just love Lord of the Rings together Johnny Montgomery, and it was also The books I've been out <mark>for</mark> a long time. I guess the movies were coming out. So it was popular when I was you know in school because of that but there was no one who was like a deep fan. So just basically we solo I'm reading Hyperion on the series right now, which is four books released between like the 80s and 90s and it's considered one of the most successful Sci-Fi series of all time. Like I think it's like the top 10 sellers on on Amazon or like up there and they want to get to the fourth. Book and I'm looking online <mark>for</mark> like reviews and Fan Art. There's nothing because so few people read books. Yeah, like once you get that far", "Start Time (s)": 2.1, "End Time (s)": 121.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "big fan of shooter games? I guess think since you were there were a lot of the Rings girl was Do they have a name <mark>for</mark> the personal Matthew? You know, this is great. That's an interesting thing about you. I feel like you should talk about on stage because everyone's a Harry Potter nerd. Everyone's a Pokemon nerd not like I said deep nerdom. It was a pretty deep nerdom. It's also hard Colbert hard to find. Yeah, so, it's me Stephen Colbert. We just love Lord of the Rings together Johnny Montgomery, and it was also The books I've been out <mark>for</mark> a long time. I guess the movies were coming out. So it was popular when I was you know in school because of that but there was no one who was like a deep fan. So just basically we solo I'm reading Hyperion on the series right now, which is four books released between like the 80s and 90s and it's considered one of the most successful Sci-Fi series of all time. Like I think it's like the top 10 sellers on on Amazon or like up there and they want to get to the fourth. Book and I'm looking online <mark>for</mark> like reviews and Fan Art. There's nothing because so few people read books. Yeah, like once you get that far unless you're like one of those like four major series like if this was a TV show I could search the hashtag and the like there would be endless like sculptures and cartoons of the characters. It's kind of sad unless they're better books are better but they require more deep sigh problem now is by the time I'm done with work everything. My brain is just Tired. Yeah Focus anymore reading on the subway is not yeah, you don't read it all anymore, which sucks. He's you're such a good reader. I used to be obsessed with reading. Yeah. I mean I read a ton but it's emails. Are you read? You read some nonfiction? Yes that Clint Watts book shutouts our home with Clint Watts. You don't read any fiction anymore. Do you very rarely? I wish I would love reading fiction. I just don't have the time very often. Yeah, you only have time to I'm a Witcher. I only have", "Start Time (s)": 55.9, "End Time (s)": 175.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "pretty well. It's a classic right? How old is it? Yeah, so and working and that's it and doing comedy. I don't ya. I have much going on. Yes, you do have it. I don't know. It is funny that one of your biggest three things those a video game but let's talk about balancing working in comedy lately. How many Mikes you been doing? We're going up. I have to have them and telling me about your sets. I know so that was a new thing that we had a great suggestion by someone who had listened to the podcast. So weird to say, it's just cool. I know I just it's just cool to hear. Yeah. Well, he's doesn't feel like you feel like you're talking to a microphone don't actually hear that. Do you feel that way like you'd like a disconnect between this and the fact is currently as many as a hundred thirty people might listen to this. We're like her. Italy are eventually gone because you could probably hear Matthew drinking his coffee right now, which maybe is not the best <mark>for</mark> sound quality of decent audio I listen to another podcast today terrible audio and I still am out who was it? It was the early episodes of my favorite theorem. Don't think that's fair the mathematics podcast the original Lander suggested. Laughs both of them equally hard so math podcast. Well, I mean your listen so clearly maybe bill will you that's true but I re come out we're talking about balancing work and comedy. It's yeah, it's freaking hard. I think we talked a little bit about that last time. But yeah, I I'm getting crushed. Uh-huh and witcher's also just been really vital part. My you know, I have a lot of you know Bandits that I need to kill so that's been it's been tough to balance that I just got a text. I don't know if that noise is gonna go through I didn't", "Start Time (s)": 223.3, "End Time (s)": 343.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I re come out we're talking about balancing work and comedy. It's yeah, it's freaking hard. I think we talked a little bit about that last time. But yeah, I I'm getting crushed. Uh-huh and witcher's also just been really vital part. My you know, I have a lot of you know Bandits that I need to kill so that's been it's been tough to balance that I just got a text. I don't know if that noise is gonna go through I didn't hear it. See, this is why we need to move to a studio so we can be more professional. So we get text that it doesn't Echo is loudly exactly and what else has been going on I've been doing I've had a lot of like interesting experiences and comedy recently. I haven't told you about most so I'm going to tell you a little bit about those a lot of bursts. I hosted a mic at the creek in the cave with Julie. What am I? Yay? That's my only favorite Blake, but I think one of the best spots <mark>for</mark> open mics in town, I would say as far as actually doing Comedy Now great as far as hanging with fun people awesome. And the main reason I say that to be fair. I've only gone to really the late-night sets and with any late-night set things start to get more rough. I've heard these three minutes. Yeah, you know, I mean they say the 11 p.m. Tuesday is when the best Mike's in town, I've heard that too but it's 11 p.m. I Tuesday. So that was a hypothetical <mark>for</mark> me probably <mark>for</mark> somebody to that's late <mark>for</mark> me. It's late. If an open mind also Tuesday such a that's like I'm working. Yeah, the next next day is really is absolutely worked at yes. So that has I'd I was hosting I was hosting it was harder than I thought it would be. I've done a little bit of I've hosted some mics at Eastvale but like Saturday afternoons, and they're usually, you know, pretty pretty chill long years longer slot time. So that was easier than hosting with another person is interesting", "Start Time (s)": 311.9, "End Time (s)": 431.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know, pretty pretty chill long years longer slot time. So that was easier than hosting with another person is interesting because you have to figure out your Dynamic I loved Least so much. She's wonderful. She's a lot of roasts check her out. But I just we've never done that before onstage. So I had a little bit of trouble balancing how I was going to be and then also I had to do jokes afterwards. So I kind of had to make that match my personality. Yeah. I mean am I joked my like performance personas not necessarily who I am. So I don't know. Does that make sense? Yes, just figuring out. How to host I don't know how to do that yet so working on it and but it was really fun long lot of people, you know, did the mic just figured out that it's really hard to read people's handwriting and then they get mad if you pronounce it correctly. Did you say any like after you finish your set and brought the first coming on stage as you say anything besides put your hands together <mark>for</mark> blank? Not really, right? Yeah, but I have no but a lot of Mike's will be I remember the first time I hosted my can Houston I went up and bombed and I got off stage. I was like how come people didn't laugh <mark>for</mark> the parts. They normally laugh at it smells like okay, you weren't first I'm like, why is that different? Look? Yeah, you put the bullet they called it the bullet spot. But I Remember by the end of it. I was so frustrated people were like Ember. Oh and made fun of my friend. Owen done was just like the shitty hotel iguanas a she was like Good hosting like everyone laughs. So then I like tried to like play around a little bit between but it's fun playing around between Comics. Yeah, I mean obviously want to bring it straight up to keep the energy going but like it's yeah to be fair. There's so many people that go to this mic and you don't even you don't even go back on your just like Dex damn next day next time. It's pretty crazy to meet someone who does time between atomic had it open under your covid when you do a minute between we've witnessed that night and it was", "Start Time (s)": 423.7, "End Time (s)": 543.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and bombed and I got off stage. I was like how come people didn't laugh <mark>for</mark> the parts. They normally laugh at it smells like okay, you weren't first I'm like, why is that different? Look? Yeah, you put the bullet they called it the bullet spot. But I Remember by the end of it. I was so frustrated people were like Ember. Oh and made fun of my friend. Owen done was just like the shitty hotel iguanas a she was like Good hosting like everyone laughs. So then I like tried to like play around a little bit between but it's fun playing around between Comics. Yeah, I mean obviously want to bring it straight up to keep the energy going but like it's yeah to be fair. There's so many people that go to this mic and you don't even you don't even go back on your just like Dex damn next day next time. It's pretty crazy to meet someone who does time between atomic had it open under your covid when you do a minute between we've witnessed that night and it was we were together. It was a it's not cool not cool. But you learn a lot I get why the host that you learned a lot like just just fucking around like that. You can oh no, I loved I definitely want to so that's one of my goals <mark>for</mark> this year. I also wrote Combi Cole's one of my goals is to host a mic and then produce a show. Yeah. So attainable goals within your control very much. I am I have one of my first experiences. I had my first experience hosting a New York club this weekend that I did not know. I've been opening <mark>for</mark> Hasan. Minhaj. He's been working on his our at The Comedy Cellar. See you just got to like and I showed up when I pull it. Yeah, I showed up at Saint Manoj. Yeah, but it's 3 p.m. In the afternoon is a little lower Stakes. It's not like it's not his taping or anything, but I showed up and there's usually a couple comics and this weekend was just me sews and obviously I always feel a little nervous of the seller because of the, you know, the legacy of that place and I had to go up and I was trying to find the balance between crowd work and how quickly I jumped into a bit. And I don't know if I did and you I mean I did so have it goes going to button either but I want to be better at it <mark>for</mark> eight years in I should I wish", "Start Time (s)": 495.0, "End Time (s)": 614.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "can oh no, I loved I definitely want to so that's one of my goals <mark>for</mark> this year. I also wrote Combi Cole's one of my goals is to host a mic and then produce a show. Yeah. So attainable goals within your control very much. I am I have one of my first experiences. I had my first experience hosting a New York club this weekend that I did not know. I've been opening <mark>for</mark> Hasan. Minhaj. He's been working on his our at The Comedy Cellar. See you just got to like and I showed up when I pull it. Yeah, I showed up at Saint Manoj. Yeah, but it's 3 p.m. In the afternoon is a little lower Stakes. It's not like it's not his taping or anything, but I showed up and there's usually a couple comics and this weekend was just me sews and obviously I always feel a little nervous of the seller because of the, you know, the legacy of that place and I had to go up and I was trying to find the balance between crowd work and how quickly I jumped into a bit. And I don't know if I did and you I mean I did so have it goes going to button either but I want to be better at it <mark>for</mark> eight years in I should I wish I should be better at it. Yeah, it's pretty something. Yeah. I've also produce your own thing. I've never done to man hosting before someone else thing is what you and Julie did that's pretty common in New York, right and it can go really well like a Knitting Factory was was three people it's a people still when they switched over. I've also done shows wishes to people Together and then they just talk and don't get anywhere and they bring you up and it's somehow even worse. Yeah, because if one person went up at the material and bombs will at least they are in the rhythm of hearing stand up versus just now that was like the bad conversation followed by a guy trying too hard. Yeah, the first concerns that that might have been no, that's not true. Julie does she's a great host. But she does it every weekend there. Yes, it's just, you know people who can host and can't do stand-up. Well, I'd rather choose to end up and not be able to host but I'd like to do both me too. I also went so talking back to that", "Start Time (s)": 552.2, "End Time (s)": 671.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "years in I should I wish I should be better at it. Yeah, it's pretty something. Yeah. I've also produce your own thing. I've never done to man hosting before someone else thing is what you and Julie did that's pretty common in New York, right and it can go really well like a Knitting Factory was was three people it's a people still when they switched over. I've also done shows wishes to people Together and then they just talk and don't get anywhere and they bring you up and it's somehow even worse. Yeah, because if one person went up at the material and bombs will at least they are in the rhythm of hearing stand up versus just now that was like the bad conversation followed by a guy trying too hard. Yeah, the first concerns that that might have been no, that's not true. Julie does she's a great host. But she does it every weekend there. Yes, it's just, you know people who can host and can't do stand-up. Well, I'd rather choose to end up and not be able to host but I'd like to do both me too. I also went so talking back to that you hosting <mark>for</mark> her son. That was quite an experience. Yes. So this was at the seller was like 3:00 p.m. On a Sunday and I signed up <mark>for</mark> a mic in the area. I would see the lanterns which is fine. So by Mike and but I got it's at 4 p.m. On a Sunday p.m. On a Sunday. So Do with that as you will right, you know, it's gonna be a appropriate amount of energy <mark>for</mark> that. But I go and watch that hose and I watched beginning of Hassan's he's working on his new our yes, it's really it's so good. So my gosh, it's so good. And also the way he does his comedy his stuff is so funny. But a lot of it just has like more broader impact on the world, you know, like it's very personal yet at the same time very it's just good. It's just makes you be like what I'm afraid. It's a forest I got trees. Yeah, exactly. It's not like I mean, there's definitely pieces you could take out that would stand alone, but it's not like a bit about women like", "Start Time (s)": 613.3, "End Time (s)": 732.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Do with that as you will right, you know, it's gonna be a appropriate amount of energy <mark>for</mark> that. But I go and watch that hose and I watched beginning of Hassan's he's working on his new our yes, it's really it's so good. So my gosh, it's so good. And also the way he does his comedy his stuff is so funny. But a lot of it just has like more broader impact on the world, you know, like it's very personal yet at the same time very it's just good. It's just makes you be like what I'm afraid. It's a forest I got trees. Yeah, exactly. It's not like I mean, there's definitely pieces you could take out that would stand alone, but it's not like a bit about women like yes, it's very much like his life and stuff like that either way afterwards three blocks away or so. I walked to go to this mic. I'm going I went up first which was you know, so I knew hosted know. Is there a host? Okay. Yeah. There was that either way. It was still very early in the Mike and I Birth <mark>for</mark> the first minute. I was just standing up there and I couldn't even get into my material because I was like, who am I like what am I doing? Why am I doing jokes about these stupid topics when he's talking about like I don't want to spoil anything. I mean, it's not it's like his yes famous enough that but talking about like you said about being a family and the things he's been through on a global level and how Talk people through most of most people in Time Magazine. Yes. It's pretty substantial. I mean, I feel that way hosting Grandma. I'm like this is so stupid compared to what he talks about. Like it's so personal and original. It was just fraud just <mark>for</mark> and then you come back and watch the end of it. I do my spot watch a little bit more than I walked back over and is an hour so he was still going and I watched the second half or so and and", "Start Time (s)": 693.3, "End Time (s)": 813.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I feel that way hosting Grandma. I'm like this is so stupid compared to what he talks about. Like it's so personal and original. It was just fraud just <mark>for</mark> and then you come back and watch the end of it. I do my spot watch a little bit more than I walked back over and is an hour so he was still going and I watched the second half or so and and it was really very jarring to have those two I think only New York can you have it be in such a short period of time where your exhibit witnessing one of the greatest and then you're on stage 3 seconds later in the lanterns a lovely location, right? You know that Mike is a wonderful Mike. However It's different. It was a different vibe. I've definitely had like a Saturday night like that where if I've gone to like I'll go from like following Colin Quinn to proceeding a guy who's doing comedy <mark>for</mark> the third time. Like it's very that's why it's that's why I think it's so stupid people has opened <mark>for</mark> been like we all mixed together. It's like the NFL where you're lucky to be on a team with him. Like we all will do any spot one of my favorite sets and comedies stop me if I told this one of our guests already, but when I did my half hour in New Orleans <mark>for</mark> Comedy Central I remember the first 10 minutes being so great. And then the last 10 being like what's going on? Why did I start bombing Midway through I can feel the sweat on my face. The energy is dying. I get offstage my tech bomb and I skip the after party and find an open mic and go up and do like five minutes at a bar <mark>for</mark> I think it was maybe 8 to 12 people and it's maybe the most fun I've ever had doing comedy just like me like this is right. I don't deserve 500 people coming. We television taping this feels nice to like to see their faces to not feel stuff to some scripts not be worried. That was really fun. I like that now. I just like the ego death. I like", "Start Time (s)": 788.5, "End Time (s)": 908.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "now. I just like the ego death. I like the second you start taking yourself too. Seriously, you stop being funny. So I love going to those rooms II think it's so important to have your ass handed to you on a frequent basis. Yeah, I can see that because God can't take this. Seriously. I went I eventually went. Okay good. I was going to say yeah, I snuck that one. One iron that one. Yeah, you got to take your victories. There's not that many. I'm just you know, and that one of my favorite writers at that show, so I'm happy. I went who's your favorite writer? He's on a Facebook and Twitter is puneet lock monni. He's a med student and he just writes really good jokes. I don't know if I'm outing him as it may be is a Doctor by now, but he's he's you meet like people do tend to say he's just like every day every take is so good. I'm such a fan of his writing. Yeah. Yeah, actually he had his Nick. I may be mad at him to measure things pretty like Mommy I Indian obviously and <mark>for</mark> a while he had to change his name on Facebook to hide this he was Pete lachman is the white. I think he thinks I'm like white guy who looked vaguely like him what other first-class you finish your class. I finished my class you had a class show and I had a clap. Oh my gosh. This is the that was cool. That was so cool. It was Okay, so I mentioned earlier if you didn't listen to the other episode I took a stand of class with Radha camozzi, and it was a really fun experience The Comedy Cellar The Comedy Cellar highly recommend super-exclusive really hard to get in. Right and I mean not exclusive. It's like III are you have to just email them as soon as it opens up? Yes. So if you're like me and you like to set alarms and alerts and things like that, no problem getting in <mark>for</mark> me. I like to just I like to I create a boss. Got to to sign up <mark>for</mark> the class immediately and then I scalped the tickets later. He's lying. I'm lying. That'd be funny how you could do that with you that you see be", "Start Time (s)": 906.9, "End Time (s)": 1025.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "actually he had his Nick. I may be mad at him to measure things pretty like Mommy I Indian obviously and <mark>for</mark> a while he had to change his name on Facebook to hide this he was Pete lachman is the white. I think he thinks I'm like white guy who looked vaguely like him what other first-class you finish your class. I finished my class you had a class show and I had a clap. Oh my gosh. This is the that was cool. That was so cool. It was Okay, so I mentioned earlier if you didn't listen to the other episode I took a stand of class with Radha camozzi, and it was a really fun experience The Comedy Cellar The Comedy Cellar highly recommend super-exclusive really hard to get in. Right and I mean not exclusive. It's like III are you have to just email them as soon as it opens up? Yes. So if you're like me and you like to set alarms and alerts and things like that, no problem getting in <mark>for</mark> me. I like to just I like to I create a boss. Got to to sign up <mark>for</mark> the class immediately and then I scalped the tickets later. He's lying. I'm lying. That'd be funny how you could do that with you that you see be probably you probably could those classes fill up so fast, but either way, so no you can just it's really turns out that if you give people enough money you give a like pretty much go wherever it's really we've already talked about that. I did improv. So I was like, no problem. Here's some money sign up a class was really fun. I know people have mixed feelings on stand up classes, but it was definitely a really good exercise in Just writing new material and Veronica's fantastic comic so being able to get, you know, great feedback and mostly the accountability of having new jokes every week. Yes, and by the end of it I had it was like four and a half five more minutes of material because you refuse to do stuff you already worked out because you have integrity and wanted to get your money's worth. Yeah. Well a lot of mostly this again, I wouldn't matter I just wanted to get my money's worth. I'd bring you some like Polish baby like yeah. Just thought of this crazy.", "Start Time (s)": 959.0, "End Time (s)": 1074.2, "Clip Length (min)": 1.92, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "exercise in Just writing new material and Veronica's fantastic comic so being able to get, you know, great feedback and mostly the accountability of having new jokes every week. Yes, and by the end of it I had it was like four and a half five more minutes of material because you refuse to do stuff you already worked out because you have integrity and wanted to get your money's worth. Yeah. Well a lot of mostly this again, I wouldn't matter I just wanted to get my money's worth. I'd bring you some like Polish baby like yeah. Just thought of this crazy. yeah, so I wrote wrote some new stuff and then at the end of the class they did there was to show cases where I mean, basically everyone just didn't you know invited their friends and but we got to perform at the cellar which is it feels like as if I had been invited to play like at the end of My Viola my six-week violin course <mark>for</mark> <mark>beginners</mark> at Hahaha, you know where you're standing there. You're like. I should not be up here. I should not. Maybe what's that the Amazon chopsticks Chopsticks and kind of look at my friends our family our like you're really doing it Yay. Good job Laura, but so felt kind of weird about that, but it was really fun. It's great. Like you were the only person in that class who does open mics. Yeah, so that was true also, and also I thought I was the only person who was who is had been doing comedy which is like Months about remains just to put that in perspective that is like not even close to where you should be. So these are brand new people but it was really interesting to watch the mechanics of how people learn how to write and the kind of subject matters that people tended to want to talk about right away. And also it was really proud of them <mark>for</mark> how much better they", "Start Time (s)": 1046.1, "End Time (s)": 1166.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "violin course <mark>for</mark> <mark>beginners</mark> at Hahaha, you know where you're standing there. You're like. I should not be up here. I should not. Maybe what's that the Amazon chopsticks Chopsticks and kind of look at my friends our family our like you're really doing it Yay. Good job Laura, but so felt kind of weird about that, but it was really fun. It's great. Like you were the only person in that class who does open mics. Yeah, so that was true also, and also I thought I was the only person who was who is had been doing comedy which is like Months about remains just to put that in perspective that is like not even close to where you should be. So these are brand new people but it was really interesting to watch the mechanics of how people learn how to write and the kind of subject matters that people tended to want to talk about right away. And also it was really proud of them <mark>for</mark> how much better they got yes six weeks in you know, the writing was solid. I like the writing I did probably right, you know, she taught like that framework of how beginning middle and That like I mean simple stuff but at the end of it, you know, their performances were solid. Yeah, it was the head of data set. It was very fun to watch we got in a fight and you werewell really well consider. We got a fight right before the show. Okay? Yeah Matthew, I'm glad you brought this up because I wasn't going to ouch you always but I didn't want to sit in the back run such a drama queen. No Veronica said, this is a perfectly normal feeling that it yeah, but it's sitting in the audience is very scary if you perform on that stage a lot and I was like right in the front very I don't know what I was afraid of but it was just weird. I wanted to sit close to the back and you're like no go sit with Julie and Katie's so I had some friends there that other Comics that were so lovely as to support, but Matt he comes down and he was like trying to sit at the back of the comics comics table according to what was considered the comics Christmas at the back.", "Start Time (s)": 1105.3, "End Time (s)": 1224.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "solid. I like the writing I did probably right, you know, she taught like that framework of how beginning middle and That like I mean simple stuff but at the end of it, you know, their performances were solid. Yeah, it was the head of data set. It was very fun to watch we got in a fight and you werewell really well consider. We got a fight right before the show. Okay? Yeah Matthew, I'm glad you brought this up because I wasn't going to ouch you always but I didn't want to sit in the back run such a drama queen. No Veronica said, this is a perfectly normal feeling that it yeah, but it's sitting in the audience is very scary if you perform on that stage a lot and I was like right in the front very I don't know what I was afraid of but it was just weird. I wanted to sit close to the back and you're like no go sit with Julie and Katie's so I had some friends there that other Comics that were so lovely as to support, but Matt he comes down and he was like trying to sit at the back of the comics comics table according to what was considered the comics Christmas at the back. Yeah, and I was like, no go sit in the <mark>for</mark> once in your damn life is about me. So I made him stay in the middle and he got all mad. and I tried to he tried to get up and not sit there and I was like I'm gonna I'm gonna cause a scene sit down and then you have fun a lot of fun. You did really well. I was very very proud of you. You just had it. I don't know why you have to have done bad rooms to appreciate the good rooms. You could the crowd was really high and when you sense the crowd was matching you so it was like the most supportive crowd you could get yes. So, I mean it was a bringer show without them having to like, you know, the of part of like a bigger thing than just like standing outside. And getting your name called or something, you know, I mean and one of the funniest people on the show brought the most friends, but I don't think she was the funniest because of her friends. I think she was just very funny. She's right. She was really good. I really like she made a joke about what was her opening joke was about that. This was a bringer comedy class show", "Start Time (s)": 1168.7, "End Time (s)": 1288.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it's sewed. It doesn't make sense how bad it makes you feel about yourself. I think it's because there's so many Charming people who are interesting and fun, but they're not good stand-ups. But when you go on stage in a room full of people reject you you think what's wrong with me, you know, let's yeah, but one thing that I think is really funny about the the class. Your set There Was You got a really good tape out of it. It's a really good take but it has it says The Comedy Cellar right behind you. That I mean you can but it's good to have the sense of not a lot of people will do produce shows at The Comedy Cellar not be book there and we'll just post pictures online with the Comedy Cellar logo very clearly letting people think that not saying it but letting people think that and I don't like that that's super fan. I mean, that would make me I mean, I guess I just make me angry when I'm like you should have better sense than that and I like that at least you're aware of that you have to earn. Yeah, basically like taking Credit <mark>for</mark> an Accolade that you don't have your strategies that with using that to since of festivals is you've been saying of here's a set of me Allah. I am not passed at The Comedy Cellar. Oh, yeah. I know I submitted to a festival that's not Russell. That's another goal of mine <mark>for</mark> the year. I also know that that's like probably a little early but there's any festivals that you know are good <mark>for</mark> beginners. Let me know you're all getting so competitiveness. I'm going to Communism. And again, it's one of those things where I'm sure a lot of them are just like you have to pay like $35. I don't believe that's what it costs them and processing. He's one of those kind of things. I mean if you made me watch you have to pay me a lot of money to watch that's 500 5 minutes sets unfiltered from any psycho with a with an iPhone and a tripod boy. That's tough. Huh? That is tough. Okay at $35 actually might be too low also production value <mark>for</mark> any Comics who are submitting to As", "Start Time (s)": 1340.5, "End Time (s)": 1459.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Yeah, basically like taking Credit <mark>for</mark> an Accolade that you don't have your strategies that with using that to since of festivals is you've been saying of here's a set of me Allah. I am not passed at The Comedy Cellar. Oh, yeah. I know I submitted to a festival that's not Russell. That's another goal of mine <mark>for</mark> the year. I also know that that's like probably a little early but there's any festivals that you know are good <mark>for</mark> beginners. Let me know you're all getting so competitiveness. I'm going to Communism. And again, it's one of those things where I'm sure a lot of them are just like you have to pay like $35. I don't believe that's what it costs them and processing. He's one of those kind of things. I mean if you made me watch you have to pay me a lot of money to watch that's 500 5 minutes sets unfiltered from any psycho with a with an iPhone and a tripod boy. That's tough. Huh? That is tough. Okay at $35 actually might be too low also production value <mark>for</mark> any Comics who are submitting to As symbols care how good of a set you think you had get a high production value video tape. It don't expect to get it in one. Try always say tape 10 sets and hope she'll get one and keep that shit tight. Don't show me. Show me your first joke going straight into your first laugh. Make sure the Comedy Cellar logo is boldly in fact and rainbow color just have it be only The Comedy Store logo also no crowd work. No, you'll need the host. Just get it tight. Just cut to the chase. It's another comic watching it so don't bullshit them. Yeah, that's true. Yeah, I sound so angry about that. I don't know how you know watching these tapes. Are you running a festival? You haven't told me I was going to be a it was going to be a birthday gift. What any other first? Looking at I wrote a list. I signed up check my notes real quick. It's like an open. Mike.", "Start Time (s)": 1398.3, "End Time (s)": 1517.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "What any other first? Looking at I wrote a list. I signed up check my notes real quick. It's like an open. Mike. What else did I write down today? Do I want to talk about? All right. Well I signed up to do a bringer show, which I'm excited about I think in general it's probably a silly or what are your thoughts actually not before I give my non expert opinion. Let's hear the expert to start on New York City. You're going to have to bring her bark at some point. I don't judge it brings a little tub bringing just an unsustainable model. Although right you can't keep being a bringer. It is fucking dope stage time because I do bring her shows as the whatever headliner a lot and those Crowds Are Juiced. Oh, it was crowds are so very fun. Never really barked. I really admire people who can park there with that New York Times article about like the stigma barking. I respect it a lot and that's more sustainable. You can keep doing that, but then your friends see you barking. Barking <mark>for</mark> those who don't know is when you stand outside a comedy club me and like I'll go encounter with scholarship and I come to a comedy show coming on the show and you get like paid some Commission on the tickets and I do let though sometimes I get to be on some of those there's clubs that are almost like the function on barking. So well the main reason that Everest wrong a lineup since Never As Good a crowds unfortunately, not fortunately. Yeah, it's just I mean it said you'd never barked. I I mean, it's not that Wouldn't want to I just win like and I also have the you know, I'd rather do a bringer in my opinion because I have a lot of friends who are like, oh I want to see you do comedy and I'm like, well, those are limited options at the moment. Yeah. I don't think you should come to a mic I've had friends who've come to my ex and I'm like bless you, but don't you stop don't do that? Yeah come to a bringer and but the main reason I've ever done a bringer. This is the this will be the first one. It's not till May so I have some time to like kind of get some new material pull together, but you get a good tape out", "Start Time (s)": 1509.0, "End Time (s)": 1628.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "not fortunately. Yeah, it's just I mean it said you'd never barked. I I mean, it's not that Wouldn't want to I just win like and I also have the you know, I'd rather do a bringer in my opinion because I have a lot of friends who are like, oh I want to see you do comedy and I'm like, well, those are limited options at the moment. Yeah. I don't think you should come to a mic I've had friends who've come to my ex and I'm like bless you, but don't you stop don't do that? Yeah come to a bringer and but the main reason I've ever done a bringer. This is the this will be the first one. It's not till May so I have some time to like kind of get some new material pull together, but you get a good tape out of it. That's what I've heard. Yes. So to solve my problem of my main tape being this Comedy Cellar one, which is just Nick not useful in practice going to do the one where I get another tape. It's just Photoshop another logo over it bleep. It's the exact same list and that's kind of funny. Yeah, and then also The Comedy Cellar is kind of known <mark>for</mark> not having that many produce show. So if you're on a Comedy Central show it does it have to be passed to you step foot on the stage. That's kind of The Prestige of it. You do a really good job of like yeah protecting. It's a really good club. Let me just say that it's a really it's a very it's a magical place. It's very strange on comedy of like there's a stigma against barking. There's a stable against doing bring her shows. There's a stigma against classes when you get to a higher level. They're like all you still do open mics. It's like, oh all the things that could make me good. I shouldn't have done I should just show up one day. Yeah. What is the like already good at it? Yeah. I think it sounds like my perspective. I was like is here telling me I could do this thing. In worst case scenario. I just write about five more minutes worth of material. That's the only thing I get out of it. Yeah, I'm gonna I'm gonna do that. Yeah, but you're getting a learn some stuff at the same time. At least it'll be you know, forced writing Network. I'd there is a thing. I think I think comedy class Comics don't typically go on to pursue it as well. I don't know why that is. I just don't think that they", "Start Time (s)": 1589.9, "End Time (s)": 1709.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I just write about five more minutes worth of material. That's the only thing I get out of it. Yeah, I'm gonna I'm gonna do that. Yeah, but you're getting a learn some stuff at the same time. At least it'll be you know, forced writing Network. I'd there is a thing. I think I think comedy class Comics don't typically go on to pursue it as well. I don't know why that is. I just don't think that they understood the challenges and I mean, you know, they'll learn about that right, but just No going from doing a bringer show at the Comedy Cellar like the best club and possibly the most supportive audience you could have yeah and then going from just like going feels like going from Hasan. Minhaj is our at the college to the lantern Open Mic 4 p.m. Yeah. Oh my gosh. So you're kind of at this conveyor belt point though. This is what happened to me when I was when I was a year into comedy had a 15-minute set that I was doing 15 minutes and every joke I had pushed out another joke, so if I like I was stuck at 18 minutes <mark>for</mark> so long. Yeah, and I feel like you've been writing new material but throwing away the original stuff. I still have the old stuff like I I've been trying to obviously when I was in the class, I was trying to like just do the new stuff and now I've tried to mix them up a little bit. I didn't know which jokes you like more than you or the old. I still like my old ones. I still have some good ones and the old ones but there's definitely a few that which isn't great because if I actually spent time on them and paid a little more attention, I could probably make them better because I still I'm still early enough that most of the concepts I'm doing. I'm like, yeah, I like that concept, you know. Yes, like I have like those ones that I've been thinking about <mark>for</mark> years kind of deal. And now I'm thinking about my jokes and I'm like, oh really? You're gonna say that you really like that concept Laura my jury duty joke, that's a new one. It's not bad or did jury duty. I did. Oh, yeah. I did jury duty. I almost got put on a two-week trial. I'm probably not supposed to talk about it. But I was somewhat like the OJ jurors like the ones the last month's", "Start Time (s)": 1689.7, "End Time (s)": 1809.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and now I've tried to mix them up a little bit. I didn't know which jokes you like more than you or the old. I still like my old ones. I still have some good ones and the old ones but there's definitely a few that which isn't great because if I actually spent time on them and paid a little more attention, I could probably make them better because I still I'm still early enough that most of the concepts I'm doing. I'm like, yeah, I like that concept, you know. Yes, like I have like those ones that I've been thinking about <mark>for</mark> years kind of deal. And now I'm thinking about my jokes and I'm like, oh really? You're gonna say that you really like that concept Laura my jury duty joke, that's a new one. It's not bad or did jury duty. I did. Oh, yeah. I did jury duty. I almost got put on a two-week trial. I'm probably not supposed to talk about it. But I was somewhat like the OJ jurors like the ones the last month's what do they do? How do this hard? It's really what their job like, what do they know? You're not alone. I mean, there's definitely like legal. Requirements that they can't fire you <mark>for</mark> being on jury duty, but my boss was like hey, yeah, don't get put on this case too weak case. He was like, I can't believe no you're not going to get on that. Yeah, but I still had to go <mark>for</mark> two days because I got pulled to the back and like interviewed and stuff like that. Well, I canceled my guy like what would happen to me while I cancel my road dates what I like cancel the show. The thing is I give you had they were like well, is there anything that would make? Get to where you couldn't, you know be on this jury <mark>for</mark> two weeks and I was like, yeah. Yeah the lantern Open Mic at 4 p.m. On a Sunday committed. Look at this email. He emailed me and said I'm on ya so I can't get out of this. Yeah, like it's pilot season, but they do editions. I mean they eat so why was there they interviewed like I was there <mark>for</mark> two full days and they interviewed 20 potential jurors really picked three and they needed pleasure. They needed eight. So that means they had to keep bringing in groups of 10 and", "Start Time (s)": 1760.6, "End Time (s)": 1879.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "do editions. I mean they eat so why was there they interviewed like I was there <mark>for</mark> two full days and they interviewed 20 potential jurors really picked three and they needed pleasure. They needed eight. So that means they had to keep bringing in groups of 10 and interviewing them to get to 8:00. Sounds like your crew had not a lot of talents not a lot of very unimpressive Bunch. We were very good at being like the horse. I'm still busy. Is there one there who like was like fuck? Yeah, I could do this. I yeah, what a guys let's go MTA bus driver and he was like hell yeah. Get on yeah, you did. Oh girl like yeah. That's so awesome. It was great the entire because I mean obviously everyone was like annoyed that they were there but it was a moment of unity when he was like, yeah, I've got plenty of time. Yeah, you know, it's really fun fact. It's also, you know, it's illegal to assault a bus driver. It's also illegal to assault a juror so you should be well suited <mark>for</mark> the thank God that was a joke. That mystery is because the Earth Yes, and you should know but you shouldn't know he's any other first. Yeah, okay. One cause I know I'm once again could be in the moment. Don't let your nose. I don't think I say seriously told me to look at my notes too much on stage. Professional Matthew it does it does bring my brother also hates. It just brings down the show. Do you bring let's talk about notes. I have been bringing up notes when I'm trying to do new stuff because otherwise I don't do it. Do you know what I mean? And then I'm like it's <mark>for</mark> new stuff. Yeah, Mike like why did I not I really like that feeling. Can I get there? And then I go to my other material like the point is to fix new stuff here. I hate doing going. The show", "Start Time (s)": 1864.8, "End Time (s)": 1984.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "feeling. Can I get there? And then I go to my other material like the point is to fix new stuff here. I hate doing going. The show where I have the freedom to try new stuff and I get offstage Mike. Well, those jokes are still jokes like you can try anything new or yeah, and another thing that I try to remind myself as the more I plan the more I improvised. So if I just met like I'll just try to know like if you sit down and write a list and where you can work in this new joke and where you can try a tag, you're more likely to find that freedom to explore a new joke. So I always try to prepare it took me a long time to learn to like sit down and write down your set before you go up. You're not you're not sure. Well and I saw you doing I guess that was something I think I've written almost every set I've done I do that too in my notebook. I don't always like David to yeah, I've been trying to date it as much as possible put where I was you think I'm attractive growth of a joke. It's kind of cool. Yeah, like flipping back and just saying, oh I started that joke in September. Yeah. I really like that. Yeah and then deletes you think tags around it. Yeah, you know <mark>for</mark> me my reaction is wow, if we're doing that joke <mark>for</mark> that long. I thought I still call that a new joke. What's been do <mark>for</mark> you? Oh, I'm so glad you asked I did another corporate gig in yourself the Carolinas. This was fun. It was not as much fun as the first one because the crowd was just a tiny bit rowdier, but it was still very fun. Yeah, it was a more Republican crowd, which is the first show hat was like super rich like it was like evil money and they were weirdly more chill and this crowd was like rich but not like evil. I mean still evil, but if Like the the Richer they are the more like yeah, we're evil like the more they can take I think I think like like ultra-rich conservatives can take can take a joke better than the ones who are a notch below like I went to a public Middle School. It was like upper middle class and East Cobb, Georgia and like where the East Cobb snobs were so rich and then I went to like a", "Start Time (s)": 1977.5, "End Time (s)": 2097.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "played I kind of I I talk about political affiliation stuff. But yeah, you mentioned it but it's not like you're like yeah conservatives are stupid. Like that's not a yeah, I try to make fun of myself I take I take digs but I like to make fun of myself. It's more funny of like, I'm a liberal and here's why we were stupid. That's to me more interesting joke except some of us and that is true. What else have I done new doing doing pilot season some auditioning certain audition a little bit. I don't I I'm having a better time this pilot season because I realized I'm not going to book anything and I've made peace with that anything I is gone. Yeah, just trying to have fun in auditions. It's such a weirdly how you feel going to open mics. That's how I still feel going to auditions. It's so demoralizing. It's so I don't know why I leave there's this feeling after you leave and you did your first audition back to her back to you. That's also like me saying he is like a lot of people how do you start auditioning <mark>for</mark> me? It was I did stand-up and I got my first TV credit doing stand-up and when they saw me I got I got signed based on the TV set pretty early on and then they just throw you to the Wolves. They're like that. My first audition was <mark>for</mark> the Entourage movie. I was I had no acting I'm not I'm not a naturally talented actor. I don't have like the basic anything. So anything I have I've worked at really hard and I bomb <mark>for</mark> many years. refuse to take classes because they felt stupid and weird and I don't know. I mean there is that thing of like comedies Defiance of authority. It's kind of the basis of it. Hmm. Maybe that's too broad. Maybe not everyone is your type A. I was a teacher's pet so I don't know what it is. Yeah. Yeah, but you had your first audition. I did non-union not I mean this is okay. So to be fair, this is I did improv with Aubrey who is I was a very talented producer. She does a lot of really cool stuff", "Start Time (s)": 2126.1, "End Time (s)": 2245.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you to the Wolves. They're like that. My first audition was <mark>for</mark> the Entourage movie. I was I had no acting I'm not I'm not a naturally talented actor. I don't have like the basic anything. So anything I have I've worked at really hard and I bomb <mark>for</mark> many years. refuse to take classes because they felt stupid and weird and I don't know. I mean there is that thing of like comedies Defiance of authority. It's kind of the basis of it. Hmm. Maybe that's too broad. Maybe not everyone is your type A. I was a teacher's pet so I don't know what it is. Yeah. Yeah, but you had your first audition. I did non-union not I mean this is okay. So to be fair, this is I did improv with Aubrey who is I was a very talented producer. She does a lot of really cool stuff and she's had me do a few things just like, you know, mmm Up scenes in a couple of things. She shot small stuff and asked me to come and audition me and a couple of other folks have done some stuff <mark>for</mark> this TV commercial that she was producing and didn't get it because acting is hard as hell but not see that coming. Yeah, you were I know I got in trouble <mark>for</mark> things last time. You were a little cocky Garnet. Oh my God, you weren't cocky, but you didn't think I was gonna bite you didn't think you were gonna be good, but you didn't think I was gonna bother you I also have no reference point. I was just like there was no sir. Script ahead of time. Yeah, you know there's things where I was like, there's no preparation to do I just like went. Oh, that's more like yeah, that's commercial. Yeah, you know, so you get there and then I had to like pretend to eat food and react as if I was trying to say something with my face. Of the cough Never mind take it back unless you let how to fill these out. Well, first of all, you're not a loser no Stakes. No Stakes didn't bother you. You didn't bought it kind of it more bothered me that I was like, why was that so hard like, why do I not know how to apparently work my face muscles", "Start Time (s)": 2198.5, "End Time (s)": 2317.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "more like yeah, that's commercial. Yeah, you know, so you get there and then I had to like pretend to eat food and react as if I was trying to say something with my face. Of the cough Never mind take it back unless you let how to fill these out. Well, first of all, you're not a loser no Stakes. No Stakes didn't bother you. You didn't bought it kind of it more bothered me that I was like, why was that so hard like, why do I not know how to apparently work my face muscles anymore because you're thinking about thinking about thinking yeah exactly. It got very in my brain about it. So I just didn't see that coming. McDaniel's great and also my favorite part was just being in the audition and all the people that were around in like actors. They're just like so serious about it and I get it their job, right and but they I mean they were obviously, you know, you have to be serious about it's your job, but it was interesting <mark>for</mark> me because I'm just not around that very much and then I was in the elevator with a child actor and his mom and he would choose like, how did you how did it go? He goes? I did really well. Yeah. I did really well. I was like, yeah, you're seven years old. What is your life? Like you're like a little person who and your mom and you probably live in like the upper west side or something. I just I really just like wanted to follow them home, but I didn't I wish I had that confidence of a child actor only God. It was incredible and I'm sure he crushed. No, that's the thing. That's the crate. That's the thing so different about it like acting is there is almost a perfect inverse correlation the better you think you did the worst you did like that. That's a pretty common thing of you leave. I audition be like what the fuck was that? I'm gonna go apologize to my agents. They're like, oh, yeah, you got a callback. Yeah, and they say it's because you having more genuine because you're confused and scared in that moment. You might be having more genuine reactions. Whereas when you think you nailed it because you did everything you plan to do and if you plan to do it, they can see that I can see that your mechanized", "Start Time (s)": 2285.9, "End Time (s)": 2405.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "incredible and I'm sure he crushed. No, that's the thing. That's the crate. That's the thing so different about it like acting is there is almost a perfect inverse correlation the better you think you did the worst you did like that. That's a pretty common thing of you leave. I audition be like what the fuck was that? I'm gonna go apologize to my agents. They're like, oh, yeah, you got a callback. Yeah, and they say it's because you having more genuine because you're confused and scared in that moment. You might be having more genuine reactions. Whereas when you think you nailed it because you did everything you plan to do and if you plan to do it, they can see that I can see that your mechanized movements so much trouble just like being seen like I guess I was it's embarrassing and also not that again. It's like because of my six months eight months of experience, maybe nine. This point I want people to laugh when I'm doing like a performance or whatever and that's not the point in an audition. They shouldn't necessarily laughs. Actually. They probably shouldn't laugh at you. I can't remember who told me that but acting is hard <mark>for</mark> comedians. Yeah, because I was like because well, I'm bombing bombing. Yeah. Yeah, so didn't love that but it is at what were the best the best feeling I've ever had an acting is when you finish it scene. And the cut and you hear a camera guy laughs like stifled laugh that he'd been holding in or something your crew member and you're like, ooh, that's a nice feeling rushed. Yeah, because you're just giving it your all a lot of a lot of like comic acting is like really selling it is right giving your own you're hearing nothing in your instincts as a comic of if there's silence adjust course. Yeah, brain is running this algorithm. Is she gonna run again? I was kind of proud that that was my instinct but also didn't you know, look the part. Oh, no, I would have had like take off. Yeah, you know that's just not you did <mark>for</mark> these reasons. It was it was just a fun glad to see you humble die. We are there like seeing humbled because it was hard <mark>for</mark> me. I would hate <mark>for</mark> comedy just be like yeah, this is easy. How much <mark>for</mark> that suck I still think that's a big Breeze in my people.", "Start Time (s)": 2372.0, "End Time (s)": 2491.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "They shouldn't necessarily laughs. Actually. They probably shouldn't laugh at you. I can't remember who told me that but acting is hard <mark>for</mark> comedians. Yeah, because I was like because well, I'm bombing bombing. Yeah. Yeah, so didn't love that but it is at what were the best the best feeling I've ever had an acting is when you finish it scene. And the cut and you hear a camera guy laughs like stifled laugh that he'd been holding in or something your crew member and you're like, ooh, that's a nice feeling rushed. Yeah, because you're just giving it your all a lot of a lot of like comic acting is like really selling it is right giving your own you're hearing nothing in your instincts as a comic of if there's silence adjust course. Yeah, brain is running this algorithm. Is she gonna run again? I was kind of proud that that was my instinct but also didn't you know, look the part. Oh, no, I would have had like take off. Yeah, you know that's just not you did <mark>for</mark> these reasons. It was it was just a fun glad to see you humble die. We are there like seeing humbled because it was hard <mark>for</mark> me. I would hate <mark>for</mark> comedy just be like yeah, this is easy. How much <mark>for</mark> that suck I still think that's a big Breeze in my people. We started this podcast to address why people have such a weird reaction when I tell them you started doing stand-up but I think that's part of it. Like we don't want it to be easy <mark>for</mark> anyone because it's not easy <mark>for</mark> anyone. Yeah, and we're afraid like what if she like what if it just all works? Out <mark>for</mark> her what if and also will do its concept, you know? Yeah, I mean, well, I think the reality is that beautiful part about comedy is there's no way to skip the dues. I mean if you make people laugh you make people laugh, that's the you know, I mean, yeah, that makes sense. Yes. Yeah, it's how it's like a so it's like swimming swimming it you either went to time or you didn't go the time and that's the end of the story. You know, I mean, right there are some aspects become. And some experiences that I've definitely had a leg up because I've been dating you but then there's also been downsides to it and you know going in with", "Start Time (s)": 2425.8, "End Time (s)": 2545.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the end of the story. You know, I mean, right there are some aspects become. And some experiences that I've definitely had a leg up because I've been dating you but then there's also been downsides to it and you know going in with more, you know hopelessness that maybe I should have at this stage or you know, I get kind of weird vibes from certain people because they're like, oh you're you're his girlfriend like what are you doing here? You know, I heard there's I mean, this is something with YouTubers like everyone like presents YouTubers Instagram stars because they start headline and clubs because they can sell tickets. I was talking to a club owner who had had one come previously and I like she was like fuck that guy had an attitude which of course the anyone who's sensitive is gonna have an attitude usually in people are insecure and don't feel that they belong there are the ones who act the most she's like but this person had a set that just wasn't a good club set of at the people were just happy to be to remove the celebrity or she it's a really funny story a friend told me that he was opening <mark>for</mark> a YouTuber and it was this you too. First time doing an hour her first time doing an hour. I like <mark>for</mark> a club or one of the first and my friends very good comedian to the opening sentence person goes up to put the does the 45 or whatever and just doesn't really connect Walks Into The Green Room, very aware very where she didn't have the set. She wanted. She was like that was how was that he was like listen, it's going to take some time. But at least you understand that you and this person showed an understanding that's and then right as he was about to be like but here's what I think you should do the agents burst through the door go. Oh my God, you are amazing. Oh, you're a star and interface. Just I am great. interesting, that's so that's a great story and then a good story that I hope no one can decipher who is about well, I think that's a great opportunity <mark>for</mark> us to end. So I", "Start Time (s)": 2532.6, "End Time (s)": 2652.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that he was opening <mark>for</mark> a YouTuber and it was this you too. First time doing an hour her first time doing an hour. I like <mark>for</mark> a club or one of the first and my friends very good comedian to the opening sentence person goes up to put the does the 45 or whatever and just doesn't really connect Walks Into The Green Room, very aware very where she didn't have the set. She wanted. She was like that was how was that he was like listen, it's going to take some time. But at least you understand that you and this person showed an understanding that's and then right as he was about to be like but here's what I think you should do the agents burst through the door go. Oh my God, you are amazing. Oh, you're a star and interface. Just I am great. interesting, that's so that's a great story and then a good story that I hope no one can decipher who is about well, I think that's a great opportunity <mark>for</mark> us to end. So I think that's it. What's up? Yeah, and we'll talk of yeah, we can talk about me next week. Yeah. I got enough going on. You deserve your own episode. It's fine. I'm happy <mark>for</mark> you. I'm happy. No, I'm happy <mark>for</mark> you Ali. Let's go. No girl. Let's make it. Just you know, how why are you rubbing my hands? Your hands are clammy. All right, that's enough of this. Good night. Goodbye. Just you know, how why are you rubbing my hands? Your hands are clammy. All right, that's enough of this. Good night. Goodbye.", "Start Time (s)": 2591.4, "End Time (s)": 2676.7, "Clip Length (min)": 1.42, "show_uri": "spotify:show:6mc7bNXW0fPRNGYqPFz2tJ", "show_name": "She Does Stand Up Too?", "show_description": "Matthew Broussard has done stand up comedy for almost a decade. His girlfriend, Laura Sogar, just started. Together they explore all aspects of stand up, from joke writing to gender dynamics through their disparate levels of experience. They address the awkwardness and talk to comics about how comedy affects relationships and how relationships affect comedy.", "publisher": "Matthew Broussard", "episode_uri": "spotify:episode:1LGrOPH2MVCMrqB18TNtWZ", "episode_name": "4: Witcher Addiction, Best NYC Mic in Town, Hosting, Laura\u2019s first (and probably last) set at the Cellar, Biting the Bullet, Matt observes a two drink minimum, A child actor walks into an elevator\u2026 ", "episode_description": "Laura hosts a mic, Matthew sits in the audience, Laura doesn't book a commercial, Matthew shares thoughts on bringer shows, fraud syndrome (or just realizing you're an actual fraud) ", "score": 4.338219, "explanation": "{\n  \"value\": 4.338219,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.017826812,\n      \"description\": \"weight(word_list:for in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.017826812,\n          \"description\": \"score(LMDirichletSimilarity, freq=64.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6486348,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 64.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.007619273,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.007619273,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.320392,\n      \"description\": \"weight(word_list:beginners in 1) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.320392,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9512,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.6095076e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6095076e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}]}