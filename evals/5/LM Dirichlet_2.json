{"query": "Effects of global warming", "clip_length": 2, "selected_index": "LM Dirichlet", "results": [{"Clip Text": "Hello and welcome to ocbc insights. I am Terrence who <mark>effects</mark> strategies at ocbc treasury research and strategy. I will be covering FX topics in ocbc insights on a regular basis. Now, let us start for today's session the FX Market cannot escape from the covid-19 related upheavals and we are now essentially experiencing a round to hit in terms <mark>of</mark> <mark>global</mark> risk sentiment. After the covid-19 situation spread Beyond China into different parts <mark>of</mark> the world. If you look at our effect sentiment index it now stands at extreme risk <mark>of</mark> level and three interesting things about how risk sentiment has evolved to the current situation. Number one. This is actually the first time we hit out right wrist off since the covid-19 episode started. We were never close to this level <mark>of</mark> fear, when the outbreak first", "Start Time (s)": 0.7, "End Time (s)": 64.7, "Clip Length (min)": 1.07, "show_uri": "spotify:show:0L8WEL0LsArgZdEh85oDRi", "show_name": "OCBC Bank", "show_description": "This is a service by OCBC Bank to keep you informed about and stay ahead of the trends and developments affecting the economy and markets.   Any content posted on this channel is solely for information purposes only and should not be construed as an offer or solicitation for the subscription, purchase or sale of the securities/instruments mentioned. No warranty whatsoever is given and no liability whatsoever is accepted for any loss arising whether directly or indirectly as a result of the recipient or any class of persons acting on such information, opinion or estimate.", "publisher": "OCBC", "episode_uri": "spotify:episode:6dJEEXH6MAG6o41BcrhRg9", "episode_name": "FX: Evolving risk dynamics to guide directionality (Terence Wu)", "episode_description": "As COVID-19 spreads globally, risk-off sentiment has taken hold and guided FX moves. However, a turnaround may be on the horizon? ", "score": 6.8456926, "explanation": "{\n  \"value\": 6.8456926,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.5712779,\n      \"description\": \"weight(word_list:effects in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.5712779,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.28671837,\n      \"description\": \"weight(word_list:of in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.28671837,\n          \"description\": \"score(LMDirichletSimilarity, freq=29.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.59713995,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 29.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9876966,\n      \"description\": \"weight(word_list:global in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9876966,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.298118,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "insights. I am Terrence who <mark>effects</mark> strategies at ocbc treasury research and strategy. I will be covering FX topics in ocbc insights on a regular basis. Now, let us start for today's session the FX Market cannot escape from the covid-19 related upheavals and we are now essentially experiencing a round to hit in terms <mark>of</mark> <mark>global</mark> risk sentiment. After the covid-19 situation spread Beyond China into different parts <mark>of</mark> the world. If you look at our effect sentiment index it now stands at extreme risk <mark>of</mark> level and three interesting things about how risk sentiment has evolved to the current situation. Number one. This is actually the first time we hit out right wrist off since the covid-19 episode started. We were never close to this level <mark>of</mark> fear, when the outbreak first started and first started to spread within China itself. The second thing is that we reached current levels very quickly by historical standards at the time <mark>of</mark> this recording. It is a second <mark>of</mark> March and we only used it sessions to move from it out right wrist on situation in the FX sentiment index to the current. Levels <mark>of</mark> risk <mark>of</mark> on hindsight. This is actually very quick compared to other episodes <mark>of</mark> resource. And the third thing we are now at extreme levels <mark>of</mark> risk <mark>of</mark> that typically pretend a turnaround in overall risk sentiment. I want to touch on this again a bit later towards the end <mark>of</mark> this podcast. Now, let us Focus first on this round <mark>of</mark> risk <mark>of</mark> sentiment the FX Market has mostly not Completely reacted", "Start Time (s)": 2.8, "End Time (s)": 122.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0L8WEL0LsArgZdEh85oDRi", "show_name": "OCBC Bank", "show_description": "This is a service by OCBC Bank to keep you informed about and stay ahead of the trends and developments affecting the economy and markets.   Any content posted on this channel is solely for information purposes only and should not be construed as an offer or solicitation for the subscription, purchase or sale of the securities/instruments mentioned. No warranty whatsoever is given and no liability whatsoever is accepted for any loss arising whether directly or indirectly as a result of the recipient or any class of persons acting on such information, opinion or estimate.", "publisher": "OCBC", "episode_uri": "spotify:episode:6dJEEXH6MAG6o41BcrhRg9", "episode_name": "FX: Evolving risk dynamics to guide directionality (Terence Wu)", "episode_description": "As COVID-19 spreads globally, risk-off sentiment has taken hold and guided FX moves. However, a turnaround may be on the horizon? ", "score": 6.8456926, "explanation": "{\n  \"value\": 6.8456926,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.5712779,\n      \"description\": \"weight(word_list:effects in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.5712779,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.28671837,\n      \"description\": \"weight(word_list:of in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.28671837,\n          \"description\": \"score(LMDirichletSimilarity, freq=29.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.59713995,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 29.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9876966,\n      \"description\": \"weight(word_list:global in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9876966,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.298118,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "hit out right wrist off since the covid-19 episode started. We were never close to this level <mark>of</mark> fear, when the outbreak first started and first started to spread within China itself. The second thing is that we reached current levels very quickly by historical standards at the time <mark>of</mark> this recording. It is a second <mark>of</mark> March and we only used it sessions to move from it out right wrist on situation in the FX sentiment index to the current. Levels <mark>of</mark> risk <mark>of</mark> on hindsight. This is actually very quick compared to other episodes <mark>of</mark> resource. And the third thing we are now at extreme levels <mark>of</mark> risk <mark>of</mark> that typically pretend a turnaround in overall risk sentiment. I want to touch on this again a bit later towards the end <mark>of</mark> this podcast. Now, let us Focus first on this round <mark>of</mark> risk <mark>of</mark> sentiment the FX Market has mostly not Completely reacted in a very typical fashion your Aussie dollar kiwi dollar has broken down to new multi-year lows. The Canadian dollar itself is also very heavy. So as a whole the cyclical currencies have significantly weakened in line with our risk <mark>of</mark> sentiment and going forward. It may continue to soften if resentments. Do not improve on the other hand your Haven. It's he's the yin and the Swiss Francs have strengthened significantly over the past eight sessions. So now what is slightly a typical is the strong Euro especially against the dollar itself. Now the strength <mark>of</mark> Euro against the dollar has gave the broad dollar a rather negative posture. We put this", "Start Time (s)": 55.3, "End Time (s)": 174.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0L8WEL0LsArgZdEh85oDRi", "show_name": "OCBC Bank", "show_description": "This is a service by OCBC Bank to keep you informed about and stay ahead of the trends and developments affecting the economy and markets.   Any content posted on this channel is solely for information purposes only and should not be construed as an offer or solicitation for the subscription, purchase or sale of the securities/instruments mentioned. No warranty whatsoever is given and no liability whatsoever is accepted for any loss arising whether directly or indirectly as a result of the recipient or any class of persons acting on such information, opinion or estimate.", "publisher": "OCBC", "episode_uri": "spotify:episode:6dJEEXH6MAG6o41BcrhRg9", "episode_name": "FX: Evolving risk dynamics to guide directionality (Terence Wu)", "episode_description": "As COVID-19 spreads globally, risk-off sentiment has taken hold and guided FX moves. However, a turnaround may be on the horizon? ", "score": 6.8456926, "explanation": "{\n  \"value\": 6.8456926,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.5712779,\n      \"description\": \"weight(word_list:effects in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.5712779,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.28671837,\n      \"description\": \"weight(word_list:of in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.28671837,\n          \"description\": \"score(LMDirichletSimilarity, freq=29.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.59713995,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 29.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9876966,\n      \"description\": \"weight(word_list:global in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9876966,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.298118,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I want to touch on this again a bit later towards the end <mark>of</mark> this podcast. Now, let us Focus first on this round <mark>of</mark> risk <mark>of</mark> sentiment the FX Market has mostly not Completely reacted in a very typical fashion your Aussie dollar kiwi dollar has broken down to new multi-year lows. The Canadian dollar itself is also very heavy. So as a whole the cyclical currencies have significantly weakened in line with our risk <mark>of</mark> sentiment and going forward. It may continue to soften if resentments. Do not improve on the other hand your Haven. It's he's the yin and the Swiss Francs have strengthened significantly over the past eight sessions. So now what is slightly a typical is the strong Euro especially against the dollar itself. Now the strength <mark>of</mark> Euro against the dollar has gave the broad dollar a rather negative posture. We put this unexpected Euro strength down to the unwinding <mark>of</mark> Euro funded carry traits. Amid the overall risk <mark>of</mark> sentiment. So this is not unlike the Yen risk <mark>of</mark> kind <mark>of</mark> movement nevertheless the shiv short-term risk <mark>of</mark> still persisting and longer term <mark>global</mark> economic race Rising the anti-cyclical properties <mark>of</mark> the broad dollar should eventually Prevail and this makes us fundamentally very uncomfortable in chasing the euro dollar upside. So broadly speaking. We still prefer to stay. Shot <mark>of</mark> the cyclic goes against the likes <mark>of</mark> the dollar and also the Swiss Francs now going forward what can change this fundamental picture in three words the Federal Reserve. We have seen a", "Start Time (s)": 107.6, "End Time (s)": 226.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0L8WEL0LsArgZdEh85oDRi", "show_name": "OCBC Bank", "show_description": "This is a service by OCBC Bank to keep you informed about and stay ahead of the trends and developments affecting the economy and markets.   Any content posted on this channel is solely for information purposes only and should not be construed as an offer or solicitation for the subscription, purchase or sale of the securities/instruments mentioned. No warranty whatsoever is given and no liability whatsoever is accepted for any loss arising whether directly or indirectly as a result of the recipient or any class of persons acting on such information, opinion or estimate.", "publisher": "OCBC", "episode_uri": "spotify:episode:6dJEEXH6MAG6o41BcrhRg9", "episode_name": "FX: Evolving risk dynamics to guide directionality (Terence Wu)", "episode_description": "As COVID-19 spreads globally, risk-off sentiment has taken hold and guided FX moves. However, a turnaround may be on the horizon? ", "score": 6.8456926, "explanation": "{\n  \"value\": 6.8456926,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.5712779,\n      \"description\": \"weight(word_list:effects in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.5712779,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.28671837,\n      \"description\": \"weight(word_list:of in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.28671837,\n          \"description\": \"score(LMDirichletSimilarity, freq=29.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.59713995,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 29.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9876966,\n      \"description\": \"weight(word_list:global in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9876966,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.298118,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "We put this unexpected Euro strength down to the unwinding <mark>of</mark> Euro funded carry traits. Amid the overall risk <mark>of</mark> sentiment. So this is not unlike the Yen risk <mark>of</mark> kind <mark>of</mark> movement nevertheless the shiv short-term risk <mark>of</mark> still persisting and longer term <mark>global</mark> economic race Rising the anti-cyclical properties <mark>of</mark> the broad dollar should eventually Prevail and this makes us fundamentally very uncomfortable in chasing the euro dollar upside. So broadly speaking. We still prefer to stay. Shot <mark>of</mark> the cyclic goes against the likes <mark>of</mark> the dollar and also the Swiss Francs now going forward what can change this fundamental picture in three words the Federal Reserve. We have seen a rare unscheduled statement from the chairman Pao on 28th <mark>of</mark> February that the FED will use its tools to act as appropriate to support the economy now, This is typically code names right code words to say that they are ready to cut as soon as the much fomc now for the much fomc we are now talking about whether they will or will not cut but actually whether the cut is going to be 25 or 50 basis points. Now two things that can follow from this number one. Are we going to see a coordinated effort by <mark>global</mark> central banks to ease monetary policy and number two if Is a coordinated <mark>Global</mark> effort how much positivity can we impute from this and is it sufficient to turn the overall risk sentiment now to be honest, we have no significant signs <mark>of</mark> this yet. Even though rest <mark>of</mark> is currently extreme levels. We are still sticking with our", "Start Time (s)": 173.0, "End Time (s)": 292.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0L8WEL0LsArgZdEh85oDRi", "show_name": "OCBC Bank", "show_description": "This is a service by OCBC Bank to keep you informed about and stay ahead of the trends and developments affecting the economy and markets.   Any content posted on this channel is solely for information purposes only and should not be construed as an offer or solicitation for the subscription, purchase or sale of the securities/instruments mentioned. No warranty whatsoever is given and no liability whatsoever is accepted for any loss arising whether directly or indirectly as a result of the recipient or any class of persons acting on such information, opinion or estimate.", "publisher": "OCBC", "episode_uri": "spotify:episode:6dJEEXH6MAG6o41BcrhRg9", "episode_name": "FX: Evolving risk dynamics to guide directionality (Terence Wu)", "episode_description": "As COVID-19 spreads globally, risk-off sentiment has taken hold and guided FX moves. However, a turnaround may be on the horizon? ", "score": 6.8456926, "explanation": "{\n  \"value\": 6.8456926,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.5712779,\n      \"description\": \"weight(word_list:effects in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.5712779,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.28671837,\n      \"description\": \"weight(word_list:of in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.28671837,\n          \"description\": \"score(LMDirichletSimilarity, freq=29.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.59713995,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 29.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9876966,\n      \"description\": \"weight(word_list:global in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9876966,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.298118,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "seen a rare unscheduled statement from the chairman Pao on 28th <mark>of</mark> February that the FED will use its tools to act as appropriate to support the economy now, This is typically code names right code words to say that they are ready to cut as soon as the much fomc now for the much fomc we are now talking about whether they will or will not cut but actually whether the cut is going to be 25 or 50 basis points. Now two things that can follow from this number one. Are we going to see a coordinated effort by <mark>global</mark> central banks to ease monetary policy and number two if Is a coordinated <mark>Global</mark> effort how much positivity can we impute from this and is it sufficient to turn the overall risk sentiment now to be honest, we have no significant signs <mark>of</mark> this yet. Even though rest <mark>of</mark> is currently extreme levels. We are still sticking with our risk off trade calls and this possible turn in overall super is sentiment is something that we will be keeping a very close. Close watch on and be ready to turn around our trade calls if we see signs <mark>of</mark> these turn in overall risk sentiment. So that's all for FX in this round <mark>of</mark> ocbc insights. I hope you will find it useful and speak again the next time thank you very much. This has been a podcast from ocbc Bank follow us on Spotify for more episodes like the one you've just heard. This has been a podcast from ocbc Bank follow us on Spotify for more episodes like the one you've just heard.", "Start Time (s)": 225.6, "End Time (s)": 329.2, "Clip Length (min)": 1.73, "show_uri": "spotify:show:0L8WEL0LsArgZdEh85oDRi", "show_name": "OCBC Bank", "show_description": "This is a service by OCBC Bank to keep you informed about and stay ahead of the trends and developments affecting the economy and markets.   Any content posted on this channel is solely for information purposes only and should not be construed as an offer or solicitation for the subscription, purchase or sale of the securities/instruments mentioned. No warranty whatsoever is given and no liability whatsoever is accepted for any loss arising whether directly or indirectly as a result of the recipient or any class of persons acting on such information, opinion or estimate.", "publisher": "OCBC", "episode_uri": "spotify:episode:6dJEEXH6MAG6o41BcrhRg9", "episode_name": "FX: Evolving risk dynamics to guide directionality (Terence Wu)", "episode_description": "As COVID-19 spreads globally, risk-off sentiment has taken hold and guided FX moves. However, a turnaround may be on the horizon? ", "score": 6.8456926, "explanation": "{\n  \"value\": 6.8456926,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.5712779,\n      \"description\": \"weight(word_list:effects in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.5712779,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.28671837,\n      \"description\": \"weight(word_list:of in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.28671837,\n          \"description\": \"score(LMDirichletSimilarity, freq=29.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.59713995,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 29.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.9876966,\n      \"description\": \"weight(word_list:global in 40) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9876966,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.298118,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.31042156,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 728.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you mentioned about authenticity. But when when I get a release for me, it's all about the music and I forget Les Mills. I forget the choreography and I don't even think about it being a workout. I just listened to the songs and I have them on the whole time. Like when I'm in the shower when I'm making food when I'm doing the laundry when I'm training gym, I just try and listen to the music as many times as possible, but I'm not even thinking about the lesson was broken all the work out. It's just filled music and what happens Instruments will pop up or lyrics or stand out all these musical landmarks will come up and you don't know what that's going to be or when it will be but it just happens after you listen to it for a while and then when you actually then go right let's plug in and learn the choreography when those two things come together and you teach your already naturally in the music. So those little moments that your son or little hit movement or shoulder wiggle that you just naturally did with the song that just comes out when you teach you welcome to the Lindsay Morrison podcast. Lindsay is a leading. Consultant in the world <mark>of</mark> group fitness as an international trainer and presenter join Lindsey has she chats all things group fitness Fitness management and interviews industry experts on the latest Fitness Trends stats and insights. Welcome to the Lindsay Morrison podcast. This is episode 15 with Matt Jackson. And Matt says the training manager <mark>of</mark> for Les Mills China. So in this episodes we talked about what inspires Matt and his teaching and performance how he finds authenticity and actually how they could run a virus is affecting life in China and they can have economic <mark>effects</mark> that's having on the group fitness instructors and the industry out there, which is really really interesting. He also answers questions from instructors around the world. So I asked Guys to send me some questions for Matt on my social platforms and I got a whole bucket full <mark>of</mark> questions so I cannot wait for you guys to hear those. I'm absolutely loving the podcast that I'm doing right now and I've spoken to", "Start Time (s)": 6.0, "End Time (s)": 125.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "did with the song that just comes out when you teach you welcome to the Lindsay Morrison podcast. Lindsay is a leading. Consultant in the world <mark>of</mark> group fitness as an international trainer and presenter join Lindsey has she chats all things group fitness Fitness management and interviews industry experts on the latest Fitness Trends stats and insights. Welcome to the Lindsay Morrison podcast. This is episode 15 with Matt Jackson. And Matt says the training manager <mark>of</mark> for Les Mills China. So in this episodes we talked about what inspires Matt and his teaching and performance how he finds authenticity and actually how they could run a virus is affecting life in China and they can have economic <mark>effects</mark> that's having on the group fitness instructors and the industry out there, which is really really interesting. He also answers questions from instructors around the world. So I asked Guys to send me some questions for Matt on my social platforms and I got a whole bucket full <mark>of</mark> questions so I cannot wait for you guys to hear those. I'm absolutely loving the podcast that I'm doing right now and I've spoken to so many amazing people including Matt Clive ormrod the CEO <mark>of</mark> Les Mills and Kaylee Jack who is one <mark>of</mark> the Les Mills ambassadors and previous podcasts and within what one caught coaching I have drawn on some <mark>of</mark> those conversations with my own clients to create Some great results. One thing that I find is that when speaking to instructors that they have these self-made barriers between themselves and creating the desired effect. They want in class a quick technique I use is to bring awareness to what the comfort zone is, which often creates that barrier and something that we call limiting beliefs or example, if your comfort zone is constantly talking and giving coaching points. You need to become aware <mark>of</mark> this when it happens and stop. And then look around the room with knowledge that this is okay. Now, I'm looking for", "Start Time (s)": 57.8, "End Time (s)": 177.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "answers questions from instructors around the world. So I asked Guys to send me some questions for Matt on my social platforms and I got a whole bucket full <mark>of</mark> questions so I cannot wait for you guys to hear those. I'm absolutely loving the podcast that I'm doing right now and I've spoken to so many amazing people including Matt Clive ormrod the CEO <mark>of</mark> Les Mills and Kaylee Jack who is one <mark>of</mark> the Les Mills ambassadors and previous podcasts and within what one caught coaching I have drawn on some <mark>of</mark> those conversations with my own clients to create Some great results. One thing that I find is that when speaking to instructors that they have these self-made barriers between themselves and creating the desired effect. They want in class a quick technique I use is to bring awareness to what the comfort zone is, which often creates that barrier and something that we call limiting beliefs or example, if your comfort zone is constantly talking and giving coaching points. You need to become aware <mark>of</mark> this when it happens and stop. And then look around the room with knowledge that this is okay. Now, I'm looking for something to coach rather than just filling the space with random coaching choose planned or unplanned and it's when we become aware <mark>of</mark> comfort zones that we actually start to use them to our advantage. My comfort zone is not doing podcasts and that's really why I started out doing my podcast was a personal challenge because it was uncomfortable and I knew space for me to explore but look at me now. I've got 7,000 downloads 15. So it's in the bank and I am taking those conversations from my podcast and to my coaching and mentoring and giving my clients value last month. I did my first public speaking gig at Main and Ricky's jump live event, and it was called Be Your Own Boss. The short story is that 15-minute talk is now been turned into a coaching program that were developing to create real confidence in group fitness instructors and how", "Start Time (s)": 109.3, "End Time (s)": 229.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in my fitness journey and group fitness. He was my body pump trainer and I owe a lot to him without his module training. I would never have phoned about Les Mills or you know phone my passion for group fitness. So it's this is a really special podcast very small. Thank you so much for coming on to my podcast. Thank you very much. Lindsay. Great to be here. And man. When was that body pump module that monster in body from 50 to 54 for was it? Yeah, 54 all my word yet. We still look so young. How about that? I know I mean, what are the odds? It's like I was I was thinking just before I came on to the podcast. When was that? So it was bodypump 54 it was 2005. Five. Well, yeah. So 15 years like yeah. Yeah 13 years. I've been you don't have indirect <mark>effects</mark> lifted weights to music and still loving it knows what's it like then? Yeah, and you are doing amazingly well, and it's so great to see and I appreciate you having me on the podcast. I'm excited. Thank you. Thanks. And so I think we'll just kick off with him for some <mark>of</mark> the listeners who Be doing no you and your backgrounds and with in Les Mills and maybe out west, you know could just tell the listeners. You know, who has Matt Jackson and what exactly do you do? Yeah, good question. What exactly do I do once I suppose I'm just a small a small country boy from Devon and England's and I ended up doing this Les Mills group fitness thing from about 2002. I was just living in the state's. I was coaching soccer and I was a High School PE teacher and I was training at Gold's Gym. And then one day the manager asks <mark>of</mark> Gold's Gym came up and said, hey you want to teach bodypump, you know, I think you'd be good at it. My husband's", "Start Time (s)": 281.3, "End Time (s)": 401.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "years. I've been you don't have indirect <mark>effects</mark> lifted weights to music and still loving it knows what's it like then? Yeah, and you are doing amazingly well, and it's so great to see and I appreciate you having me on the podcast. I'm excited. Thank you. Thanks. And so I think we'll just kick off with him for some <mark>of</mark> the listeners who Be doing no you and your backgrounds and with in Les Mills and maybe out west, you know could just tell the listeners. You know, who has Matt Jackson and what exactly do you do? Yeah, good question. What exactly do I do once I suppose I'm just a small a small country boy from Devon and England's and I ended up doing this Les Mills group fitness thing from about 2002. I was just living in the state's. I was coaching soccer and I was a High School PE teacher and I was training at Gold's Gym. And then one day the manager asks <mark>of</mark> Gold's Gym came up and said, hey you want to teach bodypump, you know, I think you'd be good at it. My husband's going to go on the training and I want And you and originally I didn't want to go I was like no because I knew nothing about group fitness. Nothing about Les Mills or bodypump but a long long story short me and her husband went on the training. We had a great time and we started teaching Body Pump and so from 2002 onwards was when I started doing this Les Mills thing, but leading into that. I was just a typical sort <mark>of</mark> boy really I played football and did weight training and I was always sporty at school went off to UNI to Sport Science degree. And then while I was there, I got my football coaching Badges and then that's kind <mark>of</mark> the reason I went to America was to just do the summer soccer camps. So I guess I've always been in and around Sport and Fitness, but I never really knew like did I want to be a PE teacher did I want to be a physiotherapist and did I want to be a professional footballer? You know, I knew it was something in and around sport, but I think what I found over in the in the USA when I", "Start Time (s)": 337.1, "End Time (s)": 456.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "My husband's going to go on the training and I want And you and originally I didn't want to go I was like no because I knew nothing about group fitness. Nothing about Les Mills or bodypump but a long long story short me and her husband went on the training. We had a great time and we started teaching Body Pump and so from 2002 onwards was when I started doing this Les Mills thing, but leading into that. I was just a typical sort <mark>of</mark> boy really I played football and did weight training and I was always sporty at school went off to UNI to Sport Science degree. And then while I was there, I got my football coaching Badges and then that's kind <mark>of</mark> the reason I went to America was to just do the summer soccer camps. So I guess I've always been in and around Sport and Fitness, but I never really knew like did I want to be a PE teacher did I want to be a physiotherapist and did I want to be a professional footballer? You know, I knew it was something in and around sport, but I think what I found over in the in the USA when I was coaching Kitty soccer was was just I guess a little bit <mark>of</mark> a talent but more <mark>of</mark> a passion The coaching and helping other people and it just happened to be that I was doing young kids football and then that developed into doing adults group fitness, but it's still kind <mark>of</mark> the same thing though. I'm coaching and trying to help and train and Mentor people I just happen to be using Les Mills as well as probably the main vehicle for how I'm able to do that. So, yeah, so now I'm on the training manager <mark>of</mark> <mark>of</mark> Les most China. So I'm looking after China Taiwan South Korea. And Hong Kong, so essentially all the instructors assessors trainers and presenters throughout those countries like a I'm the dad Granddad looking after everybody. What a job e what is your job, especially the more tender moment in the current climate, but we'll come on to talk about the coronavirus soon. I'm sure what's happening. Just", "Start Time (s)": 400.8, "End Time (s)": 519.2, "Clip Length (min)": 1.97, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "group fitness, but it's still kind <mark>of</mark> the same thing though. I'm coaching and trying to help and train and Mentor people I just happen to be using Les Mills as well as probably the main vehicle for how I'm able to do that. So, yeah, so now I'm on the training manager <mark>of</mark> <mark>of</mark> Les most China. So I'm looking after China Taiwan South Korea. And Hong Kong, so essentially all the instructors assessors trainers and presenters throughout those countries like a I'm the dad Granddad looking after everybody. What a job e what is your job, especially the more tender moment in the current climate, but we'll come on to talk about the coronavirus soon. I'm sure what's happening. Just so being a training manager for Les Mills China. What is a typical day for you in a normal day in the life <mark>of</mark> that's right. Yeah, that's a good question because I guess the immediate answer is there isn't really a typical day. I mean, I'm super lucky to do the job I do and it has many different facets. So one day I might be delivering a gfm seminar another day. It might be a call to the workshop or I'm doing feedback to one <mark>of</mark> my trainers or upskill. I could be an SLT meet senior leadership team meeting where we talkin about the budgets then the profit and loss <mark>of</mark> an event how we can get that across the line. Might be open video conference call with LMI. I mean, it's cool because there's so many different parts to this machine and I get to dip my finger in to all <mark>of</mark> them. And and I think that's one <mark>of</mark> the things that keeps it really fresh, but I guess there are some parts that are still typical. So every day involves coffee every day involves lots <mark>of</mark> emails, you know, trying to contact my team as much as possible. I've got an office that I can go into", "Start Time (s)": 471.0, "End Time (s)": 589.0, "Clip Length (min)": 1.97, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a training manager for Les Mills China. What is a typical day for you in a normal day in the life <mark>of</mark> that's right. Yeah, that's a good question because I guess the immediate answer is there isn't really a typical day. I mean, I'm super lucky to do the job I do and it has many different facets. So one day I might be delivering a gfm seminar another day. It might be a call to the workshop or I'm doing feedback to one <mark>of</mark> my trainers or upskill. I could be an SLT meet senior leadership team meeting where we talkin about the budgets then the profit and loss <mark>of</mark> an event how we can get that across the line. Might be open video conference call with LMI. I mean, it's cool because there's so many different parts to this machine and I get to dip my finger in to all <mark>of</mark> them. And and I think that's one <mark>of</mark> the things that keeps it really fresh, but I guess there are some parts that are still typical. So every day involves coffee every day involves lots <mark>of</mark> emails, you know, trying to contact my team as much as possible. I've got an office that I can go into essentially everything we're doing is trying to get more people in the group fitness retreat. Try and get instructors to a better level. We're trying to engage our instructors so they stay with us for longer. But I'm lucky that I get to travel a little bit and do these different areas <mark>of</mark> the job. And yeah, and I feel fortunate that I've got the opportunity to do that because I like to feel like I'm getting challenged in that business area because that's still kind <mark>of</mark> a new part <mark>of</mark> it to me that the business <mark>of</mark> Les Mills, but I then get to offer my experience and sort <mark>of</mark> what I've gained over the years. Friends <mark>of</mark> the training assessing and presenting, you know out on the field so it kind <mark>of</mark> Blends The Best <mark>of</mark> Both Worlds for me. Yeah, do you still go out and deliver training or as your focus? Can I do what else? I mean, obviously we've got the Advanced Training", "Start Time (s)": 524.3, "End Time (s)": 643.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "everything we're doing is trying to get more people in the group fitness retreat. Try and get instructors to a better level. We're trying to engage our instructors so they stay with us for longer. But I'm lucky that I get to travel a little bit and do these different areas <mark>of</mark> the job. And yeah, and I feel fortunate that I've got the opportunity to do that because I like to feel like I'm getting challenged in that business area because that's still kind <mark>of</mark> a new part <mark>of</mark> it to me that the business <mark>of</mark> Les Mills, but I then get to offer my experience and sort <mark>of</mark> what I've gained over the years. Friends <mark>of</mark> the training assessing and presenting, you know out on the field so it kind <mark>of</mark> Blends The Best <mark>of</mark> Both Worlds for me. Yeah, do you still go out and deliver training or as your focus? Can I do what else? I mean, obviously we've got the Advanced Training now and I'm here enjoying always we still delivering one which we're going to be renaming but we've still got a product that sort <mark>of</mark> sits in that space over technique and coaching initial module training is cordially workshops. And we do some some unique things here in terms <mark>of</mark> seminars and events for instructors and Club support. So I like to still be at the Grassroots level and deliver so partly partly because that's a great way to coach and develop the team, you know, if I mean they're doing it they can see a Life delivery and I can have new trains or presenters with me learning along the way but also it just keeps me grounded in what we're doing and it keeps me, you know understanding the market if I'm out there actually living and breathing it. So yeah, I'm still out there doing it. So there's not as much as I used to do like in the UK. I was pretty much doing a module every weekend, you know, and I remember way back when we launched it David Lloyd we were doing two or three modules a week, you know, it's pretty full on schedule so that those days are long gone, but I'd say each month. I would deliver deliver some <mark>of</mark> our products and that's sort <mark>of</mark> keeps me in touch with what's going on. And it's sort <mark>of</mark> like teaching really, you know, it's it's what you love to do. You don't", "Start Time (s)": 590.8, "End Time (s)": 710.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Training now and I'm here enjoying always we still delivering one which we're going to be renaming but we've still got a product that sort <mark>of</mark> sits in that space over technique and coaching initial module training is cordially workshops. And we do some some unique things here in terms <mark>of</mark> seminars and events for instructors and Club support. So I like to still be at the Grassroots level and deliver so partly partly because that's a great way to coach and develop the team, you know, if I mean they're doing it they can see a Life delivery and I can have new trains or presenters with me learning along the way but also it just keeps me grounded in what we're doing and it keeps me, you know understanding the market if I'm out there actually living and breathing it. So yeah, I'm still out there doing it. So there's not as much as I used to do like in the UK. I was pretty much doing a module every weekend, you know, and I remember way back when we launched it David Lloyd we were doing two or three modules a week, you know, it's pretty full on schedule so that those days are long gone, but I'd say each month. I would deliver deliver some <mark>of</mark> our products and that's sort <mark>of</mark> keeps me in touch with what's going on. And it's sort <mark>of</mark> like teaching really, you know, it's it's what you love to do. You don't you don't want to let go <mark>of</mark> that as you just love being at the coalface delivering the products and you know, and then till I'm too old or too two injured or or just unable to do any more there will me often, but I'll be kicking. This is what I love about our industries that you know, we all have a past. And what we do and there is a longevity and it you just have to be smart about it. Don't you in terms <mark>of</mark> you know, maybe there's a point where you think to yourself will care and may not be able to do that anymore. But I didn't do this so that you still are I guess teaching and from that place <mark>of</mark> passion and you're still getting that that endorphin rush from what you love to do. How do you present I mean, I think I'm a good", "Start Time (s)": 643.3, "End Time (s)": 762.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "our products and that's sort <mark>of</mark> keeps me in touch with what's going on. And it's sort <mark>of</mark> like teaching really, you know, it's it's what you love to do. You don't you don't want to let go <mark>of</mark> that as you just love being at the coalface delivering the products and you know, and then till I'm too old or too two injured or or just unable to do any more there will me often, but I'll be kicking. This is what I love about our industries that you know, we all have a past. And what we do and there is a longevity and it you just have to be smart about it. Don't you in terms <mark>of</mark> you know, maybe there's a point where you think to yourself will care and may not be able to do that anymore. But I didn't do this so that you still are I guess teaching and from that place <mark>of</mark> passion and you're still getting that that endorphin rush from what you love to do. How do you present I mean, I think I'm a good example <mark>of</mark> that that I tend to use when I'm talking to my team about your longevity or even just your life span within certain areas <mark>of</mark> the businesses is like I retired from body combat a little while back and part <mark>of</mark> that reason was I could see the talent that was coming up alongside <mark>of</mark> me. And this was when I was in New Zealand, so I had I'd people like villes this this there. Young-hee boy. That's just young fit. Good-looking jumps high kicks amazingly. Well super energetic and it's just like wow, this guy's amazing and if I stood next to him, I just like an old man. No one wants to see that and then you kind <mark>of</mark> understand that. Yeah can still teach a good class and I can still engage my members and it's fun, but I don't need to be doing called you workshops anymore because I just can't deliver the product in the way that it should be and then when I got to China, you know, we've got people like Linda and Nico just the sharpness <mark>of</mark> those guys is insane. And you know, they're young and they're cold and they just delivering a different way. So unfortunately for me, I guess I'd had five minutes <mark>of</mark>", "Start Time (s)": 703.3, "End Time (s)": 823.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that that endorphin rush from what you love to do. How do you present I mean, I think I'm a good example <mark>of</mark> that that I tend to use when I'm talking to my team about your longevity or even just your life span within certain areas <mark>of</mark> the businesses is like I retired from body combat a little while back and part <mark>of</mark> that reason was I could see the talent that was coming up alongside <mark>of</mark> me. And this was when I was in New Zealand, so I had I'd people like villes this this there. Young-hee boy. That's just young fit. Good-looking jumps high kicks amazingly. Well super energetic and it's just like wow, this guy's amazing and if I stood next to him, I just like an old man. No one wants to see that and then you kind <mark>of</mark> understand that. Yeah can still teach a good class and I can still engage my members and it's fun, but I don't need to be doing called you workshops anymore because I just can't deliver the product in the way that it should be and then when I got to China, you know, we've got people like Linda and Nico just the sharpness <mark>of</mark> those guys is insane. And you know, they're young and they're cold and they just delivering a different way. So unfortunately for me, I guess I'd had five minutes <mark>of</mark> fame. So I was able to sort <mark>of</mark> step back from that Limelight and also, you know, I was I was moving into the business space. So I'm doing a bit more coaching and mentoring and The Business <mark>of</mark> Les Mills. So like you say you start to develop your skills in a different area or you start to find other places in the business where you can have value you just need to sort <mark>of</mark> know when your time is the hang up certain parts and For me jumping up in the air and punching and kicking thin air, you know hats I had to let go <mark>of</mark> that one, you know, and I was fortunate enough to make that decision myself before I spent two or three years trying to hang on and everybody else. You might be longer or Body Balance for example, but you know, I have to listen to my", "Start Time (s)": 753.7, "End Time (s)": 873.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "jumping up in the air and punching and kicking thin air, you know hats I had to let go <mark>of</mark> that one, you know, and I was fortunate enough to make that decision myself before I spent two or three years trying to hang on and everybody else. You might be longer or Body Balance for example, but you know, I have to listen to my body and I have to understand the product and the market. It and just make an intelligent decision and it was right time, you know, and there's and there's no regrets once in a while. I might I might cover a body combat class or we might have a special event at my local Club, you know, we're doing a launch and I'll jump in and bang out some old jeans and I'll be fun but man, I'm sore for a shoe. That is up. Do you have a go to release? Do you have a particular release that you think I'll just put that one on and I'll do that. I've got to go to playlist. I mean, I'm I'm never a fan <mark>of</mark> a whole release like I love launching the new release but two or three weeks and I'm always ready to chop and change and I think when it comes to how do I deliver the best possible class? I can hit songs from various releases. So, you know the track five from body combat 15 their star, huh? That's just one <mark>of</mark> my go-to style <mark>of</mark> track 3 from I think it was combat 43 steeped hands did it because the night? Oh, yeah Kate you're shining as a classic. So yeah, I've got I've got tracks that choreographer Ali choreography. Actually. I just remember them really well because I taught him so many times and musically they're just really cool Tunes. So yeah, I've got a couple <mark>of</mark> players. So my phone that you know, if I ever get called up last minute I can jump in but yeah once a year maybe twice a year, but going back to the original point. I think it is important, you know from I guess anyone that's listening. You know do", "Start Time (s)": 846.7, "End Time (s)": 966.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "combat 43 steeped hands did it because the night? Oh, yeah Kate you're shining as a classic. So yeah, I've got I've got tracks that choreographer Ali choreography. Actually. I just remember them really well because I taught him so many times and musically they're just really cool Tunes. So yeah, I've got a couple <mark>of</mark> players. So my phone that you know, if I ever get called up last minute I can jump in but yeah once a year maybe twice a year, but going back to the original point. I think it is important, you know from I guess anyone that's listening. You know do understand that, you know, we might not be teaching women 90 when were 80 when we 70 or 60 night some point there. There is a lifespan to what we do, depending how well you look after yourself you could be teaching longer and doing workshops and trainings for longer but it's trying to try and to maybe have a bit <mark>of</mark> an eye on the future and think. Okay. What will I be doing in five years or ten years have I got a back-up plan? What's my career development, you know have I developed some skills? We'll start as leverage whatever side business that if I do have to stop doing teaching X, for example, is there something else that can fill that space now and then satisfy me and I can still have some value, you know, two other people in in this industry, and I've just been very lucky that a couple <mark>of</mark> opportunities came my way at a time and I was ready to take them and I could let go <mark>of</mark> a few things that I'm not ready to let go. Hmm. I think that I think what you said is key. It's having a plan B, isn't it? You know, it's good to be in the moment and enjoy what you do, but you have to look forward and think great. Well, I can't do this for a long time or a for ever. So what is the next step for me after this? And so I think as well H, yeah, once it's a hard decision to give up as and so I think there's probably people that battle with it. Don't know what should I give up shit or not? I really love it.", "Start Time (s)": 927.1, "End Time (s)": 1044.5, "Clip Length (min)": 1.96, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is there something else that can fill that space now and then satisfy me and I can still have some value, you know, two other people in in this industry, and I've just been very lucky that a couple <mark>of</mark> opportunities came my way at a time and I was ready to take them and I could let go <mark>of</mark> a few things that I'm not ready to let go. Hmm. I think that I think what you said is key. It's having a plan B, isn't it? You know, it's good to be in the moment and enjoy what you do, but you have to look forward and think great. Well, I can't do this for a long time or a for ever. So what is the next step for me after this? And so I think as well H, yeah, once it's a hard decision to give up as and so I think there's probably people that battle with it. Don't know what should I give up shit or not? I really love it. Is what we end up doing is what we're passionate about and I think I think teaching at Club level is something that you can definitely stretch for a lot longer and you know, certainly if you're teaching programs that might be a bit Kinder on the body, you know, because at the end <mark>of</mark> the day, you don't necessarily have to be super young super good-looking in super fit to be able to fill a room in your local Club, you know, if you're great at engaging and connecting to people and if you can create some entertainment value, you know, and they know you care about them. You can teach for a long time and it is what we do. It's what You know, it's it's how we got into all this sort <mark>of</mark> thing and to let go <mark>of</mark> that will be sort <mark>of</mark> let go <mark>of</mark> piece <mark>of</mark> your heart, you know, that will be really really difficult. But I think the the space I'm in at the moment is obviously the you know, the big events and the filming's and the stuff that's the stuff that just needs, you know <mark>of</mark> someone younger on stage. Maybe someone fitter someone coaching and bit more <mark>of</mark> a, you know, the newer coaching model way especially here in China, you know, that's it's a Cancer certain feel and I just you know had to accept that and know that I had some value elsewhere and where I can bring is I can coach the presenting team on stage. You know, I get my value and stealing them", "Start Time (s)": 1001.9, "End Time (s)": 1120.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "fit to be able to fill a room in your local Club, you know, if you're great at engaging and connecting to people and if you can create some entertainment value, you know, and they know you care about them. You can teach for a long time and it is what we do. It's what You know, it's it's how we got into all this sort <mark>of</mark> thing and to let go <mark>of</mark> that will be sort <mark>of</mark> let go <mark>of</mark> piece <mark>of</mark> your heart, you know, that will be really really difficult. But I think the the space I'm in at the moment is obviously the you know, the big events and the filming's and the stuff that's the stuff that just needs, you know <mark>of</mark> someone younger on stage. Maybe someone fitter someone coaching and bit more <mark>of</mark> a, you know, the newer coaching model way especially here in China, you know, that's it's a Cancer certain feel and I just you know had to accept that and know that I had some value elsewhere and where I can bring is I can coach the presenting team on stage. You know, I get my value and stealing them delivering a really intelligent and Powerful way. I can see the reaction <mark>of</mark> the crowd, you know, the shiny eyes and the smiles and you know, I can go out on a module training. I can watch a trainer deliver two days and I can sit with them, you know been both evenings and give them a couple hours <mark>of</mark> pretty detailed feedback and coaching on how they can be a better. Trained facilitator so I can provide a lot <mark>of</mark> value. You know, I don't need to be upfront anymore. But in terms <mark>of</mark> teaching classes, yeah, I think letting go <mark>of</mark> that's going to be really really difficult. So, you know that that might not ever happen, you know, I might still be teaching until such time that live classes aren't around anymore. I don't know. Yeah, always what the future holds it's exciting really exciting and you did. Tensions about the Live Events here. So you've just had Les Mills life Taiwan and I did see from your social media that you you wear on stage, which was awesome bicep track with Marlon and given him a run for his money.", "Start Time (s)": 1064.6, "End Time (s)": 1183.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "lot <mark>of</mark> value. You know, I don't need to be upfront anymore. But in terms <mark>of</mark> teaching classes, yeah, I think letting go <mark>of</mark> that's going to be really really difficult. So, you know that that might not ever happen, you know, I might still be teaching until such time that live classes aren't around anymore. I don't know. Yeah, always what the future holds it's exciting really exciting and you did. Tensions about the Live Events here. So you've just had Les Mills life Taiwan and I did see from your social media that you you wear on stage, which was awesome bicep track with Marlon and given him a run for his money. Hey you guys these Young Bucks coming out and go, you know, I know I know well that keep them clean did keep them going to this but in it's just before we hit recording the podcast. I was seen to mark that In he for me as the daddy <mark>of</mark> performance being authentic and just not giving a shit basically like you just go and do your thing and you make people feel good and you don't know you leave you leave a lasting impression on people like it's that it's that seeing, isn't it? It's not what you said. It's how you made them feel and you create something special. So I just wanted to kind <mark>of</mark> tap into that for a part <mark>of</mark> the podcast and I guess share Your pets your thoughts and how how do you come up with all this Goods performance crazy reaction stuff that maybe some <mark>of</mark> his quite find quite challenging to do it doesn't come naturally to us. And so I guess when when you get a release like what's the process for you in terms <mark>of</mark> performance? Well, firstly thank you for that. I appreciate you saying that I think I'm", "Start Time (s)": 1141.0, "End Time (s)": 1260.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "being authentic and just not giving a shit basically like you just go and do your thing and you make people feel good and you don't know you leave you leave a lasting impression on people like it's that it's that seeing, isn't it? It's not what you said. It's how you made them feel and you create something special. So I just wanted to kind <mark>of</mark> tap into that for a part <mark>of</mark> the podcast and I guess share Your pets your thoughts and how how do you come up with all this Goods performance crazy reaction stuff that maybe some <mark>of</mark> his quite find quite challenging to do it doesn't come naturally to us. And so I guess when when you get a release like what's the process for you in terms <mark>of</mark> performance? Well, firstly thank you for that. I appreciate you saying that I think I'm you know, if there ever was to be a bit <mark>of</mark> a lasting Legacy or a memory you leave behind I think for me I would want people to think that I was the real me and I was authentic and I just did what I loved with passion. There's always going to be some people that might not like it or they think you're an idiot, but at the end <mark>of</mark> the day if you're comfortable and confident in what you're doing, you know, you know, you're not going to please everyone. But what you're doing is real and authentic and you hope it does, you know entertain and Inspire other people and I sort <mark>of</mark> feel like the way I teach has this kind <mark>of</mark> how I just talked to other people like if we were sat having a drink and it was a party at your house. I'm the same persons when you see me on stage at a called the workshop or in my class or when I was doing the filming's I'd sort <mark>of</mark> hate people to see a version <mark>of</mark> me on stage that felt cardboard or felt forced or different and then you talk to me offstage and um, He's nothing like his onstage. And that's where there's a big disconnect. So I think I know we're probably gonna touch a little bit you met you mentioned about authenticity.", "Start Time (s)": 1202.9, "End Time (s)": 1322.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a little bit you met you mentioned about authenticity. But when when I get a release for me, it's all about the music and I forget Les Mills. I forget the choreography and I don't even think about it being a workout. I just listen to the songs and I have them on the whole time. Like when I'm in the shower when I'm making food when I'm doing the laundry when I'm training and Jim I just try and listen to the music as many times as possible, but I'm not even thinking Out the lesson was broken all the work out. It's just filled music. And what happens is instruments will pop up or lyrics or stand out all these musical landmarks will come up and you don't know what that's going to be or when it will be but it just happens after you listen to it for a while and then when you actually then go right let's plug in and learn the choreography when those two things come together and you teach your already naturally in the music. So those little moments that your son or little hit movement or shoulder wiggle that you just naturally did with the song that just comes zout when you teach you don't have to force it will put it in there because you just you're so woven into the tapestry <mark>of</mark> the song, you know, and that's all inherent in you and the great thing about that is then when you go back and teach somebody's old releases the music still in there. It's the same song it gives you the same feeling and all those things just pop up. So the landmarks in the song or the bit when the bass drops in or a symbol comes in or a lyric that sticks out, you know, those things they'll pop up for me, but the great thing about it Butlins when you when you listen to a song You'll pick out something different and I'll watch you teach and go. Oh man. That's awesome. You picked out this lyric and I'd never even heard that lyric and then I'll do something with an instrument. You'll go. I didn't even hear the ancient when I listened to it and I get super inspired by the guys on my team because obviously a lot <mark>of</mark> them there this younger new generation and and it's an Asian culture. So they're just coming in with a whole different look and feel and I'm watching my guys teach and they're doing things with the music and I'm going wow, I never even heard that or did anything to it and then I go. Okay. So, how can I take that? Interpretation and make it my interpretation. What am I looking for? So I think", "Start Time (s)": 1319.7, "End Time (s)": 1439.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the great thing about that is then when you go back and teach somebody's old releases the music still in there. It's the same song it gives you the same feeling and all those things just pop up. So the landmarks in the song or the bit when the bass drops in or a symbol comes in or a lyric that sticks out, you know, those things they'll pop up for me, but the great thing about it Butlins when you when you listen to a song You'll pick out something different and I'll watch you teach and go. Oh man. That's awesome. You picked out this lyric and I'd never even heard that lyric and then I'll do something with an instrument. You'll go. I didn't even hear the ancient when I listened to it and I get super inspired by the guys on my team because obviously a lot <mark>of</mark> them there this younger new generation and and it's an Asian culture. So they're just coming in with a whole different look and feel and I'm watching my guys teach and they're doing things with the music and I'm going wow, I never even heard that or did anything to it and then I go. Okay. So, how can I take that? Interpretation and make it my interpretation. What am I looking for? So I think the the music is key and obviously to be able to let go <mark>of</mark> your personality like you touched on that being just sort <mark>of</mark> it kind <mark>of</mark> is a little bit <mark>of</mark> that, you know, not giving a shit not worrying about what people think you're going to be confident enough to be you push the envelope a little bit. You know, I know the Les Mills tagline is be brave, but it is a little bit <mark>of</mark> being brave saying this is how I want to deliver it. I'm going to give it a try. It's a bit edgy. It might push the barriers <mark>of</mark> the But if I can make two people to my class smile or if I can Inspire one person to have a better day or if I can edit Workshop if I can Inspire one instructor or two instructors to go back and listen to their music again to try and find some moments <mark>of</mark> magic and performance so that when they teach they teach at a high level, you know, that's that's that's a win for me, you know, and obviously the more people that you can Inspire the better, but yeah that freedom to be yourself. I think just comes from actually putting in the hard work. Work behind the scenes, you know, I've those early days, you know, I think I just ate slept drunk pump like day in and day", "Start Time (s)": 1383.2, "End Time (s)": 1502.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "just sort <mark>of</mark> it kind <mark>of</mark> is a little bit <mark>of</mark> that, you know, not giving a shit not worrying about what people think you're going to be confident enough to be you push the envelope a little bit. You know, I know the Les Mills tagline is be brave, but it is a little bit <mark>of</mark> being brave saying this is how I want to deliver it. I'm going to give it a try. It's a bit edgy. It might push the barriers <mark>of</mark> the But if I can make two people to my class smile or if I can Inspire one person to have a better day or if I can edit Workshop if I can Inspire one instructor or two instructors to go back and listen to their music again to try and find some moments <mark>of</mark> magic and performance so that when they teach they teach at a high level, you know, that's that's that's a win for me, you know, and obviously the more people that you can Inspire the better, but yeah that freedom to be yourself. I think just comes from actually putting in the hard work. Work behind the scenes, you know, I've those early days, you know, I think I just ate slept drunk pump like day in and day out ssy at listen to music get in front <mark>of</mark> the mirror scripting tracks practicing. I mean, it would have been really anal when I would have been really boring to be around but it gave me a good grounding and I got pretty compliment and pretty confident quick and then I was able to then start to see what other people do that are great at this and steal ideas from other people. And then you get to a place where you know, you can step out and be yourself because behind the scenes all the hard work and preparation is done. So, you know, you deserve to be there and you should do a good job because you're ready and I think that allows you to be yourself a bit more and not worry about I must say this because it might not be you know, what Les Mills International want me to say or a training might see me teaching they're not going to put my name forward to be on the team or I won't get chosen to go on a filming or you know, we have all these things that can. Sort <mark>of</mark> suppress us just relaxing and being cool and doing our own thing. And when I look at the people that inspired me the most and I think the people that have created the biggest impact on me. They've all been a", "Start Time (s)": 1446.2, "End Time (s)": 1565.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "And when I look at the people that inspired me the most and I think the people that have created the biggest impact on me. They've all been a very unique and edgy and cool. They've never been by the book or in a box or very conservative. They've always done something a bit quirky bit random and you know pushed it a little bit but it's it reminds me something at least Smith said little Lisa the Ozzy trainer the RPM guy. Now he talks about understanding the rules. So well that you're able to break the rules, you know, when he's got this this image that he you know the system so well, you know everything you're supposed to do so, you know, those little places that you're allowed to push it a little bit if you go there and find those little Corners you can create this magic that maybe other people aren't able to do but other people can do it if they just allow themselves, you know, the the freedom to give it a try. Yeah, I think, you know personally speaking. Maybe for others listening that it's almost that fear sometimes <mark>of</mark> looking stupid or what will people think and that can hold us back and off for a long time. That's definitely what held me back. Like I would I would worry about you know trying to do something in a class or a workshop with the feet <mark>of</mark> thinking that people would think. Oh, who does she think she is, you know, so took me a long time to kind <mark>of</mark> shake goes monkeys off my shoulder and to I feel like you know be myself. I think it does it does come in a bit <mark>of</mark> experience. I think once you once you got some runs on the board and you kind <mark>of</mark> know it's about you know, you do feel like you're able to you know, you've grown and developed and then you're in that place where you can you know be a little bit risky or say something and you know, if you get a reaction from it, then it's okay. Great. You actually did like that so I can do more <mark>of</mark> that stuff because that's all what gets a response. That's what creates a memory and then like you touched on earlier. So, you know,", "Start Time (s)": 1559.0, "End Time (s)": 1677.8, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know personally speaking. Maybe for others listening that it's almost that fear sometimes <mark>of</mark> looking stupid or what will people think and that can hold us back and off for a long time. That's definitely what held me back. Like I would I would worry about you know trying to do something in a class or a workshop with the feet <mark>of</mark> thinking that people would think. Oh, who does she think she is, you know, so took me a long time to kind <mark>of</mark> shake goes monkeys off my shoulder and to I feel like you know be myself. I think it does it does come in a bit <mark>of</mark> experience. I think once you once you got some runs on the board and you kind <mark>of</mark> know it's about you know, you do feel like you're able to you know, you've grown and developed and then you're in that place where you can you know be a little bit risky or say something and you know, if you get a reaction from it, then it's okay. Great. You actually did like that so I can do more <mark>of</mark> that stuff because that's all what gets a response. That's what creates a memory and then like you touched on earlier. So, you know, the things that the people remember is the feeling that you gave us how you made them feel and and these sort <mark>of</mark> experiences. It's you know, that's what we're trying to deliver to people in class or Workshop, you know, we're trying to entertain and educate and Inspire and leave them with an memorable and I think that authenticity thing at the tool that I use that I got it from a friend mind Phil Anderson actually is the Phil Anderson was a body attacking RPM trainer and he started up his own company called bespoke leadership and he does a lot <mark>of</mark> stuff on public speaking and Leadership and development but one <mark>of</mark> these talk I went through his training and one <mark>of</mark> the tools he's got on there as about your personal brand and it's kind <mark>of</mark> that premise that it's like if I was to ask 10 people You to give me three words to describe Roger Federer all 10 people come up with very similar words, or I said give me three words to", "Start Time (s)": 1612.6, "End Time (s)": 1731.0, "Clip Length (min)": 1.97, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "But globally, you know, it'll be a common thing. The three words would be very similar because those people really understand their own personal brand and who they are and they consistently deliver authentically to themselves all the time, you know, and the challenge is you know, what are yours, you know, so it was so so when I talk to my team I say What are your three words if you were to describe yourself in three words your personal brand? What would it be? If I was to describe you what three words would I use and the idea is that if your three words match the three words that everyone else thinks then you're close to being authentic then he have integrity. But if your three words, I know fit fun and enthusiastic and everyone comes to your class thinks. You're really unfitting. You're really boring and you've got no energy. There's a big disconnect with who you think you are and who everyone else she thinks you are but you know, if your three words you really know who you are as a brand and that's actually when you deliver people actually get that brand from you when that aligns with the program Essence. That's when you can really create a lot <mark>of</mark> power and I think that's what you see when you see people teaching that just seemed to be relaxed in the moment natural engaging charismatic. They're just really comfortable with who they are. They know their strengths and they're delivering, you know in the program Essence. So it's so it's kind <mark>of</mark> like three words to describe. you that would be your own personal brand and I think if you understand what those three words are that's a standpoint where you can teach from and and that will help you be a bit more authentic and you know and my but more maybe more natural and you teach that's great. Great advice. That's awesome. That's awesome. So so yeah, let's put you on the spot. We put it in the comments box and ask the guys in the UK to put down what three words they think you are and see if it matches what yours are. Yeah,", "Start Time (s)": 1736.1, "End Time (s)": 1855.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and I think that's what you see when you see people teaching that just seemed to be relaxed in the moment natural engaging charismatic. They're just really comfortable with who they are. They know their strengths and they're delivering, you know in the program Essence. So it's so it's kind <mark>of</mark> like three words to describe. you that would be your own personal brand and I think if you understand what those three words are that's a standpoint where you can teach from and and that will help you be a bit more authentic and you know and my but more maybe more natural and you teach that's great. Great advice. That's awesome. That's awesome. So so yeah, let's put you on the spot. We put it in the comments box and ask the guys in the UK to put down what three words they think you are and see if it matches what yours are. Yeah, most <mark>of</mark> that will do that. I'll put me go It's an action from this point. It is a cool little exercise and I would have done that back in I think 2015 when when filled took us through that training and um, and you know, I still use it now and I've used it recently at our new presenter bootcamp and it just seems to resonate really well because you know, we talk so much about the essence <mark>of</mark> our programs and there's so much training around that how we actually sat down and gone. Well, what's my Essence? Who am I and what do I want people to feel or to think <mark>of</mark> me when I finish teaching that class? Yeah, it's definitely a little worthwhile to use. Yeah, I'll definitely be doing that. I'll tag you in it as well. Okay, there's accountability right there. So what has been your favorite track that you've ever taught in a release in? You know,", "Start Time (s)": 1796.5, "End Time (s)": 1915.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "presenter bootcamp and it just seems to resonate really well because you know, we talk so much about the essence <mark>of</mark> our programs and there's so much training around that how we actually sat down and gone. Well, what's my Essence? Who am I and what do I want people to feel or to think <mark>of</mark> me when I finish teaching that class? Yeah, it's definitely a little worthwhile to use. Yeah, I'll definitely be doing that. I'll tag you in it as well. Okay, there's accountability right there. So what has been your favorite track that you've ever taught in a release in? You know, oh you're filming. Yeah, yeah. I'll tell you what - in a minute. All right, cool. Cool. We're so pissed so many good songs. I mean I suppose bodypump 63. That was my first feelings. That was that was the end <mark>of</mark> 2007. So that was when I got the call to go to New Zealand film 63 me Glenn and Susan and the first track I took was the backtrack. So I took that bomb diggity getting bombed that you do think about the way we're so crazy with performance. About my solo gets a bigger reaction and some <mark>of</mark> the cool buddy Jam steps in people, but that that I'll always have a soft spot for that one because it was my first time, you know teaching on a filming and that and I was super nervous and adrenaline was pumping and it went by so fast, but actually like if I go back and play that song I still just really love it. It's just a cool song. It moves quick. It's a good workout. And then those memories sort <mark>of</mark> come back <mark>of</mark> the film week and all the emotions <mark>of</mark> that. So that's always a favorite and then I think I'm In bodypump 66 that was the <mark>global</mark> Summit. So that was February 2008. And so you're teaching to a room <mark>of</mark> 900 trainers and presenters from around the world. So you're", "Start Time (s)": 1871.4, "End Time (s)": 1990.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "We're so pissed so many good songs. I mean I suppose bodypump 63. That was my first feelings. That was that was the end <mark>of</mark> 2007. So that was when I got the call to go to New Zealand film 63 me Glenn and Susan and the first track I took was the backtrack. So I took that bomb diggity getting bombed that you do think about the way we're so crazy with performance. About my solo gets a bigger reaction and some <mark>of</mark> the cool buddy Jam steps in people, but that that I'll always have a soft spot for that one because it was my first time, you know teaching on a filming and that and I was super nervous and adrenaline was pumping and it went by so fast, but actually like if I go back and play that song I still just really love it. It's just a cool song. It moves quick. It's a good workout. And then those memories sort <mark>of</mark> come back <mark>of</mark> the film week and all the emotions <mark>of</mark> that. So that's always a favorite and then I think I'm In bodypump 66 that was the <mark>global</mark> Summit. So that was February 2008. And so you're teaching to a room <mark>of</mark> 900 trainers and presenters from around the world. So you're you know, you're sat in amongst all your peers and all the top people in the Les Mills World in one room, and I was teaching the chest rack on that one. It was a technotronic song Get Up Get down. There's just an old school sort <mark>of</mark> Hip Hop Pop Song. Yes fun. But again, you know you're teaching and just look new look over into the room and you just see all these People fit passionate people. They're all trainers and presenters moving really well and we're just thinking holy shit man. I'm on stage teaching this to all the people that are the best in the industry. So that's quite a that was quite a sort <mark>of</mark> an overwhelming moment, but I think in terms <mark>of</mark> Like what she feels good quality work and it's still get the odd message to now trains from around the world. They'll use this video clip for coaching or for connection performance in the module trainings and it's the bicep track from from body pop. Ninety", "Start Time (s)": 1923.6, "End Time (s)": 2042.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that are the best in the industry. So that's quite a that was quite a sort <mark>of</mark> an overwhelming moment, but I think in terms <mark>of</mark> Like what she feels good quality work and it's still get the odd message to now trains from around the world. They'll use this video clip for coaching or for connection performance in the module trainings and it's the bicep track from from body pop. Ninety three centuries. So I just got I did feel like every time I've watched a video back I've always hated it and you know, it's like you'll be the same you you we over criticize our self we say, why did I say that? How did I miss that Q oh my knee caves in a little bit there. That's what was a little bit short on. My elbows are out too far, you know we had ourselves a bit. So reverie my neat little detail and and it's in this horrible place to be but it's good because that's how we get better, you know, and you know, you and I are in a position where we we've got good confidence and confidence in what we do because <mark>of</mark> years <mark>of</mark> doing this, you know, breaking ourselves down trying to be better and and never being good enough and so we're always on that journey, I guess and I've never really That back and gone all that was a really good job. But with this one tracker actually watched it back and thought hey if I was on a module training like there's good coaching in there. The technique looks clean. There's some some connection moments. There's a little bit <mark>of</mark> performance. I actually felt like all around that's quite a good role modeling <mark>of</mark> the five key elements and then over these last few years. Like I said the old train or we'll send a video clip message from their training or you know, it will just send me a picture and where they've used it to train their actors and for me that just feels it just gives you that sense <mark>of</mark> worth and value. That's something some work that you did is being used to actually help other people be great at this job, you know, and I really take a lot <mark>of</mark> pride in that one. So I think that that by subtract from 93 is probably my favorite just because it feels like that's that's had some legs and some Legacy and it's", "Start Time (s)": 2017.9, "End Time (s)": 2137.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it's in this horrible place to be but it's good because that's how we get better, you know, and you know, you and I are in a position where we we've got good confidence and confidence in what we do because <mark>of</mark> years <mark>of</mark> doing this, you know, breaking ourselves down trying to be better and and never being good enough and so we're always on that journey, I guess and I've never really That back and gone all that was a really good job. But with this one tracker actually watched it back and thought hey if I was on a module training like there's good coaching in there. The technique looks clean. There's some some connection moments. There's a little bit <mark>of</mark> performance. I actually felt like all around that's quite a good role modeling <mark>of</mark> the five key elements and then over these last few years. Like I said the old train or we'll send a video clip message from their training or you know, it will just send me a picture and where they've used it to train their actors and for me that just feels it just gives you that sense <mark>of</mark> worth and value. That's something some work that you did is being used to actually help other people be great at this job, you know, and I really take a lot <mark>of</mark> pride in that one. So I think that that by subtract from 93 is probably my favorite just because it feels like that's that's had some legs and some Legacy and it's and it's helped a lot <mark>of</mark> people, you know, and even just recently Jackie. Yeah. What's she doing? She was doing Jackie Kellogg from the US you An advanced training and I see video conference called nylon, and I when we were in Taiwan during the training so we had a chat to her Advanced Training group and she goes hey, guess what? I'm going to play your by subtract from 93 minutes. Yeah. Yeah, whatever and then she said with a little video clip and it was just it was just really cool because I think like you and I were talking about before we before we recorded, you know, I've you know, I've not been at the front <mark>of</mark> the game for a long time. So 93 was my last filming and so there's thousands instructors out there that have come um since 93 so they've got no idea who I am or what I've done, you know, and every now and then this video clip might pop up and it's like, oh, who's that girl? That's quite good and then it kind <mark>of</mark> just just just keeps you a little bit relevant.", "Start Time (s)": 2068.0, "End Time (s)": 2188.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "great at this job, you know, and I really take a lot <mark>of</mark> pride in that one. So I think that that by subtract from 93 is probably my favorite just because it feels like that's that's had some legs and some Legacy and it's and it's helped a lot <mark>of</mark> people, you know, and even just recently Jackie. Yeah. What's she doing? She was doing Jackie Kellogg from the US you An advanced training and I see video conference called nylon, and I when we were in Taiwan during the training so we had a chat to her Advanced Training group and she goes hey, guess what? I'm going to play your by subtract from 93 minutes. Yeah. Yeah, whatever and then she said with a little video clip and it was just it was just really cool because I think like you and I were talking about before we before we recorded, you know, I've you know, I've not been at the front <mark>of</mark> the game for a long time. So 93 was my last filming and so there's thousands instructors out there that have come um since 93 so they've got no idea who I am or what I've done, you know, and every now and then this video clip might pop up and it's like, oh, who's that girl? That's quite good and then it kind <mark>of</mark> just just just keeps you a little bit relevant. You know, it's quite nice feeling and it's a good track. You know, it's a good workout that bicep track is I think my favorite my favorite one was a one <mark>of</mark> my favorites was Christina Aguilera the basic track in other man in or the man. Oh, yeah. Yeah. Yeah that one for me. It was going to try to sing. Yeah, I think I think what kind <mark>of</mark> stands out in someone's actually asked a question in the instructors who misses me back. I've got like 20 or questions. I'm going to fire at you shortly in but someone has mentioned the famous catching catching the bicep bar in your foot. Is that what you did at the end <mark>of</mark> that track? So yeah, that's cool. That's right. Yeah, always remember I was on and I was on a module training. Not long after an end a guy tried to do it, but I don't think he'd actually seen the video clip. You must have just heard that I'd done this bar catch and and", "Start Time (s)": 2125.5, "End Time (s)": 2245.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "man. Oh, yeah. Yeah. Yeah that one for me. It was going to try to sing. Yeah, I think I think what kind <mark>of</mark> stands out in someone's actually asked a question in the instructors who misses me back. I've got like 20 or questions. I'm going to fire at you shortly in but someone has mentioned the famous catching catching the bicep bar in your foot. Is that what you did at the end <mark>of</mark> that track? So yeah, that's cool. That's right. Yeah, always remember I was on and I was on a module training. Not long after an end a guy tried to do it, but I don't think he'd actually seen the video clip. You must have just heard that I'd done this bar catch and and he tried it but he was teaching the backtrack. Wow. There's a lot <mark>of</mark> instructors including myself. I have tried to catch the bar on my foot. And the basic track, so it's just the sign <mark>of</mark> a misspent youth is all those years <mark>of</mark> me wanting to be a professional football player make it but I think it's true to say that whenever your teacher your present or if you know instructors go back and watch anything that you've done. You just have this amazing talent or <mark>of</mark> bringing music to life making people feel good. And just being true to yourself. So thank you for that because it's inspired so many people through I thank you for that. Yeah. Yeah, it's been awesome before we move on to the questions from the instructors and something that's going on. You should be there's there's obviously where we are at", "Start Time (s)": 2202.7, "End Time (s)": 2322.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "myself. I have tried to catch the bar on my foot. And the basic track, so it's just the sign <mark>of</mark> a misspent youth is all those years <mark>of</mark> me wanting to be a professional football player make it but I think it's true to say that whenever your teacher your present or if you know instructors go back and watch anything that you've done. You just have this amazing talent or <mark>of</mark> bringing music to life making people feel good. And just being true to yourself. So thank you for that because it's inspired so many people through I thank you for that. Yeah. Yeah, it's been awesome before we move on to the questions from the instructors and something that's going on. You should be there's there's obviously where we are at the moment in terms <mark>of</mark> what's happening in the world. Our aim is the coronavirus. So I just wanted to just ask you some questions about that. And obviously we see a lot <mark>of</mark> stuff in the media at the moment about it. But what we don't hear about is they can impact having on the fitness industry in China and you know, the surrounding countries and stuff. So what's it been like for you like being I guess in the nucleus <mark>of</mark> the virus and the impact it's having on the team and Have you got it yet. Have you had it? Yeah touchwood. I think I'm okay. And now that's the thing. Nothing come like I guess all jokes aside the actual the actual statistics behind the numbers. It's not so bad, you know, and I know the media hype it up a", "Start Time (s)": 2263.7, "End Time (s)": 2383.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and you know, the surrounding countries and stuff. So what's it been like for you like being I guess in the nucleus <mark>of</mark> the virus and the impact it's having on the team and Have you got it yet. Have you had it? Yeah touchwood. I think I'm okay. And now that's the thing. Nothing come like I guess all jokes aside the actual the actual statistics behind the numbers. It's not so bad, you know, and I know the media hype it up a lot and then and obviously globally it's up. It's a big deal and they one's got some very serious and worried and and it's good that we have because I think if we Ugly everyone everyone. Obviously that's going to restrict, you know, how far it spreads and then they've done a great job <mark>of</mark> that in China, you know. So for example, I've just come back from Taiwan and I'm and I'm on 14 days quarantine lockdown. So I've got to stay in my apartment for 14 days. I can't leave my compounds because <mark>of</mark> the risk <mark>of</mark> spreading the virus. And so that's in and around trying to we're doing know everyone has to do that. So, you know, there's things Cafes restaurants and bars. They will shut down Office Buildings are closed gyms are closed. People can't conquer eight more than five in your in your building if there's a family living, you know, the whole family can't go out <mark>of</mark> the compound only one person can leave and they've got to get a pass and you're allowed to leave for an hour and you can come back and go to give you a pass back. So there's a lot <mark>of</mark> heavy restrictions that you know, it sort <mark>of</mark> seems like Overkill people are walking around in those nucleus suits and face me. I asked and you think Is this like a movie about the sensationalism", "Start Time (s)": 2342.6, "End Time (s)": 2462.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>of</mark> that in China, you know. So for example, I've just come back from Taiwan and I'm and I'm on 14 days quarantine lockdown. So I've got to stay in my apartment for 14 days. I can't leave my compounds because <mark>of</mark> the risk <mark>of</mark> spreading the virus. And so that's in and around trying to we're doing know everyone has to do that. So, you know, there's things Cafes restaurants and bars. They will shut down Office Buildings are closed gyms are closed. People can't conquer eight more than five in your in your building if there's a family living, you know, the whole family can't go out <mark>of</mark> the compound only one person can leave and they've got to get a pass and you're allowed to leave for an hour and you can come back and go to give you a pass back. So there's a lot <mark>of</mark> heavy restrictions that you know, it sort <mark>of</mark> seems like Overkill people are walking around in those nucleus suits and face me. I asked and you think Is this like a movie about the sensationalism <mark>of</mark> the Twitter and Facebook in the media when you listen to The Experts and they compare it to like Ebola or SARS or MERS or even just the common cold and the flu numbers Wise It's not actually a scary. So what what the impact is is it's not so much about people getting the virus. It's this this day to day life and like you say impacting the business so much. Meaning Gene for example a lot <mark>of</mark> them teach classes and that and that's that's their sole income. That's what I do for a living teaching 2025 classes per week. So at the moment obviously the gym isn't open so they're not teaching those classes. So they're not getting paid. Now that's spreading into three three and a half weeks. That's that's a long time to not get any income but you still have to pay rent on your building still going to pay electricity gas water. You still gotta buy food. I've got friends that are the gym owners so they own small gyms that our little Group fitness Studios. So obviously in these three three and a half weeks, they've not been able to be open", "Start Time (s)": 2402.3, "End Time (s)": 2522.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it to like Ebola or SARS or MERS or even just the common cold and the flu numbers Wise It's not actually a scary. So what what the impact is is it's not so much about people getting the virus. It's this this day to day life and like you say impacting the business so much. Meaning Gene for example a lot <mark>of</mark> them teach classes and that and that's that's their sole income. That's what I do for a living teaching 2025 classes per week. So at the moment obviously the gym isn't open so they're not teaching those classes. So they're not getting paid. Now that's spreading into three three and a half weeks. That's that's a long time to not get any income but you still have to pay rent on your building still going to pay electricity gas water. You still gotta buy food. I've got friends that are the gym owners so they own small gyms that our little Group fitness Studios. So obviously in these three three and a half weeks, they've not been able to be open so they're not running any classes. So no one's actually paying money to go to that class that they're not having income but they've still got the overheads <mark>of</mark> the rent on the facility in the listing on the equipment, you know, the rates water gas all that sort <mark>of</mark> stuff. So it's this day to day life that you know outside <mark>of</mark> actually catching the virus and then the health scare. It's just people not getting an income businesses not making money and or maybe he's being sustainable because they're losing So much money and even silly things like like going to the gym. So none <mark>of</mark> us can go to the gym, you know, so people have to try and work out a way to train in their front room so they can jump on and do the Les Mills programs. What we've found is some instructors. They're doing a livestream. So they might teach a little 30-minute hit workout live stream it from the front room and they're picking up like a big bottle <mark>of</mark> water to use as the dumbbell and then using the couch that you can buy over and they're just being really creative. Native, which is cool, but you know, you know, it's like we Fitness industry people we want to get in the gym. We want to lift weights to want to get outside you want to run, you know, we're it's cabin fever and then that affects people", "Start Time (s)": 2468.7, "End Time (s)": 2588.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "know outside <mark>of</mark> actually catching the virus and then the health scare. It's just people not getting an income businesses not making money and or maybe he's being sustainable because they're losing So much money and even silly things like like going to the gym. So none <mark>of</mark> us can go to the gym, you know, so people have to try and work out a way to train in their front room so they can jump on and do the Les Mills programs. What we've found is some instructors. They're doing a livestream. So they might teach a little 30-minute hit workout live stream it from the front room and they're picking up like a big bottle <mark>of</mark> water to use as the dumbbell and then using the couch that you can buy over and they're just being really creative. Native, which is cool, but you know, you know, it's like we Fitness industry people we want to get in the gym. We want to lift weights to want to get outside you want to run, you know, we're it's cabin fever and then that affects people mentally and people aren't going to work so they don't catch that with their friends and the office or catching up with friends after work for this day to day life really has sort <mark>of</mark> been quite heavy and quite stressful. But one thing I will say is people here are really positive and the social media that we've got is it's called we chat. So a lot <mark>of</mark> people use WeChat and About that's kind <mark>of</mark> like our Facebook and Instagram and the community is just really getting behind each other and known and everyone here trust that the government is doing the best they can to try and you know put a lid on this as quick as possible in Shanghai. We got a few days where the numbers have actually grown and there's been a few days where there's been no new cases <mark>of</mark> the virus. So that's obviously a positive. There's just a lot <mark>of</mark> travel restrictions. So, you know people aren't flying into China or flying out. So if anyone's had holidays books or if they need to travel for work, that's not happening. Ying so it's a pretty serious full on lockdown and You know a lot <mark>of</mark> that day-to-day stuff we take for granted like walking up the road and get a coffee. You know, it's just kind <mark>of</mark> you can't do it because the coffee shops not open or you're not allowed to leave the compound. So it is pretty full on and I think the", "Start Time (s)": 2537.3, "End Time (s)": 2657.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and then that affects people mentally and people aren't going to work so they don't catch that with their friends and the office or catching up with friends after work for this day to day life really has sort <mark>of</mark> been quite heavy and quite stressful. But one thing I will say is people here are really positive and the social media that we've got is it's called we chat. So a lot <mark>of</mark> people use WeChat and About that's kind <mark>of</mark> like our Facebook and Instagram and the community is just really getting behind each other and known and everyone here trust that the government is doing the best they can to try and you know put a lid on this as quick as possible in Shanghai. We got a few days where the numbers have actually grown and there's been a few days where there's been no new cases <mark>of</mark> the virus. So that's obviously a positive. There's just a lot <mark>of</mark> travel restrictions. So, you know people aren't flying into China or flying out. So if anyone's had holidays books or if they need to travel for work, that's not happening. Ying so it's a pretty serious full on lockdown and You know a lot <mark>of</mark> that day-to-day stuff we take for granted like walking up the road and get a coffee. You know, it's just kind <mark>of</mark> you can't do it because the coffee shops not open or you're not allowed to leave the compound. So it is pretty full on and I think the stress is what's happened in the leaking go Liesl up like obviously this boat off to Japan where a lot <mark>of</mark> people have caught the virus because you know, they were on that cruise liner the numbers they're a pretty scary. And then I think South Korea now has just suddenly had a big boom. I guess they you know, they didn't really they didn't really sort <mark>of</mark> our have anything to worry about in the early days. So there wasn't any restrictions on traveling or being in groups, you know, there was still getting together in big groups and business as usual and then sort <mark>of</mark> all <mark>of</mark> a sudden these last few days. They've had a few big increases in numbers and so a few other countries have had a you know, a few cases which starts to scare people, you know, and the downside is it brings out a lot <mark>of</mark> that that was xenophobia and what that racist stuff and you see people You know started to blame China or States because the Chinese are doing stuff like eating bats or they're not hiding eunuch and", "Start Time (s)": 2587.7, "End Time (s)": 2706.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "so it's a pretty serious full on lockdown and You know a lot <mark>of</mark> that day-to-day stuff we take for granted like walking up the road and get a coffee. You know, it's just kind <mark>of</mark> you can't do it because the coffee shops not open or you're not allowed to leave the compound. So it is pretty full on and I think the stress is what's happened in the leaking go Liesl up like obviously this boat off to Japan where a lot <mark>of</mark> people have caught the virus because you know, they were on that cruise liner the numbers they're a pretty scary. And then I think South Korea now has just suddenly had a big boom. I guess they you know, they didn't really they didn't really sort <mark>of</mark> our have anything to worry about in the early days. So there wasn't any restrictions on traveling or being in groups, you know, there was still getting together in big groups and business as usual and then sort <mark>of</mark> all <mark>of</mark> a sudden these last few days. They've had a few big increases in numbers and so a few other countries have had a you know, a few cases which starts to scare people, you know, and the downside is it brings out a lot <mark>of</mark> that that was xenophobia and what that racist stuff and you see people You know started to blame China or States because the Chinese are doing stuff like eating bats or they're not hiding eunuch and yeah, that stuff upsets me. Also I live here and then these are my people, you know, and so I do feel quite sort <mark>of</mark> attached to it and quite emotionally involved in the outcome. And obviously my family is you know, they're worried about me being here and you know, obviously I wasn't in China was in Taiwan and then globally nobody's flying into China, but I have to fly back into China because it's my job and I want to be one team, you know, so it's like Let's meals and use in in New Zealand. They're not letting anyone come to China. But I I could that's one <mark>of</mark> the great things you mean. It's not a great thing about a tragedy but", "Start Time (s)": 2638.3, "End Time (s)": 2757.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know, and the downside is it brings out a lot <mark>of</mark> that that was xenophobia and what that racist stuff and you see people You know started to blame China or States because the Chinese are doing stuff like eating bats or they're not hiding eunuch and yeah, that stuff upsets me. Also I live here and then these are my people, you know, and so I do feel quite sort <mark>of</mark> attached to it and quite emotionally involved in the outcome. And obviously my family is you know, they're worried about me being here and you know, obviously I wasn't in China was in Taiwan and then globally nobody's flying into China, but I have to fly back into China because it's my job and I want to be one team, you know, so it's like Let's meals and use in in New Zealand. They're not letting anyone come to China. But I I could that's one <mark>of</mark> the great things you mean. It's not a great thing about a tragedy but that often when you get a crisis, you know people. Lunch together people look after each other and look out for each other and then it brings out the best in people, you know kindness care support love, you know, there's people, you know, if they are able to you know to deliver some food or to deliver some face mask door toilet roll or whatever, you know, they're doing that and people are staying engaged online talking to each other and like I said posting this workout Clips posting advice, you know. Hey guys you wake up today and you're really stressed out because you can't move his three exercises you might wanna try Why you know, how about writing journal? How about doing some meditation? Here's a Body Balance track, you know people are just getting together and and then trying to pull through it, you know, and that's it. Yeah, it's just one tiny thing is it is yeah it is and and even even sort <mark>of</mark> I guess as a business aspect, you know, if you're a club owner and you're paying a 12-month license fee", "Start Time (s)": 2695.8, "End Time (s)": 2814.1, "Clip Length (min)": 1.97, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that's one <mark>of</mark> the great things you mean. It's not a great thing about a tragedy but that often when you get a crisis, you know people. Lunch together people look after each other and look out for each other and then it brings out the best in people, you know kindness care support love, you know, there's people, you know, if they are able to you know to deliver some food or to deliver some face mask door toilet roll or whatever, you know, they're doing that and people are staying engaged online talking to each other and like I said posting this workout Clips posting advice, you know. Hey guys you wake up today and you're really stressed out because you can't move his three exercises you might wanna try Why you know, how about writing journal? How about doing some meditation? Here's a Body Balance track, you know people are just getting together and and then trying to pull through it, you know, and that's it. Yeah, it's just one tiny thing is it is yeah it is and and even even sort <mark>of</mark> I guess as a business aspect, you know, if you're a club owner and you're paying a 12-month license fee to Les Mills to rock band bodypump, and now you had a month where you can't run bodypump you then turn around and say, okay. Well I do I get another man. Add it onto my license fee or you charging for me that so there's a business we've been going have those conversations, you know, and and so it is there's a lot more to it than than like say just the the scare <mark>of</mark> the health aspect to it. It's affecting the fitness industry and in quite a big way, you know clubs aren't buying equipment. You know, no one's looking to the Future to expand its you know, it's you know, it's it's right across the board, but we know it's got to do what we can it's that control what you can control. No the artist stoicism. Yeah. Well, hopefully you'll be over the worst <mark>of</mark> it in and things and start looking a bit more positive in four years over there. Instructor questions. Are you ready? You ready for", "Start Time (s)": 2753.8, "End Time (s)": 2869.7, "Clip Length (min)": 1.93, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "business we've been going have those conversations, you know, and and so it is there's a lot more to it than than like say just the the scare <mark>of</mark> the health aspect to it. It's affecting the fitness industry and in quite a big way, you know clubs aren't buying equipment. You know, no one's looking to the Future to expand its you know, it's you know, it's it's right across the board, but we know it's got to do what we can it's that control what you can control. No the artist stoicism. Yeah. Well, hopefully you'll be over the worst <mark>of</mark> it in and things and start looking a bit more positive in four years over there. Instructor questions. Are you ready? You ready for this? I don't like that evil tone in your voice. I know I was rubbing my hands together who know don't like the the feedback has been great. And when I put it on my social media that you were coming on to the podcast. I've had lots and lots and lots <mark>of</mark> questions from UK instructors, and I also popped into the u.s. Trip as well. So I've got some questions from the US and structures as well. So So be fun. Yeah, what we'll do is we will do a quick fire. So I'll just ask you don't you know, just what's your answer? What should I do a quick fire through these? Okay. Yeah great. So the first question is a from a very special person. It's from your mom. Okay. She says when are you coming home to see your mom? Well, whatever answer I say what you soon enough fun. That's awesome. It's it's probably going to be my birthday isn't it September? So so so if we do the <mark>global</mark> Summit in in Greece in June because I'm halfway home, so it'll be just before or just after that. So if you're listening Mom, I'll be home soon. Put the kettle on", "Start Time (s)": 2825.3, "End Time (s)": 2943.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "questions from UK instructors, and I also popped into the u.s. Trip as well. So I've got some questions from the US and structures as well. So So be fun. Yeah, what we'll do is we will do a quick fire. So I'll just ask you don't you know, just what's your answer? What should I do a quick fire through these? Okay. Yeah great. So the first question is a from a very special person. It's from your mom. Okay. She says when are you coming home to see your mom? Well, whatever answer I say what you soon enough fun. That's awesome. It's it's probably going to be my birthday isn't it September? So so so if we do the <mark>global</mark> Summit in in Greece in June because I'm halfway home, so it'll be just before or just after that. So if you're listening Mom, I'll be home soon. Put the kettle on cup <mark>of</mark> tea. Yeah, okay. Next question. When will you be having a team teach with Ricky long and can Marlon come to and that's from Jeannie. And that's from Richie Dawn yet. No. No, that's actually from TV. I tell you I actually I would love it to engage with those two guys. I think it'll be great fun. And it's simple you just all got to get on to Sarah Dunford and give us some grief and say you got a book mattracks. Don't get Marlon words over and then all three <mark>of</mark> us can do it. Yeah. We'll see Marlon is coming over and a couple <mark>of</mark> weeks time because that's right. Yeah. Yeah. Yeah. Yeah, we need to get that. That would be that would be an amazing There You Go, baby. Go. Okay a big question that came in from quite a few people was when will we see you presenting on a filming again?", "Start Time (s)": 2885.6, "End Time (s)": 3004.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Ricky long and can Marlon come to and that's from Jeannie. And that's from Richie Dawn yet. No. No, that's actually from TV. I tell you I actually I would love it to engage with those two guys. I think it'll be great fun. And it's simple you just all got to get on to Sarah Dunford and give us some grief and say you got a book mattracks. Don't get Marlon words over and then all three <mark>of</mark> us can do it. Yeah. We'll see Marlon is coming over and a couple <mark>of</mark> weeks time because that's right. Yeah. Yeah. Yeah. Yeah, we need to get that. That would be that would be an amazing There You Go, baby. Go. Okay a big question that came in from quite a few people was when will we see you presenting on a filming again? It's a nice thought but I don't think that's gonna happen. And the main reason is like in the role. I mean part <mark>of</mark> the great thing about my role is being out <mark>of</mark> shine the light on other people and like I touched on earlier I've been lucky to have a few filming's and you know do a bit <mark>of</mark> traveling and have my 5 minutes <mark>of</mark> fame and I'm in a place now where it's my reward is helping other people. So I wouldn't feel comfortable being on a filming and feeling like that's taken an opportunity away from one <mark>of</mark> my So, you know and less less Adam. I want to do a best <mark>of</mark> release and wheel out. Some <mark>of</mark> us old guys just for fun. And it does not harm the regular feelings that I can get my team on then possible wet. Yeah, nothing nothing plans, but that's it's a sweet gesture. I appreciate that. Patricia wants to know how do you come up with your awesome witek? Use your one-liners? It's funny because because occasionally I will just come up with something random off the cuff and it works quite well and you go. Oh, that's pretty cool. And other times you might come up with something that just", "Start Time (s)": 2955.4, "End Time (s)": 3075.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "And it does not harm the regular feelings that I can get my team on then possible wet. Yeah, nothing nothing plans, but that's it's a sweet gesture. I appreciate that. Patricia wants to know how do you come up with your awesome witek? Use your one-liners? It's funny because because occasionally I will just come up with something random off the cuff and it works quite well and you go. Oh, that's pretty cool. And other times you might come up with something that just bombs and doesn't work and it's you know how well you can't win them all but I but I get inspiration from just movies and books and songs. So so I might hear something in a song and somehow along the way I can translate that into my brain to acute and it's something that's quite quirky and it's and it works. So I guess the simple example is so I've always been Into into bodybuilding there's a bodybuilder from the 80s called a Draper and he wrote a book called brother iron sister Steele. And so I took that name <mark>of</mark> the book brother and sister Steele and then in a in a filming released when I was coaching I said Brothers <mark>of</mark> iron and sisters <mark>of</mark> Steel and sex appeal so I just kind <mark>of</mark> added a rhyme on to the end but but I got inspiration just from the name <mark>of</mark> that book, you know, so it can come from really random places and then occasionally you might actually be sat down and you're trying to think <mark>of</mark> thing that's intelligent or funny and you try and sort <mark>of</mark> craft something like a like a comedian rights might sit down and write a joke, but I but I struggle with that. I don't think I'm I'm naturally clever in that way. It's just something quirky will come up every once in a while just like that just like that interrupted by looking around in the background. Yeah, who is that in my house? The next question is about the evolution <mark>of</mark> bodypump. So, you know, it's changed in years. What's been the biggest change for you over the", "Start Time (s)": 3043.8, "End Time (s)": 3163.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "from the 80s called a Draper and he wrote a book called brother iron sister Steele. And so I took that name <mark>of</mark> the book brother and sister Steele and then in a in a filming released when I was coaching I said Brothers <mark>of</mark> iron and sisters <mark>of</mark> Steel and sex appeal so I just kind <mark>of</mark> added a rhyme on to the end but but I got inspiration just from the name <mark>of</mark> that book, you know, so it can come from really random places and then occasionally you might actually be sat down and you're trying to think <mark>of</mark> thing that's intelligent or funny and you try and sort <mark>of</mark> craft something like a like a comedian rights might sit down and write a joke, but I but I struggle with that. I don't think I'm I'm naturally clever in that way. It's just something quirky will come up every once in a while just like that just like that interrupted by looking around in the background. Yeah, who is that in my house? The next question is about the evolution <mark>of</mark> bodypump. So, you know, it's changed in years. What's been the biggest change for you over the years the one thing that's kind <mark>of</mark> a standard. I think I mean obviously music has changed over the years and it's you know, there's this Millennial eyes thing where the music's a bit, you know bit younger and a bit cooler and a bit more today and and the the the bpms <mark>of</mark> the program's a bit faster. Now, it's more <mark>of</mark> a cardio feel, you know, we got mountain climbers, there's heaps <mark>of</mark> overhead stuff. So it's more <mark>of</mark> a cardio athletic sort <mark>of</mark> fear as opposed to maybe the slower strength work we used to have and I guess the one <mark>of</mark> the evolutions that I've sort <mark>of</mark> welcomes the most Is where we transition from bar work to do a lot <mark>of</mark> plate work and a lot <mark>of</mark> unilateral work. So the single like stuff single arm stuff. I'm a big fan any time we can do something a bit more sort <mark>of</mark> functional, you know, like the backward step and lunge with a row using the plate single arm stuff. So you're balancing your", "Start Time (s)": 3097.1, "End Time (s)": 3216.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "The next question is about the evolution <mark>of</mark> bodypump. So, you know, it's changed in years. What's been the biggest change for you over the years the one thing that's kind <mark>of</mark> a standard. I think I mean obviously music has changed over the years and it's you know, there's this Millennial eyes thing where the music's a bit, you know bit younger and a bit cooler and a bit more today and and the the the bpms <mark>of</mark> the program's a bit faster. Now, it's more <mark>of</mark> a cardio feel, you know, we got mountain climbers, there's heaps <mark>of</mark> overhead stuff. So it's more <mark>of</mark> a cardio athletic sort <mark>of</mark> fear as opposed to maybe the slower strength work we used to have and I guess the one <mark>of</mark> the evolutions that I've sort <mark>of</mark> welcomes the most Is where we transition from bar work to do a lot <mark>of</mark> plate work and a lot <mark>of</mark> unilateral work. So the single like stuff single arm stuff. I'm a big fan any time we can do something a bit more sort <mark>of</mark> functional, you know, like the backward step and lunge with a row using the plate single arm stuff. So you're balancing your body a little more but I can't I like that transition how we've moved and now we're flexible in that way. It's not just a bar bell workout. We've got the plate work and we can do single and single leg. So it's kind <mark>of</mark> a lip just just a lil bit more intelligent. Training. Yes, that's will be the standout advancement. I felt on the way cool. What is the one thing you wish instructors understood about being a trainer? I think that's the thing I was talking about is that it doesn't matter. If you know, if you're trained a presenter your d.v.d presenter program director, whatever your title or role or what extension might have reached to we're all instructors at the end <mark>of</mark> the day Thursday night 6 p.m. I'm still teaching bodypump to 25 people because that's the size <mark>of</mark> the studio nice little intimate private studio. And that's that's what's important. That's where", "Start Time (s)": 3154.1, "End Time (s)": 3270.5, "Clip Length (min)": 1.94, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So the single like stuff single arm stuff. I'm a big fan any time we can do something a bit more sort <mark>of</mark> functional, you know, like the backward step and lunge with a row using the plate single arm stuff. So you're balancing your body a little more but I can't I like that transition how we've moved and now we're flexible in that way. It's not just a bar bell workout. We've got the plate work and we can do single and single leg. So it's kind <mark>of</mark> a lip just just a lil bit more intelligent. Training. Yes, that's will be the standout advancement. I felt on the way cool. What is the one thing you wish instructors understood about being a trainer? I think that's the thing I was talking about is that it doesn't matter. If you know, if you're trained a presenter your d.v.d presenter program director, whatever your title or role or what extension might have reached to we're all instructors at the end <mark>of</mark> the day Thursday night 6 p.m. I'm still teaching bodypump to 25 people because that's the size <mark>of</mark> the studio nice little intimate private studio. And that's that's what's important. That's where I create my biggest. Impact and I have my influence, you know what I do day in and day out in my regular classes by far has more impact and influence than doing one called Lee Workshop or being delivering one bicep track on a DVD, you know, so I always try and make sure that the people in those higher positions that none <mark>of</mark> us get get arrogant or caught up in opposition and are tired or when we think we're really important and we're better than anyone else. It's pulling it right down to all <mark>of</mark> us. We're just teaching our classes and trying to do the best we can. People have moved into a different place where they might be a trainer and that's got great value to but ultimately roll your sleeves up teach your class just like just like the rest <mark>of</mark> us, you know in the end enjoy that and understand that that's the the best part <mark>of</mark> what we do. Yeah are right. The next question is about food. Do you", "Start Time (s)": 3204.2, "End Time (s)": 3324.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "what extension might have reached to we're all instructors at the end <mark>of</mark> the day Thursday night 6 p.m. I'm still teaching bodypump to 25 people because that's the size <mark>of</mark> the studio nice little intimate private studio. And that's that's what's important. That's where I create my biggest. Impact and I have my influence, you know what I do day in and day out in my regular classes by far has more impact and influence than doing one called Lee Workshop or being delivering one bicep track on a DVD, you know, so I always try and make sure that the people in those higher positions that none <mark>of</mark> us get get arrogant or caught up in opposition and are tired or when we think we're really important and we're better than anyone else. It's pulling it right down to all <mark>of</mark> us. We're just teaching our classes and trying to do the best we can. People have moved into a different place where they might be a trainer and that's got great value to but ultimately roll your sleeves up teach your class just like just like the rest <mark>of</mark> us, you know in the end enjoy that and understand that that's the the best part <mark>of</mark> what we do. Yeah are right. The next question is about food. Do you like tackles? Oh you Frozen. I can hear you. Can you hear me? I can hear you now. Yes your back. So alright we can just chop that rebate. Okay. So the next question is about did you get that about food? Yes, I'm listening. It's a subject very close to my heart or is it right? Because I was like, oh, this is a strange question. And so what is your favorite part <mark>of</mark> a tackle? The whole damn thing. I love doctors. Yeah.", "Start Time (s)": 3255.0, "End Time (s)": 3374.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I can hear you. Can you hear me? I can hear you now. Yes your back. So alright we can just chop that rebate. Okay. So the next question is about did you get that about food? Yes, I'm listening. It's a subject very close to my heart or is it right? Because I was like, oh, this is a strange question. And so what is your favorite part <mark>of</mark> a tackle? The whole damn thing. I love doctors. Yeah. Okay. Kathy wants to know the best and worst Choose You have given so what's the best q and then what's maybe something that's kind <mark>of</mark> went down like a lead correctly? I think I mean I think. I mean just just off the cuff the the worst use I went people Q late so forget trying to say something clever or funny that bombs is if you're queuing late that's always gonna be the worst you because you know, our job is to easy to follow so I kind <mark>of</mark> feel like I'm successfully my teaching when I teach a new release for the first time and everyone in the room can follow it really easily. So the I guess the blanket answer is the best hearing is when you can treat you really well and people follow you and the worst is when you're doing late and people don't you say well but I'd have to I left the Facebook you a message and trying to think back because they'll be plenty <mark>of</mark> use I've said and there's probably some instructors there's probably some instructors listening that can go I remember infractions said that there were heaps <mark>of</mark> examples but fortunately most <mark>of</mark> the time people remember in the good ones", "Start Time (s)": 3340.0, "End Time (s)": 3449.4, "Clip Length (min)": 1.82, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Okay. Kathy wants to know the best and worst Choose You have given so what's the best q and then what's maybe something that's kind <mark>of</mark> went down like a lead correctly? I think I mean I think. I mean just just off the cuff the the worst use I went people Q late so forget trying to say something clever or funny that bombs is if you're queuing late that's always gonna be the worst you because you know, our job is to easy to follow so I kind <mark>of</mark> feel like I'm successfully my teaching when I teach a new release for the first time and everyone in the room can follow it really easily. So the I guess the blanket answer is the best hearing is when you can treat you really well and people follow you and the worst is when you're doing late and people don't you say well but I'd have to I left the Facebook you a message and trying to think back because they'll be plenty <mark>of</mark> use I've said and there's probably some instructors there's probably some instructors listening that can go I remember infractions said that there were heaps <mark>of</mark> examples but fortunately most <mark>of</mark> the time people remember in the good ones but when they get one <mark>of</mark> the sort <mark>of</mark> gets thrown around a little bit is that that one I did at a workshop once on the chest strap that's why I said you always treat your bar like your first date you never let it touch the chest and then that kind that always it was got a really good reaction back in the day and but you know you know it's like if you say a queue and it's quite cool and quite funny that works you've got to let it go you can't say every class you just end up looking like an idiot so you do it once or twice and okay that's great but you've got to let it go and move on and then try and trade something else otherwise you just end up being a one trick pony someone And Susie who is an instructor she actually taught in the US but with back Scotland, she mentioned that q and in her question, so yeah, that's probably one <mark>of</mark> the best years.", "Start Time (s)": 3384.7, "End Time (s)": 3501.6, "Clip Length (min)": 1.95, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I remember infractions said that there were heaps <mark>of</mark> examples but fortunately most <mark>of</mark> the time people remember in the good ones but when they get one <mark>of</mark> the sort <mark>of</mark> gets thrown around a little bit is that that one I did at a workshop once on the chest strap that's why I said you always treat your bar like your first date you never let it touch the chest and then that kind that always it was got a really good reaction back in the day and but you know you know it's like if you say a queue and it's quite cool and quite funny that works you've got to let it go you can't say every class you just end up looking like an idiot so you do it once or twice and okay that's great but you've got to let it go and move on and then try and trade something else otherwise you just end up being a one trick pony someone And Susie who is an instructor she actually taught in the US but with back Scotland, she mentioned that q and in her question, so yeah, that's probably one <mark>of</mark> the best years. There's only been about 350. So yeah and Christine wants to know how is your mandolin going hats 11 in China like I do you speak the language? You understand it. Can you read it? Can you write can you what's going on there? young man or a young woman face her how she's in Wow, giggling taken ha ha ha what you see if there's anyone listening to can speak Mandarin they can they can translate that. I think I just said yeah, I can speak Chinese. Well totally lies but some it's cool because it's this one <mark>of</mark> the cool parts <mark>of</mark> this job is you know, like I'm learning a new language and man it's tough but it's it's like anything if you give it some time and if you put some effort into it you get you get better", "Start Time (s)": 3441.4, "End Time (s)": 3561.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "she actually taught in the US but with back Scotland, she mentioned that q and in her question, so yeah, that's probably one <mark>of</mark> the best years. There's only been about 350. So yeah and Christine wants to know how is your mandolin going hats 11 in China like I do you speak the language? You understand it. Can you read it? Can you write can you what's going on there? young man or a young woman face her how she's in Wow, giggling taken ha ha ha what you see if there's anyone listening to can speak Mandarin they can they can translate that. I think I just said yeah, I can speak Chinese. Well totally lies but some it's cool because it's this one <mark>of</mark> the cool parts <mark>of</mark> this job is you know, like I'm learning a new language and man it's tough but it's it's like anything if you give it some time and if you put some effort into it you get you get better at it. You know, it's It's just tough because I think it's a very different language to learn from you know, French Spanish German Italian, which all the Latin kind <mark>of</mark> languages and as you know, it's cool, you know, we not only learn one or two <mark>of</mark> those and and so you're doing that every day for five days a week for three or four years, you know, whereas here I wouldn't have learned a language for a long time and so I can speak Spanish but but learning Chinese is structurally it's very different. The tones are very different, but now had a few lessons. I'm starting to get better at it I can. I can understand the structure and it makes sense and I can start to pronounce the words a little better. So it's just the case <mark>of</mark> <mark>of</mark> using it more often and you know, and then trying to study more often and then get better but for the two years I've been here <mark>of</mark> probably feel like I should be a lot better but I'm doing my best and I think it's", "Start Time (s)": 3492.0, "End Time (s)": 3611.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but some it's cool because it's this one <mark>of</mark> the cool parts <mark>of</mark> this job is you know, like I'm learning a new language and man it's tough but it's it's like anything if you give it some time and if you put some effort into it you get you get better at it. You know, it's It's just tough because I think it's a very different language to learn from you know, French Spanish German Italian, which all the Latin kind <mark>of</mark> languages and as you know, it's cool, you know, we not only learn one or two <mark>of</mark> those and and so you're doing that every day for five days a week for three or four years, you know, whereas here I wouldn't have learned a language for a long time and so I can speak Spanish but but learning Chinese is structurally it's very different. The tones are very different, but now had a few lessons. I'm starting to get better at it I can. I can understand the structure and it makes sense and I can start to pronounce the words a little better. So it's just the case <mark>of</mark> <mark>of</mark> using it more often and you know, and then trying to study more often and then get better but for the two years I've been here <mark>of</mark> probably feel like I should be a lot better but I'm doing my best and I think it's important that you know the team see that I'm trying to learn the language and the integrating the culture. I've moved countries a few times America and New Zealand Australia, but obviously they will speak English. So this is the The first time I've lived in a non-english speaking country. So that's provided a lot <mark>of</mark> challenges, but it's cool. Yeah, I've sort <mark>of</mark> got enough that the average person can hear and go. Oh, he speaks quite good Chinese, but then when a Chinese person returns and starts speaking back to me, I'm not stop making progress. Yeah, it's progress. Alright the next question from Peter. Is what is your why? Well, that's a good question. Just like the Avengers Advanced Training and when I went through that I came up with this thing engage", "Start Time (s)": 3547.2, "End Time (s)": 3665.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but I'm doing my best and I think it's important that you know the team see that I'm trying to learn the language and the integrating the culture. I've moved countries a few times America and New Zealand Australia, but obviously they will speak English. So this is the The first time I've lived in a non-english speaking country. So that's provided a lot <mark>of</mark> challenges, but it's cool. Yeah, I've sort <mark>of</mark> got enough that the average person can hear and go. Oh, he speaks quite good Chinese, but then when a Chinese person returns and starts speaking back to me, I'm not stop making progress. Yeah, it's progress. Alright the next question from Peter. Is what is your why? Well, that's a good question. Just like the Avengers Advanced Training and when I went through that I came up with this thing engage educate entertain Inspire. So I sort <mark>of</mark> felt like I wanted to put something punch in there that kind <mark>of</mark> covered. What I do and engages is absolutely an important thing for me educate and entertain I feel like in our industry, you know, it's you got have a good balance <mark>of</mark> both <mark>of</mark> those things so that you've got a good message and that message lands because it's entertaining and Resting and ultimately what we're trying to do is inspire people, you know and whatever that may be and so that's why there's or forwards as a tagline. But but when I think back to to this this this, you know and actually talked about this on on Ricky's podcast. So I'll give him a little shout out here Lord knows he could do with the exposure and the numbers. So I hope you out there Richie flimsy podcast. I think I talked a bit about when I started this thing in America with this this woman Terry whore who was the manager <mark>of</mark> Gold's Gym and she was she was my butterfly effect a moment that tap on the shoulder started this whole journey that I've been on so if it wasn't for her back in 2002 coming up to me and saying you want to teach", "Start Time (s)": 3609.4, "End Time (s)": 3728.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "covered. What I do and engages is absolutely an important thing for me educate and entertain I feel like in our industry, you know, it's you got have a good balance <mark>of</mark> both <mark>of</mark> those things so that you've got a good message and that message lands because it's entertaining and Resting and ultimately what we're trying to do is inspire people, you know and whatever that may be and so that's why there's or forwards as a tagline. But but when I think back to to this this this, you know and actually talked about this on on Ricky's podcast. So I'll give him a little shout out here Lord knows he could do with the exposure and the numbers. So I hope you out there Richie flimsy podcast. I think I talked a bit about when I started this thing in America with this this woman Terry whore who was the manager <mark>of</mark> Gold's Gym and she was she was my butterfly effect a moment that tap on the shoulder started this whole journey that I've been on so if it wasn't for her back in 2002 coming up to me and saying you want to teach this thing called pump, I think you'll be good. And you know, let's give it a go. None <mark>of</mark> this would have happened and so all along my journey anyone that I've been lucky enough to to sort <mark>of</mark> influence or have a positive effect on it can all be traced back to her, you know, and she doesn't know any <mark>of</mark> this. She won't have met any <mark>of</mark> these people that I've come across and the 18 years but absolutely the butterfly effect started with her and so as I've delved into this way bit deeper what actually turns out is that that I I want to be the Terry I want to be that butterfly effect moment for as many other people's it's possible you know because I'd love to feel like that ripple effect is out there and there's people that felt inspired by something I did or said but I don't necessarily want anyone to come back and tell me that I don't need that feedback <mark>of</mark> our thank you it's just I know that happens I know that you do that I know that Ricky does that I know Steve hands he does that I know thousand instructors they all have those Butterfly Effect moments on other people and that then creates those ripples out into the world and and the beautiful thing about that is it's a constant Quest you never achieve it you know it's you're never going to wake", "Start Time (s)": 3672.0, "End Time (s)": 3792.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "as I've delved into this way bit deeper what actually turns out is that that I I want to be the Terry I want to be that butterfly effect moment for as many other people's it's possible you know because I'd love to feel like that ripple effect is out there and there's people that felt inspired by something I did or said but I don't necessarily want anyone to come back and tell me that I don't need that feedback <mark>of</mark> our thank you it's just I know that happens I know that you do that I know that Ricky does that I know Steve hands he does that I know thousand instructors they all have those Butterfly Effect moments on other people and that then creates those ripples out into the world and and the beautiful thing about that is it's a constant Quest you never achieve it you know it's you're never going to wake up one day and say I've achieved my goal you know because that next class might be the one time when you have a conversation with someone and that changes their life or you might be in bloody Starbucks having coffee and you chat to someone in the line waiting to pay and that's The moment that changed their life and help them, you know, it's really we should never lose sight <mark>of</mark> this this small thing that we might do could create a big thing in someone else's life. And then that's that's what my wife will boils down to. Yeah. Good question. This this next question comes from Peter as well. And what's your phone number? Do I owe him some money? And I don't think that's what he meant. Here we go. Judy wants to know what your favorite body pump track ever. it's got to be Enter Sandman by Metallica bodypump 43 chest strap and just saying man I don't have one that's always going to be kind <mark>of</mark> my my all-time favorite <mark>of</mark> all time and but what I'm buzzing off at the moment is is I love that bicep track for 112 the", "Start Time (s)": 3752.0, "End Time (s)": 3871.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and you chat to someone in the line waiting to pay and that's The moment that changed their life and help them, you know, it's really we should never lose sight <mark>of</mark> this this small thing that we might do could create a big thing in someone else's life. And then that's that's what my wife will boils down to. Yeah. Good question. This this next question comes from Peter as well. And what's your phone number? Do I owe him some money? And I don't think that's what he meant. Here we go. Judy wants to know what your favorite body pump track ever. it's got to be Enter Sandman by Metallica bodypump 43 chest strap and just saying man I don't have one that's always going to be kind <mark>of</mark> my my all-time favorite <mark>of</mark> all time and but what I'm buzzing off at the moment is is I love that bicep track for 112 the how do you say it like dice array and if I subtract ice array that real Scott the Gregorian chant in the background a rat and it's a big epic and I'm oh man that's awesome track yeah that's my Chiller at the moment that's good track a good track all right next question in do teach Body Balance and I do oh you do so and how would you encourage women and to body balances from Judy Well, my my balance Journey was probably a classic story for us to become guys in that, you know, the uni gets which saw the hips get a bit tight and it affects your training and you think I need to do more Mobility work a bit more stretching and and you start doing that kind <mark>of</mark> training and you might go to a couple balance", "Start Time (s)": 3803.7, "End Time (s)": 3922.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that's always going to be kind <mark>of</mark> my my all-time favorite <mark>of</mark> all time and but what I'm buzzing off at the moment is is I love that bicep track for 112 the how do you say it like dice array and if I subtract ice array that real Scott the Gregorian chant in the background a rat and it's a big epic and I'm oh man that's awesome track yeah that's my Chiller at the moment that's good track a good track all right next question in do teach Body Balance and I do oh you do so and how would you encourage women and to body balances from Judy Well, my my balance Journey was probably a classic story for us to become guys in that, you know, the uni gets which saw the hips get a bit tight and it affects your training and you think I need to do more Mobility work a bit more stretching and and you start doing that kind <mark>of</mark> training and you might go to a couple balance classes and think I actually this stuff really works. I'm feeling better. I'm moving better you enjoy it. It's nice and music and and then you stick with it and for me I just evolved into To teaching it because I thought it would be a it would be a way <mark>of</mark> making sure that I kept in Balance myself, but also as a challenge to teach a different style <mark>of</mark> program, you know, and I was an absolute beginner. So those first few body bounce classes, I was hopeless and it was almost frustrating there to be that terrible at something when you're actually good at teaching. So it's a nice little personal Journey physically as well as spiritually and emotionally, but in terms <mark>of</mark> people just come in to do the class just just showed me a picture <mark>of</mark> Cory if anyone looks at And I think you can get anything like that from Body Balance <mark>of</mark> men which flocking to it guys are specimen he can do for money balance. We'd all can I think yeah, the thing with balance is it probably got a little bit <mark>of</mark> you know that yoga Vibe where people think it's just sitting on a mat going home and it's lame, you know, people", "Start Time (s)": 3860.9, "End Time (s)": 3980.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and it affects your training and you think I need to do more Mobility work a bit more stretching and and you start doing that kind <mark>of</mark> training and you might go to a couple balance classes and think I actually this stuff really works. I'm feeling better. I'm moving better you enjoy it. It's nice and music and and then you stick with it and for me I just evolved into To teaching it because I thought it would be a it would be a way <mark>of</mark> making sure that I kept in Balance myself, but also as a challenge to teach a different style <mark>of</mark> program, you know, and I was an absolute beginner. So those first few body bounce classes, I was hopeless and it was almost frustrating there to be that terrible at something when you're actually good at teaching. So it's a nice little personal Journey physically as well as spiritually and emotionally, but in terms <mark>of</mark> people just come in to do the class just just showed me a picture <mark>of</mark> Cory if anyone looks at And I think you can get anything like that from Body Balance <mark>of</mark> men which flocking to it guys are specimen he can do for money balance. We'd all can I think yeah, the thing with balance is it probably got a little bit <mark>of</mark> you know that yoga Vibe where people think it's just sitting on a mat going home and it's lame, you know, people don't they don't know what they don't know so men don't know what balance actually feels like until it actually tried it. So, you know, I think maybe the angle <mark>of</mark> you know, the actual good stuff that it does for you physically as well as you know, as well as mentally, you know, especially this day and age a lot <mark>of</mark> mental health awareness at the moment, you know, Mandarin a balanced glass really does make you feel good and relax you and takes away some stress for a while and and it's yeah and once we start getting more men into the program, I think more men would definitely stay. It's a great program. But yeah, let's just go with a if you want to look like Corey, New Body Balance Judy's also, ask what are your top tips for staying on top <mark>of</mark> your physical game? So what challenge you do outside <mark>of</mark> class? Yes. That's that question suspects. I suppose The", "Start Time (s)": 3914.3, "End Time (s)": 4034.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "are specimen he can do for money balance. We'd all can I think yeah, the thing with balance is it probably got a little bit <mark>of</mark> you know that yoga Vibe where people think it's just sitting on a mat going home and it's lame, you know, people don't they don't know what they don't know so men don't know what balance actually feels like until it actually tried it. So, you know, I think maybe the angle <mark>of</mark> you know, the actual good stuff that it does for you physically as well as you know, as well as mentally, you know, especially this day and age a lot <mark>of</mark> mental health awareness at the moment, you know, Mandarin a balanced glass really does make you feel good and relax you and takes away some stress for a while and and it's yeah and once we start getting more men into the program, I think more men would definitely stay. It's a great program. But yeah, let's just go with a if you want to look like Corey, New Body Balance Judy's also, ask what are your top tips for staying on top <mark>of</mark> your physical game? So what challenge you do outside <mark>of</mark> class? Yes. That's that question suspects. I suppose The Body Balance was one was one <mark>of</mark> the things in the recent couple <mark>of</mark> years that I added, you know, because I just knew that I had some imbalances in my body and some weaknesses and tightness has and and what I do when I train as it is I try and do a lot <mark>of</mark> stuff that I'm not actually doing with my group fitness so so for example with With bodypump being quite cardio these days. I did two pumps a week and one RPM. I don't do any other cardio training. I don't feel like I need more cardiovascular training. What I need to do is I need to do good strength work and I need to do good functional training. So I'll do TRX. I'll do kettlebells. I do Olympic lifting I try and do things that aren't in the program. So like chin ups and pull ups and dips on bars. We can't do that in pump. So I try and do that sort <mark>of</mark> stuff. But I try and do a bit more the mobility stuff. So I'm using a lot <mark>of</mark> bands and doing what what you would call sort <mark>of</mark> stretching but", "Start Time (s)": 3965.8, "End Time (s)": 4085.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you want to look like Corey, New Body Balance Judy's also, ask what are your top tips for staying on top <mark>of</mark> your physical game? So what challenge you do outside <mark>of</mark> class? Yes. That's that question suspects. I suppose The Body Balance was one was one <mark>of</mark> the things in the recent couple <mark>of</mark> years that I added, you know, because I just knew that I had some imbalances in my body and some weaknesses and tightness has and and what I do when I train as it is I try and do a lot <mark>of</mark> stuff that I'm not actually doing with my group fitness so so for example with With bodypump being quite cardio these days. I did two pumps a week and one RPM. I don't do any other cardio training. I don't feel like I need more cardiovascular training. What I need to do is I need to do good strength work and I need to do good functional training. So I'll do TRX. I'll do kettlebells. I do Olympic lifting I try and do things that aren't in the program. So like chin ups and pull ups and dips on bars. We can't do that in pump. So I try and do that sort <mark>of</mark> stuff. But I try and do a bit more the mobility stuff. So I'm using a lot <mark>of</mark> bands and doing what what you would call sort <mark>of</mark> stretching but stuff where I think okay. I know for example, my hip flexors are the tie and I know my hamstrings are tight. So I always do a little bit <mark>of</mark> focus on those things. I'd I try to get two massages a month, but obviously it's you know, you got the financial element <mark>of</mark> that as well, but I always try and get your massages and month to try and give it a love back to the body. I do a little bit more <mark>warming</mark> up now and the days ways to just run straight onto a call you Workshop stage and and jump up and down and do 20 job knees like an idiot fresh cold. It was no problem when I was 20, but you know now I've got to do is go. Okay. I need a bit <mark>of</mark> a warm-up. So I do some stretching my birdie get the body ready before I teach a class that helps but it is I guess I'm in that sort <mark>of</mark> space and now where it's a little bit more about, you know, training smarter not harder, you know, so I know that as an adult male strength is one <mark>of</mark> the first things to go so I try and lift the", "Start Time (s)": 4016.2, "End Time (s)": 4136.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in pump. So I try and do that sort <mark>of</mark> stuff. But I try and do a bit more the mobility stuff. So I'm using a lot <mark>of</mark> bands and doing what what you would call sort <mark>of</mark> stretching but stuff where I think okay. I know for example, my hip flexors are the tie and I know my hamstrings are tight. So I always do a little bit <mark>of</mark> focus on those things. I'd I try to get two massages a month, but obviously it's you know, you got the financial element <mark>of</mark> that as well, but I always try and get your massages and month to try and give it a love back to the body. I do a little bit more <mark>warming</mark> up now and the days ways to just run straight onto a call you Workshop stage and and jump up and down and do 20 job knees like an idiot fresh cold. It was no problem when I was 20, but you know now I've got to do is go. Okay. I need a bit <mark>of</mark> a warm-up. So I do some stretching my birdie get the body ready before I teach a class that helps but it is I guess I'm in that sort <mark>of</mark> space and now where it's a little bit more about, you know, training smarter not harder, you know, so I know that as an adult male strength is one <mark>of</mark> the first things to go so I try and lift the basic lift heavy when I can and I know personality and mobilities the next thing to go to like I said you the kettlebells the TRX and then that sort <mark>of</mark> the sort <mark>of</mark> stuff a lot <mark>of</mark> CrossFit guys would do in their warm-ups and their Mobility stuff I follow a lot <mark>of</mark> good guys on Instagram achieve Fitness activate motivation K style it move you watch those Instagram guys that day there's so much great content you can take to give it a lower back to your body and man it definitely works cool and I would say are trying to sleep more that my sleep still terrible I guess traveling or stuff like that just you know traveling in different countries and different things that just make sure you sleep for sure and Rachel has asked will you marry her absolutely how much money do you own", "Start Time (s)": 4073.9, "End Time (s)": 4190.2, "Clip Length (min)": 1.94, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "cool and I would say are trying to sleep more that my sleep still terrible I guess traveling or stuff like that just you know traveling in different countries and different things that just make sure you sleep for sure and Rachel has asked will you marry her absolutely how much money do you own and then in fact I just jump down to this next one Because there's a common thing here Lydia wants to know can you have your phone number and Julia wants to your what are you doing tomorrow night, but the and more action in one phone call that I know about this stuff. Yeah, it's cool. It's cool fun. So it's last couple <mark>of</mark> questions in so we as an instructor in the UK her name is Dianne Crouch, and I know by a yeah, okay kill because she's sad she seems lots <mark>of</mark> love and do you remember introducing her and Steve tansy to your mom before she drove you up to the federal convention? Out Festival, hi, Diane, how are you? Hope you're well and sending lots <mark>of</mark> love back to you too. I'm guessing you're still doing nine or ten programs. I use so probably added grit and bass and sort <mark>of</mark> lasting you which is fantastic. Come on, you know, there's no way I'd introduce my mum to Steve tansy. That's just not gonna happen Diane's awesome. She's such a weight and she's helped you many instructors with in her region and Am I believe decently became a chai porch, so I'll cool fantastic.", "Start Time (s)": 4166.8, "End Time (s)": 4284.7, "Clip Length (min)": 1.96, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "gonna happen Diane's awesome. She's such a weight and she's helped you many instructors with in her region and Am I believe decently became a chai porch, so I'll cool fantastic. So yes. Yeah. She's definitely a good one and doing it for the right reasons at school. Yeah. Sure. Alright last question is what's your favorite thing about instructing Liz knows workouts. I gotta say the people. I mean, you know, I love the music. I love the workouts and and it's great fun being on stage teaching. But ultimately all the best all the best feelings and the best memories are the you know, the connections you make with people seeing people smile, you know, seeing someone find you have shiny eyes and and then that reciprocity thing that you can make people feel good. They can make you feel good. And I just think it's a real positive environment to be in the people that come out <mark>of</mark> a class. They just go out about their day and Bit more positive way bit healthier, but happier, they're nicer to their husbands their wives their kids that people in their workplace. It's you know, the less I've been really lucky when I saw her family's most thing that just gave me a really powerful vehicle to do what I love doing. You know, I still teach TRX classes and kettlebell classes and battle ropes. I do freestyle Olympic lifting. Like I said, I'd there's a bunch <mark>of</mark> other things that I do to spread the love about what I do, but ultimately the Les Mills gave me the biggest platform to do it and the biggest opportunity and freighting years has been my career and I would have met more people through this Les Mills thing and gone to more different countries and experience different cultures. And so I feel so I feel like they're the best thing about being a Les Mills instructor is absolutely the People You Meet the connections you make and just that that General feel-good factor that bounces around with all <mark>of</mark> us, you know, it's really", "Start Time (s)": 4269.1, "End Time (s)": 4389.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to be in the people that come out <mark>of</mark> a class. They just go out about their day and Bit more positive way bit healthier, but happier, they're nicer to their husbands their wives their kids that people in their workplace. It's you know, the less I've been really lucky when I saw her family's most thing that just gave me a really powerful vehicle to do what I love doing. You know, I still teach TRX classes and kettlebell classes and battle ropes. I do freestyle Olympic lifting. Like I said, I'd there's a bunch <mark>of</mark> other things that I do to spread the love about what I do, but ultimately the Les Mills gave me the biggest platform to do it and the biggest opportunity and freighting years has been my career and I would have met more people through this Les Mills thing and gone to more different countries and experience different cultures. And so I feel so I feel like they're the best thing about being a Les Mills instructor is absolutely the People You Meet the connections you make and just that that General feel-good factor that bounces around with all <mark>of</mark> us, you know, it's really it's a really unique thing because I think other companies He's have something similar but they just don't seem to get what we get. You know, like Zumba has a big following and there's Massa BTS there's radical Fitness. There's other people that do music, you know exercise to music and they have a community and it works really well, but it just seems to be that any people that I know that that might have left Les Mills or that it's they falling off to the side a little bit. They always miss it. They always miss the people and they always feel like we just do something. It's just like a Dixie current Formula Secret Sauce, you know, there's just something about it. It's crazy and and the best people I've met have been through through Les Mills and you know teaching classes and sometimes it's the trainer presenter other times. It's just a member in your class a fellow instructor its its its its <mark>Global</mark> its <mark>Global</mark> and that's what's cool about doing this sort <mark>of</mark> thing, you know way back in whatever you said it was 2005", "Start Time (s)": 4326.6, "End Time (s)": 4446.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "People You Meet the connections you make and just that that General feel-good factor that bounces around with all <mark>of</mark> us, you know, it's really it's a really unique thing because I think other companies He's have something similar but they just don't seem to get what we get. You know, like Zumba has a big following and there's Massa BTS there's radical Fitness. There's other people that do music, you know exercise to music and they have a community and it works really well, but it just seems to be that any people that I know that that might have left Les Mills or that it's they falling off to the side a little bit. They always miss it. They always miss the people and they always feel like we just do something. It's just like a Dixie current Formula Secret Sauce, you know, there's just something about it. It's crazy and and the best people I've met have been through through Les Mills and you know teaching classes and sometimes it's the trainer presenter other times. It's just a member in your class a fellow instructor its its its its <mark>Global</mark> its <mark>Global</mark> and that's what's cool about doing this sort <mark>of</mark> thing, you know way back in whatever you said it was 2005 when when I trained you on bodypump 54 now and here we are now in 2020 and then I'm good. some your podcast and it's like and you know several times in between that time you and I had a couple <mark>of</mark> interactions and <mark>Global</mark> Summit and like it's just it's just it's just an incredible relationship that we have with so many people and yeah and I know that one tribe is kind <mark>of</mark> a Cheesy tagline there but it is you know you if I went to the UK that is someone I could stay at the house I could teach with someone if anyone comes to Shanghai there welcome stay with me they can come and teach with me it's just it's just a good positive healthy place to be and yeah it's a it's a bloody good thing that just allows me to Les Mills did all those years ago and I think we're very very fortunate to be a part <mark>of</mark> it and and I always be thankful for that and I never take it for granted and it is always about people cut off but cut off it", "Start Time (s)": 4380.0, "End Time (s)": 4499.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know teaching classes and sometimes it's the trainer presenter other times. It's just a member in your class a fellow instructor its its its its <mark>Global</mark> its <mark>Global</mark> and that's what's cool about doing this sort <mark>of</mark> thing, you know way back in whatever you said it was 2005 when when I trained you on bodypump 54 now and here we are now in 2020 and then I'm good. some your podcast and it's like and you know several times in between that time you and I had a couple <mark>of</mark> interactions and <mark>Global</mark> Summit and like it's just it's just it's just an incredible relationship that we have with so many people and yeah and I know that one tribe is kind <mark>of</mark> a Cheesy tagline there but it is you know you if I went to the UK that is someone I could stay at the house I could teach with someone if anyone comes to Shanghai there welcome stay with me they can come and teach with me it's just it's just a good positive healthy place to be and yeah it's a it's a bloody good thing that just allows me to Les Mills did all those years ago and I think we're very very fortunate to be a part <mark>of</mark> it and and I always be thankful for that and I never take it for granted and it is always about people cut off but cut off it cut off at the bit when it's always about the people so it's perfect it's perfect that is it yeah yeah so thank you so much for coming on and chattin it's it's been amazing like cute yeah a couple <mark>of</mark> years ago like I spoke to you at tribal Gathering and I guess I was given my life for his without you I would never have phones my love for Les Miles and group fitness and doing what I'm doing to do so yes it's absolutely beautiful so thank you very much that's lovely to get mouth thank you know that's that's exactly it isn't it you know you know that you're able to say thanks to me what I did I say thanks to someone else or what they did they say thanks to someone else what they did I'm", "Start Time (s)": 4431.3, "End Time (s)": 4551.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and I always be thankful for that and I never take it for granted and it is always about people cut off but cut off it cut off at the bit when it's always about the people so it's perfect it's perfect that is it yeah yeah so thank you so much for coming on and chattin it's it's been amazing like cute yeah a couple <mark>of</mark> years ago like I spoke to you at tribal Gathering and I guess I was given my life for his without you I would never have phones my love for Les Miles and group fitness and doing what I'm doing to do so yes it's absolutely beautiful so thank you very much that's lovely to get mouth thank you know that's that's exactly it isn't it you know you know that you're able to say thanks to me what I did I say thanks to someone else or what they did they say thanks to someone else what they did I'm sure there's hundreds <mark>of</mark> people that thank you for what you do it's it's yeah it's a beautiful little chain <mark>of</mark> you know love care and support and feel good that just keeps rolling on and that's the great thing about this whole you know Wonderful crazy world <mark>of</mark> group fitness that we do it's quite quite remarkable really yeah but thank you oh you're welcome you're welcome you've been listening to the Lindsay Morrison podcast be sure to give us a review on iTunes you've been listening to the Lindsay Morrison podcast be sure to give us a review on iTunes", "Start Time (s)": 4492.9, "End Time (s)": 4584.0, "Clip Length (min)": 1.52, "show_uri": "spotify:show:5JVDiUSPwm9d2evc05x1ZX", "show_name": "The Lyndsey Morrison Podcast", "show_description": "This Podcast is for Group Fitness Instructors. I Share Insight and Experiences From My Own Group Fitness Journey and Interview Fitness Leaders That Are Impacting The Fitness Arena.  ", "publisher": "Lyndsey Morrison", "episode_uri": "spotify:episode:6NjuxxBMvynvtNLMPAb9YL", "episode_name": "#15 Matt Thraxton", "episode_description": "Episode #15 In this episode I chat with Matt Thraxton, Training Manager for Les Mills China. This was a special episode for me personally as 15 year ago Matt introduced me to Les Mills and BODYPUMP, he was my Initial Module Training Trainer. The fitness industry is a small and wonderful world, who'd have thought all these years later we would have the conversations we did on this podcast.\u00a0 In this episode you will hear what inspires Matt when it comes to connection and performance, how he teaches from a place of authenticity and living in China with the effects of the Corona Virus and the impact is is having economically on the country and the fitness industry.\u00a0Matt also answers YOUR questions that you sent to me via my social platforms...... enjoy \ud83d\ude1d You can follow Matt on Instagram and Facebook ---------------------------------------------------------------------------------------------------------------------------------------- Last month I did my first public speaking gig at myself & Rickys JUMP LIVE event titled \u201cBe Your Own Boss\u201d!  The short story is that 15 minute talk is now being turned into a coaching programme to create real confidence in group fitness instructors in how they teach. During March the first 5 people will sample and test this. I am looking for 2-3 people who would benefit from working with me to develop self confidence both in your personal and your professional life. If you would like to be part of my new project contact me on my social platforms or email... details below: You will find me on Instagram \u00a0or Facebook or email lyndseymorrison.coaching@gmail.com\u00a0 Tag and share the love for this episode on instagram \ud83d\ude0d\u00a0 \u00a0 ", "score": 6.7710066, "explanation": "{\n  \"value\": 6.7710066,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4447348,\n      \"description\": \"weight(word_list:effects in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4447348,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.546427,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.06697365,\n      \"description\": \"weight(word_list:of in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.06697365,\n          \"description\": \"score(LMDirichletSimilarity, freq=275.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.168666,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 275.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.4168472,\n      \"description\": \"weight(word_list:global in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4168472,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.842451,\n      \"description\": \"weight(word_list:warming in 37) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.842451,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -2.1016922,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 14360.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "You're listening to the jelly donut podcast. I'm Ryan your host join me as I talk to the best and brightest and It's an economics will go beyond just Theory and discuss some <mark>of</mark> the most important real world macro questions <mark>of</mark> our time what happens next and how does all <mark>of</mark> this and pull up a seat and listen in we'll talk about it coming up next. Today's Show is brought to you by covid coffee covid has a specialty roaster out <mark>of</mark> Portland, Oregon and I specialize in single origin coffees are committed to long-term sustainable Partnerships with coffee producers. Now if you like me, I love coffee. I like to start off with usually one or two cups. I make it by hand at home with a pour-over but it doesn't matter how you make it you could be using a mr. Coffee machine. It doesn't", "Start Time (s)": 22.7, "End Time (s)": 94.4, "Clip Length (min)": 1.2, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "P10 and you get five dollars off your first purchase do it right now while you're thinking about it. You'll be happy you did. I want to welcome our newest sponsor barren fig whether you be pens. Notebooks are bags. They have you covered barren fig makes tools for thinking and the help you do your best thinking at home work and in between and if you're a podcast fan the small little notebooks they have are great for taking notes to refer back to later. I've been using the products now for gosh over five years and I love the craftsmanship and attention to detail. So if you like the podcast Show your support to barren fig go to barren fig.com and use our code JDP 10. That's JD P10 and you'll get 10% off your first purchase. So go check it out right now while you're thinking about it. Today on the show. We have Michael every Michael is head <mark>of</mark> financial markets research for the asia-pacific region at Rabobank. He has nearly two decades <mark>of</mark> experience working as an economist and strategist previously you as a senior Economist and fixed income strategist to RBS and he was an economist for Dun & Bradstreet. He holds a master's degree in economics with distinction from University College London speaks Thai and he's a contributor to Zero Hedge. Enjoy my conversation with delivery Michael welcome to the podcast great to be here was great having you. So the first question I like to ask guess is going back to 2008 tell us a little bit about what you were up to professionally and what was going through your mind and the <mark>global</mark> financial crisis. Well, to be honest, I was swimming in the pool <mark>of</mark> my condo in Bangkok doing yoga a couple <mark>of</mark> sessions a day and pretty much laughing at everyone. And during the GFC saying I Told", "Start Time (s)": 124.5, "End Time (s)": 244.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "purchase. So go check it out right now while you're thinking about it. Today on the show. We have Michael every Michael is head <mark>of</mark> financial markets research for the asia-pacific region at Rabobank. He has nearly two decades <mark>of</mark> experience working as an economist and strategist previously you as a senior Economist and fixed income strategist to RBS and he was an economist for Dun & Bradstreet. He holds a master's degree in economics with distinction from University College London speaks Thai and he's a contributor to Zero Hedge. Enjoy my conversation with delivery Michael welcome to the podcast great to be here was great having you. So the first question I like to ask guess is going back to 2008 tell us a little bit about what you were up to professionally and what was going through your mind and the <mark>global</mark> financial crisis. Well, to be honest, I was swimming in the pool <mark>of</mark> my condo in Bangkok doing yoga a couple <mark>of</mark> sessions a day and pretty much laughing at everyone. And during the GFC saying I Told You So suckers because I'd I'd quit my job in early 2007 because I could see that some looming crisis was was imminent. I was a wee bit early on the call, but I thought let's go somewhere with a nice low cost <mark>of</mark> living that isn't going to be too swept up in this particular financial crisis if it does hit so that's what I was doing. Interesting. So you were early on on that and saw some <mark>of</mark> the debt being built up in the mortgage space and maybe some other areas in the economy. I did. Yes, you know, I can dig out very dusty older PDFs from the mid 2000s with me muttering about things like the Great Depression coming back again, you know Doom Gloom, etc, etc. So basically I've been on a similar theme for quite some time for Anyone who reads", "Start Time (s)": 174.9, "End Time (s)": 294.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>of</mark> sessions a day and pretty much laughing at everyone. And during the GFC saying I Told You So suckers because I'd I'd quit my job in early 2007 because I could see that some looming crisis was was imminent. I was a wee bit early on the call, but I thought let's go somewhere with a nice low cost <mark>of</mark> living that isn't going to be too swept up in this particular financial crisis if it does hit so that's what I was doing. Interesting. So you were early on on that and saw some <mark>of</mark> the debt being built up in the mortgage space and maybe some other areas in the economy. I did. Yes, you know, I can dig out very dusty older PDFs from the mid 2000s with me muttering about things like the Great Depression coming back again, you know Doom Gloom, etc, etc. So basically I've been on a similar theme for quite some time for Anyone who reads my work. Yeah, so a lot <mark>of</mark> people might be familiar with your work from seeing it posted on Zero Hedge course you distribute, you know to clients and through through the blog there with the bank. But you know going to present day here you've written about a lot <mark>of</mark> the that build up in certain their economy, obviously right now, it's corporate debt and then, you know sovereign debt. We just saw yields hit the all-time low on the 10-year. Here in the US and the 30 year which will get into but talk a little bit about where you see the actual, you know build-up <mark>of</mark> Leverage in the system right now compared to the <mark>global</mark> financial crisis what obviously there are similarities and differences. One <mark>of</mark> the key differences now is that sovereign debt is far higher than it was before that's real obviously in the US and globally household debt if anything is slightly lower if you look at At you know some measures", "Start Time (s)": 238.3, "End Time (s)": 357.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know to clients and through through the blog there with the bank. But you know going to present day here you've written about a lot <mark>of</mark> the that build up in certain their economy, obviously right now, it's corporate debt and then, you know sovereign debt. We just saw yields hit the all-time low on the 10-year. Here in the US and the 30 year which will get into but talk a little bit about where you see the actual, you know build-up <mark>of</mark> Leverage in the system right now compared to the <mark>global</mark> financial crisis what obviously there are similarities and differences. One <mark>of</mark> the key differences now is that sovereign debt is far higher than it was before that's real obviously in the US and globally household debt if anything is slightly lower if you look at At you know some measures which is encouraging. Although it's hardly what you would call low and certainly in other parts <mark>of</mark> the <mark>global</mark> economy. Particularly China. It's going through the roof and corporate debt. Well, I'm worried about the quality <mark>of</mark> corporate debt rather than the outright level <mark>of</mark> it. But again that depends on the country that you're looking at and I take a <mark>global</mark> view rather than a purely u.s. Centric one, but the long and the short <mark>of</mark> it is, you know, if we're talking debt we still have Far too much <mark>of</mark> it in far too many places and in far too many sectors and it's a one-way path that we are on and if one understands that Dynamic it's really impossible to be optimistic in the long term. Right and I'm reading your your recent note here from titled Epoch marking the moment and treasury yields is imminent posted here on 0 head and just at the outset hear you. You talk about the 10-year going to that. I think the lowest it traded out was a one spot", "Start Time (s)": 304.6, "End Time (s)": 423.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "posted here on 0 head and just at the outset hear you. You talk about the 10-year going to that. I think the lowest it traded out was a one spot for your once bottle for and so, you know going to that possibly that sub 1 percent level and obviously we've had even some things changed since you wrote this note talk a little bit about what you see unfolding just saving in the past few days with yields touching those all-time. Was on the 10-year in the 30-year. Well, I think you have to look at it like this this virus which I'm sure will discuss in more detail in a moment is obviously a shock to the system. But if the season was healthy we wouldn't be in half the trouble that we're in now and effectively it's acting as an accelerant all be it an unprecedented accelerant an accelerant to a number <mark>of</mark> underlying Trends which are extremely negative on a broad range. Age <mark>of</mark> you know, socio economic and financial France and which have been dragging that 10-year yield down in the u.s. Anyway, it's not like we were trending higher, you know, heading up towards two then three then four as some <mark>of</mark> the other Talking Heads on Wall Street have been saying for years now and being wrong continuously by the way, and then suddenly the virus hits and we're heading back down towards one. It's not at all that it's more a sudden fast forward taking us towards an end point that seem to be inevitable to me. For a long time anyway, so that's how I like to frame how the virus is having that impact. Obviously if we are going to get the FED acting aggressively this year and that was already our expectation. By the way out house call was already that by December with your back at the zero lower Bound for the FED. We now think that's going to happen by September. So obviously yes. Those yields are going to continue to come", "Start Time (s)": 411.4, "End Time (s)": 530.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "have been saying for years now and being wrong continuously by the way, and then suddenly the virus hits and we're heading back down towards one. It's not at all that it's more a sudden fast forward taking us towards an end point that seem to be inevitable to me. For a long time anyway, so that's how I like to frame how the virus is having that impact. Obviously if we are going to get the FED acting aggressively this year and that was already our expectation. By the way out house call was already that by December with your back at the zero lower Bound for the FED. We now think that's going to happen by September. So obviously yes. Those yields are going to continue to come bring in. But as I stress we were already expecting that to be happening just Just just slightly more slowly. Yeah, and I've been reading your notes for a while and they all have the similar theme and as you mentioned you've been you've been talking about this for a while and finally, you know, some <mark>of</mark> this stuff is finally coming to fruition. So you mentioned the FED here you break down toward the end <mark>of</mark> your article here where they can actually go and what might happen you mentioned the G7 meeting. So, you know, a lot <mark>of</mark> people thought maybe the FED would put in the emergency. Cut yesterday, maybe before the Asian markets opened that didn't happen. We saw the boj make a somewhat vague statement just saying they're going to be able to provide liquidity and be accommodative. And so you break this down here in your article talking about okay the different scenarios that they could go, you know, whether it's a 25 bib 50 bip cut. Let's talk through that a little bit because that was a really interesting part <mark>of</mark> the note. Well, obviously if they Do nothing markets are going to puke at this stage. Yeah, I know everyone's expecting central banks to save the day again. So they can't do nothing. They've you know, they're really stuck.", "Start Time (s)": 489.9, "End Time (s)": 608.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the Asian markets opened that didn't happen. We saw the boj make a somewhat vague statement just saying they're going to be able to provide liquidity and be accommodative. And so you break this down here in your article talking about okay the different scenarios that they could go, you know, whether it's a 25 bib 50 bip cut. Let's talk through that a little bit because that was a really interesting part <mark>of</mark> the note. Well, obviously if they Do nothing markets are going to puke at this stage. Yeah, I know everyone's expecting central banks to save the day again. So they can't do nothing. They've you know, they're really stuck. Imagine. They do 25 basis points. What does that do? I mean it's a token gesture and even if they say well don't worry, they'll be another one coming in six weeks. And another one is six weeks after that. I don't really see that's going to calm people when globally and again, I'm This globally, you know the front page <mark>of</mark> the UK papers today just to give you a flavor <mark>of</mark> what we're seeing over here are talking about when cities are going to be locked down by the police and army and what plans we have in place and how supermarkets are trying to draw up contingency plans to make sure there'll be food now, obviously the Press does tend to get a little bit overexcited and I'm not saying there isn't some exaggeration there. Yeah, but what is 25 basis points do against that kind <mark>of</mark> backdrop? The answer is absolutely nothing. It's an insult so then okay, let's play. You will at your 50 here comes the big gun. And that's what we think they will do actually our house call is or do a 50 in March. I mean for those <mark>of</mark> you who remember when rates were still being cut rather than being hiked and you know, you have to go back a long time in the market is to actually remember fed, you know aggressive Fed rate Cuts because you know, that's pre pre GFC or into the GFC as it were. Yeah, you know 50 basis points is your bazooka. That's your big gun. Really? What does an extra 25 basis points on top <mark>of</mark> the token 25 basis points to achieve if your", "Start Time (s)": 567.8, "End Time (s)": 687.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "globally and again, I'm This globally, you know the front page <mark>of</mark> the UK papers today just to give you a flavor <mark>of</mark> what we're seeing over here are talking about when cities are going to be locked down by the police and army and what plans we have in place and how supermarkets are trying to draw up contingency plans to make sure there'll be food now, obviously the Press does tend to get a little bit overexcited and I'm not saying there isn't some exaggeration there. Yeah, but what is 25 basis points do against that kind <mark>of</mark> backdrop? The answer is absolutely nothing. It's an insult so then okay, let's play. You will at your 50 here comes the big gun. And that's what we think they will do actually our house call is or do a 50 in March. I mean for those <mark>of</mark> you who remember when rates were still being cut rather than being hiked and you know, you have to go back a long time in the market is to actually remember fed, you know aggressive Fed rate Cuts because you know, that's pre pre GFC or into the GFC as it were. Yeah, you know 50 basis points is your bazooka. That's your big gun. Really? What does an extra 25 basis points on top <mark>of</mark> the token 25 basis points to achieve if your supermarkets are running out <mark>of</mark> food and you've got you know, the Army and police on the street locking people into their houses like we saw in China or you know, dropping off sacks <mark>of</mark> potatoes and rice and then, you know people Scurry out <mark>of</mark> their homes with disinfectant and try and grab them and run back in again and boil them up like some kind <mark>of</mark> plague scenario now again, I'm not saying this is going to happen. But if that's what the market is. Off fearing and you know, there's certainly a tail risk <mark>of</mark> that happening. Most 50 basis points is also nothing. So once you actually show that you really show that the central message here is that central banks can try and step in as the Big Daddy the way they have done repeatedly during crisis after crisis over recent years. And this is a case <mark>of</mark> transmissibility trumping liquidity. What is extra liquidity going to do if everyone is holed up at home eating rice and potatoes?", "Start Time (s)": 624.7, "End Time (s)": 743.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "GFC as it were. Yeah, you know 50 basis points is your bazooka. That's your big gun. Really? What does an extra 25 basis points on top <mark>of</mark> the token 25 basis points to achieve if your supermarkets are running out <mark>of</mark> food and you've got you know, the Army and police on the street locking people into their houses like we saw in China or you know, dropping off sacks <mark>of</mark> potatoes and rice and then, you know people Scurry out <mark>of</mark> their homes with disinfectant and try and grab them and run back in again and boil them up like some kind <mark>of</mark> plague scenario now again, I'm not saying this is going to happen. But if that's what the market is. Off fearing and you know, there's certainly a tail risk <mark>of</mark> that happening. Most 50 basis points is also nothing. So once you actually show that you really show that the central message here is that central banks can try and step in as the Big Daddy the way they have done repeatedly during crisis after crisis over recent years. And this is a case <mark>of</mark> transmissibility trumping liquidity. What is extra liquidity going to do if everyone is holed up at home eating rice and potatoes? Yeah, exactly. So and at goes into the <mark>global</mark> supply chain, and when you look at China and the impacts the economy, which you know, let's just save that for kind <mark>of</mark> the toward the end hear the conversation, but you brought up a good point with the FED cutting as far as what will that actually do? So in your view obviously they're having this t7 meeting is in your view. Do you think the FED is going to do an intermittent cut? You know before the March meeting or you know, where do you stand on that? Well, I think the likelihood is moving rapidly in that direction. Obviously that needs to be coordinated with everybody else rather than just him in word. You can make an argument that are so far in the US the economy hasn't been impacted enough that just", "Start Time (s)": 675.0, "End Time (s)": 794.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "What is extra liquidity going to do if everyone is holed up at home eating rice and potatoes? Yeah, exactly. So and at goes into the <mark>global</mark> supply chain, and when you look at China and the impacts the economy, which you know, let's just save that for kind <mark>of</mark> the toward the end hear the conversation, but you brought up a good point with the FED cutting as far as what will that actually do? So in your view obviously they're having this t7 meeting is in your view. Do you think the FED is going to do an intermittent cut? You know before the March meeting or you know, where do you stand on that? Well, I think the likelihood is moving rapidly in that direction. Obviously that needs to be coordinated with everybody else rather than just him in word. You can make an argument that are so far in the US the economy hasn't been impacted enough that just knowing that there's a, you know, a 50 basis points coming at the end <mark>of</mark> the month you can afford to proceed on that basis and you know, the yield Curve will shift any way to adjust it. So from the financial side. Effectively, it's already priced in to add to a large extent. I don't really think it makes a great deal <mark>of</mark> difference except psychologically that if they bring It Forward it shows that they really do care. Yeah, I think there's some concerns about the only have so many bullets in the chamber and obviously we don't know how bad this is gonna get so they don't want to kind <mark>of</mark> use one prematurely but you know, I'm assuming obviously the market rallied today in anticipation as you mentioned that the fed and other central banks are probably Going to do some coordinated activity. Is that right? I correct if I just on this morning's note, which I just sent out. I've called it Super Trooper Tuesday quoting the lyrics from the ABBA song if anyone is listening is old enough to remember Abba and how we're going to be blinded by the Super Trouper beams, which make us feel like we're number one, you know, but unfortunately, I don't think central banks", "Start Time (s)": 738.7, "End Time (s)": 857.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I don't really think it makes a great deal <mark>of</mark> difference except psychologically that if they bring It Forward it shows that they really do care. Yeah, I think there's some concerns about the only have so many bullets in the chamber and obviously we don't know how bad this is gonna get so they don't want to kind <mark>of</mark> use one prematurely but you know, I'm assuming obviously the market rallied today in anticipation as you mentioned that the fed and other central banks are probably Going to do some coordinated activity. Is that right? I correct if I just on this morning's note, which I just sent out. I've called it Super Trooper Tuesday quoting the lyrics from the ABBA song if anyone is listening is old enough to remember Abba and how we're going to be blinded by the Super Trouper beams, which make us feel like we're number one, you know, but unfortunately, I don't think central banks and the G7 are going to be able to stop us feeling blue on this particular front here. There's not a lot that is actually going To be achieved and it's ironic actually as well because if you look at the number <mark>of</mark> <mark>global</mark> crisis, we face, you know from the debt crisis <mark>Global</mark> imbalances, you can extend that right the way through to the climate crisis. If you know, if you're in that particular camp and I understand some people listening may not be but others obviously very passionately are you know, you're talking potentially about massive <mark>Global</mark> instability on multiple fronts and in a worst case scenario the end <mark>of</mark> life on Earth, if you take the most extreme green argument, well the G7 and central banks have To lift a finger to do anything about that so far on a coordinated basis, but you know the Dow Jones Goes Down 10% a week and suddenly we can move mountains. Right and Jay Powell has mentioned in the past that he doesn't want to take rates a negative in the u.s. You know, when you look around the world we had it was I think almost 17 trillion and negative rates yielding Sovereign that I know that's gone down to maybe 11 12 trillion. When you look at past easing", "Start Time (s)": 808.3, "End Time (s)": 928.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>Global</mark> imbalances, you can extend that right the way through to the climate crisis. If you know, if you're in that particular camp and I understand some people listening may not be but others obviously very passionately are you know, you're talking potentially about massive <mark>Global</mark> instability on multiple fronts and in a worst case scenario the end <mark>of</mark> life on Earth, if you take the most extreme green argument, well the G7 and central banks have To lift a finger to do anything about that so far on a coordinated basis, but you know the Dow Jones Goes Down 10% a week and suddenly we can move mountains. Right and Jay Powell has mentioned in the past that he doesn't want to take rates a negative in the u.s. You know, when you look around the world we had it was I think almost 17 trillion and negative rates yielding Sovereign that I know that's gone down to maybe 11 12 trillion. When you look at past easing Cycles with the fed. That's a 300 400 basis point kind <mark>of</mark> move and where We are at call it one and a half then that would take us well into negative territory. What's your take on that piece? What I do think they want to avoid negative rights if they can they're gonna do. Yeah right hand though. Well that's out. There are an awful idea and there yet another example <mark>of</mark> the economics <mark>of</mark> the madhouse. Just let me take a little segue here for a second if I can to kind <mark>of</mark> link them point to the earlier part <mark>of</mark> the discussion where we were talking about. You know me being one <mark>of</mark> the the the people who did see some form <mark>of</mark> GSC coming and too much debt, etc. Etc. What frustrates me so much in this profession is the amount <mark>of</mark> commentary that comes from very smart people, you know working for all manner <mark>of</mark> different institutions who are so knowledgeable and yet haven't read any <mark>of</mark> the right stuff if you read for example kolecki who was an economist writing in the 30s and 40s", "Start Time (s)": 872.4, "End Time (s)": 991.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that's gone down to maybe 11 12 trillion. When you look at past easing Cycles with the fed. That's a 300 400 basis point kind <mark>of</mark> move and where We are at call it one and a half then that would take us well into negative territory. What's your take on that piece? What I do think they want to avoid negative rights if they can they're gonna do. Yeah right hand though. Well that's out. There are an awful idea and there yet another example <mark>of</mark> the economics <mark>of</mark> the madhouse. Just let me take a little segue here for a second if I can to kind <mark>of</mark> link them point to the earlier part <mark>of</mark> the discussion where we were talking about. You know me being one <mark>of</mark> the the the people who did see some form <mark>of</mark> GSC coming and too much debt, etc. Etc. What frustrates me so much in this profession is the amount <mark>of</mark> commentary that comes from very smart people, you know working for all manner <mark>of</mark> different institutions who are so knowledgeable and yet haven't read any <mark>of</mark> the right stuff if you read for example kolecki who was an economist writing in the 30s and 40s primarily a mark. But you know that doesn't necessarily mean he isn't worth reading. In fact, you know, some <mark>of</mark> the greats were Marxist to some degree. He makes a compelling case that structurally if you have a an economy locally, I'm particularly globally where you have a massive imbalance in power between Labour and capital. So in other words workers don't get the full fruits <mark>of</mark> productivity and that going to mainly to businesses instead and if that isn't compensated for by governments stepping in and filling the Gap to push wages higher and to keep investment up, If you end up in that Paradigm then all you will see is a larger and larger debt accumulation interest rates will try to rise and each time that will cause a crisis and they'll have to be slashed lower and lower and lower and lower and eventually you go negative. Now if the guy was arguing this in 1943", "Start Time (s)": 923.4, "End Time (s)": 1041.3, "Clip Length (min)": 1.96, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "He makes a compelling case that structurally if you have a an economy locally, I'm particularly globally where you have a massive imbalance in power between Labour and capital. So in other words workers don't get the full fruits <mark>of</mark> productivity and that going to mainly to businesses instead and if that isn't compensated for by governments stepping in and filling the Gap to push wages higher and to keep investment up, If you end up in that Paradigm then all you will see is a larger and larger debt accumulation interest rates will try to rise and each time that will cause a crisis and they'll have to be slashed lower and lower and lower and lower and eventually you go negative. Now if the guy was arguing this in 1943 because a because he's polish because he's a Marxist and see because he points out the obvious though, you know, we're up a certain creek without a paddle. I cannot tell you how many credentialed Reinstate economist's and strategists, you know that I speak to you again glorious institution. So never heard <mark>of</mark> it. You know, how can it be the equivalent <mark>of</mark> trying to deal with some kind <mark>of</mark> virus as we're dealing with now and someone's never read the basics on virus transmission and actually understanding the biology <mark>of</mark> a viruses. It's ridiculous, you know, you're trying to treat them with leeches for example, so if you put that as the backdrop collects Keys arguing there that the the imperative we have unless something changes in the structure. <mark>Of</mark> the US economy and we can maybe talk about that in a moment then ultimately. Yeah you there is the risk that you do end up going negative. I don't necessarily think that this virus is going to be the trigger that takes us there instantly and we're talking about going to the zero lower bound and hovering there for a very very long time. I would think the certainly if that doesn't work and we don't have any changes to the structure <mark>of</mark> the US economy. Then you are going to get further mutterings in the market. Well, we need more <mark>of</mark> the same. I mean, look what's happened in Europe, for example So that brings up a great point now when you look at a central bank balance sheets around the", "Start Time (s)": 1000.5, "End Time (s)": 1119.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "how many credentialed Reinstate economist's and strategists, you know that I speak to you again glorious institution. So never heard <mark>of</mark> it. You know, how can it be the equivalent <mark>of</mark> trying to deal with some kind <mark>of</mark> virus as we're dealing with now and someone's never read the basics on virus transmission and actually understanding the biology <mark>of</mark> a viruses. It's ridiculous, you know, you're trying to treat them with leeches for example, so if you put that as the backdrop collects Keys arguing there that the the imperative we have unless something changes in the structure. <mark>Of</mark> the US economy and we can maybe talk about that in a moment then ultimately. Yeah you there is the risk that you do end up going negative. I don't necessarily think that this virus is going to be the trigger that takes us there instantly and we're talking about going to the zero lower bound and hovering there for a very very long time. I would think the certainly if that doesn't work and we don't have any changes to the structure <mark>of</mark> the US economy. Then you are going to get further mutterings in the market. Well, we need more <mark>of</mark> the same. I mean, look what's happened in Europe, for example So that brings up a great point now when you look at a central bank balance sheets around the world. The FED is already been talking about for the past. I'd say three to six months maybe even the past year about obviously we had the repo issue the repo hiccup, but they've been talking about a large-scale asset prices. They've been talking about yield curve targeting and and just trying to pin rates down even on the long end <mark>of</mark> the curve. So is that something that they could they can and probably will deploy is to start buying assets whether it's treasuries and BS maybe even equities. I know that's been floated in Europe. Well, I mean you have to in this respect look and see what other people who are further ahead <mark>of</mark> us on the curb have been doing and if you pan has been trying all those things and <mark>of</mark> course the other than work I mean- rates don't work because if you have this structural imbalance in the economy, which I've already alluded", "Start Time (s)": 1051.2, "End Time (s)": 1170.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "changes to the structure <mark>of</mark> the US economy. Then you are going to get further mutterings in the market. Well, we need more <mark>of</mark> the same. I mean, look what's happened in Europe, for example So that brings up a great point now when you look at a central bank balance sheets around the world. The FED is already been talking about for the past. I'd say three to six months maybe even the past year about obviously we had the repo issue the repo hiccup, but they've been talking about a large-scale asset prices. They've been talking about yield curve targeting and and just trying to pin rates down even on the long end <mark>of</mark> the curve. So is that something that they could they can and probably will deploy is to start buying assets whether it's treasuries and BS maybe even equities. I know that's been floated in Europe. Well, I mean you have to in this respect look and see what other people who are further ahead <mark>of</mark> us on the curb have been doing and if you pan has been trying all those things and <mark>of</mark> course the other than work I mean- rates don't work because if you have this structural imbalance in the economy, which I've already alluded to then we believe passionately that is the Then lower borrowing costs don't incentivize people to actually invest more because there's no demand because people aren't earning enough. It's as simple as that and you're hamstrung by the debt that households having some corporations and in some cases governments have already built up to try and keep things moving along. So, you know, Japan's try the negative rates Europe strong a negative rates and actually net saving is going up. And in fact, ironically you do tend to see net saving increase when you get Negative interest rates because you know again your policy. Who are oh so clever think that it will incentivize people to spend. Well, it doesn't because if you have this structural imbalance on the economy where too much capital is pulled in too few hands and those hands aren't interested in actually actively investing. All they want to do is just live off <mark>of</mark> asset prices, you know, like some feudal Lord, then the lower the interest rate gets the more", "Start Time (s)": 1103.8, "End Time (s)": 1223.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>of</mark> us on the curb have been doing and if you pan has been trying all those things and <mark>of</mark> course the other than work I mean- rates don't work because if you have this structural imbalance in the economy, which I've already alluded to then we believe passionately that is the Then lower borrowing costs don't incentivize people to actually invest more because there's no demand because people aren't earning enough. It's as simple as that and you're hamstrung by the debt that households having some corporations and in some cases governments have already built up to try and keep things moving along. So, you know, Japan's try the negative rates Europe strong a negative rates and actually net saving is going up. And in fact, ironically you do tend to see net saving increase when you get Negative interest rates because you know again your policy. Who are oh so clever think that it will incentivize people to spend. Well, it doesn't because if you have this structural imbalance on the economy where too much capital is pulled in too few hands and those hands aren't interested in actually actively investing. All they want to do is just live off <mark>of</mark> asset prices, you know, like some feudal Lord, then the lower the interest rate gets the more they say to try and generate the same level <mark>of</mark> passive income. They were getting previously, you know, I have an Asian mother-in-law and I can assure you when she was still with us. That's exactly what she did. That she was not particularly wealthy, but she just lived off the interest on our on our savings and every time interest rates went down she saved more and spend less every time interest rates way up. She actually spent more because she was getting more <mark>of</mark> an income. So I've had a first-hand example have exactly how that works. So the right side won't work, you know, you talk about yield curve control. Well, okay, you can you can pin yields into a Target band to stop them Rising. If you want to you know, if the central bank has been buying assets and then suddenly the market gets spooked and says right. Well, we're all selling. Okay, you can step in and buy those bonds like jgbs and say they're not going to go above a certain level. I mean you're effectively monetizing them to do it, but you can if you want but how are you going to get in front <mark>of</mark> the", "Start Time (s)": 1158.5, "End Time (s)": 1277.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is just live off <mark>of</mark> asset prices, you know, like some feudal Lord, then the lower the interest rate gets the more they say to try and generate the same level <mark>of</mark> passive income. They were getting previously, you know, I have an Asian mother-in-law and I can assure you when she was still with us. That's exactly what she did. That she was not particularly wealthy, but she just lived off the interest on our on our savings and every time interest rates went down she saved more and spend less every time interest rates way up. She actually spent more because she was getting more <mark>of</mark> an income. So I've had a first-hand example have exactly how that works. So the right side won't work, you know, you talk about yield curve control. Well, okay, you can you can pin yields into a Target band to stop them Rising. If you want to you know, if the central bank has been buying assets and then suddenly the market gets spooked and says right. Well, we're all selling. Okay, you can step in and buy those bonds like jgbs and say they're not going to go above a certain level. I mean you're effectively monetizing them to do it, but you can if you want but how are you going to get in front <mark>of</mark> the market buying your bonds hand over fist and pushing yields lower. The only way you can do that is to sell some <mark>of</mark> your stock back into the market and it effectively, you know interest rates are just there are volume measure <mark>of</mark> how many Securities <mark>of</mark> whatever type you're buying and selling and that's the point. I think you are making their that effectively central banks start operating in developed countries more along the lines <mark>of</mark> how traditionally they used to work say in India, for example, where it's all about liquidity management data day in terms <mark>of</mark> physical levels <mark>of</mark> cache in terms <mark>of</mark> what you're buying asset wise rather than just setting something like fed funds. And letting the rest <mark>of</mark> the market do what he wants to around that Pivot Point. Yeah brings up a really good point. Now as you mentioned earlier, let's talk a little bit about some <mark>of</mark> the structural issues and some <mark>of</mark> the <mark>effects</mark> on the economy. Now, obviously the fed and central banks around the world are just focusing on on Equity markets, especially the fed and US Equity markets", "Start Time (s)": 1217.8, "End Time (s)": 1337.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "there are volume measure <mark>of</mark> how many Securities <mark>of</mark> whatever type you're buying and selling and that's the point. I think you are making their that effectively central banks start operating in developed countries more along the lines <mark>of</mark> how traditionally they used to work say in India, for example, where it's all about liquidity management data day in terms <mark>of</mark> physical levels <mark>of</mark> cache in terms <mark>of</mark> what you're buying asset wise rather than just setting something like fed funds. And letting the rest <mark>of</mark> the market do what he wants to around that Pivot Point. Yeah brings up a really good point. Now as you mentioned earlier, let's talk a little bit about some <mark>of</mark> the structural issues and some <mark>of</mark> the <mark>effects</mark> on the economy. Now, obviously the fed and central banks around the world are just focusing on on Equity markets, especially the fed and US Equity markets and any little hiccup, you know, they come out and start either jawboning or or or literally buying assets, obviously. Seen the repo it was on the short end <mark>of</mark> the curve. So these 30-day bills. So they argued well, it's not really Q week because it's not large scale asset purchases on the long end. So there's this the stock market but and this could be a short-term fix as you said on Market is expecting this and that's why we have this 5% uptick today recording on March second Monday and the market will just puke if if we don't get you know what they're looking for in this Ali accommodative policy, but let's talk a little bit about the <mark>effects</mark> down the road three months six months even a year <mark>of</mark> how the economy could just kind <mark>of</mark> grind to a halt with this with some <mark>of</mark> the virus issues going on. Well, okay on that front. This is where everybody including myself pretends to be a virologist which always entertains me because every time we have some unexpected <mark>Global</mark> crisis all the people who actually are very good economics aren't very good at Market strategy and you know, Humble enough to say I'm probably in that camp to", "Start Time (s)": 1289.4, "End Time (s)": 1409.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "out and start either jawboning or or or literally buying assets, obviously. Seen the repo it was on the short end <mark>of</mark> the curve. So these 30-day bills. So they argued well, it's not really Q week because it's not large scale asset purchases on the long end. So there's this the stock market but and this could be a short-term fix as you said on Market is expecting this and that's why we have this 5% uptick today recording on March second Monday and the market will just puke if if we don't get you know what they're looking for in this Ali accommodative policy, but let's talk a little bit about the <mark>effects</mark> down the road three months six months even a year <mark>of</mark> how the economy could just kind <mark>of</mark> grind to a halt with this with some <mark>of</mark> the virus issues going on. Well, okay on that front. This is where everybody including myself pretends to be a virologist which always entertains me because every time we have some unexpected <mark>Global</mark> crisis all the people who actually are very good economics aren't very good at Market strategy and you know, Humble enough to say I'm probably in that camp to all pretend to not also not be very good either understanding how military action works if there's a war taking place in the background or not understanding how elections work if there's an election process coming up and now we'll go to pretend we understand how viruses work but actually we done now I am fortunate enough to actually have some contacts who are very close to world-leading experts on this field. So, you know, at least second hand I get some nice some nice information on that front, but there are an underlying principles that you can see at play here and they are that this is not just a common cold. I mean how many people told me that when this was first beginning, you know weeks back in Asia. This is just a cold. I kept saying then know it ain't no I don't you you don't understand what the reaction is going to be in markets and the economy to this because I'm not talking about the the danger <mark>of</mark> the virus per", "Start Time (s)": 1341.2, "End Time (s)": 1461.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "some unexpected <mark>Global</mark> crisis all the people who actually are very good economics aren't very good at Market strategy and you know, Humble enough to say I'm probably in that camp to all pretend to not also not be very good either understanding how military action works if there's a war taking place in the background or not understanding how elections work if there's an election process coming up and now we'll go to pretend we understand how viruses work but actually we done now I am fortunate enough to actually have some contacts who are very close to world-leading experts on this field. So, you know, at least second hand I get some nice some nice information on that front, but there are an underlying principles that you can see at play here and they are that this is not just a common cold. I mean how many people told me that when this was first beginning, you know weeks back in Asia. This is just a cold. I kept saying then know it ain't no I don't you you don't understand what the reaction is going to be in markets and the economy to this because I'm not talking about the the danger <mark>of</mark> the virus per se, you know, we're looking at the impact on the economy in terms <mark>of</mark> how people panic about the dangers and first <mark>of</mark> Yeah, we can see from the supply side the entire <mark>Global</mark> model. We've built up <mark>of</mark> long highly leveraged just-in-time hyper efficient Supply chains largely centered on China Works fabulously. Well, if nothing ever goes wrong, and <mark>of</mark> course things do go wrong. I mean the parallel with the pre GFC Financial system is just amazing that you can you have this system which is priced to Perfection that regulates itself and everything is fine until you get one weakness somewhere in the system and then you get a domino effect. And it all collapses. Well, that's exactly what you're seeing on the physical side <mark>of</mark> <mark>global</mark> trade. You're not feeling the impact <mark>of</mark> it yet because everyone has inventories to run down first, but if China hasn't got the virus under control and if it starts to spread again, as soon as everyone is forced back to work by the government saying it's all good now honest take your mask off and get back in that factory. If it starts spreading again, we're going to see enormous supply", "Start Time (s)": 1400.4, "End Time (s)": 1520.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "system is just amazing that you can you have this system which is priced to Perfection that regulates itself and everything is fine until you get one weakness somewhere in the system and then you get a domino effect. And it all collapses. Well, that's exactly what you're seeing on the physical side <mark>of</mark> <mark>global</mark> trade. You're not feeling the impact <mark>of</mark> it yet because everyone has inventories to run down first, but if China hasn't got the virus under control and if it starts to spread again, as soon as everyone is forced back to work by the government saying it's all good now honest take your mask off and get back in that factory. If it starts spreading again, we're going to see enormous supply chain disruptions and you know in the US for example virus fighting gear like masks and suits Even some key drugs can no longer be manufactured in America because you've outsourced key components to China. So this shows just how big the disruption could be and the lag time to actually start a whole new productive base in the u.s. To replicate that functionality is is far beyond what anyone would want to see in terms <mark>of</mark> you know, physical comfort for key inputs particularly in fighting a virus. So that's the supply side which is real and <mark>of</mark> course with everyone now starting to go down with the virus even if China gets. Back online other people are going to get dragged down. So it's like a bunch <mark>of</mark> guys and gals all holding hands trying to cross the ice over a river and if one falls down everyone keeps falling over and soon as you stand up somebody else falls falls over and everyone gets dragged down again. That's just the supply side on the demand side, you know and linking it to the FED as I asked him this morning snow can some policy won't please tell me what the precise level <mark>of</mark> equilibrium interest rate is that means I'm no longer worried about dying on my family dying. Because I would like you to tell me what the interest rate is that you no longer worried about dying when you go to the supermarket. I'll go to a concert or you know, or decide to go to a holiday somewhere, you know, either locally or internationally. I don't think there is one and I think this is again with the idiocy <mark>of</mark> thinking monetary policy can solve it kicks in if", "Start Time (s)": 1486.1, "End Time (s)": 1606.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is far beyond what anyone would want to see in terms <mark>of</mark> you know, physical comfort for key inputs particularly in fighting a virus. So that's the supply side which is real and <mark>of</mark> course with everyone now starting to go down with the virus even if China gets. Back online other people are going to get dragged down. So it's like a bunch <mark>of</mark> guys and gals all holding hands trying to cross the ice over a river and if one falls down everyone keeps falling over and soon as you stand up somebody else falls falls over and everyone gets dragged down again. That's just the supply side on the demand side, you know and linking it to the FED as I asked him this morning snow can some policy won't please tell me what the precise level <mark>of</mark> equilibrium interest rate is that means I'm no longer worried about dying on my family dying. Because I would like you to tell me what the interest rate is that you no longer worried about dying when you go to the supermarket. I'll go to a concert or you know, or decide to go to a holiday somewhere, you know, either locally or internationally. I don't think there is one and I think this is again with the idiocy <mark>of</mark> thinking monetary policy can solve it kicks in if everyone is going to retrench and everyone I speak to in every country now around the world is starting to retrench to some degree. They've done their Panic shopping. and they're all keeping a wary eye out and at some point they're all going to go home and lock the door and you know go out a fraction <mark>of</mark> what they normally do and the blowback <mark>of</mark> that to the real economy is going to be enormous absolutely enormous and on top <mark>of</mark> the financial system that's already leveraged and price for Perfection suddenly seeing actual physical cash flows as well as physical Supply chains both massively impacted, you know, I wonder what we can possibly do monetary policy has been Kick the Can down the road you'll have to have Banks saying to companies and individuals don't worry. Your debt is not a problem. You don't have to pay your mortgage this month, you know until the virus goes away. There's no mortgage payments. There's no credit card repayments. There's no business loan repayments, etc. Etc.", "Start Time (s)": 1543.4, "End Time (s)": 1663.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "now around the world is starting to retrench to some degree. They've done their Panic shopping. and they're all keeping a wary eye out and at some point they're all going to go home and lock the door and you know go out a fraction <mark>of</mark> what they normally do and the blowback <mark>of</mark> that to the real economy is going to be enormous absolutely enormous and on top <mark>of</mark> the financial system that's already leveraged and price for Perfection suddenly seeing actual physical cash flows as well as physical Supply chains both massively impacted, you know, I wonder what we can possibly do monetary policy has been Kick the Can down the road you'll have to have Banks saying to companies and individuals don't worry. Your debt is not a problem. You don't have to pay your mortgage this month, you know until the virus goes away. There's no mortgage payments. There's no credit card repayments. There's no business loan repayments, etc. Etc. Well that's going to hit Bank earnings. Someone's gonna have to make the bank's good. So that's going to have to be the central bank. So maybe that's part <mark>of</mark> what we'll see today. Yeah, if people also need cash flow if a business or a house Sold islets old. Okay, you're not going to be earning anything for the next two months. You don't have to service your mortgage, but you've still got to live and you haven't got any savings. Where's the money going to come from? So presumably there's going to have to be a blank check to at least keep everything ticking over that's a very big bailout, you know top style for every girl's going to so kind <mark>of</mark> a tarp 2.0 or something like that. Yeah, but this time it's not going to Banks not directly. I mean, it's maybe it's going to have to go to them partly, but it's going to have to go to the real economy to So even when you recover imagine, you're you know, Joe bloggs with Acme company doing x y z you're going to have to massively increase your leverage just to get through this on the longer. It lasts the worse it will get and when we finally emerge. Yeah, they'll be a little bit <mark>of</mark> a pickup at everyone's happy and they go out on the streets. Again. We know whatever that is, but a particularly the services sector you're not going to get an extra surge <mark>of</mark> spending to", "Start Time (s)": 1609.1, "End Time (s)": 1728.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "There's no business loan repayments, etc. Etc. Well that's going to hit Bank earnings. Someone's gonna have to make the bank's good. So that's going to have to be the central bank. So maybe that's part <mark>of</mark> what we'll see today. Yeah, if people also need cash flow if a business or a house Sold islets old. Okay, you're not going to be earning anything for the next two months. You don't have to service your mortgage, but you've still got to live and you haven't got any savings. Where's the money going to come from? So presumably there's going to have to be a blank check to at least keep everything ticking over that's a very big bailout, you know top style for every girl's going to so kind <mark>of</mark> a tarp 2.0 or something like that. Yeah, but this time it's not going to Banks not directly. I mean, it's maybe it's going to have to go to them partly, but it's going to have to go to the real economy to So even when you recover imagine, you're you know, Joe bloggs with Acme company doing x y z you're going to have to massively increase your leverage just to get through this on the longer. It lasts the worse it will get and when we finally emerge. Yeah, they'll be a little bit <mark>of</mark> a pickup at everyone's happy and they go out on the streets. Again. We know whatever that is, but a particularly the services sector you're not going to get an extra surge <mark>of</mark> spending to compensate for what you missed. People are not going to get two haircuts to compensate for the haircut appointment. They missed so your revenue is going to go back to where it was previously, but you're much more highly geared. So you tell me how we get out <mark>of</mark> that. Yeah, that makes a lot <mark>of</mark> sense. I know we've seen certain stocks Zoom comes to mind the recent IPO the video conferencing company, you know, they've got no pop obviously Costco there certain, you know as stocks people are looking at and most <mark>of</mark> them have already been bit up a little bit as far as for people staying home and which areas are going to benefit but I think like as you mentioned you could see in the in the short term and even to the to the Longer-term going out who knows how long as you mentioned a huge hit to the economies", "Start Time (s)": 1661.2, "End Time (s)": 1780.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to compensate for what you missed. People are not going to get two haircuts to compensate for the haircut appointment. They missed so your revenue is going to go back to where it was previously, but you're much more highly geared. So you tell me how we get out <mark>of</mark> that. Yeah, that makes a lot <mark>of</mark> sense. I know we've seen certain stocks Zoom comes to mind the recent IPO the video conferencing company, you know, they've got no pop obviously Costco there certain, you know as stocks people are looking at and most <mark>of</mark> them have already been bit up a little bit as far as for people staying home and which areas are going to benefit but I think like as you mentioned you could see in the in the short term and even to the to the Longer-term going out who knows how long as you mentioned a huge hit to the economies for stadiums concerts. I mean just retail stores could be everything and then you brought up the supply chain issue. And when you look at most <mark>of</mark> most things coming from China, whether it's medicines and ingredients in medicine and then you know, when you look at a car 80 or 90 percent <mark>of</mark> the parts are made in China, so, you know, obviously in I could take months or even I don't know maybe even maybe even a year or two or longer to get those type <mark>of</mark> things up and running as far as factories and being able to produce those parts kind <mark>of</mark> that D globalization piece what it could do and obviously the uncertainty is something Market should be pricing for rather than the certainty That central banks are going to save them somehow, but it's a very fast-moving scenario. no one knows exactly which way it's going to go but one thing you can see I spoke early on about this being an accelerant and I'm now seeing more and more commentators saying yeah, this is an accelerant 2D globalization look we agree but we've been arguing that for", "Start Time (s)": 1728.8, "End Time (s)": 1848.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I don't know maybe even maybe even a year or two or longer to get those type <mark>of</mark> things up and running as far as factories and being able to produce those parts kind <mark>of</mark> that D globalization piece what it could do and obviously the uncertainty is something Market should be pricing for rather than the certainty That central banks are going to save them somehow, but it's a very fast-moving scenario. no one knows exactly which way it's going to go but one thing you can see I spoke early on about this being an accelerant and I'm now seeing more and more commentators saying yeah, this is an accelerant 2D globalization look we agree but we've been arguing that for years for years and actually, you know pinpointing how you were going to get protectionism you are going to get trade Wars because yeah currency Wars then trade Wars and then, you know political pressure building up to something far nastier and that at some point you were going to To get some version <mark>of</mark> modern monetary Theory or you know hand holding between central banks and governments to try and jump start the economy and the question was whether it would be environmental or military that would prove to be you know, the green light for everyone to press ahead with this. Well, it looks like to be a virus instead but on the other side <mark>of</mark> it you only really have to to kind <mark>of</mark> polemic scenarios you head towards eventually in terms <mark>of</mark> where this can logically go you can Neither aim for your one world. We have a <mark>global</mark> economy where everyone works together centrally planning how to get out <mark>of</mark> this, you know United Nations IMF style model where China and the US are friends again <mark>Global</mark> Supply demand is rebalanced alongside, you know investments in antivirus technology, etc. Etc. You know, it's an idealized world and I like to think that is a Star Trek scenario, perhaps not this current iteration <mark>of</mark> Star Trek, which is a lot more gloomy and dystopian, ironically, but you know, A classic", "Start Time (s)": 1805.7, "End Time (s)": 1924.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "pressure building up to something far nastier and that at some point you were going to To get some version <mark>of</mark> modern monetary Theory or you know hand holding between central banks and governments to try and jump start the economy and the question was whether it would be environmental or military that would prove to be you know, the green light for everyone to press ahead with this. Well, it looks like to be a virus instead but on the other side <mark>of</mark> it you only really have to to kind <mark>of</mark> polemic scenarios you head towards eventually in terms <mark>of</mark> where this can logically go you can Neither aim for your one world. We have a <mark>global</mark> economy where everyone works together centrally planning how to get out <mark>of</mark> this, you know United Nations IMF style model where China and the US are friends again <mark>Global</mark> Supply demand is rebalanced alongside, you know investments in antivirus technology, etc. Etc. You know, it's an idealized world and I like to think that is a Star Trek scenario, perhaps not this current iteration <mark>of</mark> Star Trek, which is a lot more gloomy and dystopian, ironically, but you know, A classic 1960s 1980s Star Trek Gene roddenberry's Vision the future, but if you don't go that route, it's a very strong impetus to what you're already seeing which is you know, flood the moat raise the drawbridge make sure that my Central Bank provides liquidity for my people but none <mark>of</mark> that liquidity can be used to buy products from other people keep the money circulating at home to make sure we get out <mark>of</mark> it and don't let foreigners come in because they might be a bring you germs. Which is very very anti-globalization, but at the same time is eminently sensible to some extent when you see the shocks that an integrated <mark>Global</mark> Supply Chain a capable <mark>of</mark> inflicting. I mean, how long are we going to listen or how long do we have to listen before someone's actually says as a politician why the hell can't we as country X Y Zed make antivirus masks. Why are they all made in China? Why haven't got drugs?", "Start Time (s)": 1860.2, "End Time (s)": 1980.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know, A classic 1960s 1980s Star Trek Gene roddenberry's Vision the future, but if you don't go that route, it's a very strong impetus to what you're already seeing which is you know, flood the moat raise the drawbridge make sure that my Central Bank provides liquidity for my people but none <mark>of</mark> that liquidity can be used to buy products from other people keep the money circulating at home to make sure we get out <mark>of</mark> it and don't let foreigners come in because they might be a bring you germs. Which is very very anti-globalization, but at the same time is eminently sensible to some extent when you see the shocks that an integrated <mark>Global</mark> Supply Chain a capable <mark>of</mark> inflicting. I mean, how long are we going to listen or how long do we have to listen before someone's actually says as a politician why the hell can't we as country X Y Zed make antivirus masks. Why are they all made in China? Why haven't got drugs? Why haven't we got enough hospitals to treat people? Because <mark>of</mark> austerity because <mark>of</mark> you know, small government free trade political models, etc. Etc. So the blowback you can get to all <mark>of</mark> this could be just enormous. Yeah, and that's where I where I want to go last Lee's you know big theme on the podcast is this pull between inflation and deflation and kind <mark>of</mark> that central question. And as you mentioned you can look at Japan Equity Market peaked in 8990 never recovered. They've been doing Huey for much longer than the US and and when you will look around the world, we have these forces obviously people talk about them all the time the debt I'll fix deflation these in technology really pulling inflation down and then when you look on the other side this D globalization piece, if it does play out the way that you just talked about, you know, that could really lead to a lot <mark>of</mark> inflation or or", "Start Time (s)": 1923.6, "End Time (s)": 2043.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to treat people? Because <mark>of</mark> austerity because <mark>of</mark> you know, small government free trade political models, etc. Etc. So the blowback you can get to all <mark>of</mark> this could be just enormous. Yeah, and that's where I where I want to go last Lee's you know big theme on the podcast is this pull between inflation and deflation and kind <mark>of</mark> that central question. And as you mentioned you can look at Japan Equity Market peaked in 8990 never recovered. They've been doing Huey for much longer than the US and and when you will look around the world, we have these forces obviously people talk about them all the time the debt I'll fix deflation these in technology really pulling inflation down and then when you look on the other side this D globalization piece, if it does play out the way that you just talked about, you know, that could really lead to a lot <mark>of</mark> inflation or or maybe even I saw a scenario someone wrote up online where maybe the FED just comes in and cuts way too much and then it does the opposite effect where it just Sparks fears. You're in the market, which is people sell old. How could that happen? But maybe the FED loses control rates on the long end <mark>of</mark> the curve. How are you looking at that piece? Well, I think it's a key question. We have had inflation figures in some corners <mark>of</mark> the market for years and through all <mark>of</mark> them with continue to grind deeper and deeper into deflation that's on aggregate. <mark>Of</mark> course, you know prices are through the roof or at least inflation is through the roof or lots <mark>of</mark> things that I see daily, but that's because we don't measure inflation right at all. You know, I've Had issues over whether we should really be saying, you know that flat screen television that you're not buying overall means that inflation is absolutely going down whereas, you know, your food prices and your health care prices and your house prices are going through the roof. So I don't think we measure inflation completely wrong", "Start Time (s)": 1981.9, "End Time (s)": 2101.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "or or maybe even I saw a scenario someone wrote up online where maybe the FED just comes in and cuts way too much and then it does the opposite effect where it just Sparks fears. You're in the market, which is people sell old. How could that happen? But maybe the FED loses control rates on the long end <mark>of</mark> the curve. How are you looking at that piece? Well, I think it's a key question. We have had inflation figures in some corners <mark>of</mark> the market for years and through all <mark>of</mark> them with continue to grind deeper and deeper into deflation that's on aggregate. <mark>Of</mark> course, you know prices are through the roof or at least inflation is through the roof or lots <mark>of</mark> things that I see daily, but that's because we don't measure inflation right at all. You know, I've Had issues over whether we should really be saying, you know that flat screen television that you're not buying overall means that inflation is absolutely going down whereas, you know, your food prices and your health care prices and your house prices are going through the roof. So I don't think we measure inflation completely wrong because <mark>of</mark> you know, idiotic intellectual fallacies like hedonic regression and you know Swift is switching from the from steak the chicken for example presuming less or Be happening. And that means therefore there is an inflation. So right let's take that as a base case. First <mark>of</mark> all before we move any further forward, but with that criticism in place, what will already going to see during this crisis is an extension <mark>of</mark> what we do think which is rampant inflation in some areas and deflation in others. So you'll have a very very depressing effect because demand is going to go off the cliff and good luck raising your prices, you know when through no one's coming out two shots funny throat, but equally good Not raising your prices when you can't get hold <mark>of</mark> a certain component for love nor money, you know that so you're going to have potentially sharply polemic <mark>effects</mark> on inflation with massive inflation is some areas and massive deflation and others and on aggregate, you know, again economists being useful idiots would turn around and say oh well, therefore there isn't any", "Start Time (s)": 2042.3, "End Time (s)": 2161.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "whereas, you know, your food prices and your health care prices and your house prices are going through the roof. So I don't think we measure inflation completely wrong because <mark>of</mark> you know, idiotic intellectual fallacies like hedonic regression and you know Swift is switching from the from steak the chicken for example presuming less or Be happening. And that means therefore there is an inflation. So right let's take that as a base case. First <mark>of</mark> all before we move any further forward, but with that criticism in place, what will already going to see during this crisis is an extension <mark>of</mark> what we do think which is rampant inflation in some areas and deflation in others. So you'll have a very very depressing effect because demand is going to go off the cliff and good luck raising your prices, you know when through no one's coming out two shots funny throat, but equally good Not raising your prices when you can't get hold <mark>of</mark> a certain component for love nor money, you know that so you're going to have potentially sharply polemic <mark>effects</mark> on inflation with massive inflation is some areas and massive deflation and others and on aggregate, you know, again economists being useful idiots would turn around and say oh well, therefore there isn't any inflation or deflation is 2% because it's minus 20 and some areas and you know plus 20 and others therefore, it's flat overall. Yeah, good luck. Trying to actually manage an economy on that basis, right? It doesn't actually tell you at all what's actually going Hang on but more thematically. I said earlier that you know, your ideal scenario globally is your Star Trek one, which I don't actually think is realistic politically. Your alternative is your Star Wars scenario where you do have a US versus them first order versus resistance kind <mark>of</mark> political feeling or headwind to everything that happens. And on that basis, is it inflationary? Well, yes, but it depends on who's running the global. Station because then you get a d globalization. That's genuinely genuinely for the working class so that you are bringing", "Start Time (s)": 2092.7, "End Time (s)": 2212.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "globally is your Star Trek one, which I don't actually think is realistic politically. Your alternative is your Star Wars scenario where you do have a US versus them first order versus resistance kind <mark>of</mark> political feeling or headwind to everything that happens. And on that basis, is it inflationary? Well, yes, but it depends on who's running the global. Station because then you get a d globalization. That's genuinely genuinely for the working class so that you are bringing jobs back home. You are ensuring that you know, you don't have low-cost workers coming in to suppress wages. You are forcing firms to invest more one way or another the government is filling that Gap. If not and employing people that are very high salary to Benchmark salaries higher. If you do all these things alongside industrial policy. Which is effectively what China has been doing for years then yeah, you're going to get wage inflation and overall you'd imagine you'll get a healthy level <mark>of</mark> inflation. And <mark>of</mark> course they can smack assets. If you're looking at it from a financial Market point <mark>of</mark> view, but it was smack some assets. Mainly those that have been built our be no by the idle Rich rather than the you know, the average working Joe who actually have more money in his pocket. So you'll get winners and losers and redistribution within the economy. That's if you get a certain kind <mark>of</mark> D globalization If you get actually another kind <mark>of</mark> the globalization, which is excuse me, after versus them finger-pointing angry populism run by local oligarchs within each country rather than and pretending to be for the worker but actually being for the oligarch, where's the workers still get the crumbs? I'm not going to go into too much detail detail on that. But I think you can understand the kind <mark>of</mark> picture. I'm painting then all you do is instead <mark>of</mark> substituting your <mark>Global</mark> oligarch. So the ones who are worth tens <mark>of</mark> Ian's <mark>of</mark> dollars because <mark>of</mark> the <mark>global</mark> reach <mark>of</mark> their company, you'll have a statute them for local robber barons within each particular country who are then worth maybe", "Start Time (s)": 2180.6, "End Time (s)": 2300.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "things alongside industrial policy. Which is effectively what China has been doing for years then yeah, you're going to get wage inflation and overall you'd imagine you'll get a healthy level <mark>of</mark> inflation. And <mark>of</mark> course they can smack assets. If you're looking at it from a financial Market point <mark>of</mark> view, but it was smack some assets. Mainly those that have been built our be no by the idle Rich rather than the you know, the average working Joe who actually have more money in his pocket. So you'll get winners and losers and redistribution within the economy. That's if you get a certain kind <mark>of</mark> D globalization If you get actually another kind <mark>of</mark> the globalization, which is excuse me, after versus them finger-pointing angry populism run by local oligarchs within each country rather than and pretending to be for the worker but actually being for the oligarch, where's the workers still get the crumbs? I'm not going to go into too much detail detail on that. But I think you can understand the kind <mark>of</mark> picture. I'm painting then all you do is instead <mark>of</mark> substituting your <mark>Global</mark> oligarch. So the ones who are worth tens <mark>of</mark> Ian's <mark>of</mark> dollars because <mark>of</mark> the <mark>global</mark> reach <mark>of</mark> their company, you'll have a statute them for local robber barons within each particular country who are then worth maybe just, you know, three or four billion just seen a chicken feed like that and you still won't end up with the workers actually getting a great deal. Yeah, you'll just end up having fingers pointed at you know, either other ethnic groups other religious groups are other countries as the reason why people start aren't doing any better and we've certainly seen that from history. So I'm not saying that anyone leader. We're falls into either <mark>of</mark> those two categories. I'm talking in general General memes here or general archetypes and it's up to listeners to decide who they see doing what and that you can make a very strong case in all different directions over who is or isn't doing what but it shows you that it's more complicated than people think the globalization doesn't necessarily mean, you know inflation. It doesn't it can do but it doesn't have to be Yeah makes a lot <mark>of</mark> sense and lastly kind <mark>of</mark>", "Start Time (s)": 2230.9, "End Time (s)": 2350.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "oligarch. So the ones who are worth tens <mark>of</mark> Ian's <mark>of</mark> dollars because <mark>of</mark> the <mark>global</mark> reach <mark>of</mark> their company, you'll have a statute them for local robber barons within each particular country who are then worth maybe just, you know, three or four billion just seen a chicken feed like that and you still won't end up with the workers actually getting a great deal. Yeah, you'll just end up having fingers pointed at you know, either other ethnic groups other religious groups are other countries as the reason why people start aren't doing any better and we've certainly seen that from history. So I'm not saying that anyone leader. We're falls into either <mark>of</mark> those two categories. I'm talking in general General memes here or general archetypes and it's up to listeners to decide who they see doing what and that you can make a very strong case in all different directions over who is or isn't doing what but it shows you that it's more complicated than people think the globalization doesn't necessarily mean, you know inflation. It doesn't it can do but it doesn't have to be Yeah makes a lot <mark>of</mark> sense and lastly kind <mark>of</mark> wrapping up. When you look at our set prices obviously risk assets being equities being priced where they are and when you look at the Loft evaluations now taking the other side <mark>of</mark> that as far as looking at Safe Haven half assets or where to hide. Obviously we saw gold sell-off pretty sharply. It's been a wild ride. It was up. It was down. I know it recovered a little bit today, but similar to 2008 A lot <mark>of</mark> people were selling gold to cover margin positions and basically freeing up cash in that kind <mark>of</mark> sense. And when you look at you know to 2008 we had this correlation to one <mark>of</mark> risk assets where everything was down even gold except for long-term treasuries, and now obviously but treasuries were they are move this after this 30-year Bond bull market or Thirty five-year Bond bull market seemingly. Be coming to an end at some", "Start Time (s)": 2289.2, "End Time (s)": 2408.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "after this 30-year Bond bull market or Thirty five-year Bond bull market seemingly. Be coming to an end at some point maybe like you said if rates go negative, you know how L far- could they go right? But how do you see that piece as far as maybe cash just gives you optionality there. But do you have any thought General thoughts on that? Not not really specific but more General General thoughts on that. I mean, obviously when you're talking about this topic and when you're bringing in Gold, you're talking about Paradigm shifts, I think yeah, I think rather than You know momentum trading or technical trading or even fundamentals trading you're talking Paradigm attic shifts and clearly our entire Paradigm is under threat. I think I've underlined why that is the case and you only have to open your eyes and look around you and you can see that everything is changing now. Does that make me a gold bug will the answer is no and for a couple <mark>of</mark> reasons, I mean number one on specifically the gold front look at your history whenever things get to the point where gold could actually be useful they ban it. Yeah and the same with cryptocurrencies you can argue that they're the new version <mark>of</mark> gold. First <mark>of</mark> all, they're not because you can keep creating new ones, you know makes me like this like this is gold. This is smelled this is bowls. So this is growth, you know, they're all gonna know they're not the fact that you're just able to make up a new one shows you that they're not but but equally no one's actually really using them. Everyone's hoarding them. So they don't have any function as a currency and the same is true for gold. You're not actually using it when you can use it. He pay you sovereign debt or international trading then it might really have some functionality. But unfortunately the powers that be the ones with the taxation powers and with all the military powers and with all the jails. They're the ones who get to set what you do or don't do international trade in for now, you know as as Joe bloggs, you can say right I'll pay for my widgets from China if I can get them in gold and good luck with that. You know, I", "Start Time (s)": 2400.9, "End Time (s)": 2520.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>of</mark> all, they're not because you can keep creating new ones, you know makes me like this like this is gold. This is smelled this is bowls. So this is growth, you know, they're all gonna know they're not the fact that you're just able to make up a new one shows you that they're not but but equally no one's actually really using them. Everyone's hoarding them. So they don't have any function as a currency and the same is true for gold. You're not actually using it when you can use it. He pay you sovereign debt or international trading then it might really have some functionality. But unfortunately the powers that be the ones with the taxation powers and with all the military powers and with all the jails. They're the ones who get to set what you do or don't do international trade in for now, you know as as Joe bloggs, you can say right I'll pay for my widgets from China if I can get them in gold and good luck with that. You know, I it's far more difficult than you think to set up your own International payment system particularly a very physically heavy currency, so So I don't buy into that even though I understand the impetus to look for something new when the old is collapsing but in terms <mark>of</mark> what you're going to see with cash and with them with long bonds, etc, etc. I think the logical endpoint again and I like to try and understand the Paradigm <mark>of</mark> push it to its extreme to scenario test is that yeah yields will do what they do in Japan where they go negative which point the you know, the bull market has further to run obviously you can still make money even with negative rates provided you say Somebody else who's going to buy them at even more negative rates, but at some point you do here a floor whether it's minus 0.5 minus one wherever where people say, I'm actually losing so much money with these I'm just not going to hold them anymore. I'd rather just have cash which obviously has no yields at all. And then the last person holding that Bond obviously carries the care that he's guaranteed to make a huge loss. So it's a greater fall trade which can continue for quite some time. But while that's continuing to the downside on the yield obviously as we saw, you know, Today in u.s. Time with the equity Market reacting despite fundamentals stinking and the real economy and you'll see equities", "Start Time (s)": 2474.8, "End Time (s)": 2594.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "downside on the yield obviously as we saw, you know, Today in u.s. Time with the equity Market reacting despite fundamentals stinking and the real economy and you'll see equities mathematically go up as a bond deals go down until you again get to a ludicrous level where actually there's no rope no relation to reality whatsoever. And then when the bond yield hits its absolute floor equities will hit their absolute ceiling at the same time. So you'll have an equity price which is through the ceiling and has actually no connection to reality at all. And the last person holding it. He's holding a dud. And you have a bond yield which is through the floor and then no connection to reality and the last person to buy it is again holding a dad which point then we're in a real mess. Then we really have nowhere else left to go and then other questions about what we do next will start to resurface but as I said gold and Bitcoin sadly, I don't think I'll going to be the solutions that people think they're going to be in less governments get on board with them and I don't think they will. Yeah, I think it makes a lot <mark>of</mark> sense. I read some interesting research talking about Out when the market does finally come to an area where it's somewhat priced appropriately pop. I'll put it that way then in the future at least dividend Pairs and obviously value is under performed by companies throwing off cash companies paying the dividend. Those are going to be the ones that you're going to want to hold, you know going forward because at least it's something that you get paid to own instead <mark>of</mark> just looking for that appreciation. So I thought that was kind <mark>of</mark> interesting. It's very true and effectively stocks become like bonds. You're no longer buying them for the appreciation. You're buying it just for the income stream. Yeah, which is not going to be very high. Yeah, and ironically bonds become like stocks because you're only buying them for the underlying value appreciation selling it to somebody else. We've been in that scenario for a while, but obviously this this is going to accelerate it to its terminal point quite rapidly. <mark>Of</mark> course, that's presuming that you do still have a company that can play out solid", "Start Time (s)": 2583.8, "End Time (s)": 2703.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and I don't think they will. Yeah, I think it makes a lot <mark>of</mark> sense. I read some interesting research talking about Out when the market does finally come to an area where it's somewhat priced appropriately pop. I'll put it that way then in the future at least dividend Pairs and obviously value is under performed by companies throwing off cash companies paying the dividend. Those are going to be the ones that you're going to want to hold, you know going forward because at least it's something that you get paid to own instead <mark>of</mark> just looking for that appreciation. So I thought that was kind <mark>of</mark> interesting. It's very true and effectively stocks become like bonds. You're no longer buying them for the appreciation. You're buying it just for the income stream. Yeah, which is not going to be very high. Yeah, and ironically bonds become like stocks because you're only buying them for the underlying value appreciation selling it to somebody else. We've been in that scenario for a while, but obviously this this is going to accelerate it to its terminal point quite rapidly. <mark>Of</mark> course, that's presuming that you do still have a company that can play out solid dividends and that depends what the structure <mark>of</mark> the <mark>global</mark> economy looks. Like and the other problem is that if we get the G7 on Super Trouper Tuesday starting to say okay central banks and governments are going to hold hands and work together to get this get us through this you are going down the other path that gold bugs love to talk about which is you know, the corruption <mark>of</mark> not just understanding where pricing should be and then the price discovering mechanism, but actually free markets at all <mark>of</mark> any kind. If you're going to start getting the state that involved in the economy to save us all from the virus. How does it do? Tangle itself in the future which point you know, you can end up in a very very Chinese looking economy faster than people think and the one thing I can tell you after looking at Chinese French got financial markets is that nothing means anything, you know black can be white. Why can be black Up Is Down Down is up and you know people chase rumors and suspicions and guesses <mark>of</mark> what they think policymakers in Beijing are going to be", "Start Time (s)": 2641.0, "End Time (s)": 2760.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it to its terminal point quite rapidly. <mark>Of</mark> course, that's presuming that you do still have a company that can play out solid dividends and that depends what the structure <mark>of</mark> the <mark>global</mark> economy looks. Like and the other problem is that if we get the G7 on Super Trouper Tuesday starting to say okay central banks and governments are going to hold hands and work together to get this get us through this you are going down the other path that gold bugs love to talk about which is you know, the corruption <mark>of</mark> not just understanding where pricing should be and then the price discovering mechanism, but actually free markets at all <mark>of</mark> any kind. If you're going to start getting the state that involved in the economy to save us all from the virus. How does it do? Tangle itself in the future which point you know, you can end up in a very very Chinese looking economy faster than people think and the one thing I can tell you after looking at Chinese French got financial markets is that nothing means anything, you know black can be white. Why can be black Up Is Down Down is up and you know people chase rumors and suspicions and guesses <mark>of</mark> what they think policymakers in Beijing are going to be doing to determine where they think value lies rather than ever actually looking at the balance sheet <mark>of</mark> the company involved. Well, you know, that could be our Brave New World, yeah. Yeah, bring that brings up another good point. Well Michael, this was great really appreciate having you on we're going to be looking forward to tomorrow and see what happens. I'm going to link your recent articles in the show notes and link your bio, but you want to you tell listeners where they can find you and follow follow more your work. Well, obviously for those who are rather Bank customers my work should hopefully Be coming to you and your inbox or already and if you're not one <mark>of</mark> our clients then occasionally or fairly regularly at the moment, you can see some <mark>of</mark> my daily notes on Zero Hedge obviously not on Twitter that's only can bone <mark>of</mark> contention for the for the guys who run zero correctly, but on the website from time", "Start Time (s)": 2697.6, "End Time (s)": 2817.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "markets is that nothing means anything, you know black can be white. Why can be black Up Is Down Down is up and you know people chase rumors and suspicions and guesses <mark>of</mark> what they think policymakers in Beijing are going to be doing to determine where they think value lies rather than ever actually looking at the balance sheet <mark>of</mark> the company involved. Well, you know, that could be our Brave New World, yeah. Yeah, bring that brings up another good point. Well Michael, this was great really appreciate having you on we're going to be looking forward to tomorrow and see what happens. I'm going to link your recent articles in the show notes and link your bio, but you want to you tell listeners where they can find you and follow follow more your work. Well, obviously for those who are rather Bank customers my work should hopefully Be coming to you and your inbox or already and if you're not one <mark>of</mark> our clients then occasionally or fairly regularly at the moment, you can see some <mark>of</mark> my daily notes on Zero Hedge obviously not on Twitter that's only can bone <mark>of</mark> contention for the for the guys who run zero correctly, but on the website from time to time you will see them. So if you if you find any <mark>of</mark> this <mark>of</mark> interest, please have a look there great Michael really appreciate it and thanks a lot. Thank you. Have a great day and enjoy Super Trooper Tuesday. Take care. Bye bye. Thanks for joining us today. If you enjoyed the show, we encourage you to tell a friend. You can also support the show for as little as a dollar a month through our anchor. Website just go to www.google.com", "Start Time (s)": 2747.7, "End Time (s)": 2866.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Take care. Bye bye. Thanks for joining us today. If you enjoyed the show, we encourage you to tell a friend. You can also support the show for as little as a dollar a month through our anchor. Website just go to www.google.com podcast.com. If you have feedback find us on Twitter at jelly donut pod, or you can contact us via email at jelly donut podcast at proton mail.com as a reminder all opinions expressed by gas or solely their own and do not reflect the views <mark>of</mark> their employer or any other affiliate identity. This podcast is for informational purposes only and should not be used as a basis for investment decisions or advice.", "Start Time (s)": 2830.3, "End Time (s)": 2900.1, "Clip Length (min)": 1.16, "show_uri": "spotify:show:0b6SSyIXREfabwE0wZShmb", "show_name": "Jelly Donut Podcast", "show_description": "Making finance and economics fun, one episode at a time  Support this podcast: https://anchor.fm/jellydonutpodcast/support", "publisher": "Ryan", "episode_uri": "spotify:episode:19UIiUCEcxaKlJN9Ze4BMq", "episode_name": "Jelly Donut Podcast #19 - Michael Every", "episode_description": "Jelly Donut Podcast #19 was recorded on Monday March 2, 2020 Michael Every is Head of Financial Markets Research, for the Asia-Pacific region, at Rabobank. He has nearly two decades of experience working as an Economist and Strategist. Previously, he was a Senior Economist and Fixed Income Strategist at RBS and was an Economist for Dun & Bradstreet. He holds a Masters degree in Economics with distinction from University College London, speaks Thai, and is a contributor to zero hedge. https://economics.rabobank.com/authors/michael-every/ https://www.zerohedge.com/markets/rabobank-epoch-marking-sub-1-yield-imminent https://www.zerohedge.com/markets/rabobank-what-level-interest-rates-will-incentivize-you-risk-death-yourself-and-your-family https://coavacoffee.com/ (Use CODE JDP10) https://www.baronfig.com/ (Use Code JDP10)  ---   Support this podcast: https://anchor.fm/jellydonutpodcast/support", "score": 6.60216, "explanation": "{\n  \"value\": 6.60216,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.3114285,\n      \"description\": \"weight(word_list:effects in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3114285,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.12997343,\n      \"description\": \"weight(word_list:of in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.12997343,\n          \"description\": \"score(LMDirichletSimilarity, freq=171.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7607814,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 171.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.160758,\n      \"description\": \"weight(word_list:global in 440) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.160758,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.7915664,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.630808,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 8216.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "You are listening to Episode 22 <mark>of</mark> these simple Farmhouse Life podcast today. I'm going to be bringing on a friend <mark>of</mark> mine this woman and I met let's see here probably close to or right at ten years ago. It's hard to believe that now we always shared interest in all things Natural Health. All <mark>of</mark> that kind <mark>of</mark> thing usually is what we would talk about when we get together. She's since moved away and We've just kind <mark>of</mark> we haven't chatted in a while, but it was really great to record this episode. She has spent the last several years studying herbs. Actually, she was already pretty into it whenever I met her and she has spent all these years doing that. So she's going to share some <mark>of</mark> her knowledge <mark>of</mark> herbs and we had a really good discussion. I have to apologize that I have not figured out yet, which I need to do before I do this again how to get the audio really crisp and clear when having a guest on Know how to do it with my own little microphone in my own little", "Start Time (s)": 0.2, "End Time (s)": 62.3, "Clip Length (min)": 1.03, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "hard to believe that now we always shared interest in all things Natural Health. All <mark>of</mark> that kind <mark>of</mark> thing usually is what we would talk about when we get together. She's since moved away and We've just kind <mark>of</mark> we haven't chatted in a while, but it was really great to record this episode. She has spent the last several years studying herbs. Actually, she was already pretty into it whenever I met her and she has spent all these years doing that. So she's going to share some <mark>of</mark> her knowledge <mark>of</mark> herbs and we had a really good discussion. I have to apologize that I have not figured out yet, which I need to do before I do this again how to get the audio really crisp and clear when having a guest on Know how to do it with my own little microphone in my own little studio if you will, but I will apologize but I didn't want to scrap the interview. So the audio isn't the best but I still think there's some value in the discussion. So I'm going to post it because we cover a lot <mark>of</mark> topics and go into some things that I learned quite a bit as well. So let's jump into the episode. So I am here with my friend Jen. Person have you told a little bit about yourself and your credentials and how you've been studying herbalism. And then I'm going to talk about how we met because that's fine. Sure. Sure. So I started really getting into things all the way back when are was having all her issues with like food intolerance and we were trying to figure out what was going on with your stomach issues and getting to the root <mark>of</mark> eliminating certain foods. And I think that's kind <mark>of</mark> a natural progression. A lot <mark>of</mark> people take is they Started looking at what they're eating and then our interest when they are just kind <mark>of</mark> grows in natural medicine or natural ways <mark>of</mark> doing things. So that's kind <mark>of</mark> what at my interest was piqued and using herbs that we were growing outside. And so I started studying with the absolute", "Start Time (s)": 16.1, "End Time (s)": 135.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "with my friend Jen. Person have you told a little bit about yourself and your credentials and how you've been studying herbalism. And then I'm going to talk about how we met because that's fine. Sure. Sure. So I started really getting into things all the way back when are was having all her issues with like food intolerance and we were trying to figure out what was going on with your stomach issues and getting to the root <mark>of</mark> eliminating certain foods. And I think that's kind <mark>of</mark> a natural progression. A lot <mark>of</mark> people take is they Started looking at what they're eating and then our interest when they are just kind <mark>of</mark> grows in natural medicine or natural ways <mark>of</mark> doing things. So that's kind <mark>of</mark> what at my interest was piqued and using herbs that we were growing outside. And so I started studying with the absolute Institute, which is also called The First Institute or vepar th and I did my certification <mark>of</mark> Masters and herbalism through them. And that was back in 2014. And then from there I've worked with several Farms growing herbs and tea Farm moved out here and have a flower and teeth bar T company and I decided really what I love the most about doing that is working with my customers on a special glass or customizing things for their unique body type. Or what they're specifically looking for. So I went back to get more certification to be able to do clinical practice, which is something that I had done like herbal consultations and the United States is really kind <mark>of</mark> confusing as far as what certifications you need because there aren't any official certifying boards for our herbalism in the United States. So so", "Start Time (s)": 84.4, "End Time (s)": 203.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "through them. And that was back in 2014. And then from there I've worked with several Farms growing herbs and tea Farm moved out here and have a flower and teeth bar T company and I decided really what I love the most about doing that is working with my customers on a special glass or customizing things for their unique body type. Or what they're specifically looking for. So I went back to get more certification to be able to do clinical practice, which is something that I had done like herbal consultations and the United States is really kind <mark>of</mark> confusing as far as what certifications you need because there aren't any official certifying boards for our herbalism in the United States. So so you kind <mark>of</mark> have to just East You know the people who come to you need to kind <mark>of</mark> be aware <mark>of</mark> what different credentials mean. They just have to watch your language and what you're able to say or do so with the new certification that I'm finishing up. It will allow me to do clinical practice. It's a vitalist herbalist practitioners certification. So being able to work more one-on-one with people and doing herbal consultations. And so yeah, that's Kind <mark>of</mark> kind <mark>of</mark> the quick Reader's Digest version <mark>of</mark> what I've done since 2014. Okay. Yeah and you have tell us about your website because you sell tea Blends like you mentioned now, do you you do sell them direct to Consumer as well? Right? Yes. Yes. Okay, so I do I have my", "Start Time (s)": 145.8, "End Time (s)": 265.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "chai all we're at the park and she. Showing what all the different herbs were just that were just at the park. And yeah, we learned that plantain was good for bee stings and poison. Ivy, right? Yeah. Well, and now she's probably a teenager something but at the time she was like 5 so my goodness, <mark>of</mark> course she does. That's great. So I'm going to briefly share how I met Jen and then and then I'm going to go into a few things that you guys might be interested in as far as health concerns. And some <mark>of</mark> our own personal stories as moms and Howard's have helped. So I'm at generally randomly whenever I don't know if a lot <mark>of</mark> my readers or listeners know this but I used to have a website selling cloth diapers. So I was a retailer for cloth diapers and I was at a Baby Expo and Jenna was there. I think you were super pregnant with her second child. Yes. Yes, and you are maybe a little bit interested in cloth diapers, and then I ran into her in my town and I was like wait, you're the girl that I saw at the Expo. So yeah, we met very randomly, even though that wasn't in the same town, but then we turned it turned out. We live like a couple miles apart. So now we don't now we live hours apart, but We still", "Start Time (s)": 359.2, "End Time (s)": 464.8, "Clip Length (min)": 1.76, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "interested in as far as health concerns. And some <mark>of</mark> our own personal stories as moms and Howard's have helped. So I'm at generally randomly whenever I don't know if a lot <mark>of</mark> my readers or listeners know this but I used to have a website selling cloth diapers. So I was a retailer for cloth diapers and I was at a Baby Expo and Jenna was there. I think you were super pregnant with her second child. Yes. Yes, and you are maybe a little bit interested in cloth diapers, and then I ran into her in my town and I was like wait, you're the girl that I saw at the Expo. So yeah, we met very randomly, even though that wasn't in the same town, but then we turned it turned out. We live like a couple miles apart. So now we don't now we live hours apart, but We still shared interest in herbs and all things natural. So yes, yes. And you you briefly mentioned but a lot <mark>of</mark> people don't know about this but that your daughter had some Digestive and different food intolerance issues. And that's what got you into this. Do you want to share a little bit more about that? Sure. Well, we noticed that she had a lot <mark>of</mark> Xmas. So that was one thing that would flare up and we couldn't quite pinpoint what was causing that but she also is having pretty severe digestive issues. She would be chronically constipated to the point that she would like, you know claw the floor in pain. She would have so much pain from constipation. And so we went to frequently have to take her to the hospital have Animas like it was really really severe constipation and I just thought after the second time <mark>of</mark> taking this little like four year old kid who doesn't understand what's going on. To the hospital and having them", "Start Time (s)": 413.5, "End Time (s)": 533.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in herbs and all things natural. So yes, yes. And you you briefly mentioned but a lot <mark>of</mark> people don't know about this but that your daughter had some Digestive and different food intolerance issues. And that's what got you into this. Do you want to share a little bit more about that? Sure. Well, we noticed that she had a lot <mark>of</mark> Xmas. So that was one thing that would flare up and we couldn't quite pinpoint what was causing that but she also is having pretty severe digestive issues. She would be chronically constipated to the point that she would like, you know claw the floor in pain. She would have so much pain from constipation. And so we went to frequently have to take her to the hospital have Animas like it was really really severe constipation and I just thought after the second time <mark>of</mark> taking this little like four year old kid who doesn't understand what's going on. To the hospital and having them pin her down and give her an enema that there had to be a better way. Yeah, I'm will help us invasive and just better overall for her and room for everyone involved. We're trying all <mark>of</mark> these things that people told us, you know, we relaxed and foods and we just find ourselves in the same spot like it would clear up for a while and then build up and be a big issue again. And so we started with the Almond milk and eggs, and then eventually we're able to add back in eggs, but", "Start Time (s)": 465.9, "End Time (s)": 585.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "We're trying all <mark>of</mark> these things that people told us, you know, we relaxed and foods and we just find ourselves in the same spot like it would clear up for a while and then build up and be a big issue again. And so we started with the Almond milk and eggs, and then eventually we're able to add back in eggs, but she's been gluten and Melba free since I think she's about four or five. So it's been almost 10 years now and she has no stomach issues whatsoever anymore. She's the really, you know, healthy 13 year olds that I'm glad we finally found some routes for what was going on and excellent way to because great. I just think you maybe it was berries. Once we took those two goods out that cleared up as well. How did you use herbs to support or how did that get you into the herbalism? I know that helped you to just figure out the root cause <mark>of</mark> her issues that you you know weren't just I know you talked a little bit about treating symptoms and a lot <mark>of</mark> times moms go straight for the symptom and I guess in this case the symptom that you were treating would have been going and getting the enemas instead <mark>of</mark> figuring out. Okay? Why is she not actually? Yeah. Continued to every time she had a flair <mark>of</mark> treat the flare up, but it would have kept him going back because until we figured out what was setting it off in the first place, you know, but it never fully resolved. And and when you have an issue like that your nutrition is going to be affected the nutrients you're absorbing or is going to be affected. And so then it's gonna throw up other things too. You know how that continue to build it. Could become a much a much bigger issue than it ended up being because we finally figured out what was causing it the first place. I think that's why I was always kind <mark>of</mark> attracted to natural medicine. It is just I never was fully", "Start Time (s)": 561.6, "End Time (s)": 679.1, "Clip Length (min)": 1.96, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "get you into the herbalism? I know that helped you to just figure out the root cause <mark>of</mark> her issues that you you know weren't just I know you talked a little bit about treating symptoms and a lot <mark>of</mark> times moms go straight for the symptom and I guess in this case the symptom that you were treating would have been going and getting the enemas instead <mark>of</mark> figuring out. Okay? Why is she not actually? Yeah. Continued to every time she had a flair <mark>of</mark> treat the flare up, but it would have kept him going back because until we figured out what was setting it off in the first place, you know, but it never fully resolved. And and when you have an issue like that your nutrition is going to be affected the nutrients you're absorbing or is going to be affected. And so then it's gonna throw up other things too. You know how that continue to build it. Could become a much a much bigger issue than it ended up being because we finally figured out what was causing it the first place. I think that's why I was always kind <mark>of</mark> attracted to natural medicine. It is just I never was fully I was never fully convinced when we would go to the doctor for something that you know, okay, you're experiencing this. Here's a pill it'll get better. I just for whatever reason that never sat. Well with me I just wanted to know okay, but why lie Is it happening? And and that was what really drew me I think to natural medicine which has been filtered into herbal medicine, but just that practice <mark>of</mark> figuring out but wait, let's look at the whole body and figure out what's going on because symptoms really are just a language, you know, it's the language our body speaks to tell us something to give us Clues as to what's going on. And once we are able to look at the whole body instead <mark>of</mark> isolating out apart or so. We can bring the body back into balance which then in turn does get rid <mark>of</mark> the symptoms, you know,", "Start Time (s)": 613.6, "End Time (s)": 733.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it. Could become a much a much bigger issue than it ended up being because we finally figured out what was causing it the first place. I think that's why I was always kind <mark>of</mark> attracted to natural medicine. It is just I never was fully I was never fully convinced when we would go to the doctor for something that you know, okay, you're experiencing this. Here's a pill it'll get better. I just for whatever reason that never sat. Well with me I just wanted to know okay, but why lie Is it happening? And and that was what really drew me I think to natural medicine which has been filtered into herbal medicine, but just that practice <mark>of</mark> figuring out but wait, let's look at the whole body and figure out what's going on because symptoms really are just a language, you know, it's the language our body speaks to tell us something to give us Clues as to what's going on. And once we are able to look at the whole body instead <mark>of</mark> isolating out apart or so. We can bring the body back into balance which then in turn does get rid <mark>of</mark> the symptoms, you know, because it's pretty you know, it's bringing the body to place to support whatever the issue was to begin with. So the right Well, yeah, and sometimes I feel like we get rid <mark>of</mark> the symptoms, but that actually takes away. The one thing that was being our body, you know, like when you have a fever and it there's evidence that fevers actually do fight whatever is going on inside and then we get rid <mark>of</mark> it and it's something that was actually a defense <mark>of</mark> our body. Now, <mark>of</mark> course, they'll be disclaimers at the beginning <mark>of</mark> this that I'm not a doctor and so, you know, but that is just been my experience as a mom and then also meet Sleep when I get sick when the longer I can write it out. Try to stay hydrated and let my body do what it's trying to do. Yeah, it seems faster.", "Start Time (s)": 665.8, "End Time (s)": 784.1, "Clip Length (min)": 1.97, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "evidence that fevers actually do fight whatever is going on inside and then we get rid <mark>of</mark> it and it's something that was actually a defense <mark>of</mark> our body. Now, <mark>of</mark> course, they'll be disclaimers at the beginning <mark>of</mark> this that I'm not a doctor and so, you know, but that is just been my experience as a mom and then also meet Sleep when I get sick when the longer I can write it out. Try to stay hydrated and let my body do what it's trying to do. Yeah, it seems faster. We try to do the opposite and where every time a symptom comes out. We push it down. It really leads eventually to chronic illness or autoimmune disorders because the body starts to attack itself. I mean most autoimmune disorders at its root. What it does is the body is thinking that its own self is an allergen or something to attack and react to and so, you know, we'll find cases <mark>of</mark> people who really try to oh We germs at all costs because there's not anything that's actually naturally or normally triggering their body to have an immune system response like normal viruses normal colds with our bodies have those to fight. It doesn't attack itself, you know, but in the absence <mark>of</mark> very sterile environment and environment for kids to play in the dirt or in environments where kids didn't have any childhood diseases the body guided turns on itself and thinks it's an Invader. So it thinks that it", "Start Time (s)": 755.4, "End Time (s)": 851.1, "Clip Length (min)": 1.6, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "their body to have an immune system response like normal viruses normal colds with our bodies have those to fight. It doesn't attack itself, you know, but in the absence <mark>of</mark> very sterile environment and environment for kids to play in the dirt or in environments where kids didn't have any childhood diseases the body guided turns on itself and thinks it's an Invader. So it thinks that it Feel cold in your body. Does this do you have a wet cough or do you have a dry cough instead <mark>of</mark> just kind <mark>of</mark> saying oh you have a stomachache. I mean you can you can symptom treat with herbs the same way you can sometimes treat with medicine you have a stomachache. Let's drink peppermint or we need to you know, there's a flu bug going around. Let's take garlic and those things are fine to do here and there but if Stop and look at wait, where's the stomachache coming from? Maybe the stomach ache is coming from nervousness, which a <mark>warming</mark> herb is actually going to be a better fit for that. So Ginger Ginger is going to be a better pair for a nervous stomach ache and say peppermint would because peppermint is kind <mark>of</mark> cooling it makes you feel a little bit more anxious. So so I think really what interests me and what gets me excited about herbal medicine or natural medicine is is Looking at things for face value missing crew wants is trying to tell us what's the bigger picture? Right? Yes, and I think people", "Start Time (s)": 824.5, "End Time (s)": 944.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I mean you can you can symptom treat with herbs the same way you can sometimes treat with medicine you have a stomachache. Let's drink peppermint or we need to you know, there's a flu bug going around. Let's take garlic and those things are fine to do here and there but if Stop and look at wait, where's the stomachache coming from? Maybe the stomach ache is coming from nervousness, which a <mark>warming</mark> herb is actually going to be a better fit for that. So Ginger Ginger is going to be a better pair for a nervous stomach ache and say peppermint would because peppermint is kind <mark>of</mark> cooling it makes you feel a little bit more anxious. So so I think really what interests me and what gets me excited about herbal medicine or natural medicine is is Looking at things for face value missing crew wants is trying to tell us what's the bigger picture? Right? Yes, and I think people do what you were just saying with essential oils to I hear a lot <mark>of</mark> people say when I have a stomach ache I put on digestion blend when I get sick. I put on the on guard blend, but I'm always noticing that we tend to neglect the diet and some <mark>of</mark> the other factors and think that that's going to be a cure-all and it's really not it's only going to go so far if you're not looking at the big picture. Yeah. Yeah, absolutely. And so even with myself even though I know what herb might take a symptom away. I don't always do those things. Like if I rarely get act usually probably get sick maybe once a year but in the fall and the spring I'll have flare-ups <mark>of</mark> when that whether kind <mark>of</mark> ping pongs back and forth hot or cold. I'll get you know, runny stuffy nose and kind <mark>of</mark> just sinus stuff. I don't do anything about The main reason is it doesn't knock me down. It doesn't make me incapable <mark>of</mark> doing whatever it is that I have to do with my day. And it really if we're looking at what's natural", "Start Time (s)": 888.4, "End Time (s)": 1007.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Right? Yes, and I think people do what you were just saying with essential oils to I hear a lot <mark>of</mark> people say when I have a stomach ache I put on digestion blend when I get sick. I put on the on guard blend, but I'm always noticing that we tend to neglect the diet and some <mark>of</mark> the other factors and think that that's going to be a cure-all and it's really not it's only going to go so far if you're not looking at the big picture. Yeah. Yeah, absolutely. And so even with myself even though I know what herb might take a symptom away. I don't always do those things. Like if I rarely get act usually probably get sick maybe once a year but in the fall and the spring I'll have flare-ups <mark>of</mark> when that whether kind <mark>of</mark> ping pongs back and forth hot or cold. I'll get you know, runny stuffy nose and kind <mark>of</mark> just sinus stuff. I don't do anything about The main reason is it doesn't knock me down. It doesn't make me incapable <mark>of</mark> doing whatever it is that I have to do with my day. And it really if we're looking at what's natural what is nature doing around us. It's ping-ponging back and forth to our bodies go through these transition periods that are totally normal in the fall <mark>of</mark> the spring where they're activating to the new season the new weather. ER and if we let them do that natural absolutely no activation. We actually write it out better that if we sit and try to you know treat the stuffy nose or treat the runny nose that we might have for just like a week or so as our body reset. Right, that's not going to ultimately be a huge deal. We don't have to rush and treat every glass symptom and the same way. Yeah. I'm the total say way actually I got I think I actually got the flu. I didn't go to the doctor. So I don't know but this season and it really I just let that happen. I drink a lot <mark>of</mark> water I rested I didn't really even do much with", "Start Time (s)": 942.5, "End Time (s)": 1061.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "doesn't knock me down. It doesn't make me incapable <mark>of</mark> doing whatever it is that I have to do with my day. And it really if we're looking at what's natural what is nature doing around us. It's ping-ponging back and forth to our bodies go through these transition periods that are totally normal in the fall <mark>of</mark> the spring where they're activating to the new season the new weather. ER and if we let them do that natural absolutely no activation. We actually write it out better that if we sit and try to you know treat the stuffy nose or treat the runny nose that we might have for just like a week or so as our body reset. Right, that's not going to ultimately be a huge deal. We don't have to rush and treat every glass symptom and the same way. Yeah. I'm the total say way actually I got I think I actually got the flu. I didn't go to the doctor. So I don't know but this season and it really I just let that happen. I drink a lot <mark>of</mark> water I rested I didn't really even do much with essential oils. I guess I did for my ears because I feel like I had a couple ear infections with it. Other than that, you know because that was sort <mark>of</mark> painful. I just let it happen and it was done in five days over. Let's talk about a few practical things. Like what kind <mark>of</mark> herbs do you use on a daily basis? Because we forgot to mention that you have how many children? Right. Yeah, so you probably find yourself. At least I even if you have very healthy kids still dealing with things here and there so what kind <mark>of</mark> practically how do you use herbs on a regular basis? So tell myself on a daily basis, what I do is I have a regimen so I have a tendency to have dryness", "Start Time (s)": 999.0, "End Time (s)": 1118.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in five days over. Let's talk about a few practical things. Like what kind <mark>of</mark> herbs do you use on a daily basis? Because we forgot to mention that you have how many children? Right. Yeah, so you probably find yourself. At least I even if you have very healthy kids still dealing with things here and there so what kind <mark>of</mark> practically how do you use herbs on a regular basis? So tell myself on a daily basis, what I do is I have a regimen so I have a tendency to have dryness overall. So I will have it dry skin. I'll get it done, you know flaky scalp. I am very dry hair and I am cold all the time. So I don't have great circulation. So those tend to be the patterns <mark>of</mark> things that I deal with with my own health. So just on a daily basis, I take things that support that and just kind <mark>of</mark> keeping it balanced. I don't necessarily specifically symptom tree, but why hide would every day I'm drinking <mark>warming</mark> drinks with <mark>warming</mark> herbs and I boil my body like everyday on my blog. I do have a post on body oiling and that's been one <mark>of</mark> probably the most beneficial practices for me because when I am adding moisture, I find that A lot <mark>of</mark> the things I used to have clear up don't flare up. So those are kind <mark>of</mark> daily things that I do every day. So I drink like chives hyped. He's all day long. I do it till CT which is really nice adapted genetic tea, and it also just it's a <mark>warming</mark> T. So kind <mark>of</mark> meets several needs that I have so I drink till see I drink chai I", "Start Time (s)": 1073.3, "End Time (s)": 1192.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I am very dry hair and I am cold all the time. So I don't have great circulation. So those tend to be the patterns <mark>of</mark> things that I deal with with my own health. So just on a daily basis, I take things that support that and just kind <mark>of</mark> keeping it balanced. I don't necessarily specifically symptom tree, but why hide would every day I'm drinking <mark>warming</mark> drinks with <mark>warming</mark> herbs and I boil my body like everyday on my blog. I do have a post on body oiling and that's been one <mark>of</mark> probably the most beneficial practices for me because when I am adding moisture, I find that A lot <mark>of</mark> the things I used to have clear up don't flare up. So those are kind <mark>of</mark> daily things that I do every day. So I drink like chives hyped. He's all day long. I do it till CT which is really nice adapted genetic tea, and it also just it's a <mark>warming</mark> T. So kind <mark>of</mark> meets several needs that I have so I drink till see I drink chai I body oil. And I'm get good sleep and I drink a lot <mark>of</mark> water. I mean those aren't necessarily herbal things, but they're usually the main things I see that I tried first with people before anything else. How much are you sleeping? And how much were you drinking? So those are kind <mark>of</mark> the daily things I do to support my own body. And then with my kids this is changed recently in the past couple <mark>of</mark> years how I look at this, but you know, how Ow, what our kids have emotional meltdowns and so you can try to immediately jump in and solve the problems for them or you can like kind <mark>of</mark> guide them through it and let them find Solutions themselves and I do a lot <mark>of</mark> that with herbs and with health for them to", "Start Time (s)": 1125.3, "End Time (s)": 1244.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "He's all day long. I do it till CT which is really nice adapted genetic tea, and it also just it's a <mark>warming</mark> T. So kind <mark>of</mark> meets several needs that I have so I drink till see I drink chai I body oil. And I'm get good sleep and I drink a lot <mark>of</mark> water. I mean those aren't necessarily herbal things, but they're usually the main things I see that I tried first with people before anything else. How much are you sleeping? And how much were you drinking? So those are kind <mark>of</mark> the daily things I do to support my own body. And then with my kids this is changed recently in the past couple <mark>of</mark> years how I look at this, but you know, how Ow, what our kids have emotional meltdowns and so you can try to immediately jump in and solve the problems for them or you can like kind <mark>of</mark> guide them through it and let them find Solutions themselves and I do a lot <mark>of</mark> that with herbs and with health for them to because really our emotional bodies our spiritual bodies Our physical bodies, they're not that different and so when a kid has a stomach ache or they have a flare up or something. Ask them questions. So I'll say like, where do you feel that? Where do you feel that in your body? Okay, it's your stomach. Is it up here in your upper stomach or do you feel it in your lower stomach, then we'll feel their stomach with them. So like John he was getting stomach aches for a long time and I thought oh, no, he's gonna have food allergies like era, but I'd have it filled his stomach and I could feel the stomach and where the heat was to kind <mark>of</mark> figure out. Okay. Is this intestinal? Is this higher than you know, the small intestine where it would be more: stuff and it was up higher and intended I ask him. How's this", "Start Time (s)": 1175.7, "End Time (s)": 1295.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Ask them questions. So I'll say like, where do you feel that? Where do you feel that in your body? Okay, it's your stomach. Is it up here in your upper stomach or do you feel it in your lower stomach, then we'll feel their stomach with them. So like John he was getting stomach aches for a long time and I thought oh, no, he's gonna have food allergies like era, but I'd have it filled his stomach and I could feel the stomach and where the heat was to kind <mark>of</mark> figure out. Okay. Is this intestinal? Is this higher than you know, the small intestine where it would be more: stuff and it was up higher and intended I ask him. How's this feel? It feels like I'm scared and I realize he's having anxiety stomach aches that it wasn't you know, what they the same as we were staying with are it wasn't constipation wasn't food. It was anxiety. And so I took him. Over and I helped him look at some different things and I kind <mark>of</mark> you know, I set out the things that I knew would maybe help anxiety more so than others but that I just let him play with them not like what would sound really good to drink or are you know, I love smell or whole oils like essential oils and I'll say what ones are you drawn to like what it what makes you feel really calm and just kind <mark>of</mark> giving them the power to access. I think when you're a kid and you learn your instincts tends to be right like you have a gut feeling with your That when you kind <mark>of</mark> give that power away to a doctor or someone else telling you what's going on, you stop trusting that and especially as women we go to a doctor we need to kind <mark>of</mark> know something's up and they say over your Labs or fine or a we don't show any allergy. We know our bodies pretty well at our kids do to they know their audience pretty well. So I try to let them kind <mark>of</mark> steer it but then if they will always ask them. Do you want me to give you some ideas, you know for what you could do to Or do you want to just lay here and rest and write it out. We don't", "Start Time (s)": 1256.0, "End Time (s)": 1375.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "maybe help anxiety more so than others but that I just let him play with them not like what would sound really good to drink or are you know, I love smell or whole oils like essential oils and I'll say what ones are you drawn to like what it what makes you feel really calm and just kind <mark>of</mark> giving them the power to access. I think when you're a kid and you learn your instincts tends to be right like you have a gut feeling with your That when you kind <mark>of</mark> give that power away to a doctor or someone else telling you what's going on, you stop trusting that and especially as women we go to a doctor we need to kind <mark>of</mark> know something's up and they say over your Labs or fine or a we don't show any allergy. We know our bodies pretty well at our kids do to they know their audience pretty well. So I try to let them kind <mark>of</mark> steer it but then if they will always ask them. Do you want me to give you some ideas, you know for what you could do to Or do you want to just lay here and rest and write it out. We don't have a ton <mark>of</mark> things pop up. But my oldest she's familiar enough that I think from just watching like my kids have watched me and what I do, but I don't feel good or when I'm helping people and I talk about herbs all the time. So because <mark>of</mark> that, you know, they kind <mark>of</mark> know some <mark>of</mark> it anyway and like Aaron she doesn't even ask me anymore. She'll just go make yourself some tea. You're still going to you know, grab some oils out <mark>of</mark> my bathroom or whatever it is. She needs but I'm trying to think like on a daily basis what I practically do what the kids that might be helpful, but I think just talking about it and just exposing them to the education that I have an asking lots <mark>of</mark> questions trying to get just whatever. / what they're saying is they might be saying I to stomachache but what they're really trying to communicate as I'm scared and that's really important. You know, I think to listen and know the difference in your kids when they come to you", "Start Time (s)": 1318.4, "End Time (s)": 1438.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "enough that I think from just watching like my kids have watched me and what I do, but I don't feel good or when I'm helping people and I talk about herbs all the time. So because <mark>of</mark> that, you know, they kind <mark>of</mark> know some <mark>of</mark> it anyway and like Aaron she doesn't even ask me anymore. She'll just go make yourself some tea. You're still going to you know, grab some oils out <mark>of</mark> my bathroom or whatever it is. She needs but I'm trying to think like on a daily basis what I practically do what the kids that might be helpful, but I think just talking about it and just exposing them to the education that I have an asking lots <mark>of</mark> questions trying to get just whatever. / what they're saying is they might be saying I to stomachache but what they're really trying to communicate as I'm scared and that's really important. You know, I think to listen and know the difference in your kids when they come to you with something because again, it's symptoms. It's just that way <mark>of</mark> communication and so with kids it's the same thing and sometimes they don't know sometimes they just know that their stomach hurts. They won't be able to tell you they're scared. But if you ask enough questions, then you know, I'm not giving them. Something that is just to pull the stomach ache. I'm figuring out. Oh, I needed to know that information. I needed to know that they're afraid or that something else is going on. So yeah. Yeah, I guess I don't know if that answers your question really was Harris. No it does do you have this is something I was just thinking about when you were saying this do you have on your blog like a herbs 101 get started with basic things or any influential books that you could recommend on that so people with no, you know where to even begin and never users at all. To I used to I did there still are up and you can find them on YouTube If you searched for herb talks with Jen I used to have like my top", "Start Time (s)": 1382.7, "End Time (s)": 1502.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "books that you could recommend on that so people with no, you know where to even begin and never users at all. To I used to I did there still are up and you can find them on YouTube If you searched for herb talks with Jen I used to have like my top 10 herbs. But again, this was while I was going through my first certification and I was really just getting familiar with the plant the chemical constituents the actions that they had at the body. Whereas I feel like now with the second certification. I've been working through I'm learning more about about how to tailor those to the patient and like like where I feel like my first certification was completely on just immersing myself in known plants and their properties. Now when I'm learning is people and their constitution support their ailments or their body organ systems and things like that. So because <mark>of</mark> that, I'm kind <mark>of</mark> hesitant to recommend, you know, my previous herbal 101 classes because because I wouldn't Blanket across the board say this is lavender. And here's what it does. However, how you kind of? happy okay, you know and so so the great books something that I would recommend when the anything by like Rosemary glad star Sasha Popham and I'll give you some lists that you can link in the show notes, but even some really basic one <mark>of</mark> my very favorite books is called Eat Right for your body and it's by Tanja and I can't think <mark>of</mark> your last name, but it's on like are you betta Keating and what it does is it just kind <mark>of</mark> goes into what? dudes and implants What they do once they get in your body, so they cool or they warm and it's really basic with food, but it's", "Start Time (s)": 1484.1, "End Time (s)": 1603.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "star Sasha Popham and I'll give you some lists that you can link in the show notes, but even some really basic one <mark>of</mark> my very favorite books is called Eat Right for your body and it's by Tanja and I can't think <mark>of</mark> your last name, but it's on like are you betta Keating and what it does is it just kind <mark>of</mark> goes into what? dudes and implants What they do once they get in your body, so they cool or they warm and it's really basic with food, but it's a great like primer book for knowing how something is going to react when you ingest it. And so that's a great one that I'll send you a list that you can put in your in your notes. Okay. I do occasionally on my blog the way to like if I'm if I'm spotlighting a certainty Blend or something I built. Talk about the different parts and kind <mark>of</mark> what learned known for or what they do. So so there are some things that they be able to find on my blog. There's all sorts <mark>of</mark> information on YouTube or on on the internet that you can kind <mark>of</mark> Google if you're looking for more <mark>of</mark> a real scientific break down. If you will Google like herbal energy or herbal herbal energy migraine <mark>of</mark> a bunch <mark>of</mark> weird hits, but Hey, if you write in Materia Medica herbal, you know, it'll bring up what it does in the body. And so that to me is more interested in it than just knowing like lavender is a natural antihistamine because Lavender is one <mark>of</mark> those herbs that it will really work. Well for people or it will work terribly. Okay, even something as simple as you know. Injure depending on your", "Start Time (s)": 1568.3, "End Time (s)": 1688.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "or it's going to aggravate it take you first. Oh, wow. Okay. Yeah Consulting was really getting into studying plants and then knowing your own this one affected me in this way. It's a good way to know how your body is going to respond. Right. Okay. Yeah, it's definitely not a one-size-fits-all approach. I found that too with just looking at essential oils a little bit. I feel like some people try something and it works really well for them. And like you said, sometimes it goes in the complete opposite but something that I like about talking about herbs. I feel like essential oils are really really popular and pretty much everyone uses them. But herbs are a whenever you use a dried or make a tea for example like you were talking about or like when I was pregnant. Drink lots and lots <mark>of</mark> red raspberry leaf tea for labor support. Yeah. It's not this insanely concentrated. Sometimes I think we think more is better. And so let's just down the essential oils, but using herbs to support the body is sometimes maybe a more Gentle Way. Well, it's way to you. He's so I use essential oils. I love essential oils, but it's it's steam distilled or cold pressed you're taking an isolate still from a plant which has its uses. It definitely has its place but what's nice about teased or tinctures or decoctions you're using that whole plant and you're either dehydrating it and then rehydrating it or your Using the water soluble Properties or the alcohol soluble properties and the tincture or it took action. And so you're pulling everything out <mark>of</mark> it. And then I've really been getting lately", "Start Time (s)": 1690.4, "End Time (s)": 1809.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "like when I was pregnant. Drink lots and lots <mark>of</mark> red raspberry leaf tea for labor support. Yeah. It's not this insanely concentrated. Sometimes I think we think more is better. And so let's just down the essential oils, but using herbs to support the body is sometimes maybe a more Gentle Way. Well, it's way to you. He's so I use essential oils. I love essential oils, but it's it's steam distilled or cold pressed you're taking an isolate still from a plant which has its uses. It definitely has its place but what's nice about teased or tinctures or decoctions you're using that whole plant and you're either dehydrating it and then rehydrating it or your Using the water soluble Properties or the alcohol soluble properties and the tincture or it took action. And so you're pulling everything out <mark>of</mark> it. And then I've really been getting lately into it's called. I'm going to pronounce instruments. Like listen to people say it on these modules that I'm taking is part <mark>of</mark> Jetix. I don't know but it's something that I'm just now starting to get it. It's really interesting because it takes what's left <mark>of</mark> the plant after you pull out the properties through like a tincture and it burns it down and crystallizes it and uses like the last bit <mark>of</mark> the plant so you're using and you put that in with your teacher or your tea and so it's like taking the entire plan the whole thing. Cool. Yeah. Yeah, right that that makes sense. You have to think there's a reason why you got it. But yeah, you have to think there's a reason why it came in a whole plant form and you know, not just an", "Start Time (s)": 1747.5, "End Time (s)": 1867.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "say it on these modules that I'm taking is part <mark>of</mark> Jetix. I don't know but it's something that I'm just now starting to get it. It's really interesting because it takes what's left <mark>of</mark> the plant after you pull out the properties through like a tincture and it burns it down and crystallizes it and uses like the last bit <mark>of</mark> the plant so you're using and you put that in with your teacher or your tea and so it's like taking the entire plan the whole thing. Cool. Yeah. Yeah, right that that makes sense. You have to think there's a reason why you got it. But yeah, you have to think there's a reason why it came in a whole plant form and you know, not just an isolated part. So do you have any stories like any herbal stories that you want to share knowing that most <mark>of</mark> your listeners are the most common? Yes, this is something I was going to talk about you because I have I have a story with that as well. Yeah, so that's the most common. I don't either. Dress those two things like Stress and Anxiety and really those are two sides <mark>of</mark> the same coin often most I would say 95% <mark>of</mark> people who come to me for hormonal imbalance or Stress and Anxiety. There's something going on in the HPA axis. So yeah, I have lots <mark>of</mark> neat stories, but It's been really neat and really like gratifying working with women and helping them rebalance their Cycles because typically between one to three Cycles. Owls", "Start Time (s)": 1818.3, "End Time (s)": 1938.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "this is something I was going to talk about you because I have I have a story with that as well. Yeah, so that's the most common. I don't either. Dress those two things like Stress and Anxiety and really those are two sides <mark>of</mark> the same coin often most I would say 95% <mark>of</mark> people who come to me for hormonal imbalance or Stress and Anxiety. There's something going on in the HPA axis. So yeah, I have lots <mark>of</mark> neat stories, but It's been really neat and really like gratifying working with women and helping them rebalance their Cycles because typically between one to three Cycles. Owls we've been able to get people back on track which I mean there's all sorts <mark>of</mark> things as an herbalist that you give people something. You don't know if you're helping them or not. You maybe never hear back or you do here back with that's something that's really rewarding because it is short period <mark>of</mark> time you're able to see such a big change and and sometimes it's gone for people who are experiencing infertility to being able to get pregnant like within a month or two. This is So that's why I really enjoy working with women on hormone imbalance looking at which part <mark>of</mark> their cycle. and if they're able to chart and know their Cycles pretty well and know what's a typical cycle for them what their cycle is now, whether the first half <mark>of</mark> their cycle is border or longer or their second half is shorter or longer single video phase <mark>of</mark> development that can give us a picture <mark>of</mark> kind <mark>of</mark> what's going on with our hormones typically could turn that around really quickly which is which is nice to know cause I know when there are so many women", "Start Time (s)": 1884.0, "End Time (s)": 2003.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "could turn that around really quickly which is which is nice to know cause I know when there are so many women Put up for years with knowing something's off but not knowing what and when they go to their doctor. They're told that their labs are fine. There's no which is so frustrating. I had the same thing happen like three years back. I knew after I had Clementine that my hormones were just want because I'd always been 28 days. Like on the dot and it just changed entirely after I had her and so and I didn't feel good and I went to the doctor first and they said your labs are fine. You know, we don't see anything. That's the matter and so again, I was like, okay. Well then I'm going to figure it out myself at the end, you know, just within a couple months experimenting and things and using herbs to support the different phases <mark>of</mark> the <mark>of</mark> my side. I was able to get back on a 28-day regular cycle. So I don't know I don't know that that's like a necessarily a story or narrative. But that's one that I see all the time. I guess just know that's that's huge though because that's a big big problem. And I actually have that so my big herbal story my the things I've use herbs for mostly is pregnancy and fertility and hormonal support because that has been the things that I've just seen the biggest. Mint so for example whenever I was pregnant with one <mark>of</mark> my children, I had really bad iron deficiency. In fact, I continue to have that pattern but I used herbs to make iron-rich tinctures. And then after my second child my hormones were crazy. Like I was having weeks long Cycles like 30 straight days and three different times. I took Vitex for three months", "Start Time (s)": 1997.4, "End Time (s)": 2116.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Those are 20 days almost exactly like a menstrual cycle and when you are supporting your body do a line with nature, so like circadian rhythms. We know if we sleep according the circadian rhythms are bodies just they're naturally more healthy when we you know, go to bed with the sun and wait with the sun and it's the same thing for women with lunar cycles interesting. If you spend a lot <mark>of</mark> time in danger your Cycles will naturally aligned. Really fascinating when I started studying it and if you're if you're always in doors and you're never out in nature a lot <mark>of</mark> times your Cycles will get crazy is you know, and they don't line up but when you're really my whole like hey, I go outside and I walk at night when I'm watering. My plants are almost always with the full moon and start menstrual cycle the new baby like it's just like start To see the patterns and I just when I look at that, I just think oh my gosh got spacing because yeah you see in nature is really reflected inside. It's incredible. Yeah. It's just exciting to me anymore. It's an area that I love. I can't imagine", "Start Time (s)": 2178.6, "End Time (s)": 2264.4, "Clip Length (min)": 1.43, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "doors and you're never out in nature a lot <mark>of</mark> times your Cycles will get crazy is you know, and they don't line up but when you're really my whole like hey, I go outside and I walk at night when I'm watering. My plants are almost always with the full moon and start menstrual cycle the new baby like it's just like start To see the patterns and I just when I look at that, I just think oh my gosh got spacing because yeah you see in nature is really reflected inside. It's incredible. Yeah. It's just exciting to me anymore. It's an area that I love. I can't imagine ever not being learning new things about herbs or health or yeah, it's your passion. I one <mark>of</mark> the things I read about whenever I was having those issues with usually postpartum. I would have extremely weird Cycles, which I know for postpartum is normal, but they didn't seem to ever want to come back in the balance without Vitex and something that I About was we were living in a house as you know, right next to a park and there were Park lights literally shining in our bedroom master bedroom window. I mean right outside <mark>of</mark> it. We're talking 50 feet and I've always wondered if that was causing it because all night long. Our room was like you could walk around without a light because it was so bright all the time, which I should have just got some room darkening Shades instead <mark>of</mark> worrying about this, but instead I let my Cycles go crazy and I wonder if that caused it. Yeah, that's up to do with it. Well, it's interesting because there are practitioners that I read studies about who when their truck working with women on regulating their Cycles. They will just have them open their windows at night and be like,", "Start Time (s)": 2212.9, "End Time (s)": 2332.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "was we were living in a house as you know, right next to a park and there were Park lights literally shining in our bedroom master bedroom window. I mean right outside <mark>of</mark> it. We're talking 50 feet and I've always wondered if that was causing it because all night long. Our room was like you could walk around without a light because it was so bright all the time, which I should have just got some room darkening Shades instead <mark>of</mark> worrying about this, but instead I let my Cycles go crazy and I wonder if that caused it. Yeah, that's up to do with it. Well, it's interesting because there are practitioners that I read studies about who when their truck working with women on regulating their Cycles. They will just have them open their windows at night and be like, this is called Blue mating in see I couldn't do that though because I had this artificial parklife exactly. Yeah. So that makes sense though in our new place. We we moved in and they had a dust it on light right outside <mark>of</mark> the master bedroom. And I was like unplug that thing like why no, we moved to the country no more light, but I definitely Everything is going around you and understanding that when we're in a natural world. Our bodies are going to function more. Naturally. I think it sounds simple but yeah, it sounds simple but it's but in today's world. It's actually very difficult to do it has to be intentional used to be an obvious part <mark>of</mark> life. But now it has to be an intentional thing right well enough. I'm drawn", "Start Time (s)": 2287.8, "End Time (s)": 2407.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So that makes sense though in our new place. We we moved in and they had a dust it on light right outside <mark>of</mark> the master bedroom. And I was like unplug that thing like why no, we moved to the country no more light, but I definitely Everything is going around you and understanding that when we're in a natural world. Our bodies are going to function more. Naturally. I think it sounds simple but yeah, it sounds simple but it's but in today's world. It's actually very difficult to do it has to be intentional used to be an obvious part <mark>of</mark> life. But now it has to be an intentional thing right well enough. I'm drawn to it because it's using nature, you know in whatever I'm doing it and it's not that like you here in this common. It kind <mark>of</mark> makes me cringe a little when I hear people say. Oh, yeah. I used to have some remedies. I don't use chemicals and I want to say like the first thing I studied when I studied herbs is like the chemical constituents because I hurt yeah, that's too broad <mark>of</mark> a turn chemicals and What they mean by that what they mean by the using something more natural and not chemicals is something that like it just feels intuitive. Like it's what is in your backyard. You have a connection to it. You're amongst it all day. You know, I think I can grow herbs and give them to people but I recommend obviously that they grow their own because what you're working in in your own soil and what you have your own, you know connection to", "Start Time (s)": 2341.9, "End Time (s)": 2461.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "chemicals and I want to say like the first thing I studied when I studied herbs is like the chemical constituents because I hurt yeah, that's too broad <mark>of</mark> a turn chemicals and What they mean by that what they mean by the using something more natural and not chemicals is something that like it just feels intuitive. Like it's what is in your backyard. You have a connection to it. You're amongst it all day. You know, I think I can grow herbs and give them to people but I recommend obviously that they grow their own because what you're working in in your own soil and what you have your own, you know connection to asking to be what's going to work best for you. Honestly the you can buy stuff and it can work. There's no doubt about that. But whatever you have a personal connection to I think will always be my Top Choice when you're getting out there in in the soil cultivating it and that's going to all be part <mark>of</mark> the picture so that X license. I've never thought about all <mark>of</mark> that and I do want to really quit go back to work you were talking about how Vitex doesn't work for everyone and I did I forgot to mention that because I remember whenever I was researching It I read that, you know, this could go two ways. They could either mess you up worse or it could work for you. So for me and my body type it works. I don't want to recommend anybody just start taking it because yeah, it could be the opposite effect. Yeah. What you said whenever I was having this issue and I figured out that the second", "Start Time (s)": 2420.4, "End Time (s)": 2540.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "so that X license. I've never thought about all <mark>of</mark> that and I do want to really quit go back to work you were talking about how Vitex doesn't work for everyone and I did I forgot to mention that because I remember whenever I was researching It I read that, you know, this could go two ways. They could either mess you up worse or it could work for you. So for me and my body type it works. I don't want to recommend anybody just start taking it because yeah, it could be the opposite effect. Yeah. What you said whenever I was having this issue and I figured out that the second half <mark>of</mark> my cycle was short and so I knew it was a progesterone deficiency. So I don't want just anybody to think that I just Into the start taking biotech, I did advocate for myself and figure out, you know, if it would be a beneficial thing. Yeah, so that's something to make sure you know, because you don't just jump into it and it just work for like you said, it's very individual. It's it's very it's something you need, you know at this is your first time you've never read into this because I've been pretty into this stuff for a while to and so I kind <mark>of</mark> knew how to Diagnose my cycle and know where the issues were. But if it is a where do you recommend people finding someone like you in their local area? Yeah, well, I'm sure a lot <mark>of</mark> times chiropractors will have connections or know <mark>of</mark> someone if you're wanting to see someone locally. You can try addio doctors they tend to be more open to natural alternative alternative", "Start Time (s)": 2481.0, "End Time (s)": 2600.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "for like you said, it's very individual. It's it's very it's something you need, you know at this is your first time you've never read into this because I've been pretty into this stuff for a while to and so I kind <mark>of</mark> knew how to Diagnose my cycle and know where the issues were. But if it is a where do you recommend people finding someone like you in their local area? Yeah, well, I'm sure a lot <mark>of</mark> times chiropractors will have connections or know <mark>of</mark> someone if you're wanting to see someone locally. You can try addio doctors they tend to be more open to natural alternative alternative medicine. So they may have some resources certainly if you don't even have to your paths, I do online consultations. No, no, okay. So you do take online clients, okay. There's a one-hour initial consultation. And from there. I can do follow-ups that are just 30 minutes which are you know, after I know like the background <mark>of</mark> the person and so I did this online and you can find lots <mark>of</mark> herbalist online that will do the same type <mark>of</mark> thing. So if you don't have someone local you can usually find someone Yeah, because sometimes you know, this is your first experience into using that kind <mark>of</mark> thing. It makes sense to get some guidance, especially when you're talking about something like cycles and If somebody is trying to address a particular issue, you know, you don't you don't want to undo any progress or take something like that. If you're doing IVF or you know, that would not be something good. Yeah. It's so important to know if someone is taking other medicines what they've tried in the past what tends to make you feel better what tends to make things worse before you start playing because you know at its root yes herbs can be more mild than medicine and Are certainly more natural always my first go-to, but they do have side <mark>effects</mark> like anything else and so it's important to", "Start Time (s)": 2561.0, "End Time (s)": 2680.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "30 minutes which are you know, after I know like the background <mark>of</mark> the person and so I did this online and you can find lots <mark>of</mark> herbalist online that will do the same type <mark>of</mark> thing. So if you don't have someone local you can usually find someone Yeah, because sometimes you know, this is your first experience into using that kind <mark>of</mark> thing. It makes sense to get some guidance, especially when you're talking about something like cycles and If somebody is trying to address a particular issue, you know, you don't you don't want to undo any progress or take something like that. If you're doing IVF or you know, that would not be something good. Yeah. It's so important to know if someone is taking other medicines what they've tried in the past what tends to make you feel better what tends to make things worse before you start playing because you know at its root yes herbs can be more mild than medicine and Are certainly more natural always my first go-to, but they do have side <mark>effects</mark> like anything else and so it's important to know what you're doing or doing research. Okay, so I'm going to be leaving down in the show notes links from your blog and some <mark>of</mark> the things that you mentioned some <mark>of</mark> the books that you mentioned your herbal consultations. Tell us again where we can find you. I know you already mentioned it but let's just start that up again. Instagram I met the underscore Wildflower assist and then on Facebook as The Wildflower East and then I also have my website the wild florist. Okay. Okay. Good. Damn it going to cost also will thank you so much. Thank you so much. I feel like we had a really good discussion on herbs. Nothing. It's kind <mark>of</mark> a This is something for you to start learning and exploring not this is what you should take right now, which is", "Start Time (s)": 2616.8, "End Time (s)": 2736.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "more mild than medicine and Are certainly more natural always my first go-to, but they do have side <mark>effects</mark> like anything else and so it's important to know what you're doing or doing research. Okay, so I'm going to be leaving down in the show notes links from your blog and some <mark>of</mark> the things that you mentioned some <mark>of</mark> the books that you mentioned your herbal consultations. Tell us again where we can find you. I know you already mentioned it but let's just start that up again. Instagram I met the underscore Wildflower assist and then on Facebook as The Wildflower East and then I also have my website the wild florist. Okay. Okay. Good. Damn it going to cost also will thank you so much. Thank you so much. I feel like we had a really good discussion on herbs. Nothing. It's kind <mark>of</mark> a This is something for you to start learning and exploring not this is what you should take right now, which is not really the direction I expected to go but I also definitely should have expected to go away because that's how it is. This is not I'm used to take this for this symptom and that is Often I imagine understand the desire for that because it would be so easy, right? You know, like I just but unfortunately that usually ends up serving like a bigger issue down the line, you know, whereas if you're supporting your overall health and just constantly investing in your own life Baseline Health. A lot <mark>of</mark> those things are going to resolve. Yes. Yes that makes so much sense. Well, if you enjoyed this episode make sure to join me in the next one episode", "Start Time (s)": 2669.6, "End Time (s)": 2789.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "This is something for you to start learning and exploring not this is what you should take right now, which is not really the direction I expected to go but I also definitely should have expected to go away because that's how it is. This is not I'm used to take this for this symptom and that is Often I imagine understand the desire for that because it would be so easy, right? You know, like I just but unfortunately that usually ends up serving like a bigger issue down the line, you know, whereas if you're supporting your overall health and just constantly investing in your own life Baseline Health. A lot <mark>of</mark> those things are going to resolve. Yes. Yes that makes so much sense. Well, if you enjoyed this episode make sure to join me in the next one episode 23 <mark>of</mark> the simple farmhouse. live podcast", "Start Time (s)": 2730.7, "End Time (s)": 2792.6, "Clip Length (min)": 1.03, "show_uri": "spotify:show:5OzGvjQ2nKCTHh4sNun3Eo", "show_name": "Simple Farmhouse Life", "show_description": "With over ten years experience making a home, author and mom of 6 Lisa Bass, shares her love for from scratch cooking, natural living and all things handmade. As a full-time blogger and homeschooler, Lisa also mixes in a little mom life and business tips.", "publisher": "Lisa Bass", "episode_uri": "spotify:episode:2H4TP1zhzPQh315RrApYFT", "episode_name": "22. Staying well with herbs- chatting with my friend Jen on all things herbal medicine", "episode_description": "It was so refreshing to chat herbs with someone so knowledgeable. Natural remedies definitely aren't one size fits all.\u00a0 Jens website can be found HERE. \u00a0Shop Jen's amazing herbal teas HERE.\u00a0 1 hour herbal consult with Jen \u00a0 Herb talks with Jen (her old YouTube channel) Books Jen recommends on herbs and natural health: Some links are affiliate links. As an Amazon associate I make a commission on qualifying purchases.\u00a0 Herbal Healing for Women Herbal Recipes for Vibrant Health Eat Right for Your Body Type And my friend Amy Fewell wrote this amazing herb companion, which I own and love.\u00a0 ", "score": 6.3898144, "explanation": "{\n  \"value\": 6.3898144,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.4138252,\n      \"description\": \"weight(word_list:effects in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4138252,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.8816996,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.11878367,\n      \"description\": \"weight(word_list:of in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.11878367,\n          \"description\": \"score(LMDirichletSimilarity, freq=138.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.586658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 138.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.8572054,\n      \"description\": \"weight(word_list:warming in 23) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.8572054,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 6.3250794,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "All right everybody. It is me and Christian here with our very good buddy Thomas real Stone from the history <mark>of</mark> Otero. I pronounce it, right that was pretty good. Actually. Yeah, that was pretty good. It was pretty good history <mark>of</mark> New Zealand podcast. And so tell us a little bit about your projects and what you've been working on and what we're going to be talking about today. Sure. So Kilda, my name is Thomas and I as you've just heard I'm the bloke behind the history <mark>of</mark> altered or New Zealand podcast, which is very much a does what it says on the tin podcast. It's a chronological narrative retelling <mark>of</mark> the history <mark>of</mark> altered or New Zealand. Which by my accent and stuff you probably get it. That's where I'm from. However, you've also probably gathered that that is a History Podcast as I've just explained and you're wondering what are they doing on this podcast about animals or second White House that relators it's all part <mark>of</mark> the plan baby. It's all part <mark>of</mark> the plan. So there is a there is a there is a connection one <mark>of</mark> the connections. Is that New Zealand is a very unique", "Start Time (s)": 19.8, "End Time (s)": 87.7, "Clip Length (min)": 1.13, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "All right everybody. It is me and Christian here with our very good buddy Thomas real Stone from the history <mark>of</mark> Otero. I pronounce it, right that was pretty good. Actually. Yeah, that was pretty good. It was pretty good history <mark>of</mark> New Zealand podcast. And so tell us a little bit about your projects and what you've been working on and what we're going to be talking about today. Sure. So Kilda, my name is Thomas and I as you've just heard I'm the bloke behind the history <mark>of</mark> altered or New Zealand podcast, which is very much a does what it says on the tin podcast. It's a chronological narrative retelling <mark>of</mark> the history <mark>of</mark> altered or New Zealand. Which by my accent and stuff you probably get it. That's where I'm from. However, you've also probably gathered that that is a History Podcast as I've just explained and you're wondering what are they doing on this podcast about animals or second White House that relators it's all part <mark>of</mark> the plan baby. It's all part <mark>of</mark> the plan. So there is a there is a there is a connection one <mark>of</mark> the connections. Is that New Zealand is a very unique it's very unique. Eek place and that about 50% <mark>of</mark> the animals here are endemic or they're not found anywhere else in the world. So that's makes it very very special and it sometimes kind <mark>of</mark> cool to biological Arc because a lot <mark>of</mark> our animals are very very very old have been here for a very very long time and haven't really evolved a hell <mark>of</mark> a lot and that kind <mark>of</mark> stuff and the other part <mark>of</mark> it is why I specifically am here when I run a History Podcast is that although history is kind <mark>of</mark> a passion. And I do really really enjoy that I actually work in the conservation field. I work in conservation for a living so my job a lot <mark>of</mark> it entails or a lot <mark>of</mark> it is around trying to get rid <mark>of</mark> introduced mammalian pests things like rats must a loads, which are stoked weasels and ferrets", "Start Time (s)": 19.8, "End Time (s)": 138.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I've just explained and you're wondering what are they doing on this podcast about animals or second White House that relators it's all part <mark>of</mark> the plan baby. It's all part <mark>of</mark> the plan. So there is a there is a there is a connection one <mark>of</mark> the connections. Is that New Zealand is a very unique it's very unique. Eek place and that about 50% <mark>of</mark> the animals here are endemic or they're not found anywhere else in the world. So that's makes it very very special and it sometimes kind <mark>of</mark> cool to biological Arc because a lot <mark>of</mark> our animals are very very very old have been here for a very very long time and haven't really evolved a hell <mark>of</mark> a lot and that kind <mark>of</mark> stuff and the other part <mark>of</mark> it is why I specifically am here when I run a History Podcast is that although history is kind <mark>of</mark> a passion. And I do really really enjoy that I actually work in the conservation field. I work in conservation for a living so my job a lot <mark>of</mark> it entails or a lot <mark>of</mark> it is around trying to get rid <mark>of</mark> introduced mammalian pests things like rats must a loads, which are stoked weasels and ferrets as well as possums and hedgehogs and whatever else people decided to bring over to New Zealand that weren't originally here and they caused a huge amount <mark>of</mark> Devastation to Our Wildlife particularly our Birds which is our kind <mark>of</mark> major. You know, we've got a big a lot <mark>of</mark> endemic birds and stuff with only two species <mark>of</mark> endemic mammals, which are both bets. So everything else that's a mammal here isn't really meant to be here originally. So we're trying to get rid <mark>of</mark> them because they caused a huge amount <mark>of</mark> Devastation on all <mark>of</mark> these really unique birds and stuff and you've probably heard about all these different birds things like Kia car Kapoor. We've got things like to Kiwi, <mark>of</mark> course. That's the obvious one. Yeah. So we talked about the Kia in one <mark>of</mark> our episodes Christian actually talked about the Kia and that was", "Start Time (s)": 70.1, "End Time (s)": 189.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "enjoy that I actually work in the conservation field. I work in conservation for a living so my job a lot <mark>of</mark> it entails or a lot <mark>of</mark> it is around trying to get rid <mark>of</mark> introduced mammalian pests things like rats must a loads, which are stoked weasels and ferrets as well as possums and hedgehogs and whatever else people decided to bring over to New Zealand that weren't originally here and they caused a huge amount <mark>of</mark> Devastation to Our Wildlife particularly our Birds which is our kind <mark>of</mark> major. You know, we've got a big a lot <mark>of</mark> endemic birds and stuff with only two species <mark>of</mark> endemic mammals, which are both bets. So everything else that's a mammal here isn't really meant to be here originally. So we're trying to get rid <mark>of</mark> them because they caused a huge amount <mark>of</mark> Devastation on all <mark>of</mark> these really unique birds and stuff and you've probably heard about all these different birds things like Kia car Kapoor. We've got things like to Kiwi, <mark>of</mark> course. That's the obvious one. Yeah. So we talked about the Kia in one <mark>of</mark> our episodes Christian actually talked about the Kia and that was pretty mind-blowing Kia are really strange. All <mark>of</mark> our animals are really strange but they get a lot <mark>of</mark> focus in the sense that you know the acute and they're a bit kind <mark>of</mark> fluffy and nice looking and stuff. But there are things here in New Zealand. They don't get a lot <mark>of</mark> press one <mark>of</mark> them being the wet. Te which is a large insect and it's also endemic to New Zealand the with the Puma which is the giant WETA is actually so large that it occupies the same niche as rodents here in New Zealand, which is like kind <mark>of</mark> insane. Yeah. So when you see a niche that an animal occupies, you mean like in terms <mark>of</mark> the whole ecosystem like that's the role that it is playing exactly. Yeah, so instead <mark>of</mark> rodents being over here and you know there Eating like", "Start Time (s)": 121.0, "End Time (s)": 240.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "birds things like Kia car Kapoor. We've got things like to Kiwi, <mark>of</mark> course. That's the obvious one. Yeah. So we talked about the Kia in one <mark>of</mark> our episodes Christian actually talked about the Kia and that was pretty mind-blowing Kia are really strange. All <mark>of</mark> our animals are really strange but they get a lot <mark>of</mark> focus in the sense that you know the acute and they're a bit kind <mark>of</mark> fluffy and nice looking and stuff. But there are things here in New Zealand. They don't get a lot <mark>of</mark> press one <mark>of</mark> them being the wet. Te which is a large insect and it's also endemic to New Zealand the with the Puma which is the giant WETA is actually so large that it occupies the same niche as rodents here in New Zealand, which is like kind <mark>of</mark> insane. Yeah. So when you see a niche that an animal occupies, you mean like in terms <mark>of</mark> the whole ecosystem like that's the role that it is playing exactly. Yeah, so instead <mark>of</mark> rodents being over here and you know there Eating like seeds and being eaten by birds and that kind <mark>of</mark> stuff and the terms <mark>of</mark> like, you know the food chain and the food web and that kind <mark>of</mark> stuff because we don't have rodents here. They slaughtered into that section. Essentially they you know, they sit in that same area as what you'd expect a mouse or a rat to sit in as just that it so happens to be a very very large bug. Basically that's extremely impressive <mark>of</mark> her for a bug and especially considering that you you mentioned that There aren't any native mammals other than bats right? Because it seems like bats are so far removed from other mammals that I'm really surprised to hear that there aren't like native rodents or native. Like I don't know not I guess you wouldn't expect to find like canids but maybe like felines or something else along those lines. It's just back ya know that no snakes no mammals. No, it's basically just Birds bugs and reptiles and", "Start Time (s)": 176.6, "End Time (s)": 296.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "being eaten by birds and that kind <mark>of</mark> stuff and the terms <mark>of</mark> like, you know the food chain and the food web and that kind <mark>of</mark> stuff because we don't have rodents here. They slaughtered into that section. Essentially they you know, they sit in that same area as what you'd expect a mouse or a rat to sit in as just that it so happens to be a very very large bug. Basically that's extremely impressive <mark>of</mark> her for a bug and especially considering that you you mentioned that There aren't any native mammals other than bats right? Because it seems like bats are so far removed from other mammals that I'm really surprised to hear that there aren't like native rodents or native. Like I don't know not I guess you wouldn't expect to find like canids but maybe like felines or something else along those lines. It's just back ya know that no snakes no mammals. No, it's basically just Birds bugs and reptiles and that's about it and fish and stuff. I mean Okay, In fairness, we do kind <mark>of</mark> have native mammals but the seals and so they don't really count, you know, no native terrestrial mammals. Okay, if you want to get really specific if you want to get all technical. Yeah, okay sales are native to New Zealand as well, but we don't have any others that are terrestrial like proper terrestrial apart from the bats the interesting thing about the bats and fact as well is that the only species <mark>of</mark> bat that don't feed on the wing anywhere in the world our bad? It's actually will Court crawl along the ground looking for bugs and stuff instead <mark>of</mark> my God, which is yeah, very very unique. Yeah, that doesn't seem like they would be particularly. Well suited for that. Yeah, it's not really something when you watch them do it. It isn't really I guess coordinators if you want to call it that yeah, they definitely don't look like the design to do it necessarily but they seem to manage. So they're still around here. They seem to manage it nice. I guess a lot <mark>of</mark> the mammals that I was imagining when I think <mark>of</mark> New Zealand are mostly", "Start Time (s)": 242.1, "End Time (s)": 361.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and fish and stuff. I mean Okay, In fairness, we do kind <mark>of</mark> have native mammals but the seals and so they don't really count, you know, no native terrestrial mammals. Okay, if you want to get really specific if you want to get all technical. Yeah, okay sales are native to New Zealand as well, but we don't have any others that are terrestrial like proper terrestrial apart from the bats the interesting thing about the bats and fact as well is that the only species <mark>of</mark> bat that don't feed on the wing anywhere in the world our bad? It's actually will Court crawl along the ground looking for bugs and stuff instead <mark>of</mark> my God, which is yeah, very very unique. Yeah, that doesn't seem like they would be particularly. Well suited for that. Yeah, it's not really something when you watch them do it. It isn't really I guess coordinators if you want to call it that yeah, they definitely don't look like the design to do it necessarily but they seem to manage. So they're still around here. They seem to manage it nice. I guess a lot <mark>of</mark> the mammals that I was imagining when I think <mark>of</mark> New Zealand are mostly agricultural animals. Oh, so yeah livestock. Yeah shape is usually what people think <mark>of</mark> and we've got lots <mark>of</mark> that lots <mark>of</mark> cows lots <mark>of</mark> lots <mark>of</mark> sheep. Particularly Marino is the big one here in New Zealand. That's quite famous. But yeah again, you know, they're all introduced species. They're all you know, agricultural species that kind <mark>of</mark> stuff and because <mark>of</mark> that I don't really care about them. You're allowed to feel that way. Are there fine you know, but it's not what I deal with on a daily basis that the really cool stuff is the stuff that you can only find here in New Zealand in my opinion. Anyway, yeah, and that makes sense because you know being an island. It's such an isolated ecosystem, right and over the thousands and thousands <mark>of</mark> years you evolution is just going to kind <mark>of</mark> go Haywire with it, right you're going to get some insane specialization pretty much wealth are technically it's three main islands", "Start Time (s)": 297.7, "End Time (s)": 417.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "definitely don't look like the design to do it necessarily but they seem to manage. So they're still around here. They seem to manage it nice. I guess a lot <mark>of</mark> the mammals that I was imagining when I think <mark>of</mark> New Zealand are mostly agricultural animals. Oh, so yeah livestock. Yeah shape is usually what people think <mark>of</mark> and we've got lots <mark>of</mark> that lots <mark>of</mark> cows lots <mark>of</mark> lots <mark>of</mark> sheep. Particularly Marino is the big one here in New Zealand. That's quite famous. But yeah again, you know, they're all introduced species. They're all you know, agricultural species that kind <mark>of</mark> stuff and because <mark>of</mark> that I don't really care about them. You're allowed to feel that way. Are there fine you know, but it's not what I deal with on a daily basis that the really cool stuff is the stuff that you can only find here in New Zealand in my opinion. Anyway, yeah, and that makes sense because you know being an island. It's such an isolated ecosystem, right and over the thousands and thousands <mark>of</mark> years you evolution is just going to kind <mark>of</mark> go Haywire with it, right you're going to get some insane specialization pretty much wealth are technically it's three main islands and a series <mark>of</mark> outlying islands, but It is we broke off very very early on we used to be connected to Australia and can use Australian used to be connected to wider gondwanaland and we were kind <mark>of</mark> one <mark>of</mark> the first land masses to kind <mark>of</mark> pull away from everyone else and you know all those animals that couldn't fly or anything like that. Just you know, that was it like you they were stuck here basically and so yes, we've been isolated for a significantly larger proportion <mark>of</mark> time than most <mark>of</mark> the world. Which yeah is you say, you know, you start to get mad specialization you start to get a lot <mark>of</mark> flightless birds because there's no ground-dwelling mammalian predators to attack them and stuff and you get you know, huge more which is a relation to the ostrich <mark>of</mark> the cassowary, you know, two meters tall 230", "Start Time (s)": 348.4, "End Time (s)": 468.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "right and over the thousands and thousands <mark>of</mark> years you evolution is just going to kind <mark>of</mark> go Haywire with it, right you're going to get some insane specialization pretty much wealth are technically it's three main islands and a series <mark>of</mark> outlying islands, but It is we broke off very very early on we used to be connected to Australia and can use Australian used to be connected to wider gondwanaland and we were kind <mark>of</mark> one <mark>of</mark> the first land masses to kind <mark>of</mark> pull away from everyone else and you know all those animals that couldn't fly or anything like that. Just you know, that was it like you they were stuck here basically and so yes, we've been isolated for a significantly larger proportion <mark>of</mark> time than most <mark>of</mark> the world. Which yeah is you say, you know, you start to get mad specialization you start to get a lot <mark>of</mark> flightless birds because there's no ground-dwelling mammalian predators to attack them and stuff and you get you know, huge more which is a relation to the ostrich <mark>of</mark> the cassowary, you know, two meters tall 230 kgs and wait. Yeah and you get things like the hearts Eagle which is got like something ridiculous like a five or six meter wingspan or something which fortunately or unfortunately depending on how you look at it. Those are now Extinct. So yes, you get these really weird kind <mark>of</mark> animals and you get you know is easy to get things like kiwi car cup or yeah, all these really strange looking animals, which will you know, they lose bits game bits and all sorts <mark>of</mark> different stuff. Yeah. It's really really weird. But it's also really really interesting. So like before we talk about our specific animal for today, if you'd like just take a second to explain like how you got into like the conservation work that you do. Yeah, how Did I get into kind <mark>of</mark> fell into it? I guess we're not it kind <mark>of</mark> started when I was at Uni. I actually initially started and started doing it uni genetics specifically and I got to the end <mark>of</mark> my first year and decided", "Start Time (s)": 405.4, "End Time (s)": 525.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "ground-dwelling mammalian predators to attack them and stuff and you get you know, huge more which is a relation to the ostrich <mark>of</mark> the cassowary, you know, two meters tall 230 kgs and wait. Yeah and you get things like the hearts Eagle which is got like something ridiculous like a five or six meter wingspan or something which fortunately or unfortunately depending on how you look at it. Those are now Extinct. So yes, you get these really weird kind <mark>of</mark> animals and you get you know is easy to get things like kiwi car cup or yeah, all these really strange looking animals, which will you know, they lose bits game bits and all sorts <mark>of</mark> different stuff. Yeah. It's really really weird. But it's also really really interesting. So like before we talk about our specific animal for today, if you'd like just take a second to explain like how you got into like the conservation work that you do. Yeah, how Did I get into kind <mark>of</mark> fell into it? I guess we're not it kind <mark>of</mark> started when I was at Uni. I actually initially started and started doing it uni genetics specifically and I got to the end <mark>of</mark> my first year and decided that hey genetics is really hard and I don't know if I'm cut out for it. So I didn't enjoy it as much as I thought I would but I did this one paper in my second semester that was just animal biology which is talked about animals all the time and like Like what their behaviors like and what this structure is like, well the physiology is like and all this other stuff. I was like, hey, that's pretty cool. I might just do that for the rest <mark>of</mark> my degree. So oh my gosh, that is the dream. Yeah. So I just rejigged my degree so that instead <mark>of</mark> majoring in genetics. I was minoring in genetics, but I majored in Zoology. So that's the other thing. I'm not just like, you know talking through a hole in my head. I do actually kind <mark>of</mark> know what I'm talking about. Sure. Yeah. What Qualifications migrate qualification, but it's a qualification. Hey, I will give you this.", "Start Time (s)": 456.6, "End Time (s)": 576.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "when I was at Uni. I actually initially started and started doing it uni genetics specifically and I got to the end <mark>of</mark> my first year and decided that hey genetics is really hard and I don't know if I'm cut out for it. So I didn't enjoy it as much as I thought I would but I did this one paper in my second semester that was just animal biology which is talked about animals all the time and like Like what their behaviors like and what this structure is like, well the physiology is like and all this other stuff. I was like, hey, that's pretty cool. I might just do that for the rest <mark>of</mark> my degree. So oh my gosh, that is the dream. Yeah. So I just rejigged my degree so that instead <mark>of</mark> majoring in genetics. I was minoring in genetics, but I majored in Zoology. So that's the other thing. I'm not just like, you know talking through a hole in my head. I do actually kind <mark>of</mark> know what I'm talking about. Sure. Yeah. What Qualifications migrate qualification, but it's a qualification. Hey, I will give you this. It is more <mark>of</mark> a qualification than I have. So you've already got that up on me. Either <mark>of</mark> us. Really? Yeah, either <mark>of</mark> us. You heard you already one-upped both <mark>of</mark> us. Wow. It's about to get worse. So today so you have you actually came up with the idea. Well, so I believe it was like a few months ago we put Put out a call for animal requests and you had the idea <mark>of</mark> talking about the Tuatara. Is this an acceptable way to pronounce it by the way to a torrent is an acceptable way to pronounce it. It's not quite the technically correct way to pronounce it, but 99% <mark>of</mark> people will pronounce it that way and it is sufficient. If I receive a passing score you did its it's like a it's like an a-minus right? You would have got A plus if you got you know the rest <mark>of</mark> it. The a but you know, it's pretty good. Well C's get degrees baby. So exactly take what I can get. That's how I", "Start Time (s)": 516.8, "End Time (s)": 636.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "What Qualifications migrate qualification, but it's a qualification. Hey, I will give you this. It is more <mark>of</mark> a qualification than I have. So you've already got that up on me. Either <mark>of</mark> us. Really? Yeah, either <mark>of</mark> us. You heard you already one-upped both <mark>of</mark> us. Wow. It's about to get worse. So today so you have you actually came up with the idea. Well, so I believe it was like a few months ago we put Put out a call for animal requests and you had the idea <mark>of</mark> talking about the Tuatara. Is this an acceptable way to pronounce it by the way to a torrent is an acceptable way to pronounce it. It's not quite the technically correct way to pronounce it, but 99% <mark>of</mark> people will pronounce it that way and it is sufficient. If I receive a passing score you did its it's like a it's like an a-minus right? You would have got A plus if you got you know the rest <mark>of</mark> it. The a but you know, it's pretty good. Well C's get degrees baby. So exactly take what I can get. That's how I finish my degree if you had the idea to write this animal and I committed the crime pretty much immediately <mark>of</mark> identifying it as a lizard you did and annoys me greatly. I know it was a it was a sin that I have repented. So what I what I used to tell people is we don't you is the L word we're talking about to a toddler. So I'm getting that right out <mark>of</mark> the way right at the top. Not a lizard. Yep. They are not ilysm. So explain a little bit. You're like your relationship with this animal and like you're sort <mark>of</mark> background and experience with the Tuatara. Yeah. So not long after I finished I finished uni, <mark>of</mark> course. I was looking for a zoology type job, and I found one working at an aquarium was just so happened", "Start Time (s)": 569.7, "End Time (s)": 689.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "If I receive a passing score you did its it's like a it's like an a-minus right? You would have got A plus if you got you know the rest <mark>of</mark> it. The a but you know, it's pretty good. Well C's get degrees baby. So exactly take what I can get. That's how I finish my degree if you had the idea to write this animal and I committed the crime pretty much immediately <mark>of</mark> identifying it as a lizard you did and annoys me greatly. I know it was a it was a sin that I have repented. So what I what I used to tell people is we don't you is the L word we're talking about to a toddler. So I'm getting that right out <mark>of</mark> the way right at the top. Not a lizard. Yep. They are not ilysm. So explain a little bit. You're like your relationship with this animal and like you're sort <mark>of</mark> background and experience with the Tuatara. Yeah. So not long after I finished I finished uni, <mark>of</mark> course. I was looking for a zoology type job, and I found one working at an aquarium was just so happened to be He also looking after a variety <mark>of</mark> other animals one <mark>of</mark> them being the Tuatara and so we had two species <mark>of</mark> Tortola which was the Cook Strait in the brothers Island to at utter and that was part <mark>of</mark> my job was to look after them feed them and pull them out and get people to touch them and talk about them and all that sort <mark>of</mark> stuff and I did that for about two years. So I know you guys like, you know, explaining your sources and stuff. Unfortunately for this my source will be me in my experience <mark>of</mark> working with them. You are allowed to do that. As well as things like the department <mark>of</mark> conservation and that kind <mark>of</mark> stuff as well and which are always a very reliable source, but icing on the cake. Yeah. Unfortunately, it's just out <mark>of</mark> my brain most <mark>of</mark> the stuff that is completely 100% allowed and you are you know what this is about you. So you are good to go. Everything's about me. So for people who", "Start Time (s)": 621.4, "End Time (s)": 741.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "looking after a variety <mark>of</mark> other animals one <mark>of</mark> them being the Tuatara and so we had two species <mark>of</mark> Tortola which was the Cook Strait in the brothers Island to at utter and that was part <mark>of</mark> my job was to look after them feed them and pull them out and get people to touch them and talk about them and all that sort <mark>of</mark> stuff and I did that for about two years. So I know you guys like, you know, explaining your sources and stuff. Unfortunately for this my source will be me in my experience <mark>of</mark> working with them. You are allowed to do that. As well as things like the department <mark>of</mark> conservation and that kind <mark>of</mark> stuff as well and which are always a very reliable source, but icing on the cake. Yeah. Unfortunately, it's just out <mark>of</mark> my brain most <mark>of</mark> the stuff that is completely 100% allowed and you are you know what this is about you. So you are good to go. Everything's about me. So for people who like me apparently no, like literally nothing about this animal because unfortunately, it is something that I feel does not get A lot <mark>of</mark> the media coverage that some <mark>of</mark> the other like you said more like fluffy and adorable creators from New Zealand get can you take a second to kind <mark>of</mark> introduce this animal? Like how big are they and what do they look like? Okay, so they are reptiles and so they do look ripped Ilion, and they do kind <mark>of</mark> a little look like crocodiles because crocodiles are the closest kind <mark>of</mark> relation. Okay, they don't it's kind <mark>of</mark> hard to explain because like they don't really look like that. But once you know that they are related to crocodiles you can kind <mark>of</mark> go moo, you know, kind <mark>of</mark> a kind <mark>of</mark> see this, you know, so that they kind <mark>of</mark> look like crocodiles a little bit. So yeah, so they are reptiles they just not lizards and there are about 200 60 centimeters in length, which I think is like 20, I think that's 20 inches ish. Okay. Thanks. I think it's like about like forearm plus hand length. Yeah.", "Start Time (s)": 690.8, "End Time (s)": 809.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "some <mark>of</mark> the other like you said more like fluffy and adorable creators from New Zealand get can you take a second to kind <mark>of</mark> introduce this animal? Like how big are they and what do they look like? Okay, so they are reptiles and so they do look ripped Ilion, and they do kind <mark>of</mark> a little look like crocodiles because crocodiles are the closest kind <mark>of</mark> relation. Okay, they don't it's kind <mark>of</mark> hard to explain because like they don't really look like that. But once you know that they are related to crocodiles you can kind <mark>of</mark> go moo, you know, kind <mark>of</mark> a kind <mark>of</mark> see this, you know, so that they kind <mark>of</mark> look like crocodiles a little bit. So yeah, so they are reptiles they just not lizards and there are about 200 60 centimeters in length, which I think is like 20, I think that's 20 inches ish. Okay. Thanks. I think it's like about like forearm plus hand length. Yeah. Roughly there's so this roughly the size <mark>of</mark> a feely everage adult sort <mark>of</mark> mail is about that size, but they start out obviously very very small, you know, like, you know millimeters so they start out very very small and then grow quite large but they grow quite slowly over time because they were a I guess we'll talk a little bit later, but they last they live for a very very long time. So they grow very very slowly. So yeah, so they're not huge the ones that I used to look after would sit quite comfortably on my forearm, you know from his head. Could be yes head would be about my elbow and his tail would reach about to probably about my palm maybe a little bit longer. So they're not huge animals by any stretch <mark>of</mark> the imagination but they're not necessarily small either at least the adults. So they just kind <mark>of</mark> a weird kind <mark>of</mark> reptile that has a lot <mark>of</mark> their very unassuming because they don't move a lot and they're very famous for not moving a lot relatable me also. Yeah, exactly. And so yeah, so they're very very unassuming sort <mark>of</mark> animals, but there's a lot going on there. A lot <mark>of</mark> people don't know about kind <mark>of</mark>", "Start Time (s)": 752.4, "End Time (s)": 871.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "plus hand length. Yeah. Roughly there's so this roughly the size <mark>of</mark> a feely everage adult sort <mark>of</mark> mail is about that size, but they start out obviously very very small, you know, like, you know millimeters so they start out very very small and then grow quite large but they grow quite slowly over time because they were a I guess we'll talk a little bit later, but they last they live for a very very long time. So they grow very very slowly. So yeah, so they're not huge the ones that I used to look after would sit quite comfortably on my forearm, you know from his head. Could be yes head would be about my elbow and his tail would reach about to probably about my palm maybe a little bit longer. So they're not huge animals by any stretch <mark>of</mark> the imagination but they're not necessarily small either at least the adults. So they just kind <mark>of</mark> a weird kind <mark>of</mark> reptile that has a lot <mark>of</mark> their very unassuming because they don't move a lot and they're very famous for not moving a lot relatable me also. Yeah, exactly. And so yeah, so they're very very unassuming sort <mark>of</mark> animals, but there's a lot going on there. A lot <mark>of</mark> people don't know about kind <mark>of</mark> physiologically and that kind <mark>of</mark> stuff and reasons why they do certain things and that kind <mark>of</mark> stuff that really surprises a lot <mark>of</mark> people I find that you know, there's just this weird looking reptile and then you tell them all the stuff like, oh that's kind <mark>of</mark> neat. You know, that is a perfect transition into our first category. Yep that we if this is your first time joining us on this podcast, we're eight animals out <mark>of</mark> 10 in three categories, and our first category is Effectiveness which we Define on our show as an animal's physical adaptations that let them do a good job <mark>of</mark> the things that they're trying to do. So, what would you give the Tuatara for Effectiveness? I'd probably give it up, right it probably pretty high because essentially it needs to be effective at doing nothing and it is very effective at doing nothing. So I'd probably put it like an 8 or a", "Start Time (s)": 807.8, "End Time (s)": 927.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "know about kind <mark>of</mark> physiologically and that kind <mark>of</mark> stuff and reasons why they do certain things and that kind <mark>of</mark> stuff that really surprises a lot <mark>of</mark> people I find that you know, there's just this weird looking reptile and then you tell them all the stuff like, oh that's kind <mark>of</mark> neat. You know, that is a perfect transition into our first category. Yep that we if this is your first time joining us on this podcast, we're eight animals out <mark>of</mark> 10 in three categories, and our first category is Effectiveness which we Define on our show as an animal's physical adaptations that let them do a good job <mark>of</mark> the things that they're trying to do. So, what would you give the Tuatara for Effectiveness? I'd probably give it up, right it probably pretty high because essentially it needs to be effective at doing nothing and it is very effective at doing nothing. So I'd probably put it like an 8 or a 9 so quite quite high up there. So this is kind <mark>of</mark> what I mean by these reasons like these interesting reasons for why they do these sorts <mark>of</mark> things and in the case <mark>of</mark> the reason why they don't move is because their main Predator is Birds <mark>of</mark> Prey and birds <mark>of</mark> prey quite famously have very good eyesight. So you got your Hawks in your Falcons and that sort <mark>of</mark> thing, you know, they're flying over the forest and they're looking down looking for something to eat. Naturally if you move around that's going to draw the eye they're going to see the more likely to see you and therefore you're more likely to get Eaten, so if you sit still and you're all kind <mark>of</mark> green and camouflage like the Tuatara is you're less likely to be seen and less likely to be eaten. So that's kind <mark>of</mark> why they do that and that's why I think they're quite you know, that's that's extremely effective. You know, these guys have lasted, you know, a very very long time which is something I probably should have mentioned at the top is these guys are often called living fossils. And the sense that they haven't evolved pretty much at all since the time <mark>of</mark> the dinosaurs. So they are pretty much as close as you'll get. To an", "Start Time (s)": 870.6, "End Time (s)": 990.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it like an 8 or a 9 so quite quite high up there. So this is kind <mark>of</mark> what I mean by these reasons like these interesting reasons for why they do these sorts <mark>of</mark> things and in the case <mark>of</mark> the reason why they don't move is because their main Predator is Birds <mark>of</mark> Prey and birds <mark>of</mark> prey quite famously have very good eyesight. So you got your Hawks in your Falcons and that sort <mark>of</mark> thing, you know, they're flying over the forest and they're looking down looking for something to eat. Naturally if you move around that's going to draw the eye they're going to see the more likely to see you and therefore you're more likely to get Eaten, so if you sit still and you're all kind <mark>of</mark> green and camouflage like the Tuatara is you're less likely to be seen and less likely to be eaten. So that's kind <mark>of</mark> why they do that and that's why I think they're quite you know, that's that's extremely effective. You know, these guys have lasted, you know, a very very long time which is something I probably should have mentioned at the top is these guys are often called living fossils. And the sense that they haven't evolved pretty much at all since the time <mark>of</mark> the dinosaurs. So they are pretty much as close as you'll get. To an actual dinosaur so they haven't really evolved at all and that kind <mark>of</mark> hinders them as well because with the hold not moving very much thing that works and the sense that it's designed to combat very very good eyesight. It's not very good at combating very very good noses, which is what things like stoats and rats use. Yeah, so they'll come along and they sniff out the to at Ulta and the Thought is just sitting there going. Oh, yeah, if I stay still it'll be fine. <mark>Of</mark> course the it's like well, I've seen you now. So I just gotta I just gotta run up and grab ya. Oh, man, so they're not very good at that. And the other thing is that generally if taught <mark>of</mark> feels kind <mark>of</mark> threatened it'll just run straight into its burrow because they do burrow underground and that's kind <mark>of</mark> where they live and keep the eggs and that kind <mark>of</mark> stuff and that's really good against a bird caws Birds. Just going to look in the hole and go. No, I'm not into", "Start Time (s)": 926.4, "End Time (s)": 1046.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "should have mentioned at the top is these guys are often called living fossils. And the sense that they haven't evolved pretty much at all since the time <mark>of</mark> the dinosaurs. So they are pretty much as close as you'll get. To an actual dinosaur so they haven't really evolved at all and that kind <mark>of</mark> hinders them as well because with the hold not moving very much thing that works and the sense that it's designed to combat very very good eyesight. It's not very good at combating very very good noses, which is what things like stoats and rats use. Yeah, so they'll come along and they sniff out the to at Ulta and the Thought is just sitting there going. Oh, yeah, if I stay still it'll be fine. <mark>Of</mark> course the it's like well, I've seen you now. So I just gotta I just gotta run up and grab ya. Oh, man, so they're not very good at that. And the other thing is that generally if taught <mark>of</mark> feels kind <mark>of</mark> threatened it'll just run straight into its burrow because they do burrow underground and that's kind <mark>of</mark> where they live and keep the eggs and that kind <mark>of</mark> stuff and that's really good against a bird caws Birds. Just going to look in the hole and go. No, I'm not into that. No way whereas a stone or a rat just going to go. Sweet isn't just follow you down. No worries bed and breakfast exactly. So so the very fact that the thing is you find this a lot with with New Zealand animals is they very effective it the environment that they evolved them. They are not very effective with all <mark>of</mark> these new weird thing dangly rats and Stokes and possums and hedgehogs and everything else going on coming over because they're just have no way to combat them. So I Still rated them highly because <mark>of</mark> that but yeah, they're not very effective because <mark>of</mark> the because <mark>of</mark> the whole against rats and stoats and that kind <mark>of</mark> stuff. Unfortunately. I will give them that that is not their fault. Yeah, that's kinda that's kind <mark>of</mark> what I thought is like they're effective with what they were meant to do not with the situation here.", "Start Time (s)": 978.8, "End Time (s)": 1098.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "generally if taught <mark>of</mark> feels kind <mark>of</mark> threatened it'll just run straight into its burrow because they do burrow underground and that's kind <mark>of</mark> where they live and keep the eggs and that kind <mark>of</mark> stuff and that's really good against a bird caws Birds. Just going to look in the hole and go. No, I'm not into that. No way whereas a stone or a rat just going to go. Sweet isn't just follow you down. No worries bed and breakfast exactly. So so the very fact that the thing is you find this a lot with with New Zealand animals is they very effective it the environment that they evolved them. They are not very effective with all <mark>of</mark> these new weird thing dangly rats and Stokes and possums and hedgehogs and everything else going on coming over because they're just have no way to combat them. So I Still rated them highly because <mark>of</mark> that but yeah, they're not very effective because <mark>of</mark> the because <mark>of</mark> the whole against rats and stoats and that kind <mark>of</mark> stuff. Unfortunately. I will give them that that is not their fault. Yeah, that's kinda that's kind <mark>of</mark> what I thought is like they're effective with what they were meant to do not with the situation here. And now which is not natural if you want to call it that one <mark>of</mark> the other ways actually they stopped from being able to basically be eaten by birds <mark>of</mark> prey. Is there cake she got a third eye in the center <mark>of</mark> the forehead? Well, hold on what? Yeah. Yeah. So what yeah. Yeah, the fact that you did not lead with that is like Hasbro's like the least interesting thing about so so In fairness I do I should put I in quotation marks. It's not quite an eye. It's a photoreceptor. So it basically can only tell if light is there or not? You can't actually see out <mark>of</mark> it essentially. So it's not strictly a third eye. It's a light detection thing. Essentially. I can't detect any light out <mark>of</mark> the top <mark>of</mark> my head. So", "Start Time (s)": 1032.7, "End Time (s)": 1152.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Yeah, that's kinda that's kind <mark>of</mark> what I thought is like they're effective with what they were meant to do not with the situation here. And now which is not natural if you want to call it that one <mark>of</mark> the other ways actually they stopped from being able to basically be eaten by birds <mark>of</mark> prey. Is there cake she got a third eye in the center <mark>of</mark> the forehead? Well, hold on what? Yeah. Yeah. So what yeah. Yeah, the fact that you did not lead with that is like Hasbro's like the least interesting thing about so so In fairness I do I should put I in quotation marks. It's not quite an eye. It's a photoreceptor. So it basically can only tell if light is there or not? You can't actually see out <mark>of</mark> it essentially. So it's not strictly a third eye. It's a light detection thing. Essentially. I can't detect any light out <mark>of</mark> the top <mark>of</mark> my head. So this is already more <mark>of</mark> an eye more <mark>of</mark> a third eye than I have to say. This is cool because we've seen this in other animals like the horseshoe crab and I think also the praying mantis. Yeah. So the president has had something similar that was like ocelli in a similar position like on top <mark>of</mark> Head to see if it's light or dark above them. But that's in praying mantises. Right? Like that's very far removed from reptiles. Yeah. Hey there post-production Ellen here this third eye that's like a photoreceptor shorter thing. This is called a parietal eye and I did a little bit <mark>of</mark> research after we recorded this episode and I found out that this parietal eye is actually found in many species <mark>of</mark> lizards and amphibians like frogs. It's also present. Isn't in sharks and lampreys, but what's really interesting is that it is absent in mammals as well as Turtles birds and crocodilians. So", "Start Time (s)": 1091.4, "End Time (s)": 1210.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "This is cool because we've seen this in other animals like the horseshoe crab and I think also the praying mantis. Yeah. So the president has had something similar that was like ocelli in a similar position like on top <mark>of</mark> Head to see if it's light or dark above them. But that's in praying mantises. Right? Like that's very far removed from reptiles. Yeah. Hey there post-production Ellen here this third eye that's like a photoreceptor shorter thing. This is called a parietal eye and I did a little bit <mark>of</mark> research after we recorded this episode and I found out that this parietal eye is actually found in many species <mark>of</mark> lizards and amphibians like frogs. It's also present. Isn't in sharks and lampreys, but what's really interesting is that it is absent in mammals as well as Turtles birds and crocodilians. So I thought that was pretty weird and cool anyway back to the episode. So yeah, so partially what that Third Kind <mark>of</mark> photoreceptor is for is to detect you know Birds essentially because what it does is it detects UV light specifically so essentially light from the sun because they need that UV light. To keep the bones nice and strong. So they'll use it to partially to know whether there is light in the area and so they can go all yeah. I'll sit here for a bit and get some nice to UV light and like I right I've had enough and like move long ago right Shady here. I'll sit here for a bit. But they also use it to detect whether a bird is coming because <mark>of</mark> course if a bird is bearing down on you, he's probably covering the Sun and you can go. Oh no, I need a run, um, you know Scrabble down and to you and to your burro, so as use partially for that as well and the cool thing is you can actually see See that I win the Toyota is very very young. So it's actually like a little silver dot in the center <mark>of</mark> the forehead and then it gets scaled over as they get a bit older. It's still there, but you just can't see it anymore. So yeah, so that's a weird thing that they do, you know, I've only ever seen them in pictures, but in pictures", "Start Time (s)": 1157.4, "End Time (s)": 1277.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to detect you know Birds essentially because what it does is it detects UV light specifically so essentially light from the sun because they need that UV light. To keep the bones nice and strong. So they'll use it to partially to know whether there is light in the area and so they can go all yeah. I'll sit here for a bit and get some nice to UV light and like I right I've had enough and like move long ago right Shady here. I'll sit here for a bit. But they also use it to detect whether a bird is coming because <mark>of</mark> course if a bird is bearing down on you, he's probably covering the Sun and you can go. Oh no, I need a run, um, you know Scrabble down and to you and to your burro, so as use partially for that as well and the cool thing is you can actually see See that I win the Toyota is very very young. So it's actually like a little silver dot in the center <mark>of</mark> the forehead and then it gets scaled over as they get a bit older. It's still there, but you just can't see it anymore. So yeah, so that's a weird thing that they do, you know, I've only ever seen them in pictures, but in pictures it looks like they do kind <mark>of</mark> have some like tactical defense spikes on them that I like the birds <mark>of</mark> prey. I'm about to burst your bubble here. Man those spikes for starters. Those spikes are actually what the what the Tuatara is named after so to a toddler in today on Mile D. Which is the Maori language, which is the language Maori are the indigenous peoples <mark>of</mark> New Zealand. Tuatara actually means in Maori Peaks on the back and reference to those spines. Wow. So that's a yes you fun fact for the day. So the the spines again quote unquote spines. They're not spines at all. They look like Like they are hard pieces <mark>of</mark> bone coming kind <mark>of</mark> out the back <mark>of</mark> the <mark>of</mark> the Tuatara. They're not they're actually just soft bits are scared and you can actually run your finger down them and they just flattened they're not harmful at all. They just for show. Wow, so you have plated not only me but the actual spines on the back.", "Start Time (s)": 1219.6, "End Time (s)": 1338.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "actually means in Maori Peaks on the back and reference to those spines. Wow. So that's a yes you fun fact for the day. So the the spines again quote unquote spines. They're not spines at all. They look like Like they are hard pieces <mark>of</mark> bone coming kind <mark>of</mark> out the back <mark>of</mark> the <mark>of</mark> the Tuatara. They're not they're actually just soft bits are scared and you can actually run your finger down them and they just flattened they're not harmful at all. They just for show. Wow, so you have plated not only me but the actual spines on the back. Yeah. Yeah, so you can just run your finger down them and it's not painful at all. Yeah, they just put some loud. Actually that that is something that I'm really glad you told me because since the only exposure that I have to and quite possibly will ever have to them is only seeing them in pictures and I feel like that is something I would not have known if you had not explicitly told me that yeah, so there it's something I used to get a lot because I pulled the toilet out and people be quite scared to touch and say oh no, they just soft little bits <mark>of</mark> skin, but particularly because they actually use those more so for the males when they're fighting each other for compete competition for mates and that kind <mark>of</mark> thing the males were actually puff up those spines like kind <mark>of</mark> the the just underneath it. I can provide a picture as well. If you want to put those in the show notes from one that I've taken but these big they get this big sort <mark>of</mark> like Ridge on their backs and increases the spine size by like double or even triple to make themselves look bigger and scarier and that sort <mark>of</mark> thing for when they fighting other male Tuatara and that kind <mark>of</mark> I guess if you want to call it perpetuates the myth essentially that these spines are very very hard and dangerous and that sort <mark>of</mark> thing but they're not at all they just yeah soft little bits <mark>of</mark> skin that don't really Really do anything except make them look scary. Essentially. I bet they would be so mad to know that you are out here giving away all <mark>of</mark> their secrets and telling everybody that they're not actually as tough and scary as they look like they are they they probably are so", "Start Time (s)": 1306.3, "End Time (s)": 1425.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "yeah, so there it's something I used to get a lot because I pulled the toilet out and people be quite scared to touch and say oh no, they just soft little bits <mark>of</mark> skin, but particularly because they actually use those more so for the males when they're fighting each other for compete competition for mates and that kind <mark>of</mark> thing the males were actually puff up those spines like kind <mark>of</mark> the the just underneath it. I can provide a picture as well. If you want to put those in the show notes from one that I've taken but these big they get this big sort <mark>of</mark> like Ridge on their backs and increases the spine size by like double or even triple to make themselves look bigger and scarier and that sort <mark>of</mark> thing for when they fighting other male Tuatara and that kind <mark>of</mark> I guess if you want to call it perpetuates the myth essentially that these spines are very very hard and dangerous and that sort <mark>of</mark> thing but they're not at all they just yeah soft little bits <mark>of</mark> skin that don't really Really do anything except make them look scary. Essentially. I bet they would be so mad to know that you are out here giving away all <mark>of</mark> their secrets and telling everybody that they're not actually as tough and scary as they look like they are they they probably are so hurt by your betrayal <mark>of</mark> the the illusion that they've been constructing over thousands <mark>of</mark> years. The thing the thing is though that they are they are scary. They are quite tough just another way. Ways so one <mark>of</mark> the things I used to have to tell people is do not put your finger in front <mark>of</mark> the Torterra because naturally it will bite you and people were like, oh, yeah. Okay fair enough. Yeah. Yeah. Yeah, you know, but you always get that one guy goes. No, I'm gonna do it. I'm gonna do it. I'm like, let me just finish so he go. Okay, that's fine. You want to stick your hand fingering for the toilet Allen get bitten, that's fine. But believe me finish talking. Let me finish telling you about what's going to happen because what's going to happen? Is the Tuatara has ones row <mark>of</mark> teeth on the bottom in two rows <mark>of</mark> teeth on the top <mark>of</mark> its mouth so you can have three rows <mark>of</mark> teeth", "Start Time (s)": 1358.6, "End Time (s)": 1478.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I bet they would be so mad to know that you are out here giving away all <mark>of</mark> their secrets and telling everybody that they're not actually as tough and scary as they look like they are they they probably are so hurt by your betrayal <mark>of</mark> the the illusion that they've been constructing over thousands <mark>of</mark> years. The thing the thing is though that they are they are scary. They are quite tough just another way. Ways so one <mark>of</mark> the things I used to have to tell people is do not put your finger in front <mark>of</mark> the Torterra because naturally it will bite you and people were like, oh, yeah. Okay fair enough. Yeah. Yeah. Yeah, you know, but you always get that one guy goes. No, I'm gonna do it. I'm gonna do it. I'm like, let me just finish so he go. Okay, that's fine. You want to stick your hand fingering for the toilet Allen get bitten, that's fine. But believe me finish talking. Let me finish telling you about what's going to happen because what's going to happen? Is the Tuatara has ones row <mark>of</mark> teeth on the bottom in two rows <mark>of</mark> teeth on the top <mark>of</mark> its mouth so you can have three rows <mark>of</mark> teeth chomping down on your finger. The thing about that is that those teeth are serrated. So they've got jaggedy edges on them. And what they're going to do is they're going to say there grab your finger. They're going to start grinding their teeth. They're going to start moving the jaw to try and saw blade through your fingers so that they can Lop it off and you know and eat it. And the problem with that is we're gonna have two things. I'm not done yet. I'm not done yet. So the problem with that is that could happen for quite some time because they're torta is not going to let go <mark>of</mark> you until it takes us neat next breath. They can hold their breath render upwards <mark>of</mark> half an hour to an hour. So you're gonna be there a while. You're going to be in a reasonable amount <mark>of</mark> pain. And <mark>of</mark> course the guy goes. Well, there's fine. I'll just pull my finger out my go. Actually you're not allowed. Hayes and and", "Start Time (s)": 1413.6, "End Time (s)": 1532.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Allen get bitten, that's fine. But believe me finish talking. Let me finish telling you about what's going to happen because what's going to happen? Is the Tuatara has ones row <mark>of</mark> teeth on the bottom in two rows <mark>of</mark> teeth on the top <mark>of</mark> its mouth so you can have three rows <mark>of</mark> teeth chomping down on your finger. The thing about that is that those teeth are serrated. So they've got jaggedy edges on them. And what they're going to do is they're going to say there grab your finger. They're going to start grinding their teeth. They're going to start moving the jaw to try and saw blade through your fingers so that they can Lop it off and you know and eat it. And the problem with that is we're gonna have two things. I'm not done yet. I'm not done yet. So the problem with that is that could happen for quite some time because they're torta is not going to let go <mark>of</mark> you until it takes us neat next breath. They can hold their breath render upwards <mark>of</mark> half an hour to an hour. So you're gonna be there a while. You're going to be in a reasonable amount <mark>of</mark> pain. And <mark>of</mark> course the guy goes. Well, there's fine. I'll just pull my finger out my go. Actually you're not allowed. Hayes and and all they'll say something like oh, but you just you just take it off right and I go actually no because Tuatara worthy first Native species in New Zealand to be legally protected under New Zealand law. I am not allowed to force the Tuatara to let go <mark>of</mark> you. I can't force a Jaws open. You can't even pull your finger at you do just have to sit there and wait for it to let go <mark>of</mark> you and you're probably going to scream and holler for me to pull it off and I'm just going to not touch that with a ten-foot pole because I do not want to find Hey love, it. The government is like no, you legally have to face the repercussions <mark>of</mark> your actions. I believe it's a it's a weird thing <mark>of</mark> you're not allowed to really like, you know harmer Tuatara and that kind <mark>of</mark> stuff. I don't think that they explicitly say if you get bitten, you know allowed to touch them but it is and is kind <mark>of</mark> a they're quite heavily legally protected. So", "Start Time (s)": 1463.3, "End Time (s)": 1583.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So you're gonna be there a while. You're going to be in a reasonable amount <mark>of</mark> pain. And <mark>of</mark> course the guy goes. Well, there's fine. I'll just pull my finger out my go. Actually you're not allowed. Hayes and and all they'll say something like oh, but you just you just take it off right and I go actually no because Tuatara worthy first Native species in New Zealand to be legally protected under New Zealand law. I am not allowed to force the Tuatara to let go <mark>of</mark> you. I can't force a Jaws open. You can't even pull your finger at you do just have to sit there and wait for it to let go <mark>of</mark> you and you're probably going to scream and holler for me to pull it off and I'm just going to not touch that with a ten-foot pole because I do not want to find Hey love, it. The government is like no, you legally have to face the repercussions <mark>of</mark> your actions. I believe it's a it's a weird thing <mark>of</mark> you're not allowed to really like, you know harmer Tuatara and that kind <mark>of</mark> stuff. I don't think that they explicitly say if you get bitten, you know allowed to touch them but it is and is kind <mark>of</mark> a they're quite heavily legally protected. So yeah, so you got to be a bit careful about that kind <mark>of</mark> stuff and I'm just basically like in fairness. I don't know how a hundred percent true. Is I do know that there's some sort <mark>of</mark> legal stuff around that but I don't know like how much it what the punishment is or anything like that. If you do get caught but I was kind <mark>of</mark> like, you know what I'm not willing to risk this stop it. Yeah, you got to protect yourself as well and like yeah, give people fair warning like hey, I'm going to do nothing to help you. Yeah, exactly and it was also partially like look if you're stupid enough to get bitten by something that spins its entire day doing absolutely nothing you kind <mark>of</mark> deserve it. It sucks one. So since you mentioned that they live in a burrow, that's a pretty good segue into our next category, which is ingenuity. So Ingenuity we Define as behavioral adaptations that an animal has developed that kind <mark>of</mark>", "Start Time (s)": 1519.7, "End Time (s)": 1639.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>of</mark> a they're quite heavily legally protected. So yeah, so you got to be a bit careful about that kind <mark>of</mark> stuff and I'm just basically like in fairness. I don't know how a hundred percent true. Is I do know that there's some sort <mark>of</mark> legal stuff around that but I don't know like how much it what the punishment is or anything like that. If you do get caught but I was kind <mark>of</mark> like, you know what I'm not willing to risk this stop it. Yeah, you got to protect yourself as well and like yeah, give people fair warning like hey, I'm going to do nothing to help you. Yeah, exactly and it was also partially like look if you're stupid enough to get bitten by something that spins its entire day doing absolutely nothing you kind <mark>of</mark> deserve it. It sucks one. So since you mentioned that they live in a burrow, that's a pretty good segue into our next category, which is ingenuity. So Ingenuity we Define as behavioral adaptations that an animal has developed that kind <mark>of</mark> give it a sort <mark>of</mark> a Competitive Edge maybe like maybe it's good at figuring things out some examples might be tool used or hunting strategies or cool stuff and animal does So what would you give the Tuatara for Ingenuity? I'm really <mark>of</mark> two minds <mark>of</mark> this because on the one hand some <mark>of</mark> the stuff that they do is quite good and some <mark>of</mark> the stuff that they do is really bad like some <mark>of</mark> the stuff like they adult male Tuatara will delete any young to a tunnel that they come across without discrimination. They'll just go along huh young toddler eat it then it is a seed they don't make any disagreement Nation between between whether it's the own young or the young <mark>of</mark> some other male. That's not ideal. No, it's not ideal is a good way <mark>of</mark> putting it the because the idea is right. If you can eat the young <mark>of</mark> another mail, you can you know, your chances <mark>of</mark> you're young and your", "Start Time (s)": 1579.5, "End Time (s)": 1699.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Define as behavioral adaptations that an animal has developed that kind <mark>of</mark> give it a sort <mark>of</mark> a Competitive Edge maybe like maybe it's good at figuring things out some examples might be tool used or hunting strategies or cool stuff and animal does So what would you give the Tuatara for Ingenuity? I'm really <mark>of</mark> two minds <mark>of</mark> this because on the one hand some <mark>of</mark> the stuff that they do is quite good and some <mark>of</mark> the stuff that they do is really bad like some <mark>of</mark> the stuff like they adult male Tuatara will delete any young to a tunnel that they come across without discrimination. They'll just go along huh young toddler eat it then it is a seed they don't make any disagreement Nation between between whether it's the own young or the young <mark>of</mark> some other male. That's not ideal. No, it's not ideal is a good way <mark>of</mark> putting it the because the idea is right. If you can eat the young <mark>of</mark> another mail, you can you know, your chances <mark>of</mark> you're young and your jeans and you know, your Offspring and that kind <mark>of</mark> stuff being passed on increases, but <mark>of</mark> course, you don't know, you know, you can't go either a doctor or Tyler can't go up to the young and go. Who's your Daddy? Yeah, so they just have to do it in discriminately and that does sometimes result in their own young getting eaten if they're not careful. So, you know, there's like a like I see the logic behind it, but it just sometimes it backfires horribly. So yeah, maybe not the cleverest like long-term strategy. No not hugely, but the Thing is with Tata is they are case like this is another kind <mark>of</mark> behavior <mark>of</mark> thing as well is that they don't breed all their often and that's partially just because they are very very long-lived. So they live for about 200 250 years.", "Start Time (s)": 1633.4, "End Time (s)": 1753.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "No, it's not ideal is a good way <mark>of</mark> putting it the because the idea is right. If you can eat the young <mark>of</mark> another mail, you can you know, your chances <mark>of</mark> you're young and your jeans and you know, your Offspring and that kind <mark>of</mark> stuff being passed on increases, but <mark>of</mark> course, you don't know, you know, you can't go either a doctor or Tyler can't go up to the young and go. Who's your Daddy? Yeah, so they just have to do it in discriminately and that does sometimes result in their own young getting eaten if they're not careful. So, you know, there's like a like I see the logic behind it, but it just sometimes it backfires horribly. So yeah, maybe not the cleverest like long-term strategy. No not hugely, but the Thing is with Tata is they are case like this is another kind <mark>of</mark> behavior <mark>of</mark> thing as well is that they don't breed all their often and that's partially just because they are very very long-lived. So they live for about 200 250 years. I'm sorry. What? Yeah, we don't quite know how old they get because no one's really had one for long enough. He's made about 200 250 years. Uh-huh. I was going to say how old were the ones that You were caring for the ones that I looked after were the youngest ones were I think sort <mark>of</mark> 15 ish? Okay, which is another interesting implication as well. But the brothers Island to leotardo that are looking after the two males they were about 30 years old. Wow. Yeah, and that's relatively young for a toilet. Oh like the oldest living torta who was Henry and the invercargill museum or he was in the invercargill museum probably isn't any More he is about a hundred and twenty years years old. He's probably", "Start Time (s)": 1683.9, "End Time (s)": 1803.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "so I know that tortoises for example can get like getting older than like 100 or maybe even 200 years old. I don't know toward his life span that well, I'm sorry. Right, but that's the only animal no other than the Greenland shark, right which looks for like centuries and centuries and centuries like the 400. I think they won. Yeah, it's like a ridiculous. But why too long? Yeah, that's you know, what nothing was mean to be alive that long. You know, I think that that shark had a great strategy because it survived for 400 years by minding his own business exact. He's stuck to himself and he made it for hundred years. So like I've heard this like long-lived tendency and tortoises but I didn't really know that like smaller reptiles could live that impressively long. It's not necessarily to do with like the size or anything like that. I don't quite know about the Greenland shark, but the common theme between <mark>of</mark> course tortoises and Tuatara and most other long-lived species <mark>of</mark> this kind is that they don't do very much at all. You know, they're always said Around doing nothing the move very slowly usually so that causes, you know, internally, they don't get all those diseases associated with with age, you know, when you get old and that kind <mark>of</mark> stuff they don't their cells don't Decay and all that kind <mark>of</mark> stuff is often. So yeah, so it's doing less means you live longer and <mark>of</mark> course classically you get the people and the tour group that go sit on the couch all the time. That means I'm gonna live ages writing like this and certainly not how it works. Oh man, <mark>of</mark> course, they're there because they're cold blooded, you know, their internal processes are also slow down as well. So if anyone thinking hey, I don't do very much. That means I'll I'll live a while doesn't quite work for humans, unfortunately because you internally regulate your temperature which takes up a hell <mark>of</mark> a", "Start Time (s)": 1819.0, "End Time (s)": 1938.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "between <mark>of</mark> course tortoises and Tuatara and most other long-lived species <mark>of</mark> this kind is that they don't do very much at all. You know, they're always said Around doing nothing the move very slowly usually so that causes, you know, internally, they don't get all those diseases associated with with age, you know, when you get old and that kind <mark>of</mark> stuff they don't their cells don't Decay and all that kind <mark>of</mark> stuff is often. So yeah, so it's doing less means you live longer and <mark>of</mark> course classically you get the people and the tour group that go sit on the couch all the time. That means I'm gonna live ages writing like this and certainly not how it works. Oh man, <mark>of</mark> course, they're there because they're cold blooded, you know, their internal processes are also slow down as well. So if anyone thinking hey, I don't do very much. That means I'll I'll live a while doesn't quite work for humans, unfortunately because you internally regulate your temperature which takes up a hell <mark>of</mark> a lot <mark>of</mark> energy and food and stuff and that is what is going to do you win. So if you want to live a really long time, you got to figure out a way to turn that off. No one is figured. Is so one <mark>of</mark> these days working on it will get our top scientists on it. But you heard it here first. This is this is how we create immortality. We just turn our internal regulation off. Listen as though as the Earth gets warmer. We don't have to warm our own body temperature as much if it's always 98.6 degrees on the face <mark>of</mark> the Earth. Then we don't have to warm our bodies. I'm also pretty sure that's not how it works. But I don't know enough to say no. Oh my gosh. I'm very shook by quite a few things that I've learned so far. We're not finished yet. There's a lot to go. This is so much", "Start Time (s)": 1878.4, "End Time (s)": 1998.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and that is what is going to do you win. So if you want to live a really long time, you got to figure out a way to turn that off. No one is figured. Is so one <mark>of</mark> these days working on it will get our top scientists on it. But you heard it here first. This is this is how we create immortality. We just turn our internal regulation off. Listen as though as the Earth gets warmer. We don't have to warm our own body temperature as much if it's always 98.6 degrees on the face <mark>of</mark> the Earth. Then we don't have to warm our bodies. I'm also pretty sure that's not how it works. But I don't know enough to say no. Oh my gosh. I'm very shook by quite a few things that I've learned so far. We're not finished yet. There's a lot to go. This is so much more is so much more. All right hit me. So one <mark>of</mark> the interesting things about kind <mark>of</mark> their breeding and stuff. It's really hard to breed them like so hard to breed them because as I mentioned earlier the Mets Was need to fight each other or they they do fight each other to to be able to secure a mate because what happens is the female will sit there and watch the male's fight and she won't basically breed with either <mark>of</mark> them until she is a hundred percent sure that he is the right man. And so they the male's need to basically duke it out and one <mark>of</mark> them needs to be winning more fights more often before she will mate with that male and that's a real big problem because these things can take a while, you know, Todd I don't move much. They live for a very long time. It can be years possibly even decades before they actually the males actually or one <mark>of</mark> them ends up gaining the upper hand more often than not so that's partially a quite a big problem. Christian had to win many many Fates for me just like down at the pub getting into bar fights the Coliseum style", "Start Time (s)": 1941.6, "End Time (s)": 2061.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "time. It can be years possibly even decades before they actually the males actually or one <mark>of</mark> them ends up gaining the upper hand more often than not so that's partially a quite a big problem. Christian had to win many many Fates for me just like down at the pub getting into bar fights the Coliseum style Gladiator style where I lined combatants up an arena and he had to best each one and and And combat. It's like the middle and you'll like in like the the box and he just looks at you and goes are you not entertained and you're just like shaking your head like no see sending the Lions once more you had a few decades to go honey. So yeah, so they have to spend their time doing that. And then the problem with the next stage is that the female might not actually breathe. Need for another sort <mark>of</mark> anywhere between sort <mark>of</mark> four to seven years. So that's quite a long time or then when she does actually, you know, lay the eggs and the eggs hatch and stuff and that's all good. The problem with the next generation is that it takes 20 years for them to get a gender. So the for the first 20 years <mark>of</mark> their life, they are genderless. They don't have any sort <mark>of</mark> the reproductive organs or anything like that. They are just genderless for the first 20 years <mark>of</mark> their life and then roughly around the age <mark>of</mark> 20. They essentially go through Rick. Puberty I guess and then they become a male or a female and it's a big problem because we really can't wait 20 years to be able to release that into the into the wild population and that kind <mark>of</mark> stuff. So that's like a really big problem. So takes like a really long time to be able to breed to a toddler which is a huge issue. Yeah, cuz I know that like captive breeding is a lot <mark>of</mark> times a really important part <mark>of</mark> like a species survival plan. So if you have to be breeding them like multiple decades AIDS apart", "Start Time (s)": 2040.4, "End Time (s)": 2160.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So yeah, so they have to spend their time doing that. And then the problem with the next stage is that the female might not actually breathe. Need for another sort <mark>of</mark> anywhere between sort <mark>of</mark> four to seven years. So that's quite a long time or then when she does actually, you know, lay the eggs and the eggs hatch and stuff and that's all good. The problem with the next generation is that it takes 20 years for them to get a gender. So the for the first 20 years <mark>of</mark> their life, they are genderless. They don't have any sort <mark>of</mark> the reproductive organs or anything like that. They are just genderless for the first 20 years <mark>of</mark> their life and then roughly around the age <mark>of</mark> 20. They essentially go through Rick. Puberty I guess and then they become a male or a female and it's a big problem because we really can't wait 20 years to be able to release that into the into the wild population and that kind <mark>of</mark> stuff. So that's like a really big problem. So takes like a really long time to be able to breed to a toddler which is a huge issue. Yeah, cuz I know that like captive breeding is a lot <mark>of</mark> times a really important part <mark>of</mark> like a species survival plan. So if you have to be breeding them like multiple decades AIDS apart then yeah, it's going to be slow going but that just kind <mark>of</mark> multiplies the impact when they accidentally eat their own. Yeah. Well look at all the work that went into this. Yeah, exactly. So that's that's the thing as well. They have to they have to separate the Young from you know, after like the eggs are laid like they take them off the they usually take them off the the mail they'd move the mail somewhere else is like, okay, he's just going to eat them. So, you know, like they have to move the mail. So it's like a real Yeah, it is a real problem - they're really not making it easy on you know, and this is the other issue is that they are they've got quite severely endangered as well and the particular the ones that I was looking after the Cook Strait to without a our this is a things about a hundred thousand might not be that much. It's no more than a hundred thousand left, which is", "Start Time (s)": 2092.3, "End Time (s)": 2212.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but that just kind <mark>of</mark> multiplies the impact when they accidentally eat their own. Yeah. Well look at all the work that went into this. Yeah, exactly. So that's that's the thing as well. They have to they have to separate the Young from you know, after like the eggs are laid like they take them off the they usually take them off the the mail they'd move the mail somewhere else is like, okay, he's just going to eat them. So, you know, like they have to move the mail. So it's like a real Yeah, it is a real problem - they're really not making it easy on you know, and this is the other issue is that they are they've got quite severely endangered as well and the particular the ones that I was looking after the Cook Strait to without a our this is a things about a hundred thousand might not be that much. It's no more than a hundred thousand left, which is good, but not great and the brothers Island Tuatara has about 400. left in the wild and the big problem with them is <mark>of</mark> those 400 only about 40 <mark>of</mark> them are females which is a really big problem because as I've put it in the past the females are the baby factories, which is not a not a nice way <mark>of</mark> putting it but the the are the important ones the other one sure who you know, essentially the limiting factor when it comes to the conservation because one male can Braid with a whole bunch <mark>of</mark> females that's and that's fine, you know and he can have all this Offspring but a female can mate with as many emails as she like she's only going to have one clutch. So yeah, they're the limiting factor. So you need lots <mark>of</mark> them, but with <mark>global</mark> <mark>warming</mark> in this sort <mark>of</mark> stuff going on we're getting more males being born than females. The reason for that is because Tortola are what is called temperature six dependent which basically means the agenda is defined by the temperature <mark>of</mark> the sort <mark>of</mark> the average temperature. <mark>Of</mark> the soil when the eggs are laid and because as I said, we got", "Start Time (s)": 2163.1, "End Time (s)": 2283.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "400. left in the wild and the big problem with them is <mark>of</mark> those 400 only about 40 <mark>of</mark> them are females which is a really big problem because as I've put it in the past the females are the baby factories, which is not a not a nice way <mark>of</mark> putting it but the the are the important ones the other one sure who you know, essentially the limiting factor when it comes to the conservation because one male can Braid with a whole bunch <mark>of</mark> females that's and that's fine, you know and he can have all this Offspring but a female can mate with as many emails as she like she's only going to have one clutch. So yeah, they're the limiting factor. So you need lots <mark>of</mark> them, but with <mark>global</mark> <mark>warming</mark> in this sort <mark>of</mark> stuff going on we're getting more males being born than females. The reason for that is because Tortola are what is called temperature six dependent which basically means the agenda is defined by the temperature <mark>of</mark> the sort <mark>of</mark> the average temperature. <mark>Of</mark> the soil when the eggs are laid and because as I said, we got <mark>global</mark> <mark>warming</mark> and stuff we are getting higher temperatures more often. So more males are being born because males tend to be born above 20 degrees Celsius below that threshold as usually is females. So yeah, it's a really big problem at the moment particularly with those guys but a lot <mark>of</mark> other reptiles in the world as well and fun fact about that as well. This is one <mark>of</mark> the other things you'll find in a lot <mark>of</mark> New Zealand animals as we tend to do things that every other animal in the world does but Do it backwards. So in the case <mark>of</mark> Tuatara, usually with lots <mark>of</mark> other most other reptiles that temperature six dependency is higher temperatures give females lower temperatures give males. But for toes are just said it is the other way around. So that's quite unusual for them. That is interesting. Like is there any particular function for that? Like, does that correspond to like any sort <mark>of</mark> seasonal temperature changes or like I don't know. Is there a", "Start Time (s)": 2218.1, "End Time (s)": 2337.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "which basically means the agenda is defined by the temperature <mark>of</mark> the sort <mark>of</mark> the average temperature. <mark>Of</mark> the soil when the eggs are laid and because as I said, we got <mark>global</mark> <mark>warming</mark> and stuff we are getting higher temperatures more often. So more males are being born because males tend to be born above 20 degrees Celsius below that threshold as usually is females. So yeah, it's a really big problem at the moment particularly with those guys but a lot <mark>of</mark> other reptiles in the world as well and fun fact about that as well. This is one <mark>of</mark> the other things you'll find in a lot <mark>of</mark> New Zealand animals as we tend to do things that every other animal in the world does but Do it backwards. So in the case <mark>of</mark> Tuatara, usually with lots <mark>of</mark> other most other reptiles that temperature six dependency is higher temperatures give females lower temperatures give males. But for toes are just said it is the other way around. So that's quite unusual for them. That is interesting. Like is there any particular function for that? Like, does that correspond to like any sort <mark>of</mark> seasonal temperature changes or like I don't know. Is there a reason for that I guess. Yes, probably I don't know what it is. But probably sure man. Yeah Toto one <mark>of</mark> these things that we do know a lot about them, but we equally don't really know anything about them. So it might be something that we don't actually know because with them kind <mark>of</mark> not doing much there, you know, the generational time the fact that they don't breed very often and they don't have kids very often their kind <mark>of</mark> stuff means that we can't study them as much as we have with other things like rats which you know, they have kids Every other week nearly, you know immediately for every deal. Yeah, you know, so it's harder to study them and know stuff about them without you know, you just the black observing them and doing tests and stuff because they just don't do anything they live for a very long time and they just don't have kids very often. So like with things like like things like if you want to know", "Start Time (s)": 2273.1, "End Time (s)": 2392.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Yeah Toto one <mark>of</mark> these things that we do know a lot about them, but we equally don't really know anything about them. So it might be something that we don't actually know because with them kind <mark>of</mark> not doing much there, you know, the generational time the fact that they don't breed very often and they don't have kids very often their kind <mark>of</mark> stuff means that we can't study them as much as we have with other things like rats which you know, they have kids Every other week nearly, you know immediately for every deal. Yeah, you know, so it's harder to study them and know stuff about them without you know, you just the black observing them and doing tests and stuff because they just don't do anything they live for a very long time and they just don't have kids very often. So like with things like like things like if you want to know what what gender are a young Tuatara is going to be pretty much the only Surefire way to know is to I'm open and have a look but that unfortunately is fatal to the Tuatara. So it's that kind <mark>of</mark> stuff that it's like there's not really any good ways <mark>of</mark> assessing a lot <mark>of</mark> stuff. Oh, which does remind me here's another great thing about the age that I didn't mention before is we don't as I said, we don't quite know how old they get and the reason for that is because the typical way we would look out we would look up how old an animal is is by taking out one <mark>of</mark> its ear bones. So typically what you do is you get a little thing called an otolith which is a tiny tiny little bone in the ears <mark>of</mark> reptiles and fish as well. And what you do is you send that little odorless down. By the way that this bone is like Mega tiny like it is not even a millimeter across as really tiny where you got those you gotta say in this little little over lift down and put it under a microscope and then realize you didn't do it properly. So you keep saying you put it on drinking you realize you're not quite there. So you keep saying if you hadn't guessed already, I know this. Because I've done it before with rash. That is the voice <mark>of</mark>", "Start Time (s)": 2345.9, "End Time (s)": 2464.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it's that kind <mark>of</mark> stuff that it's like there's not really any good ways <mark>of</mark> assessing a lot <mark>of</mark> stuff. Oh, which does remind me here's another great thing about the age that I didn't mention before is we don't as I said, we don't quite know how old they get and the reason for that is because the typical way we would look out we would look up how old an animal is is by taking out one <mark>of</mark> its ear bones. So typically what you do is you get a little thing called an otolith which is a tiny tiny little bone in the ears <mark>of</mark> reptiles and fish as well. And what you do is you send that little odorless down. By the way that this bone is like Mega tiny like it is not even a millimeter across as really tiny where you got those you gotta say in this little little over lift down and put it under a microscope and then realize you didn't do it properly. So you keep saying you put it on drinking you realize you're not quite there. So you keep saying if you hadn't guessed already, I know this. Because I've done it before with rash. That is the voice <mark>of</mark> frustrated experience. Yes, that is the voice <mark>of</mark> an undergraduate who just wants the thing to work. So yeah, so you saying that down you put it under a microscope and what you should see is a bunch <mark>of</mark> rings in each <mark>of</mark> those Rings just like a tree indicates a year. So how many rings there are tells you how old the reptile or the fish is? The problem with Tuatara is they don't have ears so they don't have Ear bones so you can't do it. That way. Nothing is easy. Nothing is easy. Yeah. So the other way that you might do it is if you took out the teeth and you chop the teeth in half and do the same sort <mark>of</mark> thing, you know, you send it down put it on the microscope and you should see some rings that will tell you how well the the animal is the reason that there's works and other animals is because those parts <mark>of</mark> the body grow at the same rate every year they only grow, you know, say half a millimeter Yeah, they're always going to grow half a millimeter every year so", "Start Time (s)": 2404.4, "End Time (s)": 2524.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "an undergraduate who just wants the thing to work. So yeah, so you saying that down you put it under a microscope and what you should see is a bunch <mark>of</mark> rings in each <mark>of</mark> those Rings just like a tree indicates a year. So how many rings there are tells you how old the reptile or the fish is? The problem with Tuatara is they don't have ears so they don't have Ear bones so you can't do it. That way. Nothing is easy. Nothing is easy. Yeah. So the other way that you might do it is if you took out the teeth and you chop the teeth in half and do the same sort <mark>of</mark> thing, you know, you send it down put it on the microscope and you should see some rings that will tell you how well the the animal is the reason that there's works and other animals is because those parts <mark>of</mark> the body grow at the same rate every year they only grow, you know, say half a millimeter Yeah, they're always going to grow half a millimeter every year so there's going to be no variation there. But with the teeth <mark>of</mark> the Tuatara they aren't the same as teeth from other reptiles because other reptiles like humans, you know, your teeth are sitting in your gums, right? They're not attached to the rest <mark>of</mark> your skeleton or your skull or your jaw or anything like that. But for the Tortola they are so basically the teeth are just protrusions <mark>of</mark> the lower jaw and and the skull through the gums. So the problem with that is that the skull in general, you know will grow at different rates depending on how much you get how much you're feeding them and you know kind <mark>of</mark> what's going on in the environment and that kind <mark>of</mark> stuff. So it's not a good way <mark>of</mark> telling how old they are unfortunately. So that's why we don't know how old they are is because no one is no there's really no way to tell and we're basically just waiting for Henry to die and just to see how he gets when he died. It's like kind <mark>of</mark> moving it sounds like he has no plans to do. So anytime soon. No. No,", "Start Time (s)": 2467.8, "End Time (s)": 2587.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a millimeter every year so there's going to be no variation there. But with the teeth <mark>of</mark> the Tuatara they aren't the same as teeth from other reptiles because other reptiles like humans, you know, your teeth are sitting in your gums, right? They're not attached to the rest <mark>of</mark> your skeleton or your skull or your jaw or anything like that. But for the Tortola they are so basically the teeth are just protrusions <mark>of</mark> the lower jaw and and the skull through the gums. So the problem with that is that the skull in general, you know will grow at different rates depending on how much you get how much you're feeding them and you know kind <mark>of</mark> what's going on in the environment and that kind <mark>of</mark> stuff. So it's not a good way <mark>of</mark> telling how old they are unfortunately. So that's why we don't know how old they are is because no one is no there's really no way to tell and we're basically just waiting for Henry to die and just to see how he gets when he died. It's like kind <mark>of</mark> moving it sounds like he has no plans to do. So anytime soon. No. No, he's he's pretty chipper. Actually, they couldn't get him to breed for a long while which was interesting because his enclosure actually the ceiling on his enclosure was like stopping UV light coming through so he was feeling a bit poorly for a while and they couldn't figure out why he wasn't breathing and then they figured out. Oh it's because the ceiling is blocking all the UV light so they ripped out all the I'm putting you ceiling in and away he went and it was fine. It was just problem solved. Yeah, it was really strange. So yeah, so that was a really weird thing with him. But yeah, he's not. Yeah, he is not showing any any signs <mark>of</mark> slowing down. I mean, I guess that's good news. Right like just the longer-lived that just means like more baby making opportunities, I guess exactly but I don't believe he's one <mark>of</mark> the rear ones I if I remember rightly, he is a cook straight to a tunnel which would not really that concerned about so it's just Kind <mark>of</mark> annoying.", "Start Time (s)": 2521.6, "End Time (s)": 2640.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "there's really no way to tell and we're basically just waiting for Henry to die and just to see how he gets when he died. It's like kind <mark>of</mark> moving it sounds like he has no plans to do. So anytime soon. No. No, he's he's pretty chipper. Actually, they couldn't get him to breed for a long while which was interesting because his enclosure actually the ceiling on his enclosure was like stopping UV light coming through so he was feeling a bit poorly for a while and they couldn't figure out why he wasn't breathing and then they figured out. Oh it's because the ceiling is blocking all the UV light so they ripped out all the I'm putting you ceiling in and away he went and it was fine. It was just problem solved. Yeah, it was really strange. So yeah, so that was a really weird thing with him. But yeah, he's not. Yeah, he is not showing any any signs <mark>of</mark> slowing down. I mean, I guess that's good news. Right like just the longer-lived that just means like more baby making opportunities, I guess exactly but I don't believe he's one <mark>of</mark> the rear ones I if I remember rightly, he is a cook straight to a tunnel which would not really that concerned about so it's just Kind <mark>of</mark> annoying. So to go back to what you mentioned about them not having ears. Is it the case that they just cannot hear sounds at all not quite. So what you will find is when you see pictures <mark>of</mark> Tuatara you'll see that they more often than not lying on their bellies and that's because that is how they are hearing out for things is because they feel the vibrations through their bellies or through their skin so that if something's coming along or whatever they can, you know run away from it. Or whatever which doesn't obviously really work for Birds, but you know that that's how they kind <mark>of</mark> do it. So yeah, so they actually feel the vibrations kind <mark>of</mark> through the skin and what you'll find as well part <mark>of</mark> that is that their skin is very very thin and very very soft and kind <mark>of</mark> leathery. It's not really hard and scaly like a say like a bearded dragon or a blue tongue lizard or like a snake.", "Start Time (s)": 2572.7, "End Time (s)": 2692.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I guess that's good news. Right like just the longer-lived that just means like more baby making opportunities, I guess exactly but I don't believe he's one <mark>of</mark> the rear ones I if I remember rightly, he is a cook straight to a tunnel which would not really that concerned about so it's just Kind <mark>of</mark> annoying. So to go back to what you mentioned about them not having ears. Is it the case that they just cannot hear sounds at all not quite. So what you will find is when you see pictures <mark>of</mark> Tuatara you'll see that they more often than not lying on their bellies and that's because that is how they are hearing out for things is because they feel the vibrations through their bellies or through their skin so that if something's coming along or whatever they can, you know run away from it. Or whatever which doesn't obviously really work for Birds, but you know that that's how they kind <mark>of</mark> do it. So yeah, so they actually feel the vibrations kind <mark>of</mark> through the skin and what you'll find as well part <mark>of</mark> that is that their skin is very very thin and very very soft and kind <mark>of</mark> leathery. It's not really hard and scaly like a say like a bearded dragon or a blue tongue lizard or like a snake. It's not like that. It's very soft and very kind <mark>of</mark> leathery. So yes, it's very kind <mark>of</mark> it's very different to what you might expect. Yeah. Especially when you especially when you said that they're related to crocodiles. I was expecting that sort <mark>of</mark> rough. Like yeah, like skin with like the osteoderms and stuff like that all over ya know. It's nothing nothing like that at all, which is really strange that always catches people out as well. They always think it's going to feel yet kind <mark>of</mark> kind <mark>of</mark> really hard and kind <mark>of</mark> scaly. But yeah, it feels kind <mark>of</mark> soft and leather and then always quite surprises people and I remember someone when I was on a tour, you know, they had it was a family, you know, and I I put down the toilet harder to one <mark>of</mark> the kids. The kids are The Strokes it because ha feels like Grandma so Partners grandma was there so", "Start Time (s)": 2624.2, "End Time (s)": 2742.8, "Clip Length (min)": 1.98, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "grandma was there so what a power move she took it in our stride though. She were she seemed pretty alright about it. But if ya big off, but yeah that was quite funny. That's something that like the soft thin like skin rather than Having a hard scaly exterior. Like it's something that is meant for what they're doing which is picking up vibrations but probably doesn't like the trade-off is that it doesn't offer them very much protection. Yeah, exactly. But in saying that they don't team to fight very often their only fight each other really, you know, if they're going to if they do have like a predator coming after them as I said, they'll just run into the burrow because that is in the past what has been effective. The only time that they're ever going to fight is other males and it even then They're not doing it to try and kill each other. They just doing it to establish dominance. So you will sometimes find if you see two males and like an enclosure, you know, they might have a bit <mark>of</mark> blood and you know some gashes and stuff on them, but it's all pretty pretty normal. But I do remember a few people running out going. Oh my God, you totally trying to kill each other and I'm like and they're like, let's go. Let's go. Was blond is really bad to my God. Okay, I'll come I'll come and have a look they're like really distressed and they like their distress because I'm not distressed. And so you like you like walk out and you go and have a look at them. They got this Blood along this side and stuff. You know, one <mark>of</mark> them has like a big like swollen lip and that kind <mark>of</mark> thing and then I'm like, it's fine. Like are you sure I'm like look if it's intestines aren't hanging out. I'm not worried. They're operating their own little fight club and they're in there. Closure, so it's yeah, it was like I don't really care. But yeah, I was very lucky to see them to see them fight very occasionally, which is very very cool. I saw one <mark>of</mark> them actually we had this Vlog like a like a tree log. One <mark>of</mark> them was on the like under the kind <mark>of</mark> next to it on the ground and one <mark>of</mark> them was like on the tree log", "Start Time (s)": 2740.9, "End Time (s)": 2858.7, "Clip Length (min)": 1.96, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "not doing it to try and kill each other. They just doing it to establish dominance. So you will sometimes find if you see two males and like an enclosure, you know, they might have a bit <mark>of</mark> blood and you know some gashes and stuff on them, but it's all pretty pretty normal. But I do remember a few people running out going. Oh my God, you totally trying to kill each other and I'm like and they're like, let's go. Let's go. Was blond is really bad to my God. Okay, I'll come I'll come and have a look they're like really distressed and they like their distress because I'm not distressed. And so you like you like walk out and you go and have a look at them. They got this Blood along this side and stuff. You know, one <mark>of</mark> them has like a big like swollen lip and that kind <mark>of</mark> thing and then I'm like, it's fine. Like are you sure I'm like look if it's intestines aren't hanging out. I'm not worried. They're operating their own little fight club and they're in there. Closure, so it's yeah, it was like I don't really care. But yeah, I was very lucky to see them to see them fight very occasionally, which is very very cool. I saw one <mark>of</mark> them actually we had this Vlog like a like a tree log. One <mark>of</mark> them was on the like under the kind <mark>of</mark> next to it on the ground and one <mark>of</mark> them was like on the tree log and then one <mark>of</mark> the tree like was like looking down and then I was like, oh this is kind <mark>of</mark> interesting what it was kept going to happen here and I was about to walk away because Tata, what is it? They don't do much so they fights take all day to happen. Since I'm not gonna see anything here, but just as I was about to walk away the one on the log like jumps off lands on the other one, like pins his head down with his like poor or his hand deliver as I wore High School drama. Yeah, really? I thought it was great. But I was really annoyed. I didn't capture it on camera because it was really cool. So yeah, so they fights do take like a really long time. It sounds like their whole life. They're just living in slow motion like they've just It like like .5 speed on their whole life. Yeah, this is kind <mark>of</mark> the misconception about Tuatara is that they don't move fast. They", "Start Time (s)": 2789.6, "End Time (s)": 2909.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to see them fight very occasionally, which is very very cool. I saw one <mark>of</mark> them actually we had this Vlog like a like a tree log. One <mark>of</mark> them was on the like under the kind <mark>of</mark> next to it on the ground and one <mark>of</mark> them was like on the tree log and then one <mark>of</mark> the tree like was like looking down and then I was like, oh this is kind <mark>of</mark> interesting what it was kept going to happen here and I was about to walk away because Tata, what is it? They don't do much so they fights take all day to happen. Since I'm not gonna see anything here, but just as I was about to walk away the one on the log like jumps off lands on the other one, like pins his head down with his like poor or his hand deliver as I wore High School drama. Yeah, really? I thought it was great. But I was really annoyed. I didn't capture it on camera because it was really cool. So yeah, so they fights do take like a really long time. It sounds like their whole life. They're just living in slow motion like they've just It like like .5 speed on their whole life. Yeah, this is kind <mark>of</mark> the misconception about Tuatara is that they don't move fast. They can move fast. They can move very fast, you know, they would move fast if they're chasing like insects and stuff or if they fighting each other they'll move quite quickly because what they'll do when they're fighting is actually seen <mark>of</mark> lying on their belly the raise themselves up off the ground. So there will be standing on all four leagues, you know, reading the swipe will bite or whatever so they can actually move very very fast if they Want to the thing is they just don't want to very often. So now I'm starting to see the parallels between this and the crocodilians. So the thing is is more they're not they're not slow. The lazy. There's a very subtle distinction there, you know. So yeah, I'd say I like to explain that the The Lazy more than anything rather than being slow because if they want to if they want to get up off the couch and like, you know, he'll go for a run they can. It's just that they often don't selectively athletic exactly.", "Start Time (s)": 2845.5, "End Time (s)": 2965.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "because what they'll do when they're fighting is actually seen <mark>of</mark> lying on their belly the raise themselves up off the ground. So there will be standing on all four leagues, you know, reading the swipe will bite or whatever so they can actually move very very fast if they Want to the thing is they just don't want to very often. So now I'm starting to see the parallels between this and the crocodilians. So the thing is is more they're not they're not slow. The lazy. There's a very subtle distinction there, you know. So yeah, I'd say I like to explain that the The Lazy more than anything rather than being slow because if they want to if they want to get up off the couch and like, you know, he'll go for a run they can. It's just that they often don't selectively athletic exactly. Yeah, so our last rating category is Aesthetics which speaks for itself. It's just how pretty and how aesthetically pleasing. They are what do you give the to a Tata? Yeah again, I'm <mark>of</mark> two minds <mark>of</mark> this one because I know what some people will want me to say, <mark>of</mark> course, you want me to say that they look great and they look amazing. I do think they look great and look amazing. However in Howdy what the side they call it Martie cordaro, which is like kind <mark>of</mark> stories and kind <mark>of</mark> myths and tales and stuff Tata Tata in general reptiles and lizards and stuff are actually the descendants <mark>of</mark> I think it's pulling her. I want to say it's pulling it citation needed. I didn't quite look this one up, but essentially they are the descendants <mark>of</mark> the god <mark>of</mark> ugly things. So the disrespect yeah, I feel inclined to give them a zero because But because just <mark>of</mark> that they are traditionally thought <mark>of</mark> as being quite ugly. That's Cannon. Yeah. Yeah, but I think they look really really cold, you know the heads, you know, as I said sort <mark>of</mark> quite crocodilian their spines are", "Start Time (s)": 2918.4, "End Time (s)": 3038.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "They are what do you give the to a Tata? Yeah again, I'm <mark>of</mark> two minds <mark>of</mark> this one because I know what some people will want me to say, <mark>of</mark> course, you want me to say that they look great and they look amazing. I do think they look great and look amazing. However in Howdy what the side they call it Martie cordaro, which is like kind <mark>of</mark> stories and kind <mark>of</mark> myths and tales and stuff Tata Tata in general reptiles and lizards and stuff are actually the descendants <mark>of</mark> I think it's pulling her. I want to say it's pulling it citation needed. I didn't quite look this one up, but essentially they are the descendants <mark>of</mark> the god <mark>of</mark> ugly things. So the disrespect yeah, I feel inclined to give them a zero because But because just <mark>of</mark> that they are traditionally thought <mark>of</mark> as being quite ugly. That's Cannon. Yeah. Yeah, but I think they look really really cold, you know the heads, you know, as I said sort <mark>of</mark> quite crocodilian their spines are you know, they look quite tough and then when they when they fighting they enlarge them and they look very very cool and they've, you know lift themselves up off the ground and I got very nice long claws and they got nice Tails as Well, which do also grow back if they fall off that's another thing as well. They will if they lose them they will grow back to the tech. You know, the tails are quite cool and quite beefy and quite strong and stuff. So, I think they look really really cool. But I guess out <mark>of</mark> traditionally what they've been known as I might just give them a zero cold, it's cold, it's not me it's not me. I'm just saying that's what that's what they've always been, you know, but hundreds he probably a hundreds <mark>of</mark> years people thought they looked look ugly. So you can't deny hundreds <mark>of</mark> years <mark>of</mark> people say, you know what that looks like trash their canonically garbage. So you mentioned their role in sort <mark>of</mark>", "Start Time (s)": 2974.8, "End Time (s)": 3094.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>of</mark> quite crocodilian their spines are you know, they look quite tough and then when they when they fighting they enlarge them and they look very very cool and they've, you know lift themselves up off the ground and I got very nice long claws and they got nice Tails as Well, which do also grow back if they fall off that's another thing as well. They will if they lose them they will grow back to the tech. You know, the tails are quite cool and quite beefy and quite strong and stuff. So, I think they look really really cool. But I guess out <mark>of</mark> traditionally what they've been known as I might just give them a zero cold, it's cold, it's not me it's not me. I'm just saying that's what that's what they've always been, you know, but hundreds he probably a hundreds <mark>of</mark> years people thought they looked look ugly. So you can't deny hundreds <mark>of</mark> years <mark>of</mark> people say, you know what that looks like trash their canonically garbage. So you mentioned their role in sort <mark>of</mark> traditional like mythology and Lord and I know that you you have this animal in your logo for your cover art for your podcast. I do. Oh I said I should put I should put Tony on my head, but I actually got a I got a stuffed one for Christmas from my mum. Yeah, and so I did a poll on Twitter as to you know, what should we watch? Should we name name it I guess because we don't know what Ginger it is. So it is called to either Tuatara which sits up and watches me record. Although I voted in that poll and I think that's the name I voted for. Yeah. Yeah, I get I get told off because I rigged it slightly. Oh, yeah. Well, I did two poles. The first one that I did I put hands is an Hae ins. Did which is the abbreviate or like the acronym for my podcast but that got the vote more often like this one that one and I got convinced that that name was to German and not to", "Start Time (s)": 3034.7, "End Time (s)": 3154.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Christmas from my mum. Yeah, and so I did a poll on Twitter as to you know, what should we watch? Should we name name it I guess because we don't know what Ginger it is. So it is called to either Tuatara which sits up and watches me record. Although I voted in that poll and I think that's the name I voted for. Yeah. Yeah, I get I get told off because I rigged it slightly. Oh, yeah. Well, I did two poles. The first one that I did I put hands is an Hae ins. Did which is the abbreviate or like the acronym for my podcast but that got the vote more often like this one that one and I got convinced that that name was to German and not to knock me Zealand. So I was like, okay so into the I wind up the pole again, and that was one thing I selected so I know that's a it's a slightly contentious issue with some people. I would like to say for the record that I am in support <mark>of</mark> the decision that you will Bentley made I think I think to leave the Tuatara is better because it is gender neutral sure because you know, we is a said we don't know what gender they going to be until the about 20 years old. So I thought well if it's a gender-neutral one, then you know, it can be a he or a she and it doesn't really matter. So yeah, it's very good. So, you know, you mentioned their role in mythology and lore. So, you know what we haven't mentioned this yet. But so you're you're in New Zealand? And yes right now and we are in Florida. So this is definitely the largest time zone Gap I've ever spoken across the company's what you can't get any more distant than in New Zealand because we are we're right basically next to the date line. So we are as far in the future as you can get you are 18 hours ahead <mark>of</mark> us. Correct. So for us right now it is nine p.m. On a Friday night, even though for you it is what 3:00 p.m. On a Saturday on a", "Start Time (s)": 3109.6, "End Time (s)": 3229.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "selected so I know that's a it's a slightly contentious issue with some people. I would like to say for the record that I am in support <mark>of</mark> the decision that you will Bentley made I think I think to leave the Tuatara is better because it is gender neutral sure because you know, we is a said we don't know what gender they going to be until the about 20 years old. So I thought well if it's a gender-neutral one, then you know, it can be a he or a she and it doesn't really matter. So yeah, it's very good. So, you know, you mentioned their role in mythology and lore. So, you know what we haven't mentioned this yet. But so you're you're in New Zealand? And yes right now and we are in Florida. So this is definitely the largest time zone Gap I've ever spoken across the company's what you can't get any more distant than in New Zealand because we are we're right basically next to the date line. So we are as far in the future as you can get you are 18 hours ahead <mark>of</mark> us. Correct. So for us right now it is nine p.m. On a Friday night, even though for you it is what 3:00 p.m. On a Saturday on a Saturday. Yep. It's so This is a huge time Gap. But so we're getting close to time. But I still wanted to make sure that you had a chance to talk about so so first <mark>of</mark> all, like any sort <mark>of</mark> cultural significance that you want to like describe about like what the Tuatara means to like New Zealand culture obviously taught a hold quite a high place <mark>of</mark> honor in New Zealand kind <mark>of</mark> conservation culture and that kind <mark>of</mark> stuff because they were the first species in New Zealand to be legally protected. So they kind <mark>of</mark> a partially kind <mark>of</mark> a postage. Child for that kind <mark>of</mark> stuff and <mark>of</mark> course, they are a very special endemic species to us and you can't see them anywhere else in the world and that kind <mark>of</mark> thing. So we're very, you know, they're kind <mark>of</mark> big in that way as well. But in another sense like most other will pretty much all endemic species here in New Zealand. They are what we call Tonga to the Maori people, which is basically that the", "Start Time (s)": 3160.7, "End Time (s)": 3280.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it is nine p.m. On a Friday night, even though for you it is what 3:00 p.m. On a Saturday on a Saturday. Yep. It's so This is a huge time Gap. But so we're getting close to time. But I still wanted to make sure that you had a chance to talk about so so first <mark>of</mark> all, like any sort <mark>of</mark> cultural significance that you want to like describe about like what the Tuatara means to like New Zealand culture obviously taught a hold quite a high place <mark>of</mark> honor in New Zealand kind <mark>of</mark> conservation culture and that kind <mark>of</mark> stuff because they were the first species in New Zealand to be legally protected. So they kind <mark>of</mark> a partially kind <mark>of</mark> a postage. Child for that kind <mark>of</mark> stuff and <mark>of</mark> course, they are a very special endemic species to us and you can't see them anywhere else in the world and that kind <mark>of</mark> thing. So we're very, you know, they're kind <mark>of</mark> big in that way as well. But in another sense like most other will pretty much all endemic species here in New Zealand. They are what we call Tonga to the Maori people, which is basically that the treasures essentially is what talking a kind <mark>of</mark> translates to you know, they're very very precious and very very highly valued and that kind <mark>of</mark> thing. So so the thing with Tuatara and that kind <mark>of</mark> stuff Is if you want to keep them breed them that kind <mark>of</mark> stuff you don't just have to jump through holes through the government. You have to jump through holes <mark>of</mark> kiwi which is the name front like Maori tribes essentially so that you have to give like approval and that kind <mark>of</mark> stuff as well. These are you know, these more Hoops to jump through then then just you know legal ones essentially so they hold a very very high place and kind <mark>of</mark> Maori culture and that kind <mark>of</mark> stuff just for that reason. There's not many <mark>of</mark> them left and Maori obviously have a very very very big vested interest in trying to keep them alive as well because they have a big part <mark>of</mark> their culture, you know, as I said stretching back for a very very long time because you know, they have this kind <mark>of</mark> hole, you know, all these stories around them. One <mark>of</mark> them is mentioned there, you know descended from the god <mark>of</mark> ugly things to etana also said to be messengers <mark>of</mark> I think it's the god <mark>of</mark> Darkness. He's like the", "Start Time (s)": 3222.4, "End Time (s)": 3342.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "other will pretty much all endemic species here in New Zealand. They are what we call Tonga to the Maori people, which is basically that the treasures essentially is what talking a kind <mark>of</mark> translates to you know, they're very very precious and very very highly valued and that kind <mark>of</mark> thing. So so the thing with Tuatara and that kind <mark>of</mark> stuff Is if you want to keep them breed them that kind <mark>of</mark> stuff you don't just have to jump through holes through the government. You have to jump through holes <mark>of</mark> kiwi which is the name front like Maori tribes essentially so that you have to give like approval and that kind <mark>of</mark> stuff as well. These are you know, these more Hoops to jump through then then just you know legal ones essentially so they hold a very very high place and kind <mark>of</mark> Maori culture and that kind <mark>of</mark> stuff just for that reason. There's not many <mark>of</mark> them left and Maori obviously have a very very very big vested interest in trying to keep them alive as well because they have a big part <mark>of</mark> their culture, you know, as I said stretching back for a very very long time because you know, they have this kind <mark>of</mark> hole, you know, all these stories around them. One <mark>of</mark> them is mentioned there, you know descended from the god <mark>of</mark> ugly things to etana also said to be messengers <mark>of</mark> I think it's the god <mark>of</mark> Darkness. He's like the evil God. I've kind <mark>of</mark> the Maori kind <mark>of</mark> Pantheon if you want to call it that I think it's Federal again citation needed. I don't quite remember that one, but Yeah, so they kind <mark>of</mark> associated with yeah the god <mark>of</mark> darkness and kind <mark>of</mark> evil and that kind <mark>of</mark> stuff. I'm hearing Garth icon. That's what I'm yeah a little bit. Yeah, and the thing is with that kind <mark>of</mark> lizards and reptiles and general they were used as a kind <mark>of</mark> indication <mark>of</mark> bad stuff <mark>of</mark> evil. So if you saw like reptiles carved into trees, you know, when you're like walking through the forest and stuff you'd know that. Hey, maybe I shouldn't go there that seems pretty bad. You know that kind <mark>of</mark> stuff or you put them on like your houses if something was like the bet it was something was happening in the house or whatever. But yeah, so they hold quite a high place in Maori culture is do you know a lot <mark>of</mark> endemic species with all <mark>of</mark> the stories and and that", "Start Time (s)": 3272.9, "End Time (s)": 3392.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "this kind <mark>of</mark> hole, you know, all these stories around them. One <mark>of</mark> them is mentioned there, you know descended from the god <mark>of</mark> ugly things to etana also said to be messengers <mark>of</mark> I think it's the god <mark>of</mark> Darkness. He's like the evil God. I've kind <mark>of</mark> the Maori kind <mark>of</mark> Pantheon if you want to call it that I think it's Federal again citation needed. I don't quite remember that one, but Yeah, so they kind <mark>of</mark> associated with yeah the god <mark>of</mark> darkness and kind <mark>of</mark> evil and that kind <mark>of</mark> stuff. I'm hearing Garth icon. That's what I'm yeah a little bit. Yeah, and the thing is with that kind <mark>of</mark> lizards and reptiles and general they were used as a kind <mark>of</mark> indication <mark>of</mark> bad stuff <mark>of</mark> evil. So if you saw like reptiles carved into trees, you know, when you're like walking through the forest and stuff you'd know that. Hey, maybe I shouldn't go there that seems pretty bad. You know that kind <mark>of</mark> stuff or you put them on like your houses if something was like the bet it was something was happening in the house or whatever. But yeah, so they hold quite a high place in Maori culture is do you know a lot <mark>of</mark> endemic species with all <mark>of</mark> the stories and and that kind <mark>of</mark> thing with them as well. Just based on what you've told me. It sounds like you have a lot to be proud <mark>of</mark> like this is a really really interesting cool animal that I'm really surprised isn't talked about more because just like the conversations that I've had with you like over Twitter is the only time I've ever heard <mark>of</mark> them right? Like I know where all the way. Other side <mark>of</mark> the planet but still like, you know, I've heard <mark>of</mark> like Kia and kiwi and but the fact that this was my first time ever like really learning about this animal. I think it's surprising and so I'm really excited to like share this, you know, I feel like I'm really excited for you know, a lot <mark>of</mark> people to know more about this really cool animal. So I really appreciate that. Absolutely. I really appreciate you sharing all your Insight with us. So take a quick minute to talk about your podcast. Just yeah, so I do a podcast and it's nothing like this. It's it's usually pretty serious.", "Start Time (s)": 3330.1, "End Time (s)": 3448.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>of</mark> thing with them as well. Just based on what you've told me. It sounds like you have a lot to be proud <mark>of</mark> like this is a really really interesting cool animal that I'm really surprised isn't talked about more because just like the conversations that I've had with you like over Twitter is the only time I've ever heard <mark>of</mark> them right? Like I know where all the way. Other side <mark>of</mark> the planet but still like, you know, I've heard <mark>of</mark> like Kia and kiwi and but the fact that this was my first time ever like really learning about this animal. I think it's surprising and so I'm really excited to like share this, you know, I feel like I'm really excited for you know, a lot <mark>of</mark> people to know more about this really cool animal. So I really appreciate that. Absolutely. I really appreciate you sharing all your Insight with us. So take a quick minute to talk about your podcast. Just yeah, so I do a podcast and it's nothing like this. It's it's usually pretty serious. Actually. It's not that serious. But as I mentioned at the top <mark>of</mark> the episode, I do the history <mark>of</mark> altered or New Zealand, which is a chronological and narrative history <mark>of</mark> New Zealand funny that and it's basically me talking about all things to do with New Zealand's history. So at the moment we are covering in Ocular we are covering Maori culture. So because we started before people arrived in New Zealand and we're going to go, you know all the way up to 2000. I thought it was the best way to do that was to cover Maori culture what they were doing before Europeans arrived. So the sort <mark>of</mark> things we are covering or we have covered as things like the social structure and things like what women what their life was like weaving so that's worth how to kick a flex Caravan, you know carvings on houses in and on a it's and things and at the moment I am doing a series on Tab marker which is tattoos. So, you know, Marty tattoos face tattoos, and that kind <mark>of</mark> stuff. What does", "Start Time (s)": 3392.9, "End Time (s)": 3512.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "But as I mentioned at the top <mark>of</mark> the episode, I do the history <mark>of</mark> altered or New Zealand, which is a chronological and narrative history <mark>of</mark> New Zealand funny that and it's basically me talking about all things to do with New Zealand's history. So at the moment we are covering in Ocular we are covering Maori culture. So because we started before people arrived in New Zealand and we're going to go, you know all the way up to 2000. I thought it was the best way to do that was to cover Maori culture what they were doing before Europeans arrived. So the sort <mark>of</mark> things we are covering or we have covered as things like the social structure and things like what women what their life was like weaving so that's worth how to kick a flex Caravan, you know carvings on houses in and on a it's and things and at the moment I am doing a series on Tab marker which is tattoos. So, you know, Marty tattoos face tattoos, and that kind <mark>of</mark> stuff. What does that mean? Why do they do it? How do they do it? You know that kind <mark>of</mark> thing. I'm also going to cover things like obviously Warfare food medicine music all sorts <mark>of</mark> different stuff. And then <mark>of</mark> course, we're going to move into Abel Tasman James Cook generally Europeans coming over Treaty <mark>of</mark> waitangi new. was musket was World War One World War II radda radda radda everything else so that's what I do or at least most <mark>of</mark> my free time as is doing a lot <mark>of</mark> that stuff and talking about that so yeah so that's if you're any way interested in what kind <mark>of</mark> what I've been talking about about here particularly the kind <mark>of</mark> I guess cultural stuff that we talk a lot about that at least at the moment we are talking a lot about that kind <mark>of</mark> stuff but I also do talk about New Zealand's native animals as well I have done an episode on to a toddler so if any <mark>of</mark> the stuff that we've talked about here is <mark>of</mark> interest and you kind <mark>of</mark> want to know a bit more there's probably some stuff I missed in here so I do do an episode on it in my show as well if you want to get a little bit extra from that", "Start Time (s)": 3451.6, "End Time (s)": 3571.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and at the moment I am doing a series on Tab marker which is tattoos. So, you know, Marty tattoos face tattoos, and that kind <mark>of</mark> stuff. What does that mean? Why do they do it? How do they do it? You know that kind <mark>of</mark> thing. I'm also going to cover things like obviously Warfare food medicine music all sorts <mark>of</mark> different stuff. And then <mark>of</mark> course, we're going to move into Abel Tasman James Cook generally Europeans coming over Treaty <mark>of</mark> waitangi new. was musket was World War One World War II radda radda radda everything else so that's what I do or at least most <mark>of</mark> my free time as is doing a lot <mark>of</mark> that stuff and talking about that so yeah so that's if you're any way interested in what kind <mark>of</mark> what I've been talking about about here particularly the kind <mark>of</mark> I guess cultural stuff that we talk a lot about that at least at the moment we are talking a lot about that kind <mark>of</mark> stuff but I also do talk about New Zealand's native animals as well I have done an episode on to a toddler so if any <mark>of</mark> the stuff that we've talked about here is <mark>of</mark> interest and you kind <mark>of</mark> want to know a bit more there's probably some stuff I missed in here so I do do an episode on it in my show as well if you want to get a little bit extra from that as well and I do I do patreon only episodes about New Zealand's animals as well the only the only one I've done so far is the hehe which is the Stitch Bird yeah they're quite cool and we're looking to do and the whole Hall which is the yellow-eyed penguin and then probably after that I'll do like the wetter pulling her which is the the Waiter and all sorts <mark>of</mark> other different things. So so yeah, so it is being described as kind <mark>of</mark> a conservationist podcast and a sense because I do put a bit <mark>of</mark> a conservation spin on it, but also it is what has been described by one Facebook user is unashamedly homegrown. So if you want to hear a kiwi bloke just talk about New Zealand history. That's why I do and for people who haven't seen it spelled out before by the way. That is a oh T EA Roa Ray that's", "Start Time (s)": 3501.9, "End Time (s)": 3621.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "stuff I missed in here so I do do an episode on it in my show as well if you want to get a little bit extra from that as well and I do I do patreon only episodes about New Zealand's animals as well the only the only one I've done so far is the hehe which is the Stitch Bird yeah they're quite cool and we're looking to do and the whole Hall which is the yellow-eyed penguin and then probably after that I'll do like the wetter pulling her which is the the Waiter and all sorts <mark>of</mark> other different things. So so yeah, so it is being described as kind <mark>of</mark> a conservationist podcast and a sense because I do put a bit <mark>of</mark> a conservation spin on it, but also it is what has been described by one Facebook user is unashamedly homegrown. So if you want to hear a kiwi bloke just talk about New Zealand history. That's why I do and for people who haven't seen it spelled out before by the way. That is a oh T EA Roa Ray that's correct. Yeah, if you search probably history <mark>of</mark> New Zealand, it'll probably come up as well In fairness. I have not tested that so don't know it's not but yeah, it's reasonably straightforward to find if you're looking on yeah, like, you know, pretty much any podcasts or anything like that. There's not a lot <mark>of</mark> people doing New Zealand history probably about three Forest podcasts including myself. There are doing this subject. So, you know, there's not a lot out there. So it's reasonably straightforward to find me. Just look for Tui. yes yeah yeah if you got any looking at the podcast it's got the big Tata honor that that's the one that you're looking for Perfect all right excellent great tie-in event <mark>of</mark> the century all right Tom as well it is super late where we are so it is time for us to go get some dinner but we deeply deeply appreciate you taking this time to talk to us this has been pretty eye-opening I have learned a lot and really really excited and this is just been a lot <mark>of</mark> fun this has been a really cool conversation to have so I really appreciate you taking this time to talk", "Start Time (s)": 3563.6, "End Time (s)": 3683.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "EA Roa Ray that's correct. Yeah, if you search probably history <mark>of</mark> New Zealand, it'll probably come up as well In fairness. I have not tested that so don't know it's not but yeah, it's reasonably straightforward to find if you're looking on yeah, like, you know, pretty much any podcasts or anything like that. There's not a lot <mark>of</mark> people doing New Zealand history probably about three Forest podcasts including myself. There are doing this subject. So, you know, there's not a lot out there. So it's reasonably straightforward to find me. Just look for Tui. yes yeah yeah if you got any looking at the podcast it's got the big Tata honor that that's the one that you're looking for Perfect all right excellent great tie-in event <mark>of</mark> the century all right Tom as well it is super late where we are so it is time for us to go get some dinner but we deeply deeply appreciate you taking this time to talk to us this has been pretty eye-opening I have learned a lot and really really excited and this is just been a lot <mark>of</mark> fun this has been a really cool conversation to have so I really appreciate you taking this time to talk to us definitely thank you very much for having me I very much enjoy coming on to talk about you know conservation stuff and animals and all that sort <mark>of</mark> weird stuff so yeah no definitely yeah thank you very much for having me it's awesome no problem alright we will talk to you later thank you so much no worries Chess By boy", "Start Time (s)": 3618.7, "End Time (s)": 3703.1, "Clip Length (min)": 1.41, "show_uri": "spotify:show:65tFpuBodBJAokryEYlhF3", "show_name": "Just the Zoo of Us", "show_description": "Join us, Christian and Ellen Weatherford, while we review your favorite species of animals and rate them out of ten in the categories of effectiveness, ingenuity and aesthetics. Transcripts can be found at justthezooofus.com \ud83d\ude0a Got a species you want us to review? Submit your animal friend to us at ellen@justthezooofus.com and when we review your animal we'll give you a shoutout \ud83d\ude0a Cover art by Taylor Gordon Art!", "publisher": "Christian & Ellen Weatherford", "episode_uri": "spotify:episode:4FHC1vhcTUyNpiIgGdzelu", "episode_name": "42: Tuatara w/ Thomas Rillstone!", "episode_description": "Join the Weatherfords and special guest Thomas Rillstone from the History of Aotearoa New Zealand podcast for a review of the tuatara! In this episode we get educated on what makes this ancient reptile and other New Zealand wildlife so special, with a few fun surprises along the way. ", "score": 6.031018, "explanation": "{\n  \"value\": 6.031018,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.5662508,\n      \"description\": \"weight(word_list:of in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.5662508,\n          \"description\": \"score(LMDirichletSimilarity, freq=380.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.459965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 380.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.7247595,\n      \"description\": \"weight(word_list:global in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.7247595,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6184738,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.7400074,\n      \"description\": \"weight(word_list:warming in 3) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.7400074,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.633722,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8937142,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 11288.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "My my my daughter a kick in American. I've been tracking Sasquatches for 25 years American <mark>global</mark> Awakening to the New World War II American artificial intelligence American. Do you believe in UFOs? Yes, sir. Mr. Tree a steal. What's going on? Everybody Dave bahr, my American podcast got Greg here. What's going on buddy? It's going on everybody. Finally got this freaking OBS to work pain in the butt. Hallelujah. Hallelujah my best program, but whatever it works. So anyways, I got on Instagram live last night. We have some issues got on their hopped on had a couple <mark>of</mark> I don't know ten minute conversation. Got some got some people on their the regulars. It was fun. I enjoyed it. I don't know if you gotta watch it Greg. Little bit. Yeah, I was talking a lot about the super Tuesday or as buying calls it super Thursday. I Want to Jump Right In what I want to talk about because I don't have a lot. I know you do. So. I just want to kind <mark>of</mark> recap that a little bit", "Start Time (s)": 3.6, "End Time (s)": 73.1, "Clip Length (min)": 1.16, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "American <mark>global</mark> Awakening to the New World War II American artificial intelligence American. Do you believe in UFOs? Yes, sir. Mr. Tree a steal. What's going on? Everybody Dave bahr, my American podcast got Greg here. What's going on buddy? It's going on everybody. Finally got this freaking OBS to work pain in the butt. Hallelujah. Hallelujah my best program, but whatever it works. So anyways, I got on Instagram live last night. We have some issues got on their hopped on had a couple <mark>of</mark> I don't know ten minute conversation. Got some got some people on their the regulars. It was fun. I enjoyed it. I don't know if you gotta watch it Greg. Little bit. Yeah, I was talking a lot about the super Tuesday or as buying calls it super Thursday. I Want to Jump Right In what I want to talk about because I don't have a lot. I know you do. So. I just want to kind <mark>of</mark> recap that a little bit Trump had his town hall today. I thought it was really good. Why watch I watched probably three-quarters <mark>of</mark> it. Did you get a watch that? No, I saw a clip where he was talking about mini mic doing horribly and then just went off on Joe Biden not knowing His sister from his wife and I was like, yeah. Yeah. Well, that's not really what I want to talk about. But I just want to say you know numbers are you know, obviously increasing the percentage <mark>of</mark> people the votes counted our you know increasing and it's still kind <mark>of</mark> reflecting what I talked about yesterday, which was you know, the turnout for Trump has been pretty spectacular. So I don't want to take away the fact that the Democrats have also had pretty decent turnouts but not in the younger age group that Bernie was hoping for they're still not turning out to vote. So I don't know man. I think he's gonna have a hell <mark>of</mark> a time. Well, I saw something that showed how much how many votes", "Start Time (s)": 12.5, "End Time (s)": 131.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I Want to Jump Right In what I want to talk about because I don't have a lot. I know you do. So. I just want to kind <mark>of</mark> recap that a little bit Trump had his town hall today. I thought it was really good. Why watch I watched probably three-quarters <mark>of</mark> it. Did you get a watch that? No, I saw a clip where he was talking about mini mic doing horribly and then just went off on Joe Biden not knowing His sister from his wife and I was like, yeah. Yeah. Well, that's not really what I want to talk about. But I just want to say you know numbers are you know, obviously increasing the percentage <mark>of</mark> people the votes counted our you know increasing and it's still kind <mark>of</mark> reflecting what I talked about yesterday, which was you know, the turnout for Trump has been pretty spectacular. So I don't want to take away the fact that the Democrats have also had pretty decent turnouts but not in the younger age group that Bernie was hoping for they're still not turning out to vote. So I don't know man. I think he's gonna have a hell <mark>of</mark> a time. Well, I saw something that showed how much how many votes Trump actually got in California for just the primary it to in California, dude. Yep. I got it. Yeah. Well, what is it like 2 million or sometimes like 1.8 million? Yeah, I'm rounding but I think the Democrats had some like three. Million, which is expected but what a lot <mark>of</mark> people are discussing is that Trump individually owned everybody and now to be fair when you got five or six candidates in the pool that's going to you know reflect differently because you know, once they're down like we saw today Miss Elizabeth Pocahontas Warren dropped out <mark>of</mark> the race. Yes, she did when you have that then you know, obviously some votes are going to go. To her and when she drops out they're going to go somewhere else. But what I was talking about yesterday was the fact", "Start Time (s)": 67.5, "End Time (s)": 185.1, "Clip Length (min)": 1.96, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Warren dropped out <mark>of</mark> the race. Yes, she did when you have that then you know, obviously some votes are going to go. To her and when she drops out they're going to go somewhere else. But what I was talking about yesterday was the fact that not all these votes are going to transfer over to somebody else. So no. Yeah, you got there Bernie or bust you have the Biden's or bus or I should say the moderate or bust they're not jumping over to each other. So that number is is pretty skewed when you really think about it. It is dude, and it's it should just be very For the Democrats. I mean they if Biden is who you and like your party have decided to put all your eggs in. I mean because this was a Consolidated effort. I mean what Pete Buddha judge dropped out Klobuchar dropped out now, I mean mini and mini Mike dropped out. They all three kind <mark>of</mark> ganged up and backed endorsed by didn't and then today you have Elizabeth Warren who backed out Out I don't know if she has announced to she's going to back though. I will say this. I have a feeling that Buddha judge made a deal with Biden. I'm pretty sure that Bloomberg made a deal with Biden. Hey Alan dorsia. You get me a seat on such and such or you know this or that or whatever maybe I don't think anybody likes Elizabeth Warren, so I don't think that she's gonna get offered squat to be honest with you but even like Bloomberg His numbers weren't that good as a whole he did get votes, but they weren't that good. So getting his endorsement. I mean how good is that? Really? Probably not that worthwhile. You know I'm saying well, I mean he has a lot <mark>of</mark> money so he could definitely put a lot <mark>of</mark> power behind your advertisement power. But the thing is is that look at who also came", "Start Time (s)": 171.9, "End Time (s)": 291.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "judge dropped out Klobuchar dropped out now, I mean mini and mini Mike dropped out. They all three kind <mark>of</mark> ganged up and backed endorsed by didn't and then today you have Elizabeth Warren who backed out Out I don't know if she has announced to she's going to back though. I will say this. I have a feeling that Buddha judge made a deal with Biden. I'm pretty sure that Bloomberg made a deal with Biden. Hey Alan dorsia. You get me a seat on such and such or you know this or that or whatever maybe I don't think anybody likes Elizabeth Warren, so I don't think that she's gonna get offered squat to be honest with you but even like Bloomberg His numbers weren't that good as a whole he did get votes, but they weren't that good. So getting his endorsement. I mean how good is that? Really? Probably not that worthwhile. You know I'm saying well, I mean he has a lot <mark>of</mark> money so he could definitely put a lot <mark>of</mark> power behind your advertisement power. But the thing is is that look at who also came out is Beto O'Rourke. We haven't seen that guy since he was clucking like a chicken. Unfriend yeah, CNN get away from me. You're doing good who is like saying the f word to get get the fuck back? Those are four years. Yeah. Yeah, that's actually scary. I talked about that last night. That's actually a really good topic. I wanted to bring back up and I'm glad you brought it up was the moderate Joe. You know, I'm saying Joe is the moderate they keep talking about Joe being the moderate and all signs point to the fact that he's actually not that moderate anymore. He's kind <mark>of</mark> fallen in line. With the rest <mark>of</mark> the far left movement and he's not the same Biden as he was in 16 or even during his vice presidency with Obama his border situation the fact that he brought beta-1 and said, you know, he had his arm around", "Start Time (s)": 223.2, "End Time (s)": 343.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "get away from me. You're doing good who is like saying the f word to get get the fuck back? Those are four years. Yeah. Yeah, that's actually scary. I talked about that last night. That's actually a really good topic. I wanted to bring back up and I'm glad you brought it up was the moderate Joe. You know, I'm saying Joe is the moderate they keep talking about Joe being the moderate and all signs point to the fact that he's actually not that moderate anymore. He's kind <mark>of</mark> fallen in line. With the rest <mark>of</mark> the far left movement and he's not the same Biden as he was in 16 or even during his vice presidency with Obama his border situation the fact that he brought beta-1 and said, you know, he had his arm around him and he's like, this is who I'm gonna go to for all my gun info right here, you know, whatever. I'm like that's a last person you want to go to like if you want to lose the election go to Beta or work for gun information. So well, I mean some people are saying Saying that he's suffering from Dementia or some sort <mark>of</mark> like brain loss. So this would explain it. I mean, he he's asked, you know what I mean acting more like a liberal. I mean that makes more sense some <mark>of</mark> the brain lost power, you know, well, he's being his true self probably. Well. Yeah. Yeah, he's coming to fruition. That's anyways, what did you have to talk about? Because I know you sent me a list yesterday was pretty good. I didn't want to go in too many <mark>of</mark> it the topics without you so I kind <mark>of</mark> left it hanging. I don't If any <mark>of</mark> its relevant syllabus or anything you want to talk about from that list you sent. Yes. So essentially you're seeing a lot more Q stuff at Trump rallies because it was banned. It was it was not allowed they would you know, you'd have people having a Sikh into Trump rallies like hiding their cue shirts and then they would like take off their sweatshirt mid-show and then the whoo, and then you know what? I mean, so but now they're letting all these people in not only", "Start Time (s)": 301.5, "End Time (s)": 420.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Well. Yeah. Yeah, he's coming to fruition. That's anyways, what did you have to talk about? Because I know you sent me a list yesterday was pretty good. I didn't want to go in too many <mark>of</mark> it the topics without you so I kind <mark>of</mark> left it hanging. I don't If any <mark>of</mark> its relevant syllabus or anything you want to talk about from that list you sent. Yes. So essentially you're seeing a lot more Q stuff at Trump rallies because it was banned. It was it was not allowed they would you know, you'd have people having a Sikh into Trump rallies like hiding their cue shirts and then they would like take off their sweatshirt mid-show and then the whoo, and then you know what? I mean, so but now they're letting all these people in not only that but there's a new Trump ad that has come out and front and center dude. You see a woman standing there with a big queue on an American flag in the center <mark>of</mark> her shirt and it's a good she's on there for a good one to Mississippi, dude. Yeah and I'm just saying it's it's kind <mark>of</mark> a in a trump ad when you only have like a minute <mark>of</mark> time and you're dedicating one second <mark>of</mark> that time to this woman wearing a q shirt. That's saying something. Well, he has plenty <mark>of</mark> supporters. He didn't need to use that particular one. He chose that one or whoever's working for him and did it chose that one. So, I mean he could have went through any number <mark>of</mark> videos <mark>of</mark> Patriots holding flags up or give him a thumbs up and they chose that one so it's pretty odd. Yeah, so and then going into someone like the stock market stuff. So did you see that? They they cut the rate like we were talking about. Yep. I saw that then they might cut it again. Yes, and so x 22 everybody should go listen next Wednesday. Listen to us. <mark>Of</mark> course, I mean, we're a lot more funny than x 1 into I think but x22 has some", "Start Time (s)": 374.0, "End Time (s)": 493.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "center dude. You see a woman standing there with a big queue on an American flag in the center <mark>of</mark> her shirt and it's a good she's on there for a good one to Mississippi, dude. Yeah and I'm just saying it's it's kind <mark>of</mark> a in a trump ad when you only have like a minute <mark>of</mark> time and you're dedicating one second <mark>of</mark> that time to this woman wearing a q shirt. That's saying something. Well, he has plenty <mark>of</mark> supporters. He didn't need to use that particular one. He chose that one or whoever's working for him and did it chose that one. So, I mean he could have went through any number <mark>of</mark> videos <mark>of</mark> Patriots holding flags up or give him a thumbs up and they chose that one so it's pretty odd. Yeah, so and then going into someone like the stock market stuff. So did you see that? They they cut the rate like we were talking about. Yep. I saw that then they might cut it again. Yes, and so x 22 everybody should go listen next Wednesday. Listen to us. <mark>Of</mark> course, I mean, we're a lot more funny than x 1 into I think but x22 has some good knowledge on the stock market on the markets like he has like just a good foresight on what's going to Yeah, and he's talking about how there was this thing. Have you ever heard <mark>of</mark> do you know what a dead cat bounce is? Yes. So for the people in the audience, always just explain it. Look at the way the Wikipedia definition. Okay, so it's a small brief recovery in the price <mark>of</mark> a declining stock. So it's a stock market term and it was derived from its kind <mark>of</mark> morbid but it says even a dead cat will bounce if it falls from a great height. So it's kind <mark>of</mark> like The Recoil <mark>of</mark> the body <mark>of</mark> the cat. So basically what it is is it's a small little bump Recovery after a great decline in the fall <mark>of</mark> the market, right? Yep. And so that's kind", "Start Time (s)": 427.8, "End Time (s)": 547.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "22 everybody should go listen next Wednesday. Listen to us. <mark>Of</mark> course, I mean, we're a lot more funny than x 1 into I think but x22 has some good knowledge on the stock market on the markets like he has like just a good foresight on what's going to Yeah, and he's talking about how there was this thing. Have you ever heard <mark>of</mark> do you know what a dead cat bounce is? Yes. So for the people in the audience, always just explain it. Look at the way the Wikipedia definition. Okay, so it's a small brief recovery in the price <mark>of</mark> a declining stock. So it's a stock market term and it was derived from its kind <mark>of</mark> morbid but it says even a dead cat will bounce if it falls from a great height. So it's kind <mark>of</mark> like The Recoil <mark>of</mark> the body <mark>of</mark> the cat. So basically what it is is it's a small little bump Recovery after a great decline in the fall <mark>of</mark> the market, right? Yep. And so that's kind <mark>of</mark> what we're seeing right now is you're seeing the socks go up a little bit and then what's going to happen though is they're going to declare this thing a pandemic within the next couple days dude, because it's you're seeing the picture build. I mean, they're they're illustrating it every morning when you wake up and you see a brand-new. There's a new case over in Tennessee There's a it's going all over The United States now, right and Italy shutting down their universities shutting down their schools. And then it's they're going to it's either the CDC or who is going to come out and say okay. This is a <mark>global</mark> pandemic which is going hand-in-hand with event 201 mind you. Yes, yes, but what's going to happen is the stocks are going to fall even more after that after they declared a pandemic. Shit's gonna hit the fan dude. People are going to freak", "Start Time (s)": 484.9, "End Time (s)": 604.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "within the next couple days dude, because it's you're seeing the picture build. I mean, they're they're illustrating it every morning when you wake up and you see a brand-new. There's a new case over in Tennessee There's a it's going all over The United States now, right and Italy shutting down their universities shutting down their schools. And then it's they're going to it's either the CDC or who is going to come out and say okay. This is a <mark>global</mark> pandemic which is going hand-in-hand with event 201 mind you. Yes, yes, but what's going to happen is the stocks are going to fall even more after that after they declared a pandemic. Shit's gonna hit the fan dude. People are going to freak out and we've already seen it. Like the Costco is like completely empty. Yeah, my wife just went to Walmart and she's like dude it was Bare like there was not a lot <mark>of</mark> stuff on the shelves, like people are buying stuff. So you think it's weird now wait until they declared a pandemic. Yeah. I've noticed I noticed today at work and increase in people have never seen. Before which is rare if you know where I work, but a lot <mark>of</mark> random people coming in buying a lot <mark>of</mark> goods a lot <mark>of</mark> toilet paper. I just still don't get it. I don't get it man. It's a lot <mark>of</mark> toilet paper. I'm like how much you gonna shit seriously how much you need to shit, but there's a lot <mark>of</mark> like, you know, we can't get Purell for example, that's literally you can't buy it. It's not available. We can't even get it in. So there's a lot <mark>of</mark> people that are buying that kind <mark>of</mark> stuff but we have some real weirdos man. I'm talking to the real ones are coming out right now and We had a guy I can't even see his face, but he walked into the he had a mask on he had his hood up. His hair was in his eyes. He was young guy probably early mid 20s, and he had snow gloves on like I'm talking like not", "Start Time (s)": 557.6, "End Time (s)": 676.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "can't even get it in. So there's a lot <mark>of</mark> people that are buying that kind <mark>of</mark> stuff but we have some real weirdos man. I'm talking to the real ones are coming out right now and We had a guy I can't even see his face, but he walked into the he had a mask on he had his hood up. His hair was in his eyes. He was young guy probably early mid 20s, and he had snow gloves on like I'm talking like not like latex or you know snow gloves big old pad is snow gloves and he had two backpacks one in the front one in the back and he was shopping for his goods and he's like he I rang him up. It was pretty quiet at that time, but he Cuz he's like, yeah, man. Sorry. I can't I can't push the buttons on this machine because my gloves are too big. I'm like well, I mean I can do it for you. I gave him a pen so he could push it with a pen because he did not want to take his clothes off and he was telling me he's like dude. This is so much worse than they're telling us man. We're I mean we literally could die. I think we all could die from this. This is like a you know, this is the end <mark>of</mark> the times and I'm like then what are you doing? Then? What are you doing right now? If this is it? Why not? Enjoy the last little bit <mark>of</mark> time you got, you know, go party go have a drink. Go bang a chick whatever you want to do, man. Just don't be you right now, you know, but that's what I'm saying. The level <mark>of</mark> the news the way they're covering. This is what we've been talking about Greg for a while now the the fear and the Panic that the news is causing is worse than any <mark>of</mark> this virus could possibly do. Yeah. I think the people panic is the number one concern for me right now. And because a lot <mark>of</mark> people are not a really awake to what's going on. And I mean that they will believe in everything that they're told by mainstream news mainstream science. They won't like question stuff. Even when it's saying, okay. Well, you're going to have to stay home. I mean, I know you need to go to work to make a paycheck, but you're not going to be allowed to do that. We're going to have to have you a self", "Start Time (s)": 652.4, "End Time (s)": 772.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "fear and the Panic that the news is causing is worse than any <mark>of</mark> this virus could possibly do. Yeah. I think the people panic is the number one concern for me right now. And because a lot <mark>of</mark> people are not a really awake to what's going on. And I mean that they will believe in everything that they're told by mainstream news mainstream science. They won't like question stuff. Even when it's saying, okay. Well, you're going to have to stay home. I mean, I know you need to go to work to make a paycheck, but you're not going to be allowed to do that. We're going to have to have you a self quarantine. OK you're going to have to quarantine yourself, you know, you got to do what's right because this is a dangerous thing and people like that. That who wear mittens to a Goddamn grocery store dude. I mean, come on dude. I know you've also explained that there was that woman who was afraid <mark>of</mark> Wi-Fi signals. She wears like aluminum jacket right? Mesh out <mark>of</mark> metal mesh like celery she's a night. Yeah. I'm not saying that everybody's like this guy. My point is is that this is a young man seemed very nice. I mean, he was nice. He clearly had long hair. He was really upset and I wasn't going to offer but he was like man. I really wish I could give my hair pulled back on my face because it was so much it was like in his eyes, you know, and he had these freaking mitts on yes. He wanted you to do it dude. I don't know. Maybe it's he was fishing for a response. He's like, oh man this hair in my eyes really does bug me. Well, I sure would be nice to have in hand. My boss was laughing at me. He's like did you were awfully friendly to him? You know, I'm like, well listen, here's how I look at it man. The kid is clearly nervous. Okay, he's clearly scared and I don't blame him for that. That's not his fault that he's been fed this", "Start Time (s)": 732.7, "End Time (s)": 852.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "He clearly had long hair. He was really upset and I wasn't going to offer but he was like man. I really wish I could give my hair pulled back on my face because it was so much it was like in his eyes, you know, and he had these freaking mitts on yes. He wanted you to do it dude. I don't know. Maybe it's he was fishing for a response. He's like, oh man this hair in my eyes really does bug me. Well, I sure would be nice to have in hand. My boss was laughing at me. He's like did you were awfully friendly to him? You know, I'm like, well listen, here's how I look at it man. The kid is clearly nervous. Okay, he's clearly scared and I don't blame him for that. That's not his fault that he's been fed this info that we're all gonna die, you know or that this is an extreme thing. That is so much worse than the news. He believes that so I'm not going to sit there and be like, dude, you're dumb like come on man. Like I'm just like, hey man, you know, yeah, he was talking about the goods. He was getting he was buying a bunch <mark>of</mark> stuff and he's trying to fit in a backpack. Because you had he walked a mile to get to the store walked because he didn't want to take public transportation because he thought he was going to catch something. So it literally I feel for him and I was like, I was you know, I'm sitting there like, you know, Clean Hands I had Purell and stuff that we I occasionally use but I'm like, I'm just sitting there smiling and I'm like, hey man, just you got to do you you know, like, you know, it's good that you're buying stuff is that doesn't hurt you. Don't he's like Whoa, man, you don't this could be months. This could be months man. Well, I don't you know, I don't know what to tell you at that point. I just I just wish you luck. That's all I can tell you, you know, hopefully you don't die. I guess. Well, you gotta you gotta imagine how many <mark>of</mark> those people are out there a lot and what you should ask him is. Hey, do you believe in climate change and he would have been like 100% sir? Yes, I do because it's the same it's the same people that are feeding you the the fears <mark>of</mark> climate change. Although you go to a bank and you ask for a", "Start Time (s)": 810.1, "End Time (s)": 929.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know, yeah, he was talking about the goods. He was getting he was buying a bunch <mark>of</mark> stuff and he's trying to fit in a backpack. Because you had he walked a mile to get to the store walked because he didn't want to take public transportation because he thought he was going to catch something. So it literally I feel for him and I was like, I was you know, I'm sitting there like, you know, Clean Hands I had Purell and stuff that we I occasionally use but I'm like, I'm just sitting there smiling and I'm like, hey man, just you got to do you you know, like, you know, it's good that you're buying stuff is that doesn't hurt you. Don't he's like Whoa, man, you don't this could be months. This could be months man. Well, I don't you know, I don't know what to tell you at that point. I just I just wish you luck. That's all I can tell you, you know, hopefully you don't die. I guess. Well, you gotta you gotta imagine how many <mark>of</mark> those people are out there a lot and what you should ask him is. Hey, do you believe in climate change and he would have been like 100% sir? Yes, I do because it's the same it's the same people that are feeding you the the fears <mark>of</mark> climate change. Although you go to a bank and you ask for a primary loan. Or property down on Florida Bank Street. And yeah, they'll okay. We'll give it to you no matter what. Yeah and logic 101 would tell you if <mark>global</mark> <mark>warming</mark> was real if these oceans are going to raise ten feet in the next 10 years. No one's going to sell you like a 10-year loan. No one's going to sell you property down there. Yeah, it has to do with the good example that was used in other terms bedding. So like sports betting right? I was talking about the recent Wilder Tyson fight with one <mark>of</mark> <mark>Of</mark> the guys that is that my work and he's talking about betting on it and the odds and he's like the only way to tell who's gonna like who has the best shot in with a real lodz are to look at the Sharks. You know, I'm saying the Sharks don't want to lose money. So what they're saying the odds are means that it's in their favor rewrite. It has it's no different than anything else man, like a like a bank. They're not going to give out their hard-earned cash if they feel like there's not going to be a", "Start Time (s)": 866.8, "End Time (s)": 986.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "about the recent Wilder Tyson fight with one <mark>of</mark> <mark>Of</mark> the guys that is that my work and he's talking about betting on it and the odds and he's like the only way to tell who's gonna like who has the best shot in with a real lodz are to look at the Sharks. You know, I'm saying the Sharks don't want to lose money. So what they're saying the odds are means that it's in their favor rewrite. It has it's no different than anything else man, like a like a bank. They're not going to give out their hard-earned cash if they feel like there's not going to be a return back on it. And so they're not going to be giving you Oceanfront. Opportunity if they feel like the they're not going to be able to invest or get that money invested back into them is they're just going to deny it. So yeah, the whole thing's a fraud man in my opinion. So it's a huge for them. Well, I mean it's exploitation. So they're taking problem and they're they're taking a molehill and making it a mountain. Yeah. You know I'm saying so they're blowing this thing way out <mark>of</mark> proportion and that is where the panic and the fear build up influence. I agree with you. But so this dead cat are the dead cat balance, right? So it happened. It's probably going to happen again, but x22, it's been saying that Trump is going to take this to the advantage dude. He wants this to happen because it's going to force the FED to cut the rates. N and possibly even go negative rates dude. Yeah, which he says that this will lead to the transition back into the gold standard. Which will frequency and remember there's there's even articles I brought that up on a pass podcast. Yeah, and there's Arguments for it and there's arguments against it, but I'm looking at buying stocks and gold dude, or at least buying some gold. Yeah, very soon. Well, it's a smarter thing. I'm not sure that I", "Start Time (s)": 958.3, "End Time (s)": 1078.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "this to the advantage dude. He wants this to happen because it's going to force the FED to cut the rates. N and possibly even go negative rates dude. Yeah, which he says that this will lead to the transition back into the gold standard. Which will frequency and remember there's there's even articles I brought that up on a pass podcast. Yeah, and there's Arguments for it and there's arguments against it, but I'm looking at buying stocks and gold dude, or at least buying some gold. Yeah, very soon. Well, it's a smarter thing. I'm not sure that I you know, I buy that we're going to go back into a gold standard. I don't know. I don't know either, but I know that the Federal Reserve needs to go bye-bye, you know, I think It's very evident. They have nothing they don't help us as people. It's not it's a private thing. They do what they wish it. Doesn't you know, they don't go with the flow. They kind <mark>of</mark> set their own tone. I just don't like it. I think that's what Trump's the the whole mission that he had. His had was to dismantle this thing and he's been talking about it for years that they're scum. Basically. Well, I don't have all the answers. But yeah, from what I from what I understand is that I think Trump was helped out by Admiral Rogers, right? So he was the guy who basically told him over in Trump Tower. Hey, you need to get the hell out <mark>of</mark> this Trump Tower because they have this thing bugged. Yeah, and you need to move your headquarters get somewhere else and I think he might I think he might be cute dude. I honestly do because think about it. He Q is what Q class Q status like you have classification you have access to all this material, right? He's an admiral He's like he's up there dude. He knows a lot <mark>of</mark> stuff and the fact that he knew about secret", "Start Time (s)": 1037.8, "End Time (s)": 1157.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "what they wish it. Doesn't you know, they don't go with the flow. They kind <mark>of</mark> set their own tone. I just don't like it. I think that's what Trump's the the whole mission that he had. His had was to dismantle this thing and he's been talking about it for years that they're scum. Basically. Well, I don't have all the answers. But yeah, from what I from what I understand is that I think Trump was helped out by Admiral Rogers, right? So he was the guy who basically told him over in Trump Tower. Hey, you need to get the hell out <mark>of</mark> this Trump Tower because they have this thing bugged. Yeah, and you need to move your headquarters get somewhere else and I think he might I think he might be cute dude. I honestly do because think about it. He Q is what Q class Q status like you have classification you have access to all this material, right? He's an admiral He's like he's up there dude. He knows a lot <mark>of</mark> stuff and the fact that he knew about secret operations that were happening at the CIA level about Trump Tower. He was being spied on should tell you something, you know are no hard to say man. It's really hard to say, but you know how like Trump has always come out and said like he hates the FED he wants to end the fed and all this stuff and that's a very kind <mark>of</mark> libertarian topic. I mean it draws in the libertarian crowd. Yeah. A lot <mark>of</mark> the FED can be blamed for these Foreign Wars for because you look at the countries that were invading their the people that are not involved in the federal bank and they're not involved in the central bank and they want to actually start their own profits. They want to start their own monetary system and then we go invade them to prevent them from rising up to power and gaining this axis, right? And so that's the conspiracy to this Petro dollar is that We're as soon as we", "Start Time (s)": 1094.1, "End Time (s)": 1214.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the CIA level about Trump Tower. He was being spied on should tell you something, you know are no hard to say man. It's really hard to say, but you know how like Trump has always come out and said like he hates the FED he wants to end the fed and all this stuff and that's a very kind <mark>of</mark> libertarian topic. I mean it draws in the libertarian crowd. Yeah. A lot <mark>of</mark> the FED can be blamed for these Foreign Wars for because you look at the countries that were invading their the people that are not involved in the federal bank and they're not involved in the central bank and they want to actually start their own profits. They want to start their own monetary system and then we go invade them to prevent them from rising up to power and gaining this axis, right? And so that's the conspiracy to this Petro dollar is that We're as soon as we went to this fiat currency, and we're basically based off <mark>of</mark> oil. That we have to go start wars to protect our investment and that that is why we go to all these different Foreign Wars It's because we're preventing them from utilizing their natural resources to build up their own economy and become the American dream somewhere else. Yeah, and I will say I you know, you brought up x22 quite often over the past couple podcast and I've never watched it until today. I watched it this morning on. Way to work and that's where I actually heard about the the dead cat whatever. However you say that yeah, it's a he's really good. I know you always say like check him out. He's awesome. I'm going to tell you he's really awesome, man. And even for somebody who's not really into it like you are he's very calm which is why I think you made a say that we're probably funnier than he is. He's he's pretty bland. He's pretty dry. But I as a whole I think that", "Start Time (s)": 1159.0, "End Time (s)": 1278.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "quite often over the past couple podcast and I've never watched it until today. I watched it this morning on. Way to work and that's where I actually heard about the the dead cat whatever. However you say that yeah, it's a he's really good. I know you always say like check him out. He's awesome. I'm going to tell you he's really awesome, man. And even for somebody who's not really into it like you are he's very calm which is why I think you made a say that we're probably funnier than he is. He's he's pretty bland. He's pretty dry. But I as a whole I think that he's he's pretty legit. So So I definitely think you should check out x22 so. Yeah, so other than that, I would just keep your eyes on the market, you know, it's going to they're going to declare a pandemic. Go get your food go get your toilet paper go get your you know tampons, whatever you need to get. I know I got plenty <mark>of</mark> those I need them. But anyway, well, I just want to say just keep this in mind people. The only way that we're you know going to survive this issue with with the Panic is don't be hoarders about this. Okay, get what you need. I think the rule that somebody said that I thought was good as if you buy one brick <mark>of</mark> cheese. B by 2 you know I'm saying like there you go don't buy five. Don't buy 10 <mark>of</mark> this. We have people buying multiple cases <mark>of</mark> Purell now, nobody has Purell because you have ten cases and you're not going to freaking use 10 cases, you know, I mean, so the bottom line is is like don't hoard that's going to be a huge issue because we're already going to have trouble getting trucks in it's already going to be things people not going to work. So just slow down just buy what you need. I just want to say that as a little warning Well something else I wanted to bring up there. This is actually kind <mark>of</mark> funny.", "Start Time (s)": 1243.1, "End Time (s)": 1361.8, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you need to get. I know I got plenty <mark>of</mark> those I need them. But anyway, well, I just want to say just keep this in mind people. The only way that we're you know going to survive this issue with with the Panic is don't be hoarders about this. Okay, get what you need. I think the rule that somebody said that I thought was good as if you buy one brick <mark>of</mark> cheese. B by 2 you know I'm saying like there you go don't buy five. Don't buy 10 <mark>of</mark> this. We have people buying multiple cases <mark>of</mark> Purell now, nobody has Purell because you have ten cases and you're not going to freaking use 10 cases, you know, I mean, so the bottom line is is like don't hoard that's going to be a huge issue because we're already going to have trouble getting trucks in it's already going to be things people not going to work. So just slow down just buy what you need. I just want to say that as a little warning Well something else I wanted to bring up there. This is actually kind <mark>of</mark> funny. So remember a couple podcast back we brought up Katie Katie career from MSNBC. She went out up in New Hampshire and she talked to a voter and she's like a sister who you're going to vote for. He's like, I'm going to vote for John or Donald John Trump. So she she did it again, dude. Did you see this? I sure did it's good. So she went into a local Rhett like a grocery store right downtown. Where was this at? Do you remember I don't remember the location? No. Well, the guy was Hispanic. I mean he didn't I don't think he spoke English at all. He had an interpreter with him. Yeah, she did. And so they were talking and she's like so you're gonna go Bernie or by adding, you know and and something set he's you know, the guy was like, you know, but Bernie, you know Sanders and then the guys like, okay. Yeah. Bernie Sanders is you know, he's he likes him. He's going to vote for him and then something", "Start Time (s)": 1301.3, "End Time (s)": 1421.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Did you see this? I sure did it's good. So she went into a local Rhett like a grocery store right downtown. Where was this at? Do you remember I don't remember the location? No. Well, the guy was Hispanic. I mean he didn't I don't think he spoke English at all. He had an interpreter with him. Yeah, she did. And so they were talking and she's like so you're gonna go Bernie or by adding, you know and and something set he's you know, the guy was like, you know, but Bernie, you know Sanders and then the guys like, okay. Yeah. Bernie Sanders is you know, he's he likes him. He's going to vote for him and then something they exchanged in some more talking and then the guy goes. Oh, really? And then Katie career goes you're going to vote or your daughter's going to vote for Trump. And he's like, yeah, and then she goes porque like why well, she actually what what my understanding <mark>of</mark> it is if she asked if his daughter had got him to vote for Bernie Sanders. Yes, and he said no actually in my daughter is going to be voting for Donald Trump and she said why and she says I don't know how you she loves him, you know, and she was bewildered bro. I mean she Well, he has they don't even like they think it's just rare. It's weird that they think is a rare occurrence to have somebody like Donald Trump, you know. Well, there's a if you continue that clip like her Katie Couric and the in The Interpreter walk outside and they didn't like they're talking to each other and she goes so why do you think he has daughter was going to be voting for Trump and the guy was like, well, you know, I'm really surprised. There's like a 10 to 15% these the Burn minority <mark>of</mark> our culture that won't vote the right way. I mean, we're not supposed to vote for Trump, you know Dave's a and it's like stubborn. Yeah, like", "Start Time (s)": 1382.0, "End Time (s)": 1501.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "And he's like, yeah, and then she goes porque like why well, she actually what what my understanding <mark>of</mark> it is if she asked if his daughter had got him to vote for Bernie Sanders. Yes, and he said no actually in my daughter is going to be voting for Donald Trump and she said why and she says I don't know how you she loves him, you know, and she was bewildered bro. I mean she Well, he has they don't even like they think it's just rare. It's weird that they think is a rare occurrence to have somebody like Donald Trump, you know. Well, there's a if you continue that clip like her Katie Couric and the in The Interpreter walk outside and they didn't like they're talking to each other and she goes so why do you think he has daughter was going to be voting for Trump and the guy was like, well, you know, I'm really surprised. There's like a 10 to 15% these the Burn minority <mark>of</mark> our culture that won't vote the right way. I mean, we're not supposed to vote for Trump, you know Dave's a and it's like stubborn. Yeah, like dude, you gotta you can vote whoever you want to vote for when we talked and there's a yes stubborn conservative Branch to the Immigrant immigrants are especially, you know, Mexicans Latinos and and I'm sure there are but Trump's numbers. I mean shit dude, he could get 30% <mark>of</mark> that Latino vote. You know, I'm saying he could Again, 30 percent <mark>of</mark> that African-American vote. It's you know, I don't know man. I I just I don't know why that's surprising I think it's really sad that it kind <mark>of</mark> goes to show you that Katie cure doesn't go out and talk to regular people. You know, that's what it kind <mark>of</mark> ultimately says is she's not talking to people on the ground because if she were she wouldn't be so surprised by these reactions. Well, they want to make it look surprising. I think that's part <mark>of</mark> the actor. They want to make it look like oh", "Start Time (s)": 1432.8, "End Time (s)": 1551.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "these the Burn minority <mark>of</mark> our culture that won't vote the right way. I mean, we're not supposed to vote for Trump, you know Dave's a and it's like stubborn. Yeah, like dude, you gotta you can vote whoever you want to vote for when we talked and there's a yes stubborn conservative Branch to the Immigrant immigrants are especially, you know, Mexicans Latinos and and I'm sure there are but Trump's numbers. I mean shit dude, he could get 30% <mark>of</mark> that Latino vote. You know, I'm saying he could Again, 30 percent <mark>of</mark> that African-American vote. It's you know, I don't know man. I I just I don't know why that's surprising I think it's really sad that it kind <mark>of</mark> goes to show you that Katie cure doesn't go out and talk to regular people. You know, that's what it kind <mark>of</mark> ultimately says is she's not talking to people on the ground because if she were she wouldn't be so surprised by these reactions. Well, they want to make it look surprising. I think that's part <mark>of</mark> the actor. They want to make it look like oh someone's being stubborn. Oh someone's whoa. Someone's on the outside. What? Yeah, like you're there an anomaly. Is that what? Yeah, I get you. Yeah, they want to make it look like whoa, dude. You gotta rethink what you're doing here. Okay. Yeah. Well I all I can say is that all these people who do support Trump who may be Latino, maybe African-American like they have Friends, they talk to people they discuss things they know where they stand and where their friends and family stand so it's not really going to win anybody over man. I mean, you know, I mean like she's not going to the only people she used she would be doing that for is the woke left in La who's watching it on TV going like see this is just one. This is one guy, you know, like one girl. No not there's a lot there's a lot actually wouldn't be shocked if there's a lot more man to be honest with you. Well, I think that's why I'm really interested to", "Start Time (s)": 1489.5, "End Time (s)": 1608.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and where their friends and family stand so it's not really going to win anybody over man. I mean, you know, I mean like she's not going to the only people she used she would be doing that for is the woke left in La who's watching it on TV going like see this is just one. This is one guy, you know, like one girl. No not there's a lot there's a lot actually wouldn't be shocked if there's a lot more man to be honest with you. Well, I think that's why I'm really interested to see who shows up for this presidential voting. I mean for the this year for when we vote for the president. I think it's going to be the most people voting that we've ever seen before. I don't know. I don't know and I know that Barack Obama brought this out, but I think that right now Now because it's you gotta look at it like two different ways you got to look at there's a lot <mark>of</mark> people that hate Trump and there's a lot <mark>of</mark> people that love Trump. Yeah. So when those two masses collide together, I think that that's one thing that Trump has done is definitely got people more into politics whether that's a good thing or a bad thing you could argue either way, but I think every waking everybody up into politics is essentially a good thing because how are you to know? I mean Look at our friends did when we asked him like Hey, you don't care about this like local decision below. How is it going to affect me? I don't know think big picture dude. Think about like if you have somebody who's having taxes on this one issue and having taxes on this other issue and then all <mark>of</mark> a sudden, you know as the slippery slope argument. Yeah, you can make that all day, but I'm just saying I got I got my frickin property tax today and I'm going through the itemized list <mark>of</mark> Actions like you got this tax this tax this tax, you know what I'm saying?", "Start Time (s)": 1579.0, "End Time (s)": 1698.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "right now Now because it's you gotta look at it like two different ways you got to look at there's a lot <mark>of</mark> people that hate Trump and there's a lot <mark>of</mark> people that love Trump. Yeah. So when those two masses collide together, I think that that's one thing that Trump has done is definitely got people more into politics whether that's a good thing or a bad thing you could argue either way, but I think every waking everybody up into politics is essentially a good thing because how are you to know? I mean Look at our friends did when we asked him like Hey, you don't care about this like local decision below. How is it going to affect me? I don't know think big picture dude. Think about like if you have somebody who's having taxes on this one issue and having taxes on this other issue and then all <mark>of</mark> a sudden, you know as the slippery slope argument. Yeah, you can make that all day, but I'm just saying I got I got my frickin property tax today and I'm going through the itemized list <mark>of</mark> Actions like you got this tax this tax this tax, you know what I'm saying? So dude, the thing is listen, you know you made a good point. We have a lot <mark>of</mark> friends who really just don't care and that's okay. I mean, it's not okay, but it's okay if they want to I'm not going to try to convince them otherwise but to say that you I think that the how does it affect me as the wrong way. I think a lot <mark>of</mark> them say what they do doesn't affect me. My life isn't going to change that's what it is and I have to disagree so much because on this election in particular say, it's Bernie Sanders, you know, you're talking about two extremes. You know, I'm saying you're talking about ultimate capitalism ultimate socialism. You're talking about lower taxes. To the extreme and increased taxes to the extreme now, if you want to talk about your day-to-day life, you can be stubborn and say it's not going to affect you. But when you", "Start Time (s)": 1633.1, "End Time (s)": 1752.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you I think that the how does it affect me as the wrong way. I think a lot <mark>of</mark> them say what they do doesn't affect me. My life isn't going to change that's what it is and I have to disagree so much because on this election in particular say, it's Bernie Sanders, you know, you're talking about two extremes. You know, I'm saying you're talking about ultimate capitalism ultimate socialism. You're talking about lower taxes. To the extreme and increased taxes to the extreme now, if you want to talk about your day-to-day life, you can be stubborn and say it's not going to affect you. But when you get your paycheck home and there is 20% more taken out or 30% more taken out or in his dream world 70% more taken out. I think you're going to be like what the fuck is this? I had no idea this was coming and that is a big problem when you're not paying attention and I have a feeling there's a lot <mark>of</mark> Voters who have no idea what this really really means and I think the only thing I can hope for it. Listen if there's a bigger turnout that's great in the big scheme <mark>of</mark> things. They keep saying that if it's a large large turnout it favors Democrats. I have a feeling that more people are going to vote for Trump. Trump we're going to come out for Trump and even people that were on the fence at didn't vote for him last time might actually come around because the world didn't end guys Trump didn't start a nuclear war and everybody that had questions about him are probably going. Hey, damn. I was little wrong on this we've heard it. We've seen it on YouTube. We've seen the videos. We've seen the walkaway movement. It's all over the place man. I have a feeling a lot more people are going to go pull that trick lever for Donald Trump. I agree and I think it opens the door. For further candidates to I mean just to say hey if Trump could do it I could do it too. So that's one possibility. Yeah, so I want to take this back to Bloomberg. Okay", "Start Time (s)": 1713.1, "End Time (s)": 1832.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "what this really really means and I think the only thing I can hope for it. Listen if there's a bigger turnout that's great in the big scheme <mark>of</mark> things. They keep saying that if it's a large large turnout it favors Democrats. I have a feeling that more people are going to vote for Trump. Trump we're going to come out for Trump and even people that were on the fence at didn't vote for him last time might actually come around because the world didn't end guys Trump didn't start a nuclear war and everybody that had questions about him are probably going. Hey, damn. I was little wrong on this we've heard it. We've seen it on YouTube. We've seen the videos. We've seen the walkaway movement. It's all over the place man. I have a feeling a lot more people are going to go pull that trick lever for Donald Trump. I agree and I think it opens the door. For further candidates to I mean just to say hey if Trump could do it I could do it too. So that's one possibility. Yeah, so I want to take this back to Bloomberg. Okay and kind <mark>of</mark> mix this in with what's been going on with just everything right? Did you see the video <mark>of</mark> him by the way licking his fingers like a frickin like he was sucking it off <mark>of</mark> like like a vacuum is grossly actually put a half-eaten pizza back in the box and then lick everything GE did it was it was disgusting gross and James Woods was like, yeah that so this is how you spread coronavirus 101 here. Yeah, actually the five the Five on Fox were saying like he has no self-awareness the So into himself that he literally has no idea that he's being gross or that he's just a nasty person but he is he's a turd. He's like a he's a turd. Yeah, but this guy is so on on Twitter mark Meadows. He made a really good point and this goes against the Trump Russia collusion. Right the whole Russian bought thing. So like", "Start Time (s)": 1774.7, "End Time (s)": 1894.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "It says like Trump is worried about Mike Bloomberg or something like that. Like Trump is like no he's not No, he's not. Yeah, and so you guys think about the money and think about what the claim is that the Russians spent $100,000 on Twitter Bots or Facebook bus, whatever the bot you guys have brains. Okay. You guys know when you see bullshit is bullshit. Mike Bloomberg is bullshit. Clearly. Yeah, I mean the vote shows that And well, it goes to show you that having that much money doesn't mean you're going to win missing out on the first couple debates is not a good idea. Just like Rudy Giuliani did back in the day where he skipped the first couple debates and it just doesn't work. Maybe it'll work down the road but it's not working right now didn't work for him. And also, you know, one <mark>of</mark> the one <mark>of</mark> the channels was saying like money can get you a lot <mark>of</mark> ass, but it can't buy a personality and the guy has no personality. He wasn't likable he Is not funny he was short which I'm sorry, but that's you know, if you're short you're gonna have a little tougher time being a dominant figure. That's why Trump is so, you know, I don't even know the word but he Towers over people. He looks big he is a big person. He's a little obese. You know, I'm saying like when he shakes her hand, he grabs you by the fucking Nick, you know, I mean like he's just a dominant human and Bloomberg is not and that is the same reason that I really I feel like Bernie Sanders is going to have a lot <mark>of</mark> problems because when he's on stage if it is him, I hope it's not me. I hope it's Biden. I don't really care. Who but when you go stand next to Trump, they're gonna look very weak. Biden is going to look very slow and Bernie's going to look very weak. Yes, I", "Start Time (s)": 1961.8, "End Time (s)": 2080.8, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the same reason that I really I feel like Bernie Sanders is going to have a lot <mark>of</mark> problems because when he's on stage if it is him, I hope it's not me. I hope it's Biden. I don't really care. Who but when you go stand next to Trump, they're gonna look very weak. Biden is going to look very slow and Bernie's going to look very weak. Yes, I agree after going to be insane. If it's Biden. Oh my Lord, is this debate going to be funny? Because Trump will not let him say this random stuff and not call him out on it period Well Let's get into what we're going to talk about this week and what to keep an eye on. Okay, because because I just baby. Oh, yeah. I was going to say we are getting up there in time. So we gotta we gotta go but the things we got to keep an eye on. What you just talked about Joe Biden and Bernie and all <mark>of</mark> this stuff. Remember couple podcast goes probably over a month. Maybe two months you brought up you brought up the question <mark>of</mark> what if somebody dies. While they are the candidate that's been chosen the nominee. Okay. Yeah, like if you keep that in mind everybody because we're going to go there we're going there this Sunday who is invisible and who's gonna go Greg. I don't know but I think that that we got to look at the rules because the rules matter. Okay, and if the rules if the rule suddenly change here in the next couple weeks, we got to pay attention to this because Bernie is come out Bernie came out today or last night and said if it comes to a contested convention, I'm going to give up. Religious right? He said yeah. He said yeah. I just I posted on Instagram about it. He came out and said that if Biden gets the votes he won", "Start Time (s)": 2057.9, "End Time (s)": 2176.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "While they are the candidate that's been chosen the nominee. Okay. Yeah, like if you keep that in mind everybody because we're going to go there we're going there this Sunday who is invisible and who's gonna go Greg. I don't know but I think that that we got to look at the rules because the rules matter. Okay, and if the rules if the rule suddenly change here in the next couple weeks, we got to pay attention to this because Bernie is come out Bernie came out today or last night and said if it comes to a contested convention, I'm going to give up. Religious right? He said yeah. He said yeah. I just I posted on Instagram about it. He came out and said that if Biden gets the votes he won period that's it. So I'm just saying Bernie is not going to let this go to a contested convention and they kind <mark>of</mark> want this and we're going to go into why and so but those rules everybody do their research look up those rules because we're going to be doing some research as well. Okay, I like it. And then the coronavirus news apparently now, there are two strains Dave. No boy, okay. Oh boy, there's S screen and an else train the else Train That's lethal bro. Okay, that's the hell. That's lethal Jesus. God, dude. I'm just so sick <mark>of</mark> this guy's we live in Washington state and if you follow the news at all, you know that Washington is the supposed epicenter epicenter for this Corona virus. There is what nine deaths now. From that retirement home up north and I'm just going to tell you word on the street here in my hometown. And your hometown Greg is I ain't seen nothing. You know, I'm saying I seen nothing", "Start Time (s)": 2129.4, "End Time (s)": 2247.8, "Clip Length (min)": 1.97, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and so but those rules everybody do their research look up those rules because we're going to be doing some research as well. Okay, I like it. And then the coronavirus news apparently now, there are two strains Dave. No boy, okay. Oh boy, there's S screen and an else train the else Train That's lethal bro. Okay, that's the hell. That's lethal Jesus. God, dude. I'm just so sick <mark>of</mark> this guy's we live in Washington state and if you follow the news at all, you know that Washington is the supposed epicenter epicenter for this Corona virus. There is what nine deaths now. From that retirement home up north and I'm just going to tell you word on the street here in my hometown. And your hometown Greg is I ain't seen nothing. You know, I'm saying I seen nothing but the city that we're from Longview did put out a kind <mark>of</mark> a feed saying that they're they're going into it not a state <mark>of</mark> emergency because they have no cases but just out <mark>of</mark> concern they're going to go into an emergency state that be prepared to not have to go to work be prepared to have things shut down guys. Then this is all just this is so fraudulent. I'm telling you so fraudulent. Well, I don't know. I'm curious what the numbers are. I need to look that up. I would like to talk about on the podcast what the actual numbers <mark>of</mark> flu deaths are compared to coronavirus DSR this year, so I would bet you I bet you the flu is really just killing so we'll go we'll go more into that this this So I'm just laying up the topics on what we're going to test. I know so I'm getting excited about this. But just keep an eye on that and then also the federal funding right emergency funding. So wherever the sanctuary stays were for illegal aliens. Yeah.", "Start Time (s)": 2191.6, "End Time (s)": 2311.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "because they have no cases but just out <mark>of</mark> concern they're going to go into an emergency state that be prepared to not have to go to work be prepared to have things shut down guys. Then this is all just this is so fraudulent. I'm telling you so fraudulent. Well, I don't know. I'm curious what the numbers are. I need to look that up. I would like to talk about on the podcast what the actual numbers <mark>of</mark> flu deaths are compared to coronavirus DSR this year, so I would bet you I bet you the flu is really just killing so we'll go we'll go more into that this this So I'm just laying up the topics on what we're going to test. I know so I'm getting excited about this. But just keep an eye on that and then also the federal funding right emergency funding. So wherever the sanctuary stays were for illegal aliens. Yeah. They're the ones that are coming out next to declare states <mark>of</mark> emergency. So you're going to see New York come out. You're going to see New Jersey come out people are going to be like, well, those are all the populated areas. Okay. Well those were also the sanctuary City. So yeah, there's a And there's also some news with Trump in the sanctuary cities and defunding them that's actually going to be moving forward. So it's a big conundrum if you ask me. Yes, sir. All right. Well, let's save the rest. Let's do a live feed. What tomorrow? Yeah, we're going to get on tomorrow live Instagram. We will be all in around 8 o'clock. Let's say Friday because tomorrow is today Weber's listening to this. Hopefully, I mean it will see well. Yeah. Well Friday 8:00 o'clock. Yeah, we will be live on Instagram. I don't know how many videos are going to take but we'd like to get a couple in and I'd love Greg to be able to take a couple videos. They either way we're going to have fun. It'll be enjoyable. And as usual, please follow like share and tell a friend or two.", "Start Time (s)": 2255.5, "End Time (s)": 2373.7, "Clip Length (min)": 1.97, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Let's say Friday because tomorrow is today Weber's listening to this. Hopefully, I mean it will see well. Yeah. Well Friday 8:00 o'clock. Yeah, we will be live on Instagram. I don't know how many videos are going to take but we'd like to get a couple in and I'd love Greg to be able to take a couple videos. They either way we're going to have fun. It'll be enjoyable. And as usual, please follow like share and tell a friend or two. Indeed our Greg appreciate talk to you glad we were able to do a podcast. I was a little concerned yesterday. Okay, and we're oh, yeah real quick. We got to make sure that Sunday we don't forget to update our our our followers on our carnivore diet that we've been on for this week. So, oh I'm following it to a tee. So we got to give an update. Okay. All right, where we won we go all baby. All right. All right. Talk to you later, bud sayonara. It's just awfully good that Donald Trump is not in charge <mark>of</mark> the law in our country because you'd be in jail my mom. merkin", "Start Time (s)": 2349.1, "End Time (s)": 2413.7, "Clip Length (min)": 1.08, "show_uri": "spotify:show:3t28iEniFcPVIj7JeVVNHm", "show_name": "Pardon My American", "show_description": "Podcast by Pardon My American", "publisher": "Pardon My American", "episode_uri": "spotify:episode:3VTEqJ93ElIHsORMEXSN9L", "episode_name": "#86: Dems Push Biden, Pandemic Panic, Stock Market Madness", "episode_description": "Dave and Greg discuss Super Thursday...I mean Super Tuesday! \u00a0They go into the Dems consolidated effort to push Creepy Joe in as the front runner and what impact this has moving forward. \u00a0The discussion moves into the coronavirus scare and how the people panic appears to be worse than the actual virus. \u00a0The virus will likely be declared a pandemic very soon. \u00a0The guys discuss how this will impact the stock market and what trends are in the near future. \u00a0They close discussing the upcoming week's discussions, including the further coronavirus monitoring and the rules for when a presidential candidate dies... ", "score": 5.9087276, "explanation": "{\n  \"value\": 5.9087276,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=98.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3245809,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 98.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.489771,\n      \"description\": \"weight(word_list:global in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.489771,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.418957,\n      \"description\": \"weight(word_list:warming in 373) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.418957,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.5251864,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7192.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "The audible <mark>of</mark> the best in Bitcoin. This is the crypto Cana me. If you guys have not seen it yet Gigi just recently dropped an article on his medium page and it's another great one about around the concept <mark>of</mark> Bitcoin as a living organism. So let's go ahead and jump into the read and then we'll talk a little bit about it afterward. Bitcoins habitats how Bitcoin is surviving and thriving Between Worlds as I have argued previously Bitcoin is a living organism. But where does this organism live exactly as with many questions in the world <mark>of</mark> Bitcoin exact answers", "Start Time (s)": 0.6, "End Time (s)": 61.4, "Clip Length (min)": 1.01, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "The audible <mark>of</mark> the best in Bitcoin. This is the crypto Cana me. If you guys have not seen it yet Gigi just recently dropped an article on his medium page and it's another great one about around the concept <mark>of</mark> Bitcoin as a living organism. So let's go ahead and jump into the read and then we'll talk a little bit about it afterward. Bitcoins habitats how Bitcoin is surviving and thriving Between Worlds as I have argued previously Bitcoin is a living organism. But where does this organism live exactly as with many questions in the world <mark>of</mark> Bitcoin exact answers are hard to come by living things have fuzzy edges beginnings and endings are hard to pinpoint differentiation is more or less arbitrary and what was classified as a wolf today might evolve to be a dog tomorrow. Bitcoin has no rigid specification. No absolute finality. No fixed development team. No final security guarantees. No scheduled updates. No Central brain, no central vision. No Kings and no rulers. It is a decentralized organism organically evolving without central planners the lack <mark>of</mark> any centralization is the source <mark>of</mark> Bitcoins Beauty. Its organic Behavior. and its resilience Bitcoin is everywhere and nowhere which makes figuring out where this thing lives a daunting task. However,", "Start Time (s)": 0.6, "End Time (s)": 119.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "differentiation is more or less arbitrary and what was classified as a wolf today might evolve to be a dog tomorrow. Bitcoin has no rigid specification. No absolute finality. No fixed development team. No final security guarantees. No scheduled updates. No Central brain, no central vision. No Kings and no rulers. It is a decentralized organism organically evolving without central planners the lack <mark>of</mark> any centralization is the source <mark>of</mark> Bitcoins Beauty. Its organic Behavior. and its resilience Bitcoin is everywhere and nowhere which makes figuring out where this thing lives a daunting task. However, it turns out that there is a space it lives in multiple spaces as we shall see. the habitats <mark>of</mark> Bitcoin while classifying the habitat <mark>of</mark> a decentralized organism isn't trivial we can look at the constituents <mark>of</mark> Bitcoin to make the task a bit easier as outlined in the last article <mark>of</mark> this series The Coin lives across domains with one foot in the purely informational realm ideas and code and one foot in the Physical Realm people and nodes and awareness <mark>of</mark> Bitcoins environments might help to better understand this new form <mark>of</mark> life. No, Can be meaningfully studied in isolation and Bitcoin is no exception as Alan Watts pointed out one has to be aware <mark>of</mark> the basic unity every organism forms with its environment quote for the ecologist the biologists and the physicists know but seldom feel that every organism constitutes a single field <mark>of</mark> behavior or process with its", "Start Time (s)": 68.8, "End Time (s)": 187.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the habitats <mark>of</mark> Bitcoin while classifying the habitat <mark>of</mark> a decentralized organism isn't trivial we can look at the constituents <mark>of</mark> Bitcoin to make the task a bit easier as outlined in the last article <mark>of</mark> this series The Coin lives across domains with one foot in the purely informational realm ideas and code and one foot in the Physical Realm people and nodes and awareness <mark>of</mark> Bitcoins environments might help to better understand this new form <mark>of</mark> life. No, Can be meaningfully studied in isolation and Bitcoin is no exception as Alan Watts pointed out one has to be aware <mark>of</mark> the basic unity every organism forms with its environment quote for the ecologist the biologists and the physicists know but seldom feel that every organism constitutes a single field <mark>of</mark> behavior or process with its environment. There is no a way <mark>of</mark> separating what any given organism is doing from what its environment is doing for which reason ecologist speak not <mark>of</mark> organisms in environments, but <mark>of</mark> organism environments and quote Alan Watts. With that in mind, let's take a closer. Look at the organism environments. We are dealing with as outlined above Bitcoins ideas and code inhabit one realm and Bitcoins people and nodes inhabit another to stick with tradition. Let's call the Physical Realm meet space and the purely informational realm cyberspace. Even if as always the lines might be fuzzy around the edges. The soul <mark>of</mark> Bitcoin so to speak lives in cyberspace. They are Bitcoin absorbs useful ideas and incorporates them into its code as with all living things.", "Start Time (s)": 127.0, "End Time (s)": 245.1, "Clip Length (min)": 1.97, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but <mark>of</mark> organism environments and quote Alan Watts. With that in mind, let's take a closer. Look at the organism environments. We are dealing with as outlined above Bitcoins ideas and code inhabit one realm and Bitcoins people and nodes inhabit another to stick with tradition. Let's call the Physical Realm meet space and the purely informational realm cyberspace. Even if as always the lines might be fuzzy around the edges. The soul <mark>of</mark> Bitcoin so to speak lives in cyberspace. They are Bitcoin absorbs useful ideas and incorporates them into its code as with all living things. Something is useful if it helps an organism to survive while Bitcoin has various self regulatory mechanisms to react to the environment new ideas may be necessary for survival if changes are drastic enough. The quote body <mark>of</mark> Bitcoin like all bodies is living in meatspace nodes hard drives cables and other things come together in an intricate dance pushing around electrons changing zeros to ones and vice versa making sure that Bitcoins heartbeats about a thousand times a week living things have an interest in staying alive and the Bitcoin organism is no exception Bitcoin found an ingenious way to ensure that it stays alive. If it pays people as Ralph Merkle pointed out people and increasingly organizations are incentivized to keep it alive. They shape the physical world to Bitcoins liking feed it energy renew its hardware and update its software to keep it alive. The fact that Bitcoin pays us to keep it alive opens up a third space a space <mark>of</mark> financial transactions value and mutual beneficial exchange. Let's call this", "Start Time (s)": 200.9, "End Time (s)": 320.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "ideas may be necessary for survival if changes are drastic enough. The quote body <mark>of</mark> Bitcoin like all bodies is living in meatspace nodes hard drives cables and other things come together in an intricate dance pushing around electrons changing zeros to ones and vice versa making sure that Bitcoins heartbeats about a thousand times a week living things have an interest in staying alive and the Bitcoin organism is no exception Bitcoin found an ingenious way to ensure that it stays alive. If it pays people as Ralph Merkle pointed out people and increasingly organizations are incentivized to keep it alive. They shape the physical world to Bitcoins liking feed it energy renew its hardware and update its software to keep it alive. The fact that Bitcoin pays us to keep it alive opens up a third space a space <mark>of</mark> financial transactions value and mutual beneficial exchange. Let's call this space thin space to understand Finn space. We will have to examine the other side <mark>of</mark> this coin so far. We only examined the side with the uppercase B the Bitcoin network, but there is also Bitcoin with a lowercase b, which is the unit <mark>of</mark> value itself. elf brought into existence by every copy <mark>of</mark> The Ledger These Bitcoins while deeply embedded in the Amber <mark>of</mark> The Ledger are traded worldwide on various markets and marketplaces and since these Bitcoins and their value are critical for Bitcoin survival. We will have to recognize thin space as the third space that this strange Beast lives in note that fin space. Strangely enough is solely inhabited by Bit coin with a lowercase b In total we can identify three distinct environments which the", "Start Time (s)": 254.4, "End Time (s)": 374.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Let's call this space thin space to understand Finn space. We will have to examine the other side <mark>of</mark> this coin so far. We only examined the side with the uppercase B the Bitcoin network, but there is also Bitcoin with a lowercase b, which is the unit <mark>of</mark> value itself. elf brought into existence by every copy <mark>of</mark> The Ledger These Bitcoins while deeply embedded in the Amber <mark>of</mark> The Ledger are traded worldwide on various markets and marketplaces and since these Bitcoins and their value are critical for Bitcoin survival. We will have to recognize thin space as the third space that this strange Beast lives in note that fin space. Strangely enough is solely inhabited by Bit coin with a lowercase b In total we can identify three distinct environments which the Bitcoin organism inhabits cyberspace the world <mark>of</mark> ideas and code meatspace the world <mark>of</mark> people and nodes and fin space the world <mark>of</mark> value and markets the world <mark>of</mark> dollars and SATs. Understanding these habitats becomes increasingly important especially as the climate in one or more heats up. The climate's They Are A-Changin the three spaces outlined above cyberspace meatspace and fin space have different restrictions different climates. So to speak in short, they operate under different rules. Once these rules change drastically enough people will say that quote. The political climate is heating up and reports on the quote coming Financial climate will be written citizens will be unable to speak and act freely. If things change drastically enough people will rise up in protest or if all else fails", "Start Time (s)": 319.6, "End Time (s)": 438.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "important especially as the climate in one or more heats up. The climate's They Are A-Changin the three spaces outlined above cyberspace meatspace and fin space have different restrictions different climates. So to speak in short, they operate under different rules. Once these rules change drastically enough people will say that quote. The political climate is heating up and reports on the quote coming Financial climate will be written citizens will be unable to speak and act freely. If things change drastically enough people will rise up in protest or if all else fails lie. cyberspace while we don't have precise words for it. It is obvious that the climate in cyberspace has changed quite drastically in the last two decades or so, the idealistic utopian ideas, which were the foundation <mark>of</mark> most <mark>of</mark> the internet were perverted by the advertisement driven surveillance companies, which are the Giants <mark>of</mark> today. People and politicians are slowly waking up to the strange reality that we are living in the fact that Facebook can manipulate moods and sway elections is as disturbing as the fact that Google knows you better than you know yourself. Edward Snowden showed that the most paranoid netizens were right all along everyone in cyberspace is under constant surveillance without suspicion by default while the Western world does not immediately feel the repercussions that come with living in a constant state <mark>of</mark> surveillance. Chinese citizens are gathering first-hand experience with each passing day. In the Western World, the consequences are advertisements which range from Annoying too spooky in China. The consequences are frozen bank accounts", "Start Time (s)": 395.3, "End Time (s)": 514.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "surveillance companies, which are the Giants <mark>of</mark> today. People and politicians are slowly waking up to the strange reality that we are living in the fact that Facebook can manipulate moods and sway elections is as disturbing as the fact that Google knows you better than you know yourself. Edward Snowden showed that the most paranoid netizens were right all along everyone in cyberspace is under constant surveillance without suspicion by default while the Western world does not immediately feel the repercussions that come with living in a constant state <mark>of</mark> surveillance. Chinese citizens are gathering first-hand experience with each passing day. In the Western World, the consequences are advertisements which range from Annoying too spooky in China. The consequences are frozen bank accounts and inability to by train or plane tickets elimination <mark>of</mark> credit worthiness automated fines for trivial offenses and more voicing the wrong opinion quote on quote online or not can lead to restricted access to schools hotels and jobs and after ruining Life with a flip <mark>of</mark> a bit you will be publicly named as a bad Citizen and the government will even take away your dog. If that doesn't sound dystopian enough for your taste, I bet that it will be in a couple <mark>of</mark> years remind yourself that this is only the beginning. In the quote free world things are more subtle multiple efforts are underway to curb net neutrality. The very Cornerstone <mark>of</mark> the internet legislation is being passed which is inherently incompatible with the laws <mark>of</mark> cyberspace. It seems like the last battle <mark>of</mark> the crypto Wars is yet to be fault as politicians are calling for responsible encryption and", "Start Time (s)": 458.5, "End Time (s)": 578.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "China. The consequences are frozen bank accounts and inability to by train or plane tickets elimination <mark>of</mark> credit worthiness automated fines for trivial offenses and more voicing the wrong opinion quote on quote online or not can lead to restricted access to schools hotels and jobs and after ruining Life with a flip <mark>of</mark> a bit you will be publicly named as a bad Citizen and the government will even take away your dog. If that doesn't sound dystopian enough for your taste, I bet that it will be in a couple <mark>of</mark> years remind yourself that this is only the beginning. In the quote free world things are more subtle multiple efforts are underway to curb net neutrality. The very Cornerstone <mark>of</mark> the internet legislation is being passed which is inherently incompatible with the laws <mark>of</mark> cyberspace. It seems like the last battle <mark>of</mark> the crypto Wars is yet to be fault as politicians are calling for responsible encryption and the ban <mark>of</mark> certain CAD files. Companies are in charge <mark>of</mark> the speakers corners <mark>of</mark> cyberspace and are making arbitrary decisions on what can be uttered by whom and what is off-limits bitcoin knows no borders. No jurisdictions. However, it has to conform to the laws <mark>of</mark> cyberspace and if these laws change or in other words, if large parts <mark>of</mark> the world block Bitcoin traffic and or the usage <mark>of</mark> tour the Bitcoin organism will have to adapt Meatspace meatspace climate differs wildly from jurisdiction to jurisdiction some bastions <mark>of</mark> Freedom still exist. But once you try to board an international flight, it becomes obvious that you were right to privacy and your freedom to bring a bottle <mark>of</mark> water with you are null and void protests across the globe indicate that the powerless are", "Start Time (s)": 511.8, "End Time (s)": 631.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is inherently incompatible with the laws <mark>of</mark> cyberspace. It seems like the last battle <mark>of</mark> the crypto Wars is yet to be fault as politicians are calling for responsible encryption and the ban <mark>of</mark> certain CAD files. Companies are in charge <mark>of</mark> the speakers corners <mark>of</mark> cyberspace and are making arbitrary decisions on what can be uttered by whom and what is off-limits bitcoin knows no borders. No jurisdictions. However, it has to conform to the laws <mark>of</mark> cyberspace and if these laws change or in other words, if large parts <mark>of</mark> the world block Bitcoin traffic and or the usage <mark>of</mark> tour the Bitcoin organism will have to adapt Meatspace meatspace climate differs wildly from jurisdiction to jurisdiction some bastions <mark>of</mark> Freedom still exist. But once you try to board an international flight, it becomes obvious that you were right to privacy and your freedom to bring a bottle <mark>of</mark> water with you are null and void protests across the globe indicate that the powerless are fed up with the powerful who do everything they can to stay in control and solidified their positions <mark>of</mark> influence. History shows that governments do not shy away from using their power in 1933 executive order 6102 was signed effectively forcing the whole population <mark>of</mark> the United States to hand over their gold and gold certificates to the government. Yes, seizing Bitcoin is way harder than season gold in some cases even impossible but it would surprise me if those who currently control our money the governments and central banks <mark>of</mark> this world would simply roll over and let Bitcoin march on unhindered governments have a monopoly on violence and they are able and willing to abuse this violence in their own interest with Bitcoin. However, people can flee a country with their wealth intact", "Start Time (s)": 566.0, "End Time (s)": 685.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to hand over their gold and gold certificates to the government. Yes, seizing Bitcoin is way harder than season gold in some cases even impossible but it would surprise me if those who currently control our money the governments and central banks <mark>of</mark> this world would simply roll over and let Bitcoin march on unhindered governments have a monopoly on violence and they are able and willing to abuse this violence in their own interest with Bitcoin. However, people can flee a country with their wealth intact while this is definitely not easy and not Something I would wish on anyone it is now possible. thin space Where should I even begin the current debt based Financial system has an appetite for printing money which is beyond belief quantitative easing negative interest rate policies currency Wars hyperinflations. And a looming recession are just a few <mark>of</mark> the recipes <mark>of</mark> the <mark>global</mark> instability soup, which is currently Brewing The Current financial system seems so far removed from common sense and reality that all the jargon in the world won't be able Stabilize this house <mark>of</mark> cards people know that our money is broken, which is why they flee to buying real estate stocks and all kinds <mark>of</mark> complicated Financial constructs to preserve their wealth in the current system. You have to be an investment expert just to hold your value. And we haven't even talked about the looming recession and the virtual inevitability <mark>of</mark> the next financial crisis yet. Yes governments might be able to Kick the Can down the road by printing ever more money, but no road is endless and the experiment which is Fiat money will come to an end one way or another how Bitcoin will react to a catastrophe in fin space is anyone's guess some people might flee from their failing fiat currency into Bitcoin", "Start Time (s)": 653.5, "End Time (s)": 773.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "reality that all the jargon in the world won't be able Stabilize this house <mark>of</mark> cards people know that our money is broken, which is why they flee to buying real estate stocks and all kinds <mark>of</mark> complicated Financial constructs to preserve their wealth in the current system. You have to be an investment expert just to hold your value. And we haven't even talked about the looming recession and the virtual inevitability <mark>of</mark> the next financial crisis yet. Yes governments might be able to Kick the Can down the road by printing ever more money, but no road is endless and the experiment which is Fiat money will come to an end one way or another how Bitcoin will react to a catastrophe in fin space is anyone's guess some people might flee from their failing fiat currency into Bitcoin using it as a risk. Off asset others might sell Bitcoin to buy something. They consider more stable such as real estate or land a rising number <mark>of</mark> people will identify Bitcoin as the best money. We have ever had shunning other assets and other monies in the quest to stack as many SATs as they can. However, it might play out Bitcoin is the cure for many <mark>of</mark> the current systems ills it is hard money, which doesn't devalue over time. It is an Incorruptible system, which forms the basis <mark>of</mark> a new Financial reality quote. It can't be changed. It can't be argued with it can't be tampered with it can't be corrupted. It can't be stopped. It can't even be interrupted end quote. Ralph Merkle in addition to the above. It seems to have many indirect effects. It lowers the time preference <mark>of</mark> those who use it. It incentivizes users to have better personal and operational security. It incentivizes individuals and companies to have better digital hygiene. It propels", "Start Time (s)": 722.5, "End Time (s)": 842.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "identify Bitcoin as the best money. We have ever had shunning other assets and other monies in the quest to stack as many SATs as they can. However, it might play out Bitcoin is the cure for many <mark>of</mark> the current systems ills it is hard money, which doesn't devalue over time. It is an Incorruptible system, which forms the basis <mark>of</mark> a new Financial reality quote. It can't be changed. It can't be argued with it can't be tampered with it can't be corrupted. It can't be stopped. It can't even be interrupted end quote. Ralph Merkle in addition to the above. It seems to have many indirect effects. It lowers the time preference <mark>of</mark> those who use it. It incentivizes users to have better personal and operational security. It incentivizes individuals and companies to have better digital hygiene. It propels the development <mark>of</mark> Chip manufacturing and encryption technology while Bitcoin definitely influences is environments and vice versa how Bitcoin reacts to drastic changes is yet to be seen migration Bitcoin lives on the internet as Ralph Merkle points out the internet however is not a necessary requirement for Bitcoin to work. Bitcoin is text pure information in every system capable <mark>of</mark> transmitting and storing information is a potential habitat for the Bitcoin organism. The internet just happens to be the most suitable habitat, which currently exists since it is the most efficient system to transmit information we have to date. cyberspace the Bitcoin organism could migrate to other environments and multiple efforts are underway, which enable Bitcoin to spread to places where access to Internet infrastructure is limited", "Start Time (s)": 783.0, "End Time (s)": 902.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "technology while Bitcoin definitely influences is environments and vice versa how Bitcoin reacts to drastic changes is yet to be seen migration Bitcoin lives on the internet as Ralph Merkle points out the internet however is not a necessary requirement for Bitcoin to work. Bitcoin is text pure information in every system capable <mark>of</mark> transmitting and storing information is a potential habitat for the Bitcoin organism. The internet just happens to be the most suitable habitat, which currently exists since it is the most efficient system to transmit information we have to date. cyberspace the Bitcoin organism could migrate to other environments and multiple efforts are underway, which enable Bitcoin to spread to places where access to Internet infrastructure is limited or non-existent as <mark>of</mark> this writing Bitcoin transactions and lightning invoices have been sent via radio waves mesh and satellite networks just to name a few all <mark>of</mark> these can be seen as Bitcoin conservation efforts so to speak Whether we will see the migration <mark>of</mark> Bitcoin to another system in the decades and centuries to come depends in essence on whether the internet will remain a suitable habitat or not. If the online climate changes drastically enough we might see the migration to even more resilient less restrictive environments. Meet space we can already see that mining facilities pop up where energy is cheapest or even stranded in essence mining is done where it makes the most sense economically speaking. The same is true for running nodes if people can run nodes at low risk and near zero marginal cost. They will thus visualizing Bitcoin on a map nodes and Mining facilities migrate geographically from", "Start Time (s)": 845.1, "End Time (s)": 964.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is done where it makes the most sense economically speaking. The same is true for running nodes if people can run nodes at low risk and near zero marginal cost. They will thus visualizing Bitcoin on a map nodes and Mining facilities migrate geographically from unfriendly places to friendlier places over time. Unprofitable mining facilities will shut down profitable mining facilities will go online the same again is true for nodes increasingly people will migrate to jurisdictions which are more favorable to their Bitcoin Holdings. And if you want to start a Bitcoin company, you might also move to a jurisdiction which is more favorable to you and your future business. Thin space in the last 10 years many people decided to buy Bitcoin effectively feeding the Bitcoin organism by investing in it. This Capital allocation will continue as more people understand the nature <mark>of</mark> this Beast and the ultimate goal <mark>of</mark> Bitcoin the separation <mark>of</mark> money and state what investors described as portfolio balancing and allocation <mark>of</mark> capital can be seen as a migration <mark>of</mark> value from worse assets to better. Sets from Bad stores <mark>of</mark> value to better stores <mark>of</mark> value Bitcoin being the ultimate asset in terms <mark>of</mark> portability verifiability divisibility scarcity and uncie's ability will continue to suck up value and grow in the process. Conclusion Bitcoin lives at the intersection <mark>of</mark> three spaces meet space cyberspace and fin space these spaces have different laws different rules and different climates to fully understand any organism. We must not only look at the organism itself, but examine the organism environment a listicle e", "Start Time (s)": 947.7, "End Time (s)": 1067.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Beast and the ultimate goal <mark>of</mark> Bitcoin the separation <mark>of</mark> money and state what investors described as portfolio balancing and allocation <mark>of</mark> capital can be seen as a migration <mark>of</mark> value from worse assets to better. Sets from Bad stores <mark>of</mark> value to better stores <mark>of</mark> value Bitcoin being the ultimate asset in terms <mark>of</mark> portability verifiability divisibility scarcity and uncie's ability will continue to suck up value and grow in the process. Conclusion Bitcoin lives at the intersection <mark>of</mark> three spaces meet space cyberspace and fin space these spaces have different laws different rules and different climates to fully understand any organism. We must not only look at the organism itself, but examine the organism environment a listicle e because <mark>of</mark> its decentralized nature Bitcoin is able to overcome many if not all obstacles in its environment. It's it can migrate to favorable jurisdictions in meatspace use different transportation and storage media in cyberspace and feed on the instability <mark>of</mark> other asset classes in thin space. Whatever the future may bring Bitcoin is equipped to survive and thrive in the various environments it lives in it is remarkably resilient. Well adapted to survive any coming storm. However, perfect it may be and we closed a another great article by GG. Let's go ahead and hit our sponsor and then I want to talk about talk about the habitats <mark>of</mark> Bitcoin. For anyone who has a podcast anchor cannot be beaten particularly for trying to get off the ground their entire platform is free. This", "Start Time (s)": 1008.2, "End Time (s)": 1127.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "jurisdictions in meatspace use different transportation and storage media in cyberspace and feed on the instability <mark>of</mark> other asset classes in thin space. Whatever the future may bring Bitcoin is equipped to survive and thrive in the various environments it lives in it is remarkably resilient. Well adapted to survive any coming storm. However, perfect it may be and we closed a another great article by GG. Let's go ahead and hit our sponsor and then I want to talk about talk about the habitats <mark>of</mark> Bitcoin. For anyone who has a podcast anchor cannot be beaten particularly for trying to get off the ground their entire platform is free. This includes unlimited hosting both in audio that you upload and how much your listeners download. I have uploaded an incredible library <mark>of</mark> audio now and I've never paid anchor a dime. In fact, they connect me with other sponsors and have run an ad consistently on my show. So they've paid For exposure to my audience that's really hard to beat even if we ignore that I can record directly in the app or my browser. I don't need any other software. If I don't want it I can edit at sound <mark>effects</mark> clips and they automatically published to all <mark>of</mark> the top podcasting platforms. I never had to do a thing. So if you were thinking <mark>of</mark> starting a show or already have a podcast, there's no better platform out there check out anchor by downloading the app or go to Anchor dot f FM today So jumping right into meatspace. China's social credit system is basically my dystopian nightmare. It is one <mark>of</mark> the most insane overreaches <mark>of</mark> power and", "Start Time (s)": 1076.2, "End Time (s)": 1196.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and how much your listeners download. I have uploaded an incredible library <mark>of</mark> audio now and I've never paid anchor a dime. In fact, they connect me with other sponsors and have run an ad consistently on my show. So they've paid For exposure to my audience that's really hard to beat even if we ignore that I can record directly in the app or my browser. I don't need any other software. If I don't want it I can edit at sound <mark>effects</mark> clips and they automatically published to all <mark>of</mark> the top podcasting platforms. I never had to do a thing. So if you were thinking <mark>of</mark> starting a show or already have a podcast, there's no better platform out there check out anchor by downloading the app or go to Anchor dot f FM today So jumping right into meatspace. China's social credit system is basically my dystopian nightmare. It is one <mark>of</mark> the most insane overreaches <mark>of</mark> power and you know, they're Communists. So I guess it shouldn't be unexpected and they would be rushing to utilize the digital world and the technology <mark>of</mark> the internet to maintain as stricter. On their population as possible. So I guess it shouldn't really be crazy that this actually occurred or this is in development and they really intend they expect actually this year to to have everyone every quote unquote citizen <mark>of</mark> China on their social credit system. And when GG made the remark that they will literally take your dog, it was actually link to an article about just how unbelievably like nanny State they are going with this social credit system and you know, the incentive structures, like people don't really change that much from", "Start Time (s)": 1131.7, "End Time (s)": 1251.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>of</mark> power and you know, they're Communists. So I guess it shouldn't be unexpected and they would be rushing to utilize the digital world and the technology <mark>of</mark> the internet to maintain as stricter. On their population as possible. So I guess it shouldn't really be crazy that this actually occurred or this is in development and they really intend they expect actually this year to to have everyone every quote unquote citizen <mark>of</mark> China on their social credit system. And when GG made the remark that they will literally take your dog, it was actually link to an article about just how unbelievably like nanny State they are going with this social credit system and you know, the incentive structures, like people don't really change that much from being children. Like the state is one <mark>of</mark> those institutions just like any other they will they will push to the limits <mark>of</mark> whatever they can get away with and they'll just keep taking more power taking more control and telling more and more people what to do to a greater and greater degree until there is essentially pushed. In the incentives <mark>of</mark> the <mark>of</mark> the nature <mark>of</mark> government that it is a monopoly on the right to enact violence against peaceful people with the justification that just because they have the Monopoly on violence. They are right by default and you have to defend your case against them. Well that leads to essentially an incredibly High a cost to exit is a great piece by Nick Szabo that we've read on this show called. old exit and freedom from his unenumerated from his blog and it's a wonderful piece just talking about how like incentives and the barrier to exit are such a critical factor in how well", "Start Time (s)": 1194.6, "End Time (s)": 1313.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "just keep taking more power taking more control and telling more and more people what to do to a greater and greater degree until there is essentially pushed. In the incentives <mark>of</mark> the <mark>of</mark> the nature <mark>of</mark> government that it is a monopoly on the right to enact violence against peaceful people with the justification that just because they have the Monopoly on violence. They are right by default and you have to defend your case against them. Well that leads to essentially an incredibly High a cost to exit is a great piece by Nick Szabo that we've read on this show called. old exit and freedom from his unenumerated from his blog and it's a wonderful piece just talking about how like incentives and the barrier to exit are such a critical factor in how well one can actually maintain or essentially fight back against you know, the destruction <mark>of</mark> Liberty and that's one <mark>of</mark> those things that makes Bitcoin such a potent tool on the actually brings up is that now you can actually take value With you you can exit the jurisdiction without necessarily losing your job. Maybe you work remotely maybe you have a business or a productive environment, which is totally in the digital realm which exists almost completely in cyberspace. Maybe the bulk <mark>of</mark> your savings the more that your savings are in Bitcoin the more that you can easily take with you without Without running into some huge hindrance or some fee or some restriction on being able to get back up and running in the new jurisdiction or the new location that you go. So it is Bitcoin is one <mark>of</mark> those tools that massively lowers the the ability and the cost to exit a totalitarian communist or just disliking like like a uncomfortable jurisdiction or a set <mark>of</mark> rules", "Start Time (s)": 1261.6, "End Time (s)": 1380.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know, the destruction <mark>of</mark> Liberty and that's one <mark>of</mark> those things that makes Bitcoin such a potent tool on the actually brings up is that now you can actually take value With you you can exit the jurisdiction without necessarily losing your job. Maybe you work remotely maybe you have a business or a productive environment, which is totally in the digital realm which exists almost completely in cyberspace. Maybe the bulk <mark>of</mark> your savings the more that your savings are in Bitcoin the more that you can easily take with you without Without running into some huge hindrance or some fee or some restriction on being able to get back up and running in the new jurisdiction or the new location that you go. So it is Bitcoin is one <mark>of</mark> those tools that massively lowers the the ability and the cost to exit a totalitarian communist or just disliking like like a uncomfortable jurisdiction or a set <mark>of</mark> rules and you know, like the the incentives <mark>of</mark> I meant are such that I compared to the incentives <mark>of</mark> you know, like a bad DirecTV plan or like cable and internet plan. Is that the barrier there is that you know, if they if they make me wait on hold and I have to call him to customer support five times for a problem that's clearly on their side and I can't get help. Well, then my barrier is dealing with you know, having crappy internet for a couple <mark>of</mark> days or having no internet or having to work off my cellular before I get the new company, too. Come in and use a different service or if that's not even possible. Let's say there's a geographic monopoly in my area. Well, then, you know, I'd have to use a hot spot or something and I could pay for crazy huge like cellular and that's possible. You know, that's not even like if you do it by one device, I've actually done that for multiple weeks. It's a pain but", "Start Time (s)": 1320.8, "End Time (s)": 1439.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "incentives <mark>of</mark> I meant are such that I compared to the incentives <mark>of</mark> you know, like a bad DirecTV plan or like cable and internet plan. Is that the barrier there is that you know, if they if they make me wait on hold and I have to call him to customer support five times for a problem that's clearly on their side and I can't get help. Well, then my barrier is dealing with you know, having crappy internet for a couple <mark>of</mark> days or having no internet or having to work off my cellular before I get the new company, too. Come in and use a different service or if that's not even possible. Let's say there's a geographic monopoly in my area. Well, then, you know, I'd have to use a hot spot or something and I could pay for crazy huge like cellular and that's possible. You know, that's not even like if you do it by one device, I've actually done that for multiple weeks. It's a pain but that is not a that is not the barrier to exit <mark>of</mark> a government system with the Lead to enact violence against people to violently control. What they do at like is something as ridiculous as whether or not you have your dog on your leash. That's what that was alluding to in that article <mark>of</mark> how China was essentially getting down to giving people pet owner scores and travel scores and like politeness scores like all <mark>of</mark> this utterly insane stuff where they would essentially take your pet. Yet until you passed a test and prove to the court that you knew all <mark>of</mark> the regulations around the pet that you gave all the proper vaccinations and that you knew win and when they could not be on or off the leash and that they will just steal a member <mark>of</mark> your family. If you you know don't know them well enough or misbehave enough times. Certainly something like that would never be", "Start Time (s)": 1382.6, "End Time (s)": 1501.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "essentially getting down to giving people pet owner scores and travel scores and like politeness scores like all <mark>of</mark> this utterly insane stuff where they would essentially take your pet. Yet until you passed a test and prove to the court that you knew all <mark>of</mark> the regulations around the pet that you gave all the proper vaccinations and that you knew win and when they could not be on or off the leash and that they will just steal a member <mark>of</mark> your family. If you you know don't know them well enough or misbehave enough times. Certainly something like that would never be abused to you know, get someone to sell their land if they didn't want to or to, you know, pay a politician to get someone to push something because some money wasn't buying the right thing or making a deal with the right company. Holy shit the mountain <mark>of</mark> corruption that would come from such an absurd system is truly hard to comprehend. and But <mark>of</mark> course being the barrier <mark>of</mark> exit being so high being that essentially one has to be willing to risk death to risk incredible physical harm in order to even attempt to stand up against it. Well, then that's exactly why corruption totalitarianism why governments essentially all end in a gloriously brutal and violent conclusion There are very few governments that have collapsed that did not pair with genocide and unbelievable corruption and just evil in every sense <mark>of</mark> the word. So there's nothing", "Start Time (s)": 1461.8, "End Time (s)": 1580.2, "Clip Length (min)": 1.97, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Holy shit the mountain <mark>of</mark> corruption that would come from such an absurd system is truly hard to comprehend. and But <mark>of</mark> course being the barrier <mark>of</mark> exit being so high being that essentially one has to be willing to risk death to risk incredible physical harm in order to even attempt to stand up against it. Well, then that's exactly why corruption totalitarianism why governments essentially all end in a gloriously brutal and violent conclusion There are very few governments that have collapsed that did not pair with genocide and unbelievable corruption and just evil in every sense <mark>of</mark> the word. So there's nothing quite so empowering to the individual as to lower their barrier to exit and both cyberspace just in general the connectivity <mark>of</mark> the internet and the ability to exchange with other countries and across jurisdictions the ability for a large portion <mark>of</mark> your livelihood to exist outside <mark>of</mark> any geographical area and the ability to actually take your wealth. Maybe you're in Your life savings with you across the border in your brain is is something to not be underestimated? And when you think about how bad the Chinese social credit system could get that quote Gigi has a really good quote in this article that says if that doesn't sound dystopian enough for your taste, I bet that it will be in a couple <mark>of</mark> years remind yourself that this is only the beginning end quote", "Start Time (s)": 1517.6, "End Time (s)": 1637.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "corruption and just evil in every sense <mark>of</mark> the word. So there's nothing quite so empowering to the individual as to lower their barrier to exit and both cyberspace just in general the connectivity <mark>of</mark> the internet and the ability to exchange with other countries and across jurisdictions the ability for a large portion <mark>of</mark> your livelihood to exist outside <mark>of</mark> any geographical area and the ability to actually take your wealth. Maybe you're in Your life savings with you across the border in your brain is is something to not be underestimated? And when you think about how bad the Chinese social credit system could get that quote Gigi has a really good quote in this article that says if that doesn't sound dystopian enough for your taste, I bet that it will be in a couple <mark>of</mark> years remind yourself that this is only the beginning end quote and that is so true. What they are doing is they are setting the foundation's up for the next genocide and the next quarter rific. Ends <mark>of</mark> privacy and confiscations <mark>of</mark> any sort <mark>of</mark> Liberty or individuality and the Chinese government is not really in any better financial situation. They are in a horrible spot. And obviously this Wuhan virus has not made it any the coronavirus or whatever has not made this any easier for them. But when the shit hits the fan when you got to be kidding yourself if you think they're not going to you. use this against their population when things get hairy for the political hierarchy when things start to get threatened when people start to challenge them or financial", "Start Time (s)": 1574.0, "End Time (s)": 1692.1, "Clip Length (min)": 1.97, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that is so true. What they are doing is they are setting the foundation's up for the next genocide and the next quarter rific. Ends <mark>of</mark> privacy and confiscations <mark>of</mark> any sort <mark>of</mark> Liberty or individuality and the Chinese government is not really in any better financial situation. They are in a horrible spot. And obviously this Wuhan virus has not made it any the coronavirus or whatever has not made this any easier for them. But when the shit hits the fan when you got to be kidding yourself if you think they're not going to you. use this against their population when things get hairy for the political hierarchy when things start to get threatened when people start to challenge them or financial assurances get weaker when those cities and parts <mark>of</mark> the country that we did are actually the rich ones thus quote-unquote modern side <mark>of</mark> China, which is actually a small portion and a couple <mark>of</mark> specks <mark>of</mark> China really The vast majority <mark>of</mark> China is incredibly poor, but when the when the Comforts <mark>of</mark> those who are living in the little Oasis though a through Oasis <mark>Of</mark> China when that is threatened when their stability is threatened and they have to essentially hit the poor harder when they have to add new restrictions add new taxes add additional confiscations and controls on people. There will be a Breaking Point and they will use the social credit system for every horror. They can possibly come up with before there is nothing left to take and before they've done so much damage and caused so much harm that the people are willing to die to get", "Start Time (s)": 1638.5, "End Time (s)": 1758.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that we did are actually the rich ones thus quote-unquote modern side <mark>of</mark> China, which is actually a small portion and a couple <mark>of</mark> specks <mark>of</mark> China really The vast majority <mark>of</mark> China is incredibly poor, but when the when the Comforts <mark>of</mark> those who are living in the little Oasis though a through Oasis <mark>Of</mark> China when that is threatened when their stability is threatened and they have to essentially hit the poor harder when they have to add new restrictions add new taxes add additional confiscations and controls on people. There will be a Breaking Point and they will use the social credit system for every horror. They can possibly come up with before there is nothing left to take and before they've done so much damage and caused so much harm that the people are willing to die to get out <mark>of</mark> it. That is a very sad truth but it is something that history has never really contested that that's just kind <mark>of</mark> always the case. Government can get away with something and it has the power to do something. It will absolutely abuse the shit out <mark>of</mark> it and that leads to what the climate <mark>of</mark> cyberspace is. Like how well can the controls and the costs the barriers <mark>of</mark> meatspace be re-implemented in cyberspace. How well does the great firewall <mark>of</mark> China work? And there's an app that actually another interesting quote here. I think this one are you at where are you at? Yeah. Okay, and this is in the article obviously Bitcoin knows no borders no jurisdictions. However, it has to conform to the laws <mark>of</mark> cyberspace and if these laws", "Start Time (s)": 1698.6, "End Time (s)": 1817.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that the people are willing to die to get out <mark>of</mark> it. That is a very sad truth but it is something that history has never really contested that that's just kind <mark>of</mark> always the case. Government can get away with something and it has the power to do something. It will absolutely abuse the shit out <mark>of</mark> it and that leads to what the climate <mark>of</mark> cyberspace is. Like how well can the controls and the costs the barriers <mark>of</mark> meatspace be re-implemented in cyberspace. How well does the great firewall <mark>of</mark> China work? And there's an app that actually another interesting quote here. I think this one are you at where are you at? Yeah. Okay, and this is in the article obviously Bitcoin knows no borders no jurisdictions. However, it has to conform to the laws <mark>of</mark> cyberspace and if these laws change in other words, if large parts <mark>of</mark> the world block Bitcoin traffic and or the usage <mark>of</mark> tore the Bitcoin organism will have Doubt in quote. This is another crazy thing about Bitcoin. Is it like I love the way he brought up how like Bitcoin doesn't exactly live cyberspace or well not cyberspace, but the internet itself is really just the best habitat right now and it could become not the best habitat, but Bitcoin does not necessarily have Have to live on the internet. There are a lot <mark>of</mark> ways information can be transmitted and there could be many alternative networks, but it's very interesting to think about how Bitcoin might adapt. Um how things might have to evolve in order for Bitcoin to stay alive.", "Start Time (s)": 1755.3, "End Time (s)": 1875.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "these laws change in other words, if large parts <mark>of</mark> the world block Bitcoin traffic and or the usage <mark>of</mark> tore the Bitcoin organism will have Doubt in quote. This is another crazy thing about Bitcoin. Is it like I love the way he brought up how like Bitcoin doesn't exactly live cyberspace or well not cyberspace, but the internet itself is really just the best habitat right now and it could become not the best habitat, but Bitcoin does not necessarily have Have to live on the internet. There are a lot <mark>of</mark> ways information can be transmitted and there could be many alternative networks, but it's very interesting to think about how Bitcoin might adapt. Um how things might have to evolve in order for Bitcoin to stay alive. And that is another <mark>of</mark> the billion reasons why as much as painful as it is and as much as I wish this wasn't the case Have to keep the block size small we have to keep the bandwidth to to reach consensus to completely defend the auditability and consensus rules <mark>of</mark> the Bitcoin mechanism as tightly limited as possible. Because we do not necessarily have the internet to use to keep consensus. We do not necessarily have all <mark>of</mark> the conveniences and bandwidth and capacity that we have at this very moment. This must live in an adversarial environment. Not a welcoming comforting environment. And I think something that we're probably going to cover on the show because so many shit coins have had have seen some incredible", "Start Time (s)": 1817.0, "End Time (s)": 1936.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "as much as painful as it is and as much as I wish this wasn't the case Have to keep the block size small we have to keep the bandwidth to to reach consensus to completely defend the auditability and consensus rules <mark>of</mark> the Bitcoin mechanism as tightly limited as possible. Because we do not necessarily have the internet to use to keep consensus. We do not necessarily have all <mark>of</mark> the conveniences and bandwidth and capacity that we have at this very moment. This must live in an adversarial environment. Not a welcoming comforting environment. And I think something that we're probably going to cover on the show because so many shit coins have had have seen some incredible consequences and we have we can learn a lot <mark>of</mark> lessons from some staking coins and some highly centralized coins that have seen their whole worlds and their foundations <mark>of</mark> yes, it's quote-unquote decentralized Shake underneath them. I think they are giving us exactly samples <mark>of</mark> exactly why these things are so important. We're constantly being reinforced that Yep. This is basically the only way whatever limitations and whatever hard truths we have to admit. This is it and we have to figure that out but as centralized quote on quote as block streams satellite network is it's amazing to think that we do have there is a satellite Network that can run and To propagate the information <mark>of</mark> the Bitcoin blockchain entirely external to the internet. It is not needed. The internet is not needed in order to stay in sync and consensus with the Bitcoin", "Start Time (s)": 1880.7, "End Time (s)": 2000.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and some highly centralized coins that have seen their whole worlds and their foundations <mark>of</mark> yes, it's quote-unquote decentralized Shake underneath them. I think they are giving us exactly samples <mark>of</mark> exactly why these things are so important. We're constantly being reinforced that Yep. This is basically the only way whatever limitations and whatever hard truths we have to admit. This is it and we have to figure that out but as centralized quote on quote as block streams satellite network is it's amazing to think that we do have there is a satellite Network that can run and To propagate the information <mark>of</mark> the Bitcoin blockchain entirely external to the internet. It is not needed. The internet is not needed in order to stay in sync and consensus with the Bitcoin blockchain. Now, if all <mark>of</mark> it ended up being a necessary to do over the satellite Network, you know, then we suddenly have a problem, you know, the internet went down there Great Wall <mark>of</mark> great firewall <mark>of</mark> China went up and started blocking all Bitcoin traffic same with the US. As you know, if every country essentially tried to use every amount <mark>of</mark> influence possible to stop it. There would be luckily most <mark>of</mark> it or most <mark>of</mark> it a lot <mark>of</mark> traffic <mark>of</mark> Bitcoin goes over tour and that is another incredibly important thing and I don't think they'd be able to absolutely ban the use <mark>of</mark> tour. This is one <mark>of</mark> those things where the incentives are so strong because the reason tour exist is because governments use it. Governments want that privacy. They will they would literally need to implement an alternative in some way in order to make it make sense for them to actually ban tour. They cut themselves. They you know, they cut off their own foot by", "Start Time (s)": 1942.9, "End Time (s)": 2062.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "being a necessary to do over the satellite Network, you know, then we suddenly have a problem, you know, the internet went down there Great Wall <mark>of</mark> great firewall <mark>of</mark> China went up and started blocking all Bitcoin traffic same with the US. As you know, if every country essentially tried to use every amount <mark>of</mark> influence possible to stop it. There would be luckily most <mark>of</mark> it or most <mark>of</mark> it a lot <mark>of</mark> traffic <mark>of</mark> Bitcoin goes over tour and that is another incredibly important thing and I don't think they'd be able to absolutely ban the use <mark>of</mark> tour. This is one <mark>of</mark> those things where the incentives are so strong because the reason tour exist is because governments use it. Governments want that privacy. They will they would literally need to implement an alternative in some way in order to make it make sense for them to actually ban tour. They cut themselves. They you know, they cut off their own foot by getting rid <mark>of</mark> tour in order to stop the internet. I mean, excuse me in order to stop Bitcoin. So the fact that Bitcoin is, you know, hat tip to car Camp it for Bitcoin is the blockade Honor the fact that Bitcoin is Nimble enough that it is a high-capacity enough in value and low capacity enough in bandwidth in digit is it is small it is Speedy. It is Nimble it can get through every single crack the fact that Bitcoin can do that and that it can run very well over two were in fact one <mark>of</mark> my nodes runs entirely over to her as no problem. It is caught up with Threat with my other node just the same. They are always on the same block the fact that it does that well, um is I think a potent reality to at least a potent characteristic to how we can know that Bitcoin will be", "Start Time (s)": 2003.5, "End Time (s)": 2122.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is, you know, hat tip to car Camp it for Bitcoin is the blockade Honor the fact that Bitcoin is Nimble enough that it is a high-capacity enough in value and low capacity enough in bandwidth in digit is it is small it is Speedy. It is Nimble it can get through every single crack the fact that Bitcoin can do that and that it can run very well over two were in fact one <mark>of</mark> my nodes runs entirely over to her as no problem. It is caught up with Threat with my other node just the same. They are always on the same block the fact that it does that well, um is I think a potent reality to at least a potent characteristic to how we can know that Bitcoin will be resilient and I'd be very curious is a very interesting thought experiment to think how could Bitcoin run without the major Avenues <mark>of</mark> the internet? How could we Bridge every jurisdiction? How could we get across every single border? And through every crack in all <mark>of</mark> these informational networks to keep it going to live in the in the face <mark>of</mark> truly every government as an adversary. And I think that's the goal. It's not keeping it the most, you know, powerful computer network in the world. I mean, obviously all <mark>of</mark> those things would be great. But I think just keeping it alive would would push it to that next stage which would make it come back from Um the dead and even if it took one <mark>of</mark> the hardest hits it's ever taken in its life that all we have to do is keep the heartbeat running. All we have to do is keep the organism alive and eventually it will come out as the winner in the end. It's a game <mark>of</mark> survivability. Does it survive if it does it wins?", "Start Time (s)": 2071.4, "End Time (s)": 2191.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "interesting thought experiment to think how could Bitcoin run without the major Avenues <mark>of</mark> the internet? How could we Bridge every jurisdiction? How could we get across every single border? And through every crack in all <mark>of</mark> these informational networks to keep it going to live in the in the face <mark>of</mark> truly every government as an adversary. And I think that's the goal. It's not keeping it the most, you know, powerful computer network in the world. I mean, obviously all <mark>of</mark> those things would be great. But I think just keeping it alive would would push it to that next stage which would make it come back from Um the dead and even if it took one <mark>of</mark> the hardest hits it's ever taken in its life that all we have to do is keep the heartbeat running. All we have to do is keep the organism alive and eventually it will come out as the winner in the end. It's a game <mark>of</mark> survivability. Does it survive if it does it wins? It's not a game <mark>of</mark> who can have the best features who has the most gadgets. It's a game <mark>of</mark> who can survive in the face <mark>of</mark> the greatest challenges because we will have challenges now talking about Vince space speaking <mark>of</mark> fin space. Um, that is that that was an interesting addition to this because I've always thought <mark>of</mark> it as a bridge between meet space and cyberspace and I never really thought about Finn space as its own. Part <mark>of</mark> this puzzle, but truly like if you really could make an argument that fin space really isn't cyber space cyberspace does not really have anything to do with the markets <mark>of</mark> value in and <mark>of</mark> itself. Like there is a climate <mark>of</mark> cyberspace that is totally external to the climate <mark>of</mark> fin space. But what's funny is there is no there is", "Start Time (s)": 2125.7, "End Time (s)": 2245.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "all we have to do is keep the heartbeat running. All we have to do is keep the organism alive and eventually it will come out as the winner in the end. It's a game <mark>of</mark> survivability. Does it survive if it does it wins? It's not a game <mark>of</mark> who can have the best features who has the most gadgets. It's a game <mark>of</mark> who can survive in the face <mark>of</mark> the greatest challenges because we will have challenges now talking about Vince space speaking <mark>of</mark> fin space. Um, that is that that was an interesting addition to this because I've always thought <mark>of</mark> it as a bridge between meet space and cyberspace and I never really thought about Finn space as its own. Part <mark>of</mark> this puzzle, but truly like if you really could make an argument that fin space really isn't cyber space cyberspace does not really have anything to do with the markets <mark>of</mark> value in and <mark>of</mark> itself. Like there is a climate <mark>of</mark> cyberspace that is totally external to the climate <mark>of</mark> fin space. But what's funny is there is no there is nothing. That has as much fuel for the fire <mark>of</mark> Bitcoin to consume as fin space. They just it is just kindling from like to the Horizon and that is that is one <mark>of</mark> the craziest the climate <mark>of</mark> thin space is is a perfect storm for Bitcoin in some it's in some context like right now, but obviously the the the meats are the fin space response as As to restrictions and Integrations and being able to move Capital back and forth and get into and out <mark>of</mark> Bitcoin could change drastically in very short order. And that is that is a climate that is entirely dependent on The Strokes <mark>of</mark> a bunch <mark>of</mark> narcissist hens. So that could", "Start Time (s)": 2176.6, "End Time (s)": 2295.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "cyberspace does not really have anything to do with the markets <mark>of</mark> value in and <mark>of</mark> itself. Like there is a climate <mark>of</mark> cyberspace that is totally external to the climate <mark>of</mark> fin space. But what's funny is there is no there is nothing. That has as much fuel for the fire <mark>of</mark> Bitcoin to consume as fin space. They just it is just kindling from like to the Horizon and that is that is one <mark>of</mark> the craziest the climate <mark>of</mark> thin space is is a perfect storm for Bitcoin in some it's in some context like right now, but obviously the the the meats are the fin space response as As to restrictions and Integrations and being able to move Capital back and forth and get into and out <mark>of</mark> Bitcoin could change drastically in very short order. And that is that is a climate that is entirely dependent on The Strokes <mark>of</mark> a bunch <mark>of</mark> narcissist hens. So that could easily turn against us but the the underlying climate the real nature <mark>of</mark> value and those imbalances don't go anywhere those things are still Fuel for the fire. Now. They can try to put in Fire breaks. They can try to you know stamp it out every single place that you know, people try to start it back up essentially to fight against this thing as it spreads through the economy, but the more the worse they try to control the more Capital controls in the more restrictions on value. The the better Bitcoin looks just like we did in just like we talked about in yesterday's article with the distrust <mark>of</mark> Inez banks that they tried to resell the freedoms and privileges that they already had in the banking institution that were just stripped from them and dub it fresh money like the arrogance <mark>of</mark> that is unbelievable.", "Start Time (s)": 2230.6, "End Time (s)": 2349.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that is entirely dependent on The Strokes <mark>of</mark> a bunch <mark>of</mark> narcissist hens. So that could easily turn against us but the the underlying climate the real nature <mark>of</mark> value and those imbalances don't go anywhere those things are still Fuel for the fire. Now. They can try to put in Fire breaks. They can try to you know stamp it out every single place that you know, people try to start it back up essentially to fight against this thing as it spreads through the economy, but the more the worse they try to control the more Capital controls in the more restrictions on value. The the better Bitcoin looks just like we did in just like we talked about in yesterday's article with the distrust <mark>of</mark> Inez banks that they tried to resell the freedoms and privileges that they already had in the banking institution that were just stripped from them and dub it fresh money like the arrogance <mark>of</mark> that is unbelievable. But in that situation they've lost trust completely like it's gone like nobody's going to get fresh money and think. Oh thank God I got it back there. It was taken it was sold to them by the very people who took it from them and the greater those restrictions are the greater the Lee <mark>of</mark> the financial system <mark>of</mark> thin space <mark>of</mark> the fin space climate the less Bitcoin is any sort <mark>of</mark> a trade-off it's like well I got volatility just awful down just just horrific plummeting chaotic volatility on the one hand or I've got like just Bitcoins just average volatility mostly goes up. And if on the left hand, they've got you know Capital controls. They've got I can't integrate with any apps all the shit stopped working. Nothing. They get her just the whole thing is just crumbling apart. Everybody is reaching for", "Start Time (s)": 2288.0, "End Time (s)": 2407.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "unbelievable. But in that situation they've lost trust completely like it's gone like nobody's going to get fresh money and think. Oh thank God I got it back there. It was taken it was sold to them by the very people who took it from them and the greater those restrictions are the greater the Lee <mark>of</mark> the financial system <mark>of</mark> thin space <mark>of</mark> the fin space climate the less Bitcoin is any sort <mark>of</mark> a trade-off it's like well I got volatility just awful down just just horrific plummeting chaotic volatility on the one hand or I've got like just Bitcoins just average volatility mostly goes up. And if on the left hand, they've got you know Capital controls. They've got I can't integrate with any apps all the shit stopped working. Nothing. They get her just the whole thing is just crumbling apart. Everybody is reaching for every ounce <mark>of</mark> control every government and major player in the financial system is reaching for every ounce <mark>of</mark> control and restriction that they can put on people so that they don't save value so that they cannot escape the the to that barrier <mark>of</mark> exit all the inconveniences and costs <mark>of</mark> Bitcoin look super easy to deal with in comparison. And I truly I truly hope that doesn't come to this that you know, like there is some sense in these people left. But you know when it's their livelihoods versus our livelihoods, what do you think? They're going to choose? And Gigi even brings up that in 1934 They confiscated all gold all gold from the citizens <mark>of</mark> their own country during the height <mark>of</mark> a group <mark>of</mark> the Great Depression.", "Start Time (s)": 2348.7, "End Time (s)": 2468.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "They get her just the whole thing is just crumbling apart. Everybody is reaching for every ounce <mark>of</mark> control every government and major player in the financial system is reaching for every ounce <mark>of</mark> control and restriction that they can put on people so that they don't save value so that they cannot escape the the to that barrier <mark>of</mark> exit all the inconveniences and costs <mark>of</mark> Bitcoin look super easy to deal with in comparison. And I truly I truly hope that doesn't come to this that you know, like there is some sense in these people left. But you know when it's their livelihoods versus our livelihoods, what do you think? They're going to choose? And Gigi even brings up that in 1934 They confiscated all gold all gold from the citizens <mark>of</mark> their own country during the height <mark>of</mark> a group <mark>of</mark> the Great Depression. How insane is that? And the country was a whole lot Freer and a whole lot more independent than it is now. People are way more obedient and subservient than they were then we've had another 70 years <mark>of</mark> conditioning. And if they you know, they crack down the start. I'm confiscating Bitcoin and stuff. I'm put it as flat as possible. I'm already making plans to get the fuck out <mark>of</mark> Dodge. Like I'm not staying here. Then I get in my Bitcoin. If anything if I can do anything to prevent that from happening, I'm gonna do it. No way in hell. I'm letting the same corrupt arrogant machine that has absolutely destroyed the American economy that has driven the", "Start Time (s)": 2403.2, "End Time (s)": 2522.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "was a whole lot Freer and a whole lot more independent than it is now. People are way more obedient and subservient than they were then we've had another 70 years <mark>of</mark> conditioning. And if they you know, they crack down the start. I'm confiscating Bitcoin and stuff. I'm put it as flat as possible. I'm already making plans to get the fuck out <mark>of</mark> Dodge. Like I'm not staying here. Then I get in my Bitcoin. If anything if I can do anything to prevent that from happening, I'm gonna do it. No way in hell. I'm letting the same corrupt arrogant machine that has absolutely destroyed the American economy that has driven the entire the entire population into impossible deaths and has destroyed an entire money rip up my life vest and the life vest <mark>of</mark> my family. The last thing that we've actually got to possibly weather the storm that is clearly on the horizon. Hell, no. I am not playing that game. So thank thy Lord Satoshi for bringing this tool onto us to lower the barrier to exit and hopefully put enough pressure. That's that's another actually thing. Oh, actually, let me let me go ahead and hit that for we close this episode out. There is recommended reading at the end <mark>of</mark> this first he's got proof <mark>of</mark> life, which is Gigi's other article and we've done it on the show. So I'll be sure to link to that then the sovereign individual by James Dale Davidson and whoa, whoa William Rees MOG. I have listened to that. I'm probably going to listen to it again, but they actually talked about in that art at", "Start Time (s)": 2473.5, "End Time (s)": 2593.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Oh, actually, let me let me go ahead and hit that for we close this episode out. There is recommended reading at the end <mark>of</mark> this first he's got proof <mark>of</mark> life, which is Gigi's other article and we've done it on the show. So I'll be sure to link to that then the sovereign individual by James Dale Davidson and whoa, whoa William Rees MOG. I have listened to that. I'm probably going to listen to it again, but they actually talked about in that art at that article in that very long book, which is brilliant, by the way about how just lowering. Hmm. Excuse me. Just lowering the barrier to exit. is often enough to restrict their ability to enact Draconian laws to actually commit the violence that would necessarily cause people to leave because the easier it is to leave the the faster they feel the <mark>effects</mark> <mark>of</mark> incredibly stupid or incredibly aggressive decisions and understand if people with wealth people with the productive capacity people who are <mark>of</mark> the the underlying The underlying workers who hold up the economy the producers that really make the machine turn if they leave if they can leave quickly and easily and you don't have to be super wealthy anymore a permanent upper-middle-class can usually up in peace out a whole lot easier than they used to be able to the the sort <mark>of</mark> the the spread the unbelievable spread <mark>of</mark> the coronavirus virus is massive evidence <mark>of</mark> this 40 50 years ago. Do not have this level <mark>of</mark> travel globally like and now in a matter <mark>of</mark> days the coronavirus is basically everywhere in the world. I mean, that's scary and it sucks, but it's also A powerful demonstration <mark>of</mark>", "Start Time (s)": 2564.1, "End Time (s)": 2683.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the <mark>effects</mark> <mark>of</mark> incredibly stupid or incredibly aggressive decisions and understand if people with wealth people with the productive capacity people who are <mark>of</mark> the the underlying The underlying workers who hold up the economy the producers that really make the machine turn if they leave if they can leave quickly and easily and you don't have to be super wealthy anymore a permanent upper-middle-class can usually up in peace out a whole lot easier than they used to be able to the the sort <mark>of</mark> the the spread the unbelievable spread <mark>of</mark> the coronavirus virus is massive evidence <mark>of</mark> this 40 50 years ago. Do not have this level <mark>of</mark> travel globally like and now in a matter <mark>of</mark> days the coronavirus is basically everywhere in the world. I mean, that's scary and it sucks, but it's also A powerful demonstration <mark>of</mark> how much we are a <mark>global</mark> economy. We are a <mark>global</mark> Community now where we were not in the past. So the faster people are able to leave to jump jurisdictions and the lower those restrictions are the the faster the power to actually enact those controls to actually create that violence the state actually holds Because all they have is mercenaries. They have paid soldiers. Those soldiers will not fight for free most <mark>of</mark> the people who go into police military and all <mark>of</mark> that stuff. They go because <mark>of</mark> a job they go because good benefits. The state's power to enact violence against its own population is dependent on its purchasing power. It's dependent on the wealth <mark>of</mark> its economy the stability and the to the trust the believability <mark>of</mark> their nonsense narratives", "Start Time (s)": 2623.6, "End Time (s)": 2743.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "basically everywhere in the world. I mean, that's scary and it sucks, but it's also A powerful demonstration <mark>of</mark> how much we are a <mark>global</mark> economy. We are a <mark>global</mark> Community now where we were not in the past. So the faster people are able to leave to jump jurisdictions and the lower those restrictions are the the faster the power to actually enact those controls to actually create that violence the state actually holds Because all they have is mercenaries. They have paid soldiers. Those soldiers will not fight for free most <mark>of</mark> the people who go into police military and all <mark>of</mark> that stuff. They go because <mark>of</mark> a job they go because good benefits. The state's power to enact violence against its own population is dependent on its purchasing power. It's dependent on the wealth <mark>of</mark> its economy the stability and the to the trust the believability <mark>of</mark> their nonsense narratives are entirely dependent on the wealth <mark>of</mark> the economy if the wealthy and the truly productive the ones that are being bled dry right now and still propping up this Giant machine start leaving the purchasing power the control and the narrative will break apart very very quickly. And as they proposed in the sovereign individual that could actually lead to all <mark>of</mark> these what we think <mark>of</mark> these huge transitions in history that are usually massively violent that usually take decades and decades to play out should happen much much. Quicker and should basically escalate to a much lesser degree in this day and age because <mark>of</mark> the movement on that is", "Start Time (s)": 2674.5, "End Time (s)": 2793.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "dependent on the wealth <mark>of</mark> its economy the stability and the to the trust the believability <mark>of</mark> their nonsense narratives are entirely dependent on the wealth <mark>of</mark> the economy if the wealthy and the truly productive the ones that are being bled dry right now and still propping up this Giant machine start leaving the purchasing power the control and the narrative will break apart very very quickly. And as they proposed in the sovereign individual that could actually lead to all <mark>of</mark> these what we think <mark>of</mark> these huge transitions in history that are usually massively violent that usually take decades and decades to play out should happen much much. Quicker and should basically escalate to a much lesser degree in this day and age because <mark>of</mark> the movement on that is available to us. But then again, you know caveat to that. We also have one <mark>of</mark> the not not one <mark>of</mark> we have the largest financial imbalance and the largest state institutions that have ever existed so Hopefully hopefully it still good news and a Davidson and William Reese mogs thesis plays out as they explained in that book on the that is a amazing book and I highly highly recommend it. I will link to both <mark>of</mark> those further reading that Gigi gave in the article. Both <mark>of</mark> those will be available in the show notes and on the website. All right. Thank you guys so much for listening. I'll actually direct Ohio. Yeah holidays. We have Bitcoin holidays today is gold parody day. So I had a hard time trying to name these holidays", "Start Time (s)": 2733.0, "End Time (s)": 2852.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "we have the largest financial imbalance and the largest state institutions that have ever existed so Hopefully hopefully it still good news and a Davidson and William Reese mogs thesis plays out as they explained in that book on the that is a amazing book and I highly highly recommend it. I will link to both <mark>of</mark> those further reading that Gigi gave in the article. Both <mark>of</mark> those will be available in the show notes and on the website. All right. Thank you guys so much for listening. I'll actually direct Ohio. Yeah holidays. We have Bitcoin holidays today is gold parody day. So I had a hard time trying to name these holidays because there's gold parity day and then there's gold market cap day or gold is greater than Bitcoin day. I'm not not sure exactly maybe maybe we can crowdsource the naming <mark>of</mark> this holiday, but gold parody day was March 3rd, 2017 and One Bitcoin past the price <mark>of</mark> one ounce <mark>of</mark> gold and that was the first time that happened. I think it crashed back down underneath it for a little while before on its way back up but it basically passed it and stayed past it since then I'll but in the not too distant future. I expect to see a new gold parody day where the entire market cap <mark>of</mark> the Bitcoin system matches the market cap <mark>of</mark> the entire world's gold Supply. And that is going to be a crazy and exciting time. But yeah, that's that is today March 3rd is gold parody day and I recommend celebrating with a little bit <mark>of</mark> Goldschlager and also your backup ritual whatever you do to back up your keys do it today. That is what Bitcoin holidays are", "Start Time (s)": 2801.4, "End Time (s)": 2920.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "down underneath it for a little while before on its way back up but it basically passed it and stayed past it since then I'll but in the not too distant future. I expect to see a new gold parody day where the entire market cap <mark>of</mark> the Bitcoin system matches the market cap <mark>of</mark> the entire world's gold Supply. And that is going to be a crazy and exciting time. But yeah, that's that is today March 3rd is gold parody day and I recommend celebrating with a little bit <mark>of</mark> Goldschlager and also your backup ritual whatever you do to back up your keys do it today. That is what Bitcoin holidays are for is so that we are constantly reminded to keep our Bitcoin safe to keep our Bitcoin safe from thieves. You keep them on our Hardware wallet to make sure that we are holding our keys and to make sure our keys will not be lost in the case <mark>of</mark> disaster. So take a show take a shot <mark>of</mark> Goldschlager and backup your keys. If you would like to check out the entire list <mark>of</mark> Bitcoin holidays that I have pulled together, you can find that on the crypto Kana me.com and up the top bar. It says holidays. It's hard to miss. So check that out. All right guys, thank you to my patrons. I've had a number <mark>of</mark> new people added to the crew and it is awesome to have everybody. Thank you guys for supporting the show. It makes a world <mark>of</mark> difference and I couldn't do this without you. So I You all thank you so much for listening. This is the crypto economy. I am guys swung and until next time take it easy everybody.", "Start Time (s)": 2875.8, "End Time (s)": 2981.8, "Clip Length (min)": 1.77, "show_uri": "spotify:show:16c6WR2znCZM1wveeeJoSz", "show_name": "Bitcoin Audible (previously the cryptoconomy)", "show_description": "The Best in Bitcoin made Audible!  Guy Swann makes the knowledge of the world's most secure, independent money, accessible to everyone. [part of The Cryptoconomy Network]", "publisher": "Guy Swann", "episode_uri": "spotify:episode:1Gs0FfKfblOH4nFbIi0yIL", "episode_name": "CryptoQuikRead_361 - Bitcoin's Habitats [DerGigi]", "episode_description": "\"\"\"To fully understand any organism, we must not only look at the organism itself, but examine the organism-environment holistically.\"\" - Gigi  If Bitcoin is a new organism, then where exactly does it live? Is it in cyberspace, the human realm, in financial markets and value\u2026 or all 3? Find out in Gigi\u2019s excellent new piece on the Habitats of Bitcoin. Bitcoin Habitats by @Dergigi: https://medium.com/@dergigi/bitcoins-habitats-9ce3064bd3a7  Recommended Further Reading: Proof of Life - Why Bitcoin is a Living Organism by Gigi \ud83c\udfa7\u2022 https://anchor.fm/thecryptoconomy/episodes/CryptoQuikRead_285---Proof-of-Life-dergigi-e51lt1 The Sovereign Individual by James Dale Davidson and William Rees-Mogg \ud83c\udfa7\u2022 https://www.audible.com/pd/The-Sovereign-Individual-Audiobook/1797103385?qid=1583275273&sr=1-1&ref=a_search_c3_lProduct_1_1&pf_rd_p=e81b7c27-6880-467a-b5a7-13cef5d729fe&pf_rd_r=3VY4T21FG3XNYQ1RGENK  Become a patron below to support the project of making all the best in Bitcoin Audible! Plus get access to the Cryptoconomy Telegram and hang out with a bunch of veteran Bitcoiners!  patreon.com/thecryptoconomy  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  ---   Send in a voice message: https://anchor.fm/thecryptoconomy/message\"", "score": 5.523353, "explanation": "{\n  \"value\": 5.523353,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.4743621,\n      \"description\": \"weight(word_list:effects in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.4743621,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.50190794,\n      \"description\": \"weight(word_list:of in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.50190794,\n          \"description\": \"score(LMDirichletSimilarity, freq=219.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9697824,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 219.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.547083,\n      \"description\": \"weight(word_list:global in 6) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.547083,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.0149574,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Thanks for listening to the derivative. This podcast is provided for informational purposes only and should not be relied upon as legal business investment or tax advice all opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions <mark>of</mark> RCM Alternatives their Affiliates or companies featured do to Industry regulations participants on this podcast or instructed not to make specific trade recommendations nor reference pass their potential. Pets and listeners are reminded that managed Futures commodity trading and other alternative Investments are complex and carry a risk <mark>of</mark> substantial losses as such they are not suitable for all investors. Welcome to the derivative by our Sam Alternatives where we dive into what makes alternative Investments. Go analyze the strategies <mark>of</mark> unique hedge fund managers and chat with interesting guests from across the investment World. Alpha is a process for you. You're never arrived. It is the constant process <mark>of</mark> trying to be the right amount ahead <mark>of</mark> the curve. You don't you can't be too far ahead because in you just nonsense, but you can't just be thinking Making <mark>of</mark> things from from the perspective <mark>of</mark> where everybody else is thinking <mark>of</mark> them or you're not going to get different results. You have to be different in that", "Start Time (s)": 6.8, "End Time (s)": 76.9, "Clip Length (min)": 1.17, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "for informational purposes only and should not be relied upon as legal business investment or tax advice all opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions <mark>of</mark> RCM Alternatives their Affiliates or companies featured do to Industry regulations participants on this podcast or instructed not to make specific trade recommendations nor reference pass their potential. Pets and listeners are reminded that managed Futures commodity trading and other alternative Investments are complex and carry a risk <mark>of</mark> substantial losses as such they are not suitable for all investors. Welcome to the derivative by our Sam Alternatives where we dive into what makes alternative Investments. Go analyze the strategies <mark>of</mark> unique hedge fund managers and chat with interesting guests from across the investment World. Alpha is a process for you. You're never arrived. It is the constant process <mark>of</mark> trying to be the right amount ahead <mark>of</mark> the curve. You don't you can't be too far ahead because in you just nonsense, but you can't just be thinking Making <mark>of</mark> things from from the perspective <mark>of</mark> where everybody else is thinking <mark>of</mark> them or you're not going to get different results. You have to be different in that welcome to the derivative by RCM Alternatives coming to you from Sunny Miami or some <mark>of</mark> the top investing talent in the world is gathered for the annual context conference. I'm your host Jeff Malik and have managed to peel away a couple <mark>of</mark> Talents from their conference duties today Rodrigo Gordillo Adam Butler and Mike philbrick <mark>of</mark> resolve Asset Management. Welcome guys. Thanks for having us resolves. A toronto-based asset manager doing all sorts <mark>of</mark> cool things around asset allocation strategies for managing mutual funds to private hedge funds and are one <mark>of</mark> the more prolific firms in terms <mark>of</mark> investor education and writing with white papers webinars and podcasts under the resolve Banner. I'll have to admit we've been known to peek over at your guys writing from time to time and", "Start Time (s)": 10.1, "End Time (s)": 129.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "welcome to the derivative by RCM Alternatives coming to you from Sunny Miami or some <mark>of</mark> the top investing talent in the world is gathered for the annual context conference. I'm your host Jeff Malik and have managed to peel away a couple <mark>of</mark> Talents from their conference duties today Rodrigo Gordillo Adam Butler and Mike philbrick <mark>of</mark> resolve Asset Management. Welcome guys. Thanks for having us resolves. A toronto-based asset manager doing all sorts <mark>of</mark> cool things around asset allocation strategies for managing mutual funds to private hedge funds and are one <mark>of</mark> the more prolific firms in terms <mark>of</mark> investor education and writing with white papers webinars and podcasts under the resolve Banner. I'll have to admit we've been known to peek over at your guys writing from time to time and Borrow some ideas for blog posts and whatnot feeling's mutual got it. So we'll start personal and we'll start with Rodrigo. Give a little background. You're from Peru right Born and Raised. Yeah. So how do you become a hedge fund manager out <mark>of</mark> Peru using you experienced a massive economic event for the for the nation at an early age and those formative years really make a big impact this what you do when you're older. So in 1989 88 89 The Shining path terrorist group came down upon the city amongst other economic issues that were happening at the time high inflation would not but when they came down and the president decided to renege on his IMF loans inflation went to seven thousand percent six months my parents lost it all my neighbor who had his mortgage and it was about to be evicted was able to pay down his mortgage with a few US Dollars and a lot <mark>of</mark> people emigrated out <mark>of</mark> Canada out <mark>of</mark> a Peru. Toured Canada and and Australia we decided on Canada and the rest is history. So all that kind <mark>of</mark> wood, you know, the background is also come from a mathematics family got the Quant bug fairly", "Start Time (s)": 87.8, "End Time (s)": 204.9, "Clip Length (min)": 1.95, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Give a little background. You're from Peru right Born and Raised. Yeah. So how do you become a hedge fund manager out <mark>of</mark> Peru using you experienced a massive economic event for the for the nation at an early age and those formative years really make a big impact this what you do when you're older. So in 1989 88 89 The Shining path terrorist group came down upon the city amongst other economic issues that were happening at the time high inflation would not but when they came down and the president decided to renege on his IMF loans inflation went to seven thousand percent six months my parents lost it all my neighbor who had his mortgage and it was about to be evicted was able to pay down his mortgage with a few US Dollars and a lot <mark>of</mark> people emigrated out <mark>of</mark> Canada out <mark>of</mark> a Peru. Toured Canada and and Australia we decided on Canada and the rest is history. So all that kind <mark>of</mark> wood, you know, the background is also come from a mathematics family got the Quant bug fairly early in the investment career. And then from there Matt Mike and Adam 2011. We're Off to the Races sounds good Adam. How about yourself? Nothing nearly. So interesting on a background stamp? point but I didn't really discover that I wanted to be in the investing field until most <mark>of</mark> the way through University and I entered into trading competition and ended up doing well and caught the bug and worked on a trading desk and learn some very valuable lessons and I guess sort <mark>of</mark> as a third major lesson after the 2008 crisis does decided that I didn't want to run strategies anymore that were vulnerable to that type <mark>of</mark> outcome again, and and", "Start Time (s)": 139.5, "End Time (s)": 258.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and the rest is history. So all that kind <mark>of</mark> wood, you know, the background is also come from a mathematics family got the Quant bug fairly early in the investment career. And then from there Matt Mike and Adam 2011. We're Off to the Races sounds good Adam. How about yourself? Nothing nearly. So interesting on a background stamp? point but I didn't really discover that I wanted to be in the investing field until most <mark>of</mark> the way through University and I entered into trading competition and ended up doing well and caught the bug and worked on a trading desk and learn some very valuable lessons and I guess sort <mark>of</mark> as a third major lesson after the 2008 crisis does decided that I didn't want to run strategies anymore that were vulnerable to that type <mark>of</mark> outcome again, and and that was the Catalyst for a move into systemic <mark>Global</mark> macro, and that's kind <mark>of</mark> where we've been ever since and I need a ride. What would you what do you place in that trading competition? I placed first in the first one. It was great and and got it was what was so great. Was that the I was in the psych program and the Commerce students. There are three classes <mark>of</mark> Commerce students were all the students also participated in it was a national contest and and I wanted and none <mark>of</mark> the other Commerce students did very well. So it was a nice sort <mark>of</mark> Psych Department versus Commerce Department rivalry point <mark>of</mark> discussion for a while. I love Canada calls it the Commerce Department. That would be like economics at a u.s. University. Yeah business economics. Yeah Commerce and Mike you might have the most interesting background some Canadian football league in there. Yeah. Yeah.", "Start Time (s)": 196.1, "End Time (s)": 315.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "for a move into systemic <mark>Global</mark> macro, and that's kind <mark>of</mark> where we've been ever since and I need a ride. What would you what do you place in that trading competition? I placed first in the first one. It was great and and got it was what was so great. Was that the I was in the psych program and the Commerce students. There are three classes <mark>of</mark> Commerce students were all the students also participated in it was a national contest and and I wanted and none <mark>of</mark> the other Commerce students did very well. So it was a nice sort <mark>of</mark> Psych Department versus Commerce Department rivalry point <mark>of</mark> discussion for a while. I love Canada calls it the Commerce Department. That would be like economics at a u.s. University. Yeah business economics. Yeah Commerce and Mike you might have the most interesting background some Canadian football league in there. Yeah. Yeah. I actually grew up on a farm, you know learned learned learned the value <mark>of</mark> hard work and and then had the opportunity to play football professionally in Canada for 12 years whilst I was doing that. I also was fortunate enough to be hired by a firm who allowed me to do both at the same time because in Canada, you can't you can't quite make enough. I need to just retire Forever After and and and I you know, I want to be challenged. I like I like the the nature <mark>of</mark> our business in the way in which it allows you to be competitive and that competition is something that is enticing and I'd like to play a game every day where you know, the score is yeah. It is very similar to Athletics, right? There's a score there's a winner there's a loser each and every day and it And in some case it, you know Sports is the ultimate zero-sum game. It worked great. The Super Bowl is going to happen on Sunday and there was two hundred and fifty six games played in the NFL this year and there always is and there's", "Start Time (s)": 261.6, "End Time (s)": 381.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that. I also was fortunate enough to be hired by a firm who allowed me to do both at the same time because in Canada, you can't you can't quite make enough. I need to just retire Forever After and and and I you know, I want to be challenged. I like I like the the nature <mark>of</mark> our business in the way in which it allows you to be competitive and that competition is something that is enticing and I'd like to play a game every day where you know, the score is yeah. It is very similar to Athletics, right? There's a score there's a winner there's a loser each and every day and it And in some case it, you know Sports is the ultimate zero-sum game. It worked great. The Super Bowl is going to happen on Sunday and there was two hundred and fifty six games played in the NFL this year and there always is and there's a winner and loser to everyone and you have a winner at the end and teams take different approaches to add Alpha and value and win the end <mark>of</mark> the day there can only be one winner. So there's some my Bears didn't add a lot <mark>of</mark> alpha this year. Yeah. I do like the Bears though. They're coming around. We'll see who do you like in the Super Bowl? Oh, I would I would say so probabilistically thinking that they're there it's probably underestimated the opportunity that the Niners have I think that it's probably the Chiefs. But yeah, I think you and I were talking about this last night. I think there's a lot <mark>of</mark> strange opportunities within the potential Futures that will go on in the next few days. That would maybe favor the Niners a little bit more than the oddsmakers are suggesting. So throw it back out to any <mark>of</mark> you have how did the three <mark>of</mark> you come together and found resolve? Well, when there's there's you know, three zebras walking amongst, you know herd <mark>of</mark> horses you find each other pretty quickly and Adam and I as you as Adam alluded to a 2008 was was you know, sort <mark>of</mark> informative", "Start Time (s)": 330.3, "End Time (s)": 450.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the end <mark>of</mark> the day there can only be one winner. So there's some my Bears didn't add a lot <mark>of</mark> alpha this year. Yeah. I do like the Bears though. They're coming around. We'll see who do you like in the Super Bowl? Oh, I would I would say so probabilistically thinking that they're there it's probably underestimated the opportunity that the Niners have I think that it's probably the Chiefs. But yeah, I think you and I were talking about this last night. I think there's a lot <mark>of</mark> strange opportunities within the potential Futures that will go on in the next few days. That would maybe favor the Niners a little bit more than the oddsmakers are suggesting. So throw it back out to any <mark>of</mark> you have how did the three <mark>of</mark> you come together and found resolve? Well, when there's there's you know, three zebras walking amongst, you know herd <mark>of</mark> horses you find each other pretty quickly and Adam and I as you as Adam alluded to a 2008 was was you know, sort <mark>of</mark> informative to us as to how we might think about the investment problem and we ran into Rodrigo who was managing his assets all from an alternative perspective. And who had prospered very very well in 2008. So when we met each other was It was kind <mark>of</mark> obvious that this is something that should come together and and it's it really is hard to find great talent to work with people that are talented but also Mindful and you know constructive to all situations and so it's been it's been Rivers skill sets right now. It was absolutely I had a few Partnerships before that and it was always about Okay, we all do the same thing really. Well, let's get together and try to do something and it was always a an ego trip, right who's doing better at the one thing that we are all good at when I met Mike and Adam. We all had very diverse skill sets Adam on the writing", "Start Time (s)": 390.0, "End Time (s)": 508.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "well in 2008. So when we met each other was It was kind <mark>of</mark> obvious that this is something that should come together and and it's it really is hard to find great talent to work with people that are talented but also Mindful and you know constructive to all situations and so it's been it's been Rivers skill sets right now. It was absolutely I had a few Partnerships before that and it was always about Okay, we all do the same thing really. Well, let's get together and try to do something and it was always a an ego trip, right who's doing better at the one thing that we are all good at when I met Mike and Adam. We all had very diverse skill sets Adam on the writing side and the Quant and analytic side. Mike was has been leading men and women his whole career through both bank system and and in sports and I was you know, pretty good business development person and It's so a little bit <mark>of</mark> a Venn diagram there but enough diversity that it made it easy for us to just trust each other and what we're good at and say, all right, everybody do their own thing in their own area and let's build this up. And that the content size that you mention is that in a conscious effort to educate or did that just come out <mark>of</mark> your research process and wanting to figure out things for your own and then sharing what you found out that that publishing effort was a catharsis after the 2008 crash. Honestly, it was sort <mark>of</mark> an effort to find. Ourselves, you know, it was sort <mark>of</mark> Mike and I had recently teamed up we had this very interesting experience trying to navigate around how to emerge from it. Not just sort <mark>of</mark> learning lessons and then Moving on but learning lessons and making changes and so it was just sort <mark>of</mark> an effort to document that journey and hold us accountable to that thinking and it was it ended up being this incredible", "Start Time (s)": 463.5, "End Time (s)": 583.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and in sports and I was you know, pretty good business development person and It's so a little bit <mark>of</mark> a Venn diagram there but enough diversity that it made it easy for us to just trust each other and what we're good at and say, all right, everybody do their own thing in their own area and let's build this up. And that the content size that you mention is that in a conscious effort to educate or did that just come out <mark>of</mark> your research process and wanting to figure out things for your own and then sharing what you found out that that publishing effort was a catharsis after the 2008 crash. Honestly, it was sort <mark>of</mark> an effort to find. Ourselves, you know, it was sort <mark>of</mark> Mike and I had recently teamed up we had this very interesting experience trying to navigate around how to emerge from it. Not just sort <mark>of</mark> learning lessons and then Moving on but learning lessons and making changes and so it was just sort <mark>of</mark> an effort to document that journey and hold us accountable to that thinking and it was it ended up being this incredible feedback mechanism where you sort <mark>of</mark> put yourself out there you don't Fully understand the problem in the beginning even though you don't really know enough to know what you don't know. So at each stage along the journey you think you know a lot more than you do but, you know, then people sort <mark>of</mark> surrounding you or they're increasingly reading the material. They're giving you feedback you're learning about how you might want to shift a little bit how you think about the problem and you know that was beginning <mark>of</mark> 109. We're in the beginning <mark>of</mark> 2020. So that's a 10-year journey, and I think we We've all learned an incredible amount about the Quan community and how to think about the problem and I know our Evolution or thinking has evolved very substantially in that time. Do you ever look back at some <mark>of</mark> the oh nine and ten eleven stuff and be like, oh my God, we didn't know what we didn't know. Oh, absolutely. Yeah, I", "Start Time (s)": 516.6, "End Time (s)": 636.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Not just sort <mark>of</mark> learning lessons and then Moving on but learning lessons and making changes and so it was just sort <mark>of</mark> an effort to document that journey and hold us accountable to that thinking and it was it ended up being this incredible feedback mechanism where you sort <mark>of</mark> put yourself out there you don't Fully understand the problem in the beginning even though you don't really know enough to know what you don't know. So at each stage along the journey you think you know a lot more than you do but, you know, then people sort <mark>of</mark> surrounding you or they're increasingly reading the material. They're giving you feedback you're learning about how you might want to shift a little bit how you think about the problem and you know that was beginning <mark>of</mark> 109. We're in the beginning <mark>of</mark> 2020. So that's a 10-year journey, and I think we We've all learned an incredible amount about the Quan community and how to think about the problem and I know our Evolution or thinking has evolved very substantially in that time. Do you ever look back at some <mark>of</mark> the oh nine and ten eleven stuff and be like, oh my God, we didn't know what we didn't know. Oh, absolutely. Yeah, I mean really stuff prior to 2012 is complete nonsense and and stuff prior to 2014 mostly needs a Complete rewrite but you know, that's that's part <mark>of</mark> the journey. Is it still out there? Yeah. Absolutely. They're still valid like they're still good even though it's it seems like a little bit Mickey Mouse to us. Now with the time. It was a massive leap in our thinking. Yeah. So yeah, definitely definitely worth. Well reading if you want to go back down that far. I mean, I think it's a an excellent example that Alpha is approximately Process are you you're never arrived? It is the constant process <mark>of</mark> trying to be the right amount ahead <mark>of</mark> the curve. You don't you can't be too far ahead because", "Start Time (s)": 570.3, "End Time (s)": 689.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "about the problem and I know our Evolution or thinking has evolved very substantially in that time. Do you ever look back at some <mark>of</mark> the oh nine and ten eleven stuff and be like, oh my God, we didn't know what we didn't know. Oh, absolutely. Yeah, I mean really stuff prior to 2012 is complete nonsense and and stuff prior to 2014 mostly needs a Complete rewrite but you know, that's that's part <mark>of</mark> the journey. Is it still out there? Yeah. Absolutely. They're still valid like they're still good even though it's it seems like a little bit Mickey Mouse to us. Now with the time. It was a massive leap in our thinking. Yeah. So yeah, definitely definitely worth. Well reading if you want to go back down that far. I mean, I think it's a an excellent example that Alpha is approximately Process are you you're never arrived? It is the constant process <mark>of</mark> trying to be the right amount ahead <mark>of</mark> the curve. You don't you can't be too far ahead because in you just nonsense, but you can't just be thinking <mark>of</mark> things from from the perspective <mark>of</mark> where everybody else is thinking <mark>of</mark> them or you're not going to get different results. You have to be different enough and if you go back through the evolution <mark>of</mark> the thinking and I would I would argue you go. It's kind <mark>of</mark> funny Twelve eleven nine last year. Absolutely. So so our you know, our process is one <mark>of</mark> understandings process. Well said tell me a little bit more about the overall firm. So there's you three how many others but what 15 or 16 people in total an operations team has been Trading. Futures for almost 20 years now 16 years and", "Start Time (s)": 622.3, "End Time (s)": 742.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "going to get different results. You have to be different enough and if you go back through the evolution <mark>of</mark> the thinking and I would I would argue you go. It's kind <mark>of</mark> funny Twelve eleven nine last year. Absolutely. So so our you know, our process is one <mark>of</mark> understandings process. Well said tell me a little bit more about the overall firm. So there's you three how many others but what 15 or 16 people in total an operations team has been Trading. Futures for almost 20 years now 16 years and I mean research team voting retouching got well you yeah walk through the research team. That's a great. Yeah. Well, I mean our our product line is evolved, you know, we started out running systemic ETF strategies kind <mark>of</mark> <mark>global</mark> asset allocation, and then there was demand from new clients who were really enamored with how we But the problem and it sort <mark>of</mark> nudged us into thinking about whether you want to do Express these types <mark>of</mark> Concepts through Futures instead. And so we took our time and went about that thoroughly and mindfully and that was several years ago now and so are our research needs have changed, you know, we are the products we run right now are orders <mark>of</mark> magnitude more sophisticated. Other than the ones that we ran five or six years ago, but and you know while the thinking has evolved some <mark>of</mark> the major themes that inform how we think about markets and think about the problem really haven't really haven't changed that much but you know, we've added people to the team with backgrounds in high frequency", "Start Time (s)": 698.5, "End Time (s)": 818.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "there was demand from new clients who were really enamored with how we But the problem and it sort <mark>of</mark> nudged us into thinking about whether you want to do Express these types <mark>of</mark> Concepts through Futures instead. And so we took our time and went about that thoroughly and mindfully and that was several years ago now and so are our research needs have changed, you know, we are the products we run right now are orders <mark>of</mark> magnitude more sophisticated. Other than the ones that we ran five or six years ago, but and you know while the thinking has evolved some <mark>of</mark> the major themes that inform how we think about markets and think about the problem really haven't really haven't changed that much but you know, we've added people to the team with backgrounds in high frequency trading backgrounds in applied math. One <mark>of</mark> the members <mark>of</mark> the team did some <mark>of</mark> the founding research on neural Nets. In the 1980s and then went on to found and build a software company and now is back doing work in machine learning, you know, it's a diverse team with complementary skill sets a lot like the way that the partners the founding Partners kind <mark>of</mark> came together and it's been really neat to see all that reinforced. You feel like it's a bit <mark>of</mark> an arms race that you need to spend an iron in order to stay relevant. Avant and keep up with your peers and competitors a little bit but you've also got to know where you fit. You know, I mean, we're not going to compete with with rentec, you know, we're not going to compete at the at the microsecond scale that really is an arms race at least not right. Now, you know, we may we may evolve to get higher and higher frequency. There's mathematical reasons, why higher frequency has", "Start Time (s)": 762.5, "End Time (s)": 882.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a diverse team with complementary skill sets a lot like the way that the partners the founding Partners kind <mark>of</mark> came together and it's been really neat to see all that reinforced. You feel like it's a bit <mark>of</mark> an arms race that you need to spend an iron in order to stay relevant. Avant and keep up with your peers and competitors a little bit but you've also got to know where you fit. You know, I mean, we're not going to compete with with rentec, you know, we're not going to compete at the at the microsecond scale that really is an arms race at least not right. Now, you know, we may we may evolve to get higher and higher frequency. There's mathematical reasons, why higher frequency has higher expectancy all things equal but you know, I think you've got to know who you are. Are and who you're competing against in the Alfie who you're competing against in the market and where are there gaps that you might be able to fill with your expertise and I think we're uniquely positioned to fill some sort <mark>of</mark> mid-frequency gaps that are pretty exciting in the next sort <mark>of</mark> 6 to 12 months. And in the meantime just bringing on New Blood who've been very successful thinking about the problem in a very different way has inspired us to think about The problem and in very different ways and just the evolution in our thinking on the research side over the last year. It has been pretty incredible to see. Yeah, I think it's a function <mark>of</mark> strategy structure execution and behavior. So you you you have a strategy what what structures are going to be in the because that will have limitations on how you might be able to execute it. And are you going to be able to behaviorally stick with it? So then how do Fit in to the marketplace in order to extract some error or some mistakes in the marketplace that are being made on a regular basis where you're going to be able to reliably", "Start Time (s)": 840.4, "End Time (s)": 958.2, "Clip Length (min)": 1.96, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the evolution in our thinking on the research side over the last year. It has been pretty incredible to see. Yeah, I think it's a function <mark>of</mark> strategy structure execution and behavior. So you you you have a strategy what what structures are going to be in the because that will have limitations on how you might be able to execute it. And are you going to be able to behaviorally stick with it? So then how do Fit in to the marketplace in order to extract some error or some mistakes in the marketplace that are being made on a regular basis where you're going to be able to reliably extract those opportunities for excess return and I think that we think very very carefully about that in order to manifest the strategy that's going to provide for some excess return. That's That's reliable and then having a number <mark>of</mark> those edges and then assembling those edges in a way that's thoughtful and different. I think that the way we approach that is quite unique in the things that we are willing to do that others aren't is largely where we're going to gather some excess return from which that's a good lead into getting in diving into the strategies have been tweaked kind <mark>of</mark> buried the lead a little here, but maybe Rodrigo give me the 30 second elevator pitch on what you guys do and what you're good at from Strategy standpoint. Well, I think we alluded to worse hundred systematic and one <mark>of</mark> the things that Mike mentioned isn't the structure and where we want this business to really grow and so we consider ourselves to be institutional quality research and product. And in order to do that. You need to accommodate large a um, you need to be able to bring it in so you can't go down on the microscopic like take that data level you have to do in a day. In order to be able to accommodate the institutional interest", "Start Time (s)": 919.6, "End Time (s)": 1039.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a good lead into getting in diving into the strategies have been tweaked kind <mark>of</mark> buried the lead a little here, but maybe Rodrigo give me the 30 second elevator pitch on what you guys do and what you're good at from Strategy standpoint. Well, I think we alluded to worse hundred systematic and one <mark>of</mark> the things that Mike mentioned isn't the structure and where we want this business to really grow and so we consider ourselves to be institutional quality research and product. And in order to do that. You need to accommodate large a um, you need to be able to bring it in so you can't go down on the microscopic like take that data level you have to do in a day. In order to be able to accommodate the institutional interest that's coming our way while still being different enough to to get paid what an alpha manager should get paid. And so what were the way the our Revolution Futures program is designed. It is not it is all Futures, but it's a different way <mark>of</mark> managing future. So it's not it's the traditional Trend. It is a multi Strat with different Alpha buckets that include some <mark>of</mark> the basic Fundamental understanding that you see in the style premium space on quality value and so on except we're trying to extract other behavioral laws that are less popular and still provide a robust Alpha as we see the traditional style premium really collapse. And so the evolution you just programs designed to fill that Gap to provide a series <mark>of</mark> non-correlated alpha strategies, like seasonality skewness mean reversion certain types <mark>of</mark> carry strategies in in ensembles. So each one <mark>of</mark> these little Alpha buckets has not just one or two ways <mark>of</mark> trying to extract that particular signal but thousands <mark>of</mark> different ways and we were written a ton on the values <mark>of</mark> Ensemble and and then the other side <mark>of</mark> the equation Beyond just trying to find better Alpha buckets that allow us to choose across 80 different Futures contracts for better or worse is", "Start Time (s)": 995.7, "End Time (s)": 1115.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "what an alpha manager should get paid. And so what were the way the our Revolution Futures program is designed. It is not it is all Futures, but it's a different way <mark>of</mark> managing future. So it's not it's the traditional Trend. It is a multi Strat with different Alpha buckets that include some <mark>of</mark> the basic Fundamental understanding that you see in the style premium space on quality value and so on except we're trying to extract other behavioral laws that are less popular and still provide a robust Alpha as we see the traditional style premium really collapse. And so the evolution you just programs designed to fill that Gap to provide a series <mark>of</mark> non-correlated alpha strategies, like seasonality skewness mean reversion certain types <mark>of</mark> carry strategies in in ensembles. So each one <mark>of</mark> these little Alpha buckets has not just one or two ways <mark>of</mark> trying to extract that particular signal but thousands <mark>of</mark> different ways and we were written a ton on the values <mark>of</mark> Ensemble and and then the other side <mark>of</mark> the equation Beyond just trying to find better Alpha buckets that allow us to choose across 80 different Futures contracts for better or worse is the weighting scheme, which I think is ignored by a lot <mark>of</mark> the alternative space, right so we focus too much on trying to find an edge and to little on then once The Edge being what are the winners? What am I going to go long? What am I going to short? Very little time spent on how you wait those and we spent in an equal amount <mark>of</mark> time on that side <mark>of</mark> the equation which has the ability increased Sharpe ratios as much as 50% <mark>of</mark> X. So that is I think where our Niche is very different portfolio construction. We're working in an area that is yet to be harvested globally and in a very aggressive way and that means that our correlation for this strategy to traditional risk Premia ctas and whatnot is nearly zero. And take me one level up though. So the evolution strategist one <mark>of</mark> your products. It's yeah, Charlie had fun product long-short Futures product. Okay, and", "Start Time (s)": 1046.0, "End Time (s)": 1165.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "not just one or two ways <mark>of</mark> trying to extract that particular signal but thousands <mark>of</mark> different ways and we were written a ton on the values <mark>of</mark> Ensemble and and then the other side <mark>of</mark> the equation Beyond just trying to find better Alpha buckets that allow us to choose across 80 different Futures contracts for better or worse is the weighting scheme, which I think is ignored by a lot <mark>of</mark> the alternative space, right so we focus too much on trying to find an edge and to little on then once The Edge being what are the winners? What am I going to go long? What am I going to short? Very little time spent on how you wait those and we spent in an equal amount <mark>of</mark> time on that side <mark>of</mark> the equation which has the ability increased Sharpe ratios as much as 50% <mark>of</mark> X. So that is I think where our Niche is very different portfolio construction. We're working in an area that is yet to be harvested globally and in a very aggressive way and that means that our correlation for this strategy to traditional risk Premia ctas and whatnot is nearly zero. And take me one level up though. So the evolution strategist one <mark>of</mark> your products. It's yeah, Charlie had fun product long-short Futures product. Okay, and then there's how many others we run a 40 act fun as well. That is run by the rational funds. So we some advice for them and that one is a kind <mark>of</mark> coming in from our some <mark>of</mark> our Legacy programs which were completion portfolios. Right? So you have it's a long flat strategy using similar. Kind <mark>of</mark> alpha signals in order to decide what the waiting is going to be in the same type <mark>of</mark> optimization at the back end but it's designed to be a bit more transparent transparent and approachable for the retail space where you have a 60/40 portfolio. This leave can represent 10% and give you exposure to things like Commodities real estate <mark>Global</mark> equities German buns and that sort <mark>of</mark> your guys DNA <mark>of</mark> asset allocation, right? Not just I'm focusing on one trade. That makes money but these different pieces as you call them The Ensemble and how to the", "Start Time (s)": 1099.7, "End Time (s)": 1219.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "correlation for this strategy to traditional risk Premia ctas and whatnot is nearly zero. And take me one level up though. So the evolution strategist one <mark>of</mark> your products. It's yeah, Charlie had fun product long-short Futures product. Okay, and then there's how many others we run a 40 act fun as well. That is run by the rational funds. So we some advice for them and that one is a kind <mark>of</mark> coming in from our some <mark>of</mark> our Legacy programs which were completion portfolios. Right? So you have it's a long flat strategy using similar. Kind <mark>of</mark> alpha signals in order to decide what the waiting is going to be in the same type <mark>of</mark> optimization at the back end but it's designed to be a bit more transparent transparent and approachable for the retail space where you have a 60/40 portfolio. This leave can represent 10% and give you exposure to things like Commodities real estate <mark>Global</mark> equities German buns and that sort <mark>of</mark> your guys DNA <mark>of</mark> asset allocation, right? Not just I'm focusing on one trade. That makes money but these different pieces as you call them The Ensemble and how to the different assets mix and correct together. That's right. Well, even even thinking about not just the assets. How did the different resulting strategies that you're running on various assets manifest in return stream that you would then optimize within a portfolio. But if you guys found one thing that work just really well on oil, you know, if it's an ensemble approach in many different. He probably wouldn't trade that because you wanted more. Based asset that you have exposure. I'm not going to say anything about that. Actually that's that's funny. But it's also an interesting point because I think you know used to be the point when we were running strategies that were informed primarily by Trend or momentum that we shared all <mark>of</mark> our research there wasn't anything behind the the veil,", "Start Time (s)": 1149.9, "End Time (s)": 1269.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to things like Commodities real estate <mark>Global</mark> equities German buns and that sort <mark>of</mark> your guys DNA <mark>of</mark> asset allocation, right? Not just I'm focusing on one trade. That makes money but these different pieces as you call them The Ensemble and how to the different assets mix and correct together. That's right. Well, even even thinking about not just the assets. How did the different resulting strategies that you're running on various assets manifest in return stream that you would then optimize within a portfolio. But if you guys found one thing that work just really well on oil, you know, if it's an ensemble approach in many different. He probably wouldn't trade that because you wanted more. Based asset that you have exposure. I'm not going to say anything about that. Actually that's that's funny. But it's also an interesting point because I think you know used to be the point when we were running strategies that were informed primarily by Trend or momentum that we shared all <mark>of</mark> our research there wasn't anything behind the the veil, you know in as a strategies have become more sophisticated and we've realized just how how quickly Other investors including you know, commercial investors will steal your IP and you know use it for themselves then we've and we've seen we've developed IP. That is I think legitimately different and represents genuine Alpha. We're a lot less inclined to publish all <mark>of</mark> that research, you know, we still publish lots <mark>of</mark> research, but there's now A lot <mark>of</mark> stuff that goes on behind the scenes that were a little bit less willing to share the details about you know, and do see that with some <mark>of</mark> the biggest pensions and endowments out there bringing strategies in House <mark>of</mark> okay. I've watched this for", "Start Time (s)": 1204.5, "End Time (s)": 1324.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that were informed primarily by Trend or momentum that we shared all <mark>of</mark> our research there wasn't anything behind the the veil, you know in as a strategies have become more sophisticated and we've realized just how how quickly Other investors including you know, commercial investors will steal your IP and you know use it for themselves then we've and we've seen we've developed IP. That is I think legitimately different and represents genuine Alpha. We're a lot less inclined to publish all <mark>of</mark> that research, you know, we still publish lots <mark>of</mark> research, but there's now A lot <mark>of</mark> stuff that goes on behind the scenes that were a little bit less willing to share the details about you know, and do see that with some <mark>of</mark> the biggest pensions and endowments out there bringing strategies in House <mark>of</mark> okay. I've watched this for five years absolutely guys have shown me the ropes. I'm gonna hire some p.m. For less money and try it myself, which I personally think so Road dangerous road for them. Well, we've wee it absolutely is if you didn't develop The strategy you didn't build the strategy. We have heard <mark>of</mark> several scenarios where adaptive asset allocation has been that paper that was written back in 2012. 2011 Lee 11. Yeah how that was adopted by some major pension family plans with catastrophic results mainly because they just didn't quite fully understand the depth <mark>of</mark> what was required always want to add your own tilt and they go sideways so it Is again this hope it does whole idea <mark>of</mark> alpha is a process. You you need, you know hits the it's what is it the Red Queen", "Start Time (s)": 1258.9, "End Time (s)": 1378.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to share the details about you know, and do see that with some <mark>of</mark> the biggest pensions and endowments out there bringing strategies in House <mark>of</mark> okay. I've watched this for five years absolutely guys have shown me the ropes. I'm gonna hire some p.m. For less money and try it myself, which I personally think so Road dangerous road for them. Well, we've wee it absolutely is if you didn't develop The strategy you didn't build the strategy. We have heard <mark>of</mark> several scenarios where adaptive asset allocation has been that paper that was written back in 2012. 2011 Lee 11. Yeah how that was adopted by some major pension family plans with catastrophic results mainly because they just didn't quite fully understand the depth <mark>of</mark> what was required always want to add your own tilt and they go sideways so it Is again this hope it does whole idea <mark>of</mark> alpha is a process. You you need, you know hits the it's what is it the Red Queen Syndrome from The Mad Hatter, right? You need to be running just to keep up. Yeah, and there's so what Micah speaking <mark>of</mark> is the difficulty operationally and trying to replicate a bunch <mark>of</mark> white papers that are trying to extract whatever premium. So the Adaptive asset allocation frame. Is what we run in the 40 act fun, but it can it hasn't evolved every year as we continue to do the research, but I think there's also the issue <mark>of</mark> publishing and what the impact <mark>of</mark> that once it's widely accepted and I think we can see that in the factor space right? There's as we speak to institution after institution. They're all rationalizing their firing their external managers that are charging any fees and trying to bring the factors in house, and we actually just did a pot. We have a podcast <mark>of</mark> our Phone call Gestalt University and we just did an interview with the what was his", "Start Time (s)": 1312.5, "End Time (s)": 1432.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Is again this hope it does whole idea <mark>of</mark> alpha is a process. You you need, you know hits the it's what is it the Red Queen Syndrome from The Mad Hatter, right? You need to be running just to keep up. Yeah, and there's so what Micah speaking <mark>of</mark> is the difficulty operationally and trying to replicate a bunch <mark>of</mark> white papers that are trying to extract whatever premium. So the Adaptive asset allocation frame. Is what we run in the 40 act fun, but it can it hasn't evolved every year as we continue to do the research, but I think there's also the issue <mark>of</mark> publishing and what the impact <mark>of</mark> that once it's widely accepted and I think we can see that in the factor space right? There's as we speak to institution after institution. They're all rationalizing their firing their external managers that are charging any fees and trying to bring the factors in house, and we actually just did a pot. We have a podcast <mark>of</mark> our Phone call Gestalt University and we just did an interview with the what was his position at the time <mark>Global</mark> tactical asset allocation and then eventually, you know <mark>Global</mark> style Premia or something. Yeah, so he developed a style preemie approach from first principles back in 2004 before anybody was doing it and the Sharpe ratio was a bubble one like 1.2 and then he said that in 2010 when all the papers came out and everybody finally accepted it. He saw hundred x a um going to the product and Sharp get caught by 30% And so what's interesting now this year is that I'm seeing and hearing more and more and more institutions saying we're bringing we're going to do style premium. We're going to do factors we can bring them all in house. So you can imagine this is what this is already a trend. That's bad. It's going to get even worse. And so the even if they replicated poorly but that does mean is for the people who are getting paid for that. They're probably going to get fired or they're just not going to be any return to speak up. So the key for us is to make sure the word", "Start Time (s)": 1368.0, "End Time (s)": 1487.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the time <mark>Global</mark> tactical asset allocation and then eventually, you know <mark>Global</mark> style Premia or something. Yeah, so he developed a style preemie approach from first principles back in 2004 before anybody was doing it and the Sharpe ratio was a bubble one like 1.2 and then he said that in 2010 when all the papers came out and everybody finally accepted it. He saw hundred x a um going to the product and Sharp get caught by 30% And so what's interesting now this year is that I'm seeing and hearing more and more and more institutions saying we're bringing we're going to do style premium. We're going to do factors we can bring them all in house. So you can imagine this is what this is already a trend. That's bad. It's going to get even worse. And so the even if they replicated poorly but that does mean is for the people who are getting paid for that. They're probably going to get fired or they're just not going to be any return to speak up. So the key for us is to make sure the word tacking. And that space from an acute angle and providing something completely different and seeing those sort <mark>of</mark> bringing in house or they're going to a bank platform or whatnot. That's offering those different risk premiums. I'm seeing it more and house. I think the sophisticated guys I can pull it off the quad because their art they're hiring Quant internally and those quants recognize that that you know, simple left 50 basis point swap that they can get from the banks are not you know, yeah, it's that we're going to try to do a little bit better. But at the end <mark>of</mark> the day, I think a lot <mark>of</mark> them have been Turned on those Ultra simplistic Bank oriented Factor strategies. And I mean what the banks do <mark>of</mark> course is they create a strategy and they let it run they call it something and then it doesn't work out in the event something, you know pretty well similar and then they let it run and it doesn't work out and it's you know, they like Trend one trying to try and three Transformer. I guess if served they can just keep manufacturing these things and Trend without short energy. He Trend with yeah. Yeah. Yeah, exactly", "Start Time (s)": 1433.1, "End Time (s)": 1550.2, "Clip Length (min)": 1.95, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "guys I can pull it off the quad because their art they're hiring Quant internally and those quants recognize that that you know, simple left 50 basis point swap that they can get from the banks are not you know, yeah, it's that we're going to try to do a little bit better. But at the end <mark>of</mark> the day, I think a lot <mark>of</mark> them have been Turned on those Ultra simplistic Bank oriented Factor strategies. And I mean what the banks do <mark>of</mark> course is they create a strategy and they let it run they call it something and then it doesn't work out in the event something, you know pretty well similar and then they let it run and it doesn't work out and it's you know, they like Trend one trying to try and three Transformer. I guess if served they can just keep manufacturing these things and Trend without short energy. He Trend with yeah. Yeah. Yeah, exactly coming back to the waiting's you were saying is really important half or good part <mark>of</mark> your research and your process or process as Mike would say I'm just I do that don't I it's yours do an 18 it's good. So if you don't bring that in-house that's got to be a big issue. Right? Like I made know how to work the model but the waiting's the risk control. Actually. That's a really good. Point and and the current situation is a really good example. So if you look across a lot <mark>of</mark> the trend funds in the early part <mark>of</mark> 2020, you can tell that the vast majority <mark>of</mark> the returns have come because they're all like a trampoline right you get all your guys moving over to the same point on the trampoline your old jumping up and down together. You can go really high right but you're also going to all go down together and so you can you can see all the equity index based exposure did really well for a lot <mark>of</mark> these guys for most <mark>of</mark> the month and now they've got a lot <mark>of</mark> them or last couple days <mark>of</mark> really taking a beating", "Start Time (s)": 1500.8, "End Time (s)": 1619.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "coming back to the waiting's you were saying is really important half or good part <mark>of</mark> your research and your process or process as Mike would say I'm just I do that don't I it's yours do an 18 it's good. So if you don't bring that in-house that's got to be a big issue. Right? Like I made know how to work the model but the waiting's the risk control. Actually. That's a really good. Point and and the current situation is a really good example. So if you look across a lot <mark>of</mark> the trend funds in the early part <mark>of</mark> 2020, you can tell that the vast majority <mark>of</mark> the returns have come because they're all like a trampoline right you get all your guys moving over to the same point on the trampoline your old jumping up and down together. You can go really high right but you're also going to all go down together and so you can you can see all the equity index based exposure did really well for a lot <mark>of</mark> these guys for most <mark>of</mark> the month and now they've got a lot <mark>of</mark> them or last couple days <mark>of</mark> really taking a beating whereas we are strategies are designed to acknowledge the fact that you need to be very have very strong confidence in your signals to give up on the opportunity for diversification. So we're explicitly bouncing off. The opportunity from increasing exposure to certain markets and certain signals against the opportunity to you know, lower the overall systemic portfolio Risk by using diversification. So that that really is the guts <mark>of</mark> how we think about the optimization. I think that that a lot <mark>of</mark> more traditional systematic firm spent a lot <mark>of</mark> time thinking about their indicators and their signals and their execution, but Maybe the portfolio construction is is a bit <mark>of</mark> an", "Start Time (s)": 1556.3, "End Time (s)": 1672.6, "Clip Length (min)": 1.94, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but you're also going to all go down together and so you can you can see all the equity index based exposure did really well for a lot <mark>of</mark> these guys for most <mark>of</mark> the month and now they've got a lot <mark>of</mark> them or last couple days <mark>of</mark> really taking a beating whereas we are strategies are designed to acknowledge the fact that you need to be very have very strong confidence in your signals to give up on the opportunity for diversification. So we're explicitly bouncing off. The opportunity from increasing exposure to certain markets and certain signals against the opportunity to you know, lower the overall systemic portfolio Risk by using diversification. So that that really is the guts <mark>of</mark> how we think about the optimization. I think that that a lot <mark>of</mark> more traditional systematic firm spent a lot <mark>of</mark> time thinking about their indicators and their signals and their execution, but Maybe the portfolio construction is is a bit <mark>of</mark> an orphan that I think is a real strength <mark>of</mark> ours and I've been banging that drum for a while here. I think in order to survive a lot <mark>of</mark> classic managed Futures program said hey, we got to add long bias. We got to add more Equity exposure or else we're going to be flat to down 4% for eight years, right and then they assets leave so it was either change or die. So they've either explicitly or not added some <mark>of</mark> that exposure and it comes back to bite them from time to time. So how have you how did you guys manage that last, you know, because you're a long ball type program, right? Would you agree with that or not? I mean we've got we've got sort <mark>of</mark> forty percent <mark>of</mark> the risk budget is is designed to be positive convexity and then maybe 60% is sort <mark>of</mark>", "Start Time (s)": 1603.8, "End Time (s)": 1723.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that really is the guts <mark>of</mark> how we think about the optimization. I think that that a lot <mark>of</mark> more traditional systematic firm spent a lot <mark>of</mark> time thinking about their indicators and their signals and their execution, but Maybe the portfolio construction is is a bit <mark>of</mark> an orphan that I think is a real strength <mark>of</mark> ours and I've been banging that drum for a while here. I think in order to survive a lot <mark>of</mark> classic managed Futures program said hey, we got to add long bias. We got to add more Equity exposure or else we're going to be flat to down 4% for eight years, right and then they assets leave so it was either change or die. So they've either explicitly or not added some <mark>of</mark> that exposure and it comes back to bite them from time to time. So how have you how did you guys manage that last, you know, because you're a long ball type program, right? Would you agree with that or not? I mean we've got we've got sort <mark>of</mark> forty percent <mark>of</mark> the risk budget is is designed to be positive convexity and then maybe 60% is sort <mark>of</mark> You don't have zero correlation to the equity beta strategically. So I wouldn't say we're necessarily long vowel biased think we're probably all neutral. Okay, so that was part <mark>of</mark> how you differentiate it and we're different over those what it's been a painful eight years for classic Trend followers classic volatility breakout type strategies that were struggling with Vol just getting sucked out <mark>of</mark> not just equities, but across all the asset classes. Yeah. Yeah, I mean fall is sort <mark>of</mark> omnipresent right? I mean it you can't kind <mark>of</mark> Escape it and it's it is a source <mark>of</mark> Premium. But the one <mark>of</mark> the objective is how do you kind <mark>of</mark> diversify away from just you can't you can't totally get completely away from it and also expect to", "Start Time (s)": 1655.7, "End Time (s)": 1774.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know, because you're a long ball type program, right? Would you agree with that or not? I mean we've got we've got sort <mark>of</mark> forty percent <mark>of</mark> the risk budget is is designed to be positive convexity and then maybe 60% is sort <mark>of</mark> You don't have zero correlation to the equity beta strategically. So I wouldn't say we're necessarily long vowel biased think we're probably all neutral. Okay, so that was part <mark>of</mark> how you differentiate it and we're different over those what it's been a painful eight years for classic Trend followers classic volatility breakout type strategies that were struggling with Vol just getting sucked out <mark>of</mark> not just equities, but across all the asset classes. Yeah. Yeah, I mean fall is sort <mark>of</mark> omnipresent right? I mean it you can't kind <mark>of</mark> Escape it and it's it is a source <mark>of</mark> Premium. But the one <mark>of</mark> the objective is how do you kind <mark>of</mark> diversify away from just you can't you can't totally get completely away from it and also expect to generate a premium. But but you can diversify into other risk exposures and structural in efficiencies. He's that so you're not entirely relying on ball to deliver your performance that did really well over the last 10 years. Yeah, if you're depending purely on Trend and you require that ball and extension <mark>of</mark> a trend in order to make money Beyond a couple <mark>of</mark> weeks, then you're going to have a tough time with so the approach when using all these other factors that we use is that you know, yes, we portion <mark>of</mark> the portfolio may be suffering because Trend continues to suffer, but if you have these other very A non orthogonal uncorrelated Alpha streams that didn't suffer the same fate as Trend in the Futures Rena. Then you have a product that", "Start Time (s)": 1707.0, "End Time (s)": 1825.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that did really well over the last 10 years. Yeah, if you're depending purely on Trend and you require that ball and extension <mark>of</mark> a trend in order to make money Beyond a couple <mark>of</mark> weeks, then you're going to have a tough time with so the approach when using all these other factors that we use is that you know, yes, we portion <mark>of</mark> the portfolio may be suffering because Trend continues to suffer, but if you have these other very A non orthogonal uncorrelated Alpha streams that didn't suffer the same fate as Trend in the Futures Rena. Then you have a product that you're not necessarily going to get sold out. And so let's unpack. What are those different Alpha generators as much as you can share that you don't want it the all the IP out there. Well, I mean, I think we were we are presentations and stuff share the fact that we've got some Trend ensembles. Some carry ensembles and we think about Carrie I think in a some <mark>of</mark> our carry indicators are a little more traditional and others I think are very different and the ones that are very different are just as powerful as a more traditional ones, but they're worth Ogle. So they are really complementary in the portfolio in some <mark>of</mark> the other and I don't want to go to down this far down this path, but there are other Arbitrage opportunities are not pure Arbitrage, but that sort <mark>of</mark> regulatory Arbitrage and structural Arbitrage factors that have been extraordinarily steady profitable over many many many years and that we if you sort <mark>of</mark> look at simplistic versions <mark>of</mark> strategies that try to harness those In efficiencies, they they work but they're not attractive enough to really generate much attention, which is what we really love. We sort <mark>of</mark> try to Target", "Start Time (s)": 1789.3, "End Time (s)": 1906.2, "Clip Length (min)": 1.95, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and we think about Carrie I think in a some <mark>of</mark> our carry indicators are a little more traditional and others I think are very different and the ones that are very different are just as powerful as a more traditional ones, but they're worth Ogle. So they are really complementary in the portfolio in some <mark>of</mark> the other and I don't want to go to down this far down this path, but there are other Arbitrage opportunities are not pure Arbitrage, but that sort <mark>of</mark> regulatory Arbitrage and structural Arbitrage factors that have been extraordinarily steady profitable over many many many years and that we if you sort <mark>of</mark> look at simplistic versions <mark>of</mark> strategies that try to harness those In efficiencies, they they work but they're not attractive enough to really generate much attention, which is what we really love. We sort <mark>of</mark> try to Target anomalies or in efficiencies or edges that there have been some papers published on them, but not very many because they're not the original papers weren't very exciting. But if you just think about them in a slightly different way and you apply, you know Ensemble type thinking then what emerges is actually this incredibly powerful signal that you can't capture using traditional thinking but if you use the type <mark>of</mark> thinking that we bring to bear is fabulously profitable how very high Sharpe ratio and orthogonal to the other the other things in the portfolio. So it's I think that type <mark>of</mark> thinking is also Important part <mark>of</mark> our age it's almost like Google AdWords platform. You don't want to just compete on the highest and like you can want to find the really long tail keyword. That's not a lot <mark>of</mark> people are using that delivers", "Start Time (s)": 1845.4, "End Time (s)": 1965.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "which is what we really love. We sort <mark>of</mark> try to Target anomalies or in efficiencies or edges that there have been some papers published on them, but not very many because they're not the original papers weren't very exciting. But if you just think about them in a slightly different way and you apply, you know Ensemble type thinking then what emerges is actually this incredibly powerful signal that you can't capture using traditional thinking but if you use the type <mark>of</mark> thinking that we bring to bear is fabulously profitable how very high Sharpe ratio and orthogonal to the other the other things in the portfolio. So it's I think that type <mark>of</mark> thinking is also Important part <mark>of</mark> our age it's almost like Google AdWords platform. You don't want to just compete on the highest and like you can want to find the really long tail keyword. That's not a lot <mark>of</mark> people are using that delivers to your business. Exactly and you're looking for large sustainable structural. Sometimes their regulatory rate-related willing losers. Those who are driven to make transactions that are not necessarily driven by sort <mark>of</mark> simple or pure wealth maximization. There is some other driver that's driving the behavior that forces them to make mistakes there for the mistakes are consistent and more reliable that are and they're happy to do it. So this is an interesting topic <mark>of</mark> the crescendo brought up where the other side is making a rational decision to give you money. Yeah. So I have that spurred some examples. We have some sort <mark>of</mark> an example. Sure. Let's take a simple example. I'm an advisor and someone gives me an order for an ETF and the orders before 9:30 in the morning and I'm obliged by The", "Start Time (s)": 1903.0, "End Time (s)": 2022.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Sometimes their regulatory rate-related willing losers. Those who are driven to make transactions that are not necessarily driven by sort <mark>of</mark> simple or pure wealth maximization. There is some other driver that's driving the behavior that forces them to make mistakes there for the mistakes are consistent and more reliable that are and they're happy to do it. So this is an interesting topic <mark>of</mark> the crescendo brought up where the other side is making a rational decision to give you money. Yeah. So I have that spurred some examples. We have some sort <mark>of</mark> an example. Sure. Let's take a simple example. I'm an advisor and someone gives me an order for an ETF and the orders before 9:30 in the morning and I'm obliged by The Regulators to make sure that market order is put in the market by 9:30 a.m. And that may not be the best time for that order to get executed and you you so that you say all kinds <mark>of</mark> Harry bars on certain different types <mark>of</mark> each as a simple simple example. so you can take that example <mark>of</mark> that simple riaa, which would be a small ledge and then think about that at an Institutional level when institutions are driving transactions where their main objective is not optimizing the transaction, but it's the speed <mark>of</mark> the transaction or an investment board who has to manage a number <mark>of</mark> domestic investment committee is managing a portfolio and they're making decisions based on that portfolio that aren't necessarily 100% wealth maximizing Or the or the requirement to hedge risk out the portfolio and being your pain and insurance premium by buying puts protecting the portfolio in certain times. This is driven by a committee committee. They're making a conscious decision that helps them. I thought you're going to say it's driven by a comedian that's going to end. Yeah, well kind <mark>of</mark> aspire and then the other side is able to provide the other side <mark>of</mark> what their needs are and so", "Start Time (s)": 1973.6, "End Time (s)": 2092.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "by 9:30 a.m. And that may not be the best time for that order to get executed and you you so that you say all kinds <mark>of</mark> Harry bars on certain different types <mark>of</mark> each as a simple simple example. so you can take that example <mark>of</mark> that simple riaa, which would be a small ledge and then think about that at an Institutional level when institutions are driving transactions where their main objective is not optimizing the transaction, but it's the speed <mark>of</mark> the transaction or an investment board who has to manage a number <mark>of</mark> domestic investment committee is managing a portfolio and they're making decisions based on that portfolio that aren't necessarily 100% wealth maximizing Or the or the requirement to hedge risk out the portfolio and being your pain and insurance premium by buying puts protecting the portfolio in certain times. This is driven by a committee committee. They're making a conscious decision that helps them. I thought you're going to say it's driven by a comedian that's going to end. Yeah, well kind <mark>of</mark> aspire and then the other side is able to provide the other side <mark>of</mark> what their needs are and so it is a ecosystem <mark>of</mark> You know winners and losers in different areas, but at the end <mark>of</mark> the day, it's their there in in a positive way. I'll give you one concrete example imagine that the you know, big due to banking regulations banks are required to square their duration book Square their treasury book and monitor a variety <mark>of</mark> other VAR related measures into the end <mark>of</mark> reporting season every month and every quarter. Now if you don't think that that impacts Bond returns around those dates, then you're probably missing something right. So there's one simple example <mark>of</mark> how the regulations impose behavior that is structural. It's not going away and is systematic and is profitable for those who are", "Start Time (s)": 2026.2, "End Time (s)": 2145.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "so it is a ecosystem <mark>of</mark> You know winners and losers in different areas, but at the end <mark>of</mark> the day, it's their there in in a positive way. I'll give you one concrete example imagine that the you know, big due to banking regulations banks are required to square their duration book Square their treasury book and monitor a variety <mark>of</mark> other VAR related measures into the end <mark>of</mark> reporting season every month and every quarter. Now if you don't think that that impacts Bond returns around those dates, then you're probably missing something right. So there's one simple example <mark>of</mark> how the regulations impose behavior that is structural. It's not going away and is systematic and is profitable for those who are able to identify and harvested systematically just the carry trade is a structural example ultimate <mark>of</mark> sure. I mean, yeah. And Kari is it's been argued depending on the asset class carries can't can be kind <mark>of</mark> risk based because it hurts when it hurts when it hurts to hurt right sort <mark>of</mark> procyclical, especially on the currency side. But if you sort <mark>of</mark> put it together like traditional carry into a into a diversified portfolio you find it's not nearly so so risk-based and it becomes more <mark>of</mark> a sort <mark>of</mark> inefficiency. So yeah, I mean, it's it's hard to try and describe cause <mark>of</mark> Effect to a lot <mark>of</mark> these things is I think really challenging but you can sort <mark>of</mark> point to enough examples <mark>of</mark> where structural <mark>effects</mark> are identifiable that you can say. Okay these structural if I can identify these ones through some kind <mark>of</mark> narrative or some sort <mark>of</mark> cause-effect. Then there must be a wide variety <mark>of</mark> other ones that I can't see, but I can kind <mark>of</mark> harvest in the same way.", "Start Time (s)": 2092.5, "End Time (s)": 2211.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and is profitable for those who are able to identify and harvested systematically just the carry trade is a structural example ultimate <mark>of</mark> sure. I mean, yeah. And Kari is it's been argued depending on the asset class carries can't can be kind <mark>of</mark> risk based because it hurts when it hurts when it hurts to hurt right sort <mark>of</mark> procyclical, especially on the currency side. But if you sort <mark>of</mark> put it together like traditional carry into a into a diversified portfolio you find it's not nearly so so risk-based and it becomes more <mark>of</mark> a sort <mark>of</mark> inefficiency. So yeah, I mean, it's it's hard to try and describe cause <mark>of</mark> Effect to a lot <mark>of</mark> these things is I think really challenging but you can sort <mark>of</mark> point to enough examples <mark>of</mark> where structural <mark>effects</mark> are identifiable that you can say. Okay these structural if I can identify these ones through some kind <mark>of</mark> narrative or some sort <mark>of</mark> cause-effect. Then there must be a wide variety <mark>of</mark> other ones that I can't see, but I can kind <mark>of</mark> harvest in the same way. And that comes back into some Game Theory and who's doing what they need to do. Why do they need to do it? Hmm, do they care if they're giving up the edge? Exactly and so are you guys consciously pressing on that game? Theory? Are you identifying the players identifying their motives or you're just seeing it in the price action? Well, I think probably it's mostly in the price action. But then if there's a thesis about why we might Expect to see behavior in the price action and then you go and sort <mark>of</mark> poke and prod and there's something there and then if you apply some <mark>of</mark> the sort <mark>of</mark> boosting bagging Ensemble type type thinking to it then something meaningful emerges from it, but you know, sometimes it's it emerges from the data. Sometimes it emerges from a thesis,", "Start Time (s)": 2144.6, "End Time (s)": 2264.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "probably it's mostly in the price action. But then if there's a thesis about why we might Expect to see behavior in the price action and then you go and sort <mark>of</mark> poke and prod and there's something there and then if you apply some <mark>of</mark> the sort <mark>of</mark> boosting bagging Ensemble type type thinking to it then something meaningful emerges from it, but you know, sometimes it's it emerges from the data. Sometimes it emerges from a thesis, but we're happy to come at it from either direction. The research team is actively trying to find these pieces. Only Jesus has these these these I these signs. Is there any machine learning or AI involved? I think we talked about that at some points before but where do you guys stand on that? Yeah, what's funny is I mean talk about the evolution <mark>of</mark> thinking right. I mean, I think we had an associate who worked with us about five years ago. And I remember him he was very enthusiastic about machine learning and I remember him saying we're asking you know, when are you going to start thinking about using some machine learning and I said to him we will never be using machine learning as a major source <mark>of</mark> information in our strategies and I think our thinking on that has well our understanding <mark>of</mark> what is meant by Machine learning and air quotes has evolved very substantially and my big caveat I was whenever I ask someone to use AI with the caveat that almost anyone who says they do they're really just Just talking about automation. Sure, not Pure Black Box the machines doing all the everything. Yeah, exactly. And I think certainly are the direction <mark>of</mark> motion for us isn't is in the direction <mark>of</mark> using the tools that fall out <mark>of</mark> the machine learning space to do a better job", "Start Time (s)": 2232.3, "End Time (s)": 2352.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Is there any machine learning or AI involved? I think we talked about that at some points before but where do you guys stand on that? Yeah, what's funny is I mean talk about the evolution <mark>of</mark> thinking right. I mean, I think we had an associate who worked with us about five years ago. And I remember him he was very enthusiastic about machine learning and I remember him saying we're asking you know, when are you going to start thinking about using some machine learning and I said to him we will never be using machine learning as a major source <mark>of</mark> information in our strategies and I think our thinking on that has well our understanding <mark>of</mark> what is meant by Machine learning and air quotes has evolved very substantially and my big caveat I was whenever I ask someone to use AI with the caveat that almost anyone who says they do they're really just Just talking about automation. Sure, not Pure Black Box the machines doing all the everything. Yeah, exactly. And I think certainly are the direction <mark>of</mark> motion for us isn't is in the direction <mark>of</mark> using the tools that fall out <mark>of</mark> the machine learning space to do a better job <mark>of</mark> finding and refining strategies and and portfolios and from a pure like Manpower kind <mark>of</mark> you can just process way. Or data points e yeah, there's there's that side <mark>of</mark> it and it's just a again without going too far into it. It's just a shift in thinking about what's possible with a different tool set. You know, like if you if you want to build a house and all you've got is a rock. Acts, you know, you're going to build a different house than if you've got a bunch <mark>of</mark> modern tools and I think it is that's really the week. We covered this extensively in a podcast. We did it was machine learning Pandora's black box or something like that and", "Start Time (s)": 2283.3, "End Time (s)": 2402.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "with a different tool set. You know, like if you if you want to build a house and all you've got is a rock. Acts, you know, you're going to build a different house than if you've got a bunch <mark>of</mark> modern tools and I think it is that's really the week. We covered this extensively in a podcast. We did it was machine learning Pandora's black box or something like that and we go through the different looting two atoms tool analogy. So there are many different tools in the machine learning tool box. That effect and can improve the portfolio construction process understanding covariances clustering and so on that have nothing to do with picking better Futures. It's using a completely different area. And in that that tool said we have been using for years. Yeah, but everybody thinks <mark>of</mark> machine learning as can you can then can you stick it on the market and it will come back and find this magical equity line and what we show is that that's not the case that it really does continue to come down to the imagination <mark>of</mark> the individual or individuals who are working on the problem understanding that all the machine learning is doing Quinn trying to find Trends or trying to find some Alpha is finding patterns and the vast majority <mark>of</mark> those patterns are overfit and garbage and aren't going to actually work out a sample. So the big human aspect <mark>of</mark> to all <mark>of</mark> this is do you have a filtering or And system that truly works to only let in the patterns identified by the process that are going to work on a sample and that's really where a couple <mark>of</mark> our quants came from that space. I've been profiting in a bay substantial way using these tools as Quantum mental approach <mark>of</mark> using the machine", "Start Time (s)": 2376.2, "End Time (s)": 2495.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but everybody thinks <mark>of</mark> machine learning as can you can then can you stick it on the market and it will come back and find this magical equity line and what we show is that that's not the case that it really does continue to come down to the imagination <mark>of</mark> the individual or individuals who are working on the problem understanding that all the machine learning is doing Quinn trying to find Trends or trying to find some Alpha is finding patterns and the vast majority <mark>of</mark> those patterns are overfit and garbage and aren't going to actually work out a sample. So the big human aspect <mark>of</mark> to all <mark>of</mark> this is do you have a filtering or And system that truly works to only let in the patterns identified by the process that are going to work on a sample and that's really where a couple <mark>of</mark> our quants came from that space. I've been profiting in a bay substantial way using these tools as Quantum mental approach <mark>of</mark> using the machine learning to find better edges, but making sure that the filtering process is tight and that's really where the IP comes in in the machine learning space. And it sounds like you would always no matter what comes out <mark>of</mark> even that research process would come in front <mark>of</mark> a committee or have to be like, okay. Is there a fundamental reason behind this before we sick the computers on it? I think our thinking on that has evolved you got lots <mark>of</mark> stuff that we've got fundamental backing behind and I think we're we're being a little bit more flexible in our thinking how deep how deep do you want to go on the yeah. Well, I'll totally are we getting yeah exactly. Has every economic reasoning is simply a story. Yeah, and the stories get more and more complex to appease the complex thinker which again then comes into the AI scenario where you're going to talk to an investment committee and you're going to say we were running some AI in your Calpers", "Start Time (s)": 2435.2, "End Time (s)": 2554.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "fund. Why did it do what it did? We don't know and we can't tell you whether it does good or bad. So you tell me how many people are going to be? Really able to jump on that bandwagon now eventually when everybody's doing it they probably will but at the beginning there's likely going to be for thoughtful practitioners. There's probably going to be an opportunity there to provide some excess returns that's overlooked by others. And it really then from a business trip type perspective becomes how much like a Michael saying earlier how far into the future you want to go not just on this strategy development if it works it works but is it going to sell actually going to raise assets and a pure machine learning space so the truth is that from the institutional space they're not ready for a full on a ID you know there's no narrative there's nothing but you can use the tools in the other areas <mark>of</mark> portfolio construction and also you can apply machine learning to these factors to identify better ways <mark>of</mark> combining them right rather than just saying I'm going to grab the same universe and do a bunch <mark>of</mark> mean reversion strategies and I'm going to do it the same thing and just focus on carry or whatever you actually put all <mark>of</mark> those into a bag and let the machine combine them in ways that you get a pretty decent outcome so at the end <mark>of</mark> the day you're still based on fundamental understanding and that Persistence <mark>of</mark> those factors but you're combining them in interesting ways the other side <mark>of</mark> things and where we may actually launched a completely separate product is the We're just going to find patterns. I don't I don't when you look under the hood. You don't you don't even want to know what the indicators are but it works really well and it says zero correlation everything else and there is an audience for that. It generally tends to be really Advanced Quant based family offices. Yeah, and so that'll probably be the beginning <mark>of</mark> that", "Start Time (s)": 2555.0, "End Time (s)": 2674.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "other areas <mark>of</mark> portfolio construction and also you can apply machine learning to these factors to identify better ways <mark>of</mark> combining them right rather than just saying I'm going to grab the same universe and do a bunch <mark>of</mark> mean reversion strategies and I'm going to do it the same thing and just focus on carry or whatever you actually put all <mark>of</mark> those into a bag and let the machine combine them in ways that you get a pretty decent outcome so at the end <mark>of</mark> the day you're still based on fundamental understanding and that Persistence <mark>of</mark> those factors but you're combining them in interesting ways the other side <mark>of</mark> things and where we may actually launched a completely separate product is the We're just going to find patterns. I don't I don't when you look under the hood. You don't you don't even want to know what the indicators are but it works really well and it says zero correlation everything else and there is an audience for that. It generally tends to be really Advanced Quant based family offices. Yeah, and so that'll probably be the beginning <mark>of</mark> that side <mark>of</mark> the machine learning Evolution. You would have risk controls and and whatnot on it's not just going to be like, oh we're going on or percent purple Natural Gas. Importantly as well. That's right. So that's the future that's the evolution <mark>of</mark> evolution <mark>of</mark> evolution know and we see in our side <mark>of</mark> the world heavy interest in AI again air quotes AI investment strategies. They don't understand it. They think it's going to make everything better. Hmm. There was an interesting blog post been hunt. You guys know if I'm saying the markets a bonfire and its basic like you can't model a bonfire. Even the most sophisticated computer you couldn't recreate the so everyone thinks they can just get the holy grail and get the key to the clock or whatever but there's no such thing. So if I think as you're saying you can get you're AI mind to say, hey, I'm not trying to figure out the secret quote unquote secret. I'm just trying to pull a little pieces out <mark>of</mark> the puzzle.", "Start Time (s)": 2614.1, "End Time (s)": 2733.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "be the beginning <mark>of</mark> that side <mark>of</mark> the machine learning Evolution. You would have risk controls and and whatnot on it's not just going to be like, oh we're going on or percent purple Natural Gas. Importantly as well. That's right. So that's the future that's the evolution <mark>of</mark> evolution <mark>of</mark> evolution know and we see in our side <mark>of</mark> the world heavy interest in AI again air quotes AI investment strategies. They don't understand it. They think it's going to make everything better. Hmm. There was an interesting blog post been hunt. You guys know if I'm saying the markets a bonfire and its basic like you can't model a bonfire. Even the most sophisticated computer you couldn't recreate the so everyone thinks they can just get the holy grail and get the key to the clock or whatever but there's no such thing. So if I think as you're saying you can get you're AI mind to say, hey, I'm not trying to figure out the secret quote unquote secret. I'm just trying to pull a little pieces out <mark>of</mark> the puzzle. It's just it's a I thought your analogy on a better tool set. I mean, you know, you have a set <mark>of</mark> tools you're going to get you're going to get results. You have a different set <mark>of</mark> tools you have the potential for Better results different results part <mark>of</mark> the tool set is is finding tools to help explain. What what's going on beneath the hood, you know, I mean, it's I subscribe to the effect theory <mark>of</mark> decision making so the limbic system drives Behavior and the prefrontal cortex defends it right. So, you know, we all think about cause effect as if we take in information the prefrontal cortex. Is it like a computer and then we take some logical action from what falls out <mark>of</mark> that logical processing in reality? If you look at how the actual brain operates drives a decision or drives the behavior information comes in the limbic system reacts far more quickly, you", "Start Time (s)": 2673.4, "End Time (s)": 2792.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the limbic system drives Behavior and the prefrontal cortex defends it right. So, you know, we all think about cause effect as if we take in information the prefrontal cortex. Is it like a computer and then we take some logical action from what falls out <mark>of</mark> that logical processing in reality? If you look at how the actual brain operates drives a decision or drives the behavior information comes in the limbic system reacts far more quickly, you act and then the cerebral cortex kicks in the neocortex kicks in and says this is why you did this right explains. The biological cover-ups non-stop. Exactly It Go create a Ariane why we did that. Yeah. And so I think we you know, you're going to create tools things are going to work on other things are not going to work. You're maybe not going to have a precise cause effect connection there, but you can tease out enough <mark>of</mark> probabilistic cause-effect narrative so that we can get comfortable and client can get comfortable but different clients are going to get comfortable with different levels <mark>of</mark> abstraction. Okay, so putting this all this package together things have gone pretty well for the firm for the program's. I think assets are close to all-time highs. Yeah, pretty much and you were nominated for some awards recently. Yeah. No, we were lucky enough to be nominated for four to the 15 HFM Point Awards recently 140 act fund and the other ones for the In Futures program. So we're pumping will see fingers crossed. It'll go announce it next month. We're our CMS nominated for a few things as well. So we'll see you there. Hopefully. Yeah, that's and we'll celebrate time for our favorites would do a little quick fire.", "Start Time (s)": 2761.1, "End Time (s)": 2880.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Okay, so putting this all this package together things have gone pretty well for the firm for the program's. I think assets are close to all-time highs. Yeah, pretty much and you were nominated for some awards recently. Yeah. No, we were lucky enough to be nominated for four to the 15 HFM Point Awards recently 140 act fund and the other ones for the In Futures program. So we're pumping will see fingers crossed. It'll go announce it next month. We're our CMS nominated for a few things as well. So we'll see you there. Hopefully. Yeah, that's and we'll celebrate time for our favorites would do a little quick fire. And I also wanted to mention we're all low carb proponents here on this trip not in this not in Miami, but in our real life, I'm carbo carbo-loading carb cycling what? How'd you guys get to that place and is a kind <mark>of</mark> I like it because it kind <mark>of</mark> shows a discipline that also is needed in the marketplace. But there's yeah, I mean two seconds on your low carb aspirations. I started it years like it's been a long time. It's been more than yeah. It's just my body agreed with it. When I started reading up on it then halfway through I found keto the kitty genic diet and you know that's cutting out even more on this. It's a very Sighs you have to thread that needle really precisely for it to work for you. But I just found you cognitive abilities go way up your you don't you know that Lull in the middle <mark>of</mark> the day and you know body composition gets better everything just basically improve her for me and we were able to spread the love the workplace and try to get our partners to join us with a lot <mark>of</mark> resistance and Rodrigo are evangelists for things that they are passionate about and both have a real sort <mark>of</mark> coach. Seeing Dimension to them", "Start Time (s)": 2839.7, "End Time (s)": 2957.2, "Clip Length (min)": 1.96, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "not in Miami, but in our real life, I'm carbo carbo-loading carb cycling what? How'd you guys get to that place and is a kind <mark>of</mark> I like it because it kind <mark>of</mark> shows a discipline that also is needed in the marketplace. But there's yeah, I mean two seconds on your low carb aspirations. I started it years like it's been a long time. It's been more than yeah. It's just my body agreed with it. When I started reading up on it then halfway through I found keto the kitty genic diet and you know that's cutting out even more on this. It's a very Sighs you have to thread that needle really precisely for it to work for you. But I just found you cognitive abilities go way up your you don't you know that Lull in the middle <mark>of</mark> the day and you know body composition gets better everything just basically improve her for me and we were able to spread the love the workplace and try to get our partners to join us with a lot <mark>of</mark> resistance and Rodrigo are evangelists for things that they are passionate about and both have a real sort <mark>of</mark> coach. Seeing Dimension to them and so I think there when they caught on to something it's infectious and took me a while to embrace it and I fought it for a while and eventually thought I'd try it and it just magical. So we were mixing in a little fasting now to you've had some great results with the intermittent fasting. Yep, and a seven-day fasts as a pretty fun. It's too long. Yeah. Well, I think that so many years ago. Someone said something to me. That sort <mark>of</mark> stock which is here's a diet. You should try and personal say well, I can't do that or it's not going to work. It's not this or that it's like no hold on a second you do it and then tell me if it works do not listen to me. Don't listen to me get off your ass", "Start Time (s)": 2888.0, "End Time (s)": 3006.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "so I think there when they caught on to something it's infectious and took me a while to embrace it and I fought it for a while and eventually thought I'd try it and it just magical. So we were mixing in a little fasting now to you've had some great results with the intermittent fasting. Yep, and a seven-day fasts as a pretty fun. It's too long. Yeah. Well, I think that so many years ago. Someone said something to me. That sort <mark>of</mark> stock which is here's a diet. You should try and personal say well, I can't do that or it's not going to work. It's not this or that it's like no hold on a second you do it and then tell me if it works do not listen to me. Don't listen to me get off your ass and do it and then you tell me what impact it had on you and so I think for us it's well, the carnivore died we've cycled in and out <mark>of</mark> that kiito's intermittent fasting. It really is a function <mark>of</mark> I'm going to do some eating and that can have some positive effects. It can have some side sideways effects. Why don't I just mindfully observe how I feel in different ways that I might eat and then think about how I would like to feel and then understand that what I can zoom from a food perspective will have implications on that so I should think about that and do some stuff and so we just Try a bunch <mark>of</mark> stuff and say wow, the the carnivore diet has some really interesting manifestations in your body that are amazing. It's really difficult socially difficult. I was talking to a couple people at the table last night about how fast and can be difficult socially. How do you match build it into your daily life? But the point is just try a protocol and see what it does for you. It's the old n equals one. You're one biological system. Sometimes these things work for people sometimes they", "Start Time (s)": 2957.7, "End Time (s)": 3077.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to do some eating and that can have some positive effects. It can have some side sideways effects. Why don't I just mindfully observe how I feel in different ways that I might eat and then think about how I would like to feel and then understand that what I can zoom from a food perspective will have implications on that so I should think about that and do some stuff and so we just Try a bunch <mark>of</mark> stuff and say wow, the the carnivore diet has some really interesting manifestations in your body that are amazing. It's really difficult socially difficult. I was talking to a couple people at the table last night about how fast and can be difficult socially. How do you match build it into your daily life? But the point is just try a protocol and see what it does for you. It's the old n equals one. You're one biological system. Sometimes these things work for people sometimes they don't but don't tell me just go and try it. I like and ties back to York want kind <mark>of</mark> roots, right? I'm like Hey, we're going to test we're going to try we're going to see that the results are then we'll make a decision and we have the lovely people say you're crazy. That sounds crazy. I'm like, it's crazy. I probably was not very popular. But when we started it was no leisure on it was no food was nothing there was no food. Now you can actually do it and get cookies and stuff at the time everybody thought we were Nuts I still want McDonald's to just nuts L like a bag <mark>of</mark> peanuts or something because that's your have kids you're going to end up at McDonald's and there's no there's nothing you got to prepare for sure. Yeah in that I put I wrote a personal blog once on this because I lost like 30 pounds going low carb and I think one or died like 10 points how to do this. And number two is like you're going to get made fun <mark>of</mark> yeah, because you're at a Cubs game and you're like eating a hot dog without the bun and people like, what are you doing? Yeah, but once you get Past that it's probably one <mark>of</mark> my superpowers to be able to be made fun <mark>of</mark> and not really thinking much about it. I'm not going to sleep.", "Start Time (s)": 3022.9, "End Time (s)": 3140.9, "Clip Length (min)": 1.97, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "sometimes they don't but don't tell me just go and try it. I like and ties back to York want kind <mark>of</mark> roots, right? I'm like Hey, we're going to test we're going to try we're going to see that the results are then we'll make a decision and we have the lovely people say you're crazy. That sounds crazy. I'm like, it's crazy. I probably was not very popular. But when we started it was no leisure on it was no food was nothing there was no food. Now you can actually do it and get cookies and stuff at the time everybody thought we were Nuts I still want McDonald's to just nuts L like a bag <mark>of</mark> peanuts or something because that's your have kids you're going to end up at McDonald's and there's no there's nothing you got to prepare for sure. Yeah in that I put I wrote a personal blog once on this because I lost like 30 pounds going low carb and I think one or died like 10 points how to do this. And number two is like you're going to get made fun <mark>of</mark> yeah, because you're at a Cubs game and you're like eating a hot dog without the bun and people like, what are you doing? Yeah, but once you get Past that it's probably one <mark>of</mark> my superpowers to be able to be made fun <mark>of</mark> and not really thinking much about it. I'm not going to sleep. I think that's it. You guys want to leave any last thoughts or will put in the show notes links to the Pod and your white papers. And what are you can follow us on Twitter where Mike and Adam are pretty active on Twitter. So maybe give it your Twitter handles out. I'm at Gestalt you GST alt you I'm looking minor and I'm Rod Gordillo P Gordillo hot rod Gordy GOP. Yeah, you guys are active on Twitter and all the it's maybe one day they'll do a case study <mark>of</mark> like this is how you grow assets and become a professional right? I think it's been a great forum for discussion, you know, and I know that probably Adam takes advantage <mark>of</mark> that more than any <mark>of</mark> us, but it is just a great way to have a conversation about you know, it's refreshing. They're way too many managers, who are you mentioned <mark>of</mark> like trying to hide", "Start Time (s)": 3076.9, "End Time (s)": 3196.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "yeah, because you're at a Cubs game and you're like eating a hot dog without the bun and people like, what are you doing? Yeah, but once you get Past that it's probably one <mark>of</mark> my superpowers to be able to be made fun <mark>of</mark> and not really thinking much about it. I'm not going to sleep. I think that's it. You guys want to leave any last thoughts or will put in the show notes links to the Pod and your white papers. And what are you can follow us on Twitter where Mike and Adam are pretty active on Twitter. So maybe give it your Twitter handles out. I'm at Gestalt you GST alt you I'm looking minor and I'm Rod Gordillo P Gordillo hot rod Gordy GOP. Yeah, you guys are active on Twitter and all the it's maybe one day they'll do a case study <mark>of</mark> like this is how you grow assets and become a professional right? I think it's been a great forum for discussion, you know, and I know that probably Adam takes advantage <mark>of</mark> that more than any <mark>of</mark> us, but it is just a great way to have a conversation about you know, it's refreshing. They're way too many managers, who are you mentioned <mark>of</mark> like trying to hide their IP so much that they don't want to give up anything or even engage in a conversation and it's kind <mark>of</mark> a bit <mark>of</mark> a galaxy brain to you know, like I came up with a just a kernel which we don't need to get into a car and idea and I I drew it out and I didn't want to bother my Quantum with it and I said, can you anyone give me a function that maps to this shape and I had 15 people write and say Yeah, this function maps that Colonel this function use this step function or this polynomial or whatever and it's just stuff that you this kind <mark>of</mark> wacky. There's always an expert that if you just put it out there that they're happy to kind <mark>of</mark> dig in and through also have to give in order to get absolutely a lot <mark>of</mark> people just get on there. They're like, how do I do this? Yeah. We're getting been getting a lot <mark>of</mark> traction. We did a miniseries", "Start Time (s)": 3127.5, "End Time (s)": 3246.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "grow assets and become a professional right? I think it's been a great forum for discussion, you know, and I know that probably Adam takes advantage <mark>of</mark> that more than any <mark>of</mark> us, but it is just a great way to have a conversation about you know, it's refreshing. They're way too many managers, who are you mentioned <mark>of</mark> like trying to hide their IP so much that they don't want to give up anything or even engage in a conversation and it's kind <mark>of</mark> a bit <mark>of</mark> a galaxy brain to you know, like I came up with a just a kernel which we don't need to get into a car and idea and I I drew it out and I didn't want to bother my Quantum with it and I said, can you anyone give me a function that maps to this shape and I had 15 people write and say Yeah, this function maps that Colonel this function use this step function or this polynomial or whatever and it's just stuff that you this kind <mark>of</mark> wacky. There's always an expert that if you just put it out there that they're happy to kind <mark>of</mark> dig in and through also have to give in order to get absolutely a lot <mark>of</mark> people just get on there. They're like, how do I do this? Yeah. We're getting been getting a lot <mark>of</mark> traction. We did a miniseries podcast 12 episodes 50 minutes <mark>of</mark> Peace on a wide variety <mark>of</mark> important topics on portfolio construction one. That's a practitioners love that. And alligators that are getting to know us actually like listening to those because you can double click into and get the content behind it. I was I would say that that's called the resolves 12 days <mark>of</mark> investment wisdom. You can have it in any podcast listener. It's pretty I think it's a pretty neat collection <mark>of</mark> thoughts. I mean listen to it 2x speed you can get through it a lot. So it's like Game <mark>of</mark> Thrones. Once you do episode 1 you can't stop it. I sound way better at 2x I do to it. I know it just went you know, when content is thick in your that's how I know the Is really good one like two two and a half. This is not I'm not I can't follow supposedly Netflix is experimenting on watching it being able to speed up the watch. I watch all my utility told us not to I", "Start Time (s)": 3178.4, "End Time (s)": 3298.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "wisdom. You can have it in any podcast listener. It's pretty I think it's a pretty neat collection <mark>of</mark> thoughts. I mean listen to it 2x speed you can get through it a lot. So it's like Game <mark>of</mark> Thrones. Once you do episode 1 you can't stop it. I sound way better at 2x I do to it. I know it just went you know, when content is thick in your that's how I know the Is really good one like two two and a half. This is not I'm not I can't follow supposedly Netflix is experimenting on watching it being able to speed up the watch. I watch all my utility told us not to I was in an hour. All right. Thanks guys. That's it. Thanks Jeff. Thank you. You've been listening to the derivative links from this episode will be in the episode description <mark>of</mark> this channel follow us on Twitter at rcml and visit our website to read our blog or subscribe to our newsletter at our CM ultimate calm. If you liked our show introduce a friend and show them how to subscribe and be sure to leave comments. We'd love to hear from you.", "Start Time (s)": 3265.6, "End Time (s)": 3338.8, "Clip Length (min)": 1.22, "show_uri": "spotify:show:4TPlJsnx3OSpiCooVAcx8Z", "show_name": "The Derivative", "show_description": "Welcome to The Derivative by RCM Alternatives, where we dive into what makes alternative investments go, analyze the strategies of unique hedge fund managers, and chat with interesting guests from across the investment world. Hosted by RCM Managing Partner, Jeff Malec, join us to take a ride through the world of alternative investments. ", "publisher": "RCM Alternatives", "episode_uri": "spotify:episode:1RgnPIj7xYVWrVAgPrMk2e", "episode_name": "Asset Allocation, AI, and the Alpha Process with Resolve Asset Management", "episode_description": "We sit down with the three Canadian founders of Resolve Asset Management to talk zebras walking amongst horses, mid-frequency trading (move over HFT), how the Chicago Bears don\u2019t add Alpha, extracting structural market flaws, low carb diets, regulatory and structural arbitrage, \u00a0Peru and the Shining Path terrorist group, orthogonal carry, fasting, \u00a0winning the content game, and economic reasoning to appease the complex thinker. Resolve Asset Management is a systematic asset manager out of Toronto focusing on unique and advanced ways of implementing global asset allocation. They operate managed account, private funds, and a mutual fund (RDMIX); using varying automated investment and allocation strategies; including flavors and ensembles of trend following, carry, seasonality, skewnewss, behavioral arbitrage (think trading around a big fund needing to rebalance at end of quarter), and AI/machine learning informed \u201calpha buckets\u201d. Episode Links:\u00a0   Rodrigo Gordillo Twitter & LinkedIn  Adam Butler Twitter & LinkedIn  Mike Philbrick Twitter & LinkedIn  Gestalt University Podcast   Resolve Website   Rational/Resolve Adaptive Asset Allocation Fund\u00a0  And last but not least, don't forget to subscribe to The Derivative, and follow us on Facebook, Twitter, or LinkedIn, and sign-up for our blog digest. Disclaimer: This podcast is provided for informational purposes only and should not be relied upon as legal, business, or tax advice. All opinions expressed by podcast participants are solely their own opinions and do not necessarily reflect the opinions of RCM Alternatives, their affiliates, or companies featured. Due to industry regulations, participants on this podcast are instructed not to make specific trade recommendations, nor reference past or potential profits. And listeners are reminded that managed futures, commodity trading, and other alternative investments are complex and carry a risk of substantial losses. As such, they are not suitable for all investors. For more information, visit www.rcmalternatives.com/disclaimer ", "score": 5.370001, "explanation": "{\n  \"value\": 5.370001,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 2.2159047,\n      \"description\": \"weight(word_list:effects in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.2159047,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9422364,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.36188862,\n      \"description\": \"weight(word_list:of in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.36188862,\n          \"description\": \"score(LMDirichletSimilarity, freq=251.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0882204,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 251.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.7922077,\n      \"description\": \"weight(word_list:global in 39) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.7922077,\n          \"description\": \"score(LMDirichletSimilarity, freq=5.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.5185394,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 5.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Hey, this is Marc a Altman if you enjoying listening to us, imagine how entertaining will be when you are watching us. Now. You can watch the 4:30 movie with Steven watching Darren Doctrine Ashley Miller and me Mark a Altman every day on electric. Now. How do you get electric now? You download distro TV stir TV Zumo TV and soon the electric now app and you just have to pick one. You don't have to have all your not them all <mark>of</mark> them, but it helps and you can watch us on the Electric now channel don't miss us as we bring you the 4:30 movie in your house in person. Hey, this is Marc a Altman from Inglorious trucks birds in the 4:30 movie. And if you're a James Bond fan, you want to pick up my new book Nobody Does it Better the complete uncensored oral history <mark>of</mark> James Bond and spy Mania. It's a hefty Tom and it's available. Now wherever you purchase books audiobooks and digital check it out and I will renew your license to Kill personally. Hey,", "Start Time (s)": 0.2, "End Time (s)": 86.2, "Clip Length (min)": 1.43, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "birds in the 4:30 movie. And if you're a James Bond fan, you want to pick up my new book Nobody Does it Better the complete uncensored oral history <mark>of</mark> James Bond and spy Mania. It's a hefty Tom and it's available. Now wherever you purchase books audiobooks and digital check it out and I will renew your license to Kill personally. Hey, this is Mark a Altman and this is Darren doctor Min and we are the Inglorious treks Birds coming to you straight from the John age Gail Memorial podcasting Studio here on ecos. Those <mark>of</mark> you watching on the electric stream channel will know what we're talking about. If you have until then just close your eyes and imagine imagine exactly the chancellery and all its Glory. Yeah, you know, it's funny because you know, for those <mark>of</mark> you don't know last last week actually for the new year electric has built is wonderful beautiful new podcasting Studio because we used to broadcast from the the mixing stage, but they have a lot <mark>of</mark> shows going and we have a lot <mark>of</mark> shows going with the podcast and it was becoming sort <mark>of</mark> problematic. So they built this beautiful new podcasting studio for us and the other podcast and the electric surge line up. And the first thing we came in here. Darren says, oh my God, where's John Gill? There's this little window and a curtain and heat and you know, we'll have to put pictures on social media because damned if it doesn't look just like I mean, I'm literally waiting for, you know, did the time to shoot exactly. Do a good", "Start Time (s)": 41.0, "End Time (s)": 160.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "If you have until then just close your eyes and imagine imagine exactly the chancellery and all its Glory. Yeah, you know, it's funny because you know, for those <mark>of</mark> you don't know last last week actually for the new year electric has built is wonderful beautiful new podcasting Studio because we used to broadcast from the the mixing stage, but they have a lot <mark>of</mark> shows going and we have a lot <mark>of</mark> shows going with the podcast and it was becoming sort <mark>of</mark> problematic. So they built this beautiful new podcasting studio for us and the other podcast and the electric surge line up. And the first thing we came in here. Darren says, oh my God, where's John Gill? There's this little window and a curtain and heat and you know, we'll have to put pictures on social media because damned if it doesn't look just like I mean, I'm literally waiting for, you know, did the time to shoot exactly. Do a good podcast I ordered the recall <mark>of</mark> to Starfleet malecon is a self-serving Adventurer, but it was the most efficient podcast ever made. Oh my God, and it's funny because behind the glass. I have no idea what we're talking about. Not only you know, like I mean, you know most active State Earth ever knew and this is the most effective podcast. Yes. That's right. So we're look we're thrilled because <mark>of</mark> course we have two special guests with us returning is Ashley Miller Ashley, you know as a writer Thor X-Men first Class, he was a writer producer on Fringe and Black Sails and Sarah Connor Chronicles. And <mark>of</mark> course has a fantastic new show that he will be talking about very soon, but can't right now Ashley Miller, welcome back. Thank you for having me back and it's been a while since this last guest graced us with his Presence but he is here he is back and he is ready to talk truck his name <mark>of</mark> course", "Start Time (s)": 105.7, "End Time (s)": 225.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>of</mark> to Starfleet malecon is a self-serving Adventurer, but it was the most efficient podcast ever made. Oh my God, and it's funny because behind the glass. I have no idea what we're talking about. Not only you know, like I mean, you know most active State Earth ever knew and this is the most effective podcast. Yes. That's right. So we're look we're thrilled because <mark>of</mark> course we have two special guests with us returning is Ashley Miller Ashley, you know as a writer Thor X-Men first Class, he was a writer producer on Fringe and Black Sails and Sarah Connor Chronicles. And <mark>of</mark> course has a fantastic new show that he will be talking about very soon, but can't right now Ashley Miller, welcome back. Thank you for having me back and it's been a while since this last guest graced us with his Presence but he is here he is back and he is ready to talk truck his name <mark>of</mark> course is the legendary day for Aussie. Thanks guys. Thanks for having me back day was the director <mark>of</mark> Special Projects over at the Star Trek offices. It's going to say back in the <mark>global</mark> build the Glory Days <mark>of</mark> the Heyday. Let's put it that way and you know worked very closely with with Rick Berman and so we're going to talk about today. Say that was a very interesting thing that happened to 2006 for those <mark>of</mark> us. You know, who'd been watching Star Trek, you know for for for for many who say for many decades. It wasn't really many decades. It was you know, host couple years. Yeah. We you watch Star Trek often. It was these tattered 16-millimeter prints that were being broadcast. Sometimes better than that. It was finally we remastered for DVD. They look great, but The high-def revolution had happened TVs were now being formatted for widescreen", "Start Time (s)": 165.7, "End Time (s)": 285.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the <mark>global</mark> build the Glory Days <mark>of</mark> the Heyday. Let's put it that way and you know worked very closely with with Rick Berman and so we're going to talk about today. Say that was a very interesting thing that happened to 2006 for those <mark>of</mark> us. You know, who'd been watching Star Trek, you know for for for for many who say for many decades. It wasn't really many decades. It was you know, host couple years. Yeah. We you watch Star Trek often. It was these tattered 16-millimeter prints that were being broadcast. Sometimes better than that. It was finally we remastered for DVD. They look great, but The high-def revolution had happened TVs were now being formatted for widescreen high-def was all the rage and you know CBS looked at the Star Trek and realized that I was time to to sort <mark>of</mark> upgrade change the the visual effects. I would love to know because Dave how you got involved with this and and sort <mark>of</mark> the impetus for sort <mark>of</mark> going back to the original episodes and creating all new. X sure there was an executive at CBS had worked in the sanitation department named David LaFontaine and they were about to or they were trying to re-release the original series into syndication again, and they were having trouble getting advertisers to bite because they're like why are we going to pay for this, you know 40 year-old show and it's we're done you got to give us something else and so he called me and asked to meet for lunch. And he explained this and said so we have a couple <mark>of</mark> ideas and frankly. I don't remember what all the ideas were but they were all kind <mark>of</mark> goofy. But but one <mark>of</mark> them really want to know what can we put it out black and white I'll try I'll have to try to remember but", "Start Time (s)": 235.2, "End Time (s)": 355.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you know CBS looked at the Star Trek and realized that I was time to to sort <mark>of</mark> upgrade change the the visual effects. I would love to know because Dave how you got involved with this and and sort <mark>of</mark> the impetus for sort <mark>of</mark> going back to the original episodes and creating all new. X sure there was an executive at CBS had worked in the sanitation department named David LaFontaine and they were about to or they were trying to re-release the original series into syndication again, and they were having trouble getting advertisers to bite because they're like why are we going to pay for this, you know 40 year-old show and it's we're done you got to give us something else and so he called me and asked to meet for lunch. And he explained this and said so we have a couple <mark>of</mark> ideas and frankly. I don't remember what all the ideas were but they were all kind <mark>of</mark> goofy. But but one <mark>of</mark> them really want to know what can we put it out black and white I'll try I'll have to try to remember but it with that I don't ride they kind <mark>of</mark> fell to the Wayside but but over this conversation he had said one <mark>of</mark> the things we want to do is change the visual <mark>effects</mark> upgrade all the visual <mark>effects</mark> and I immediately I was I said your app, you're crazy. I said you do you not And what George Lucas just went through and he you know did this I said you just had a show that ended with Enterprise kind <mark>of</mark> ending the franchise run <mark>of</mark> the series right now. People are you know, they're throwing around this word, you know for franchise fatigue or whatever and I said now you want to with the remaining fans you have you want to get their hackles up I doing this said it's crazy and any and so he said we'll just think about it because we have to do something we're going to release the show one way or the other we have Have to do something and he one <mark>of</mark> the other things was redoing the theme not not changing it but", "Start Time (s)": 288.4, "End Time (s)": 406.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "said so we have a couple <mark>of</mark> ideas and frankly. I don't remember what all the ideas were but they were all kind <mark>of</mark> goofy. But but one <mark>of</mark> them really want to know what can we put it out black and white I'll try I'll have to try to remember but it with that I don't ride they kind <mark>of</mark> fell to the Wayside but but over this conversation he had said one <mark>of</mark> the things we want to do is change the visual <mark>effects</mark> upgrade all the visual <mark>effects</mark> and I immediately I was I said your app, you're crazy. I said you do you not And what George Lucas just went through and he you know did this I said you just had a show that ended with Enterprise kind <mark>of</mark> ending the franchise run <mark>of</mark> the series right now. People are you know, they're throwing around this word, you know for franchise fatigue or whatever and I said now you want to with the remaining fans you have you want to get their hackles up I doing this said it's crazy and any and so he said we'll just think about it because we have to do something we're going to release the show one way or the other we have Have to do something and he one <mark>of</mark> the other things was redoing the theme not not changing it but re-recorded re-recording it with the new singer and and so, you know, I went away and thought about it for about a week and we had lunch again and I said listen, I got to tell you I just I don't think this is a good idea because what you're going to get is some visual <mark>effects</mark> person who is looking at this as oh my God, I'm going to make the Enterprise do barrel rolls. And I'm going to you know, I mean they're going to they're going to just start cramming stuff in and treat like Star Wars and exactly and I said in the chat, I think you're just you. There's going to be no way to control it. You know, I mean, if you could find someone passionate enough about the show to to do it and would have its best interest at heart and he said how would you like to do it? And I said, okay, you know all those concerns I was talking about forget it. Well, I you know, I thought because his point was we're doing it. We're going to do something Carlos we regard Yes, so how would you like to", "Start Time (s)": 341.9, "End Time (s)": 461.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "redoing the theme not not changing it but re-recorded re-recording it with the new singer and and so, you know, I went away and thought about it for about a week and we had lunch again and I said listen, I got to tell you I just I don't think this is a good idea because what you're going to get is some visual <mark>effects</mark> person who is looking at this as oh my God, I'm going to make the Enterprise do barrel rolls. And I'm going to you know, I mean they're going to they're going to just start cramming stuff in and treat like Star Wars and exactly and I said in the chat, I think you're just you. There's going to be no way to control it. You know, I mean, if you could find someone passionate enough about the show to to do it and would have its best interest at heart and he said how would you like to do it? And I said, okay, you know all those concerns I was talking about forget it. Well, I you know, I thought because his point was we're doing it. We're going to do something Carlos we regard Yes, so how would you like to be involved and then you can help kind <mark>of</mark> steer this and I was like, okay that's you know, so I at the time Star Trek it just ended for me in 2005 and I was actually working with Mike and Denise okuda cataloging things for the CBS auction which was a fun horrific job. I mean it was so morbid and you know weird anyway, I and that was when they were selling off with Enterprise you gone off the air and they were selling off everything all everything that Because up until then everything's Next Generation had should have been stored on the lot in case they exact needed it and the movies everything and there is even stuff from the original is not a lot from the original series but a few things from there as well. But I mean when I say everything, I mean, you know Brent Spiner, 's t-shirts that he wore in the makeup chair so that he didn't get stuff. I mean, it's like crazy they kept everything that you want to buy when you want to have a Brent break. Yeah, so we had to go through it all and identify it and you know do this whole thing so, So I went to my candies because I realized look I I am a huge", "Start Time (s)": 403.4, "End Time (s)": 523.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and you know weird anyway, I and that was when they were selling off with Enterprise you gone off the air and they were selling off everything all everything that Because up until then everything's Next Generation had should have been stored on the lot in case they exact needed it and the movies everything and there is even stuff from the original is not a lot from the original series but a few things from there as well. But I mean when I say everything, I mean, you know Brent Spiner, 's t-shirts that he wore in the makeup chair so that he didn't get stuff. I mean, it's like crazy they kept everything that you want to buy when you want to have a Brent break. Yeah, so we had to go through it all and identify it and you know do this whole thing so, So I went to my candies because I realized look I I am a huge Star Trek fan. The original series is my forte when it comes to all the shows, but I am not in the in the realm that you guys are in in that you study and know the background like the the you know, what was Matt Jeffries, you know thinking when he did I mean you guys know that level <mark>of</mark> intimacy with the show. I didn't I love the show right? So I know that when Captain Kirk laid out a plan. And to escape then they would cut to the Enterprise just moving left to right on the street that the romulans had broken code to but you didn't know exactly you know, why, you know Jeffries I felt that I was not a production per shred in that sense <mark>of</mark> it. So I needed somebody on board who knew that first <mark>of</mark> all and I'm working with Mike and Denise. So I started talking to them about it. And <mark>of</mark> course they have the same reaction. I did this is crazy you Can't do it. You can't do it. I said, well what if we did it and they were like, okay. Well, maybe then and after I had that conversation with Mike literally minutes later, I walked away and I called. An old friend <mark>of</mark> mine named Aaron. Dr. Ehrman. Yes, and I said I know him we're doing this. Can you do the", "Start Time (s)": 482.0, "End Time (s)": 601.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "know the background like the the you know, what was Matt Jeffries, you know thinking when he did I mean you guys know that level <mark>of</mark> intimacy with the show. I didn't I love the show right? So I know that when Captain Kirk laid out a plan. And to escape then they would cut to the Enterprise just moving left to right on the street that the romulans had broken code to but you didn't know exactly you know, why, you know Jeffries I felt that I was not a production per shred in that sense <mark>of</mark> it. So I needed somebody on board who knew that first <mark>of</mark> all and I'm working with Mike and Denise. So I started talking to them about it. And <mark>of</mark> course they have the same reaction. I did this is crazy you Can't do it. You can't do it. I said, well what if we did it and they were like, okay. Well, maybe then and after I had that conversation with Mike literally minutes later, I walked away and I called. An old friend <mark>of</mark> mine named Aaron. Dr. Ehrman. Yes, and I said I know him we're doing this. Can you do the visual <mark>effects</mark> for it? And the and <mark>of</mark> course it would have been a perfect fit but because a couple years before this like in 2004, I had actually gone through several layers <mark>of</mark> Paramount brass pitching this very idea. <mark>Of</mark> replacing the visual <mark>effects</mark> and doing everything in high-def, but basically duplicating the visual <mark>effects</mark> to look exactly like they did in the show. Just clean right? That was my pitch. And like I said, I went through several meetings <mark>of</mark> a couple different layers <mark>of</mark> <mark>of</mark> establishment and then heard nothing and that I thought that was that and you know, but obviously from the CBS. I'd this need a", "Start Time (s)": 534.5, "End Time (s)": 653.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I know him we're doing this. Can you do the visual <mark>effects</mark> for it? And the and <mark>of</mark> course it would have been a perfect fit but because a couple years before this like in 2004, I had actually gone through several layers <mark>of</mark> Paramount brass pitching this very idea. <mark>Of</mark> replacing the visual <mark>effects</mark> and doing everything in high-def, but basically duplicating the visual <mark>effects</mark> to look exactly like they did in the show. Just clean right? That was my pitch. And like I said, I went through several meetings <mark>of</mark> a couple different layers <mark>of</mark> <mark>of</mark> establishment and then heard nothing and that I thought that was that and you know, but obviously from the CBS. I'd this need a rose, right? And it was also a weird time in that the the whole vision <mark>of</mark> the CBS and Paramount and and no one was talking to one another. Yeah, and no one knew who could do what and it was a really kind <mark>of</mark> wacky time. But but I called Darren to see it and the I mean really the only problem was he didn't have the infrastructure available to do it because this was a we were going to be cranking on this and so we ended up getting in touch with Gary hutsul who was visual <mark>effects</mark> on On Deep Space Nine, but also then went on to battle start so and he had you know, Doug Drexler was working with them and they were really excited. And so what the proposed the initial proposal was all space exterior shots all planets and any matte paintings that we wanted to do. And so Gary gave us a bit and there was no money to do this. <mark>Of</mark> course as these things always are he gave us a bid and sent us a test and we were like we're This is great. But what his his kind <mark>of</mark> cautionary Tale To Us was I'm just doing", "Start Time (s)": 599.1, "End Time (s)": 718.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "also a weird time in that the the whole vision <mark>of</mark> the CBS and Paramount and and no one was talking to one another. Yeah, and no one knew who could do what and it was a really kind <mark>of</mark> wacky time. But but I called Darren to see it and the I mean really the only problem was he didn't have the infrastructure available to do it because this was a we were going to be cranking on this and so we ended up getting in touch with Gary hutsul who was visual <mark>effects</mark> on On Deep Space Nine, but also then went on to battle start so and he had you know, Doug Drexler was working with them and they were really excited. And so what the proposed the initial proposal was all space exterior shots all planets and any matte paintings that we wanted to do. And so Gary gave us a bit and there was no money to do this. <mark>Of</mark> course as these things always are he gave us a bid and sent us a test and we were like we're This is great. But what his his kind <mark>of</mark> cautionary Tale To Us was I'm just doing the shots that are called for you know what I mean? So there's not enough money to do what Mike and I had kind <mark>of</mark> pitched and so there was a which was we don't want it, you know, there are 17 shots <mark>of</mark> the Enterprise available or something aside from some episode specific things there weren't very many shots <mark>of</mark> it. And so that's what everyone was was thinking. This was everywhere going to running ways. Do episode specific shy exactly, right? That's what my it Mike and I wanted to we don't want 17 shots in the Android. We want 300 shots <mark>of</mark> the Enterprise ride differ all different angles and things we've never seen and you know, and so but Gary was like for this money, this is what you're going to get and we were like, okay wait that's you know, that's fair. So he sent us it was great. And then we were just about to start and Gary contacted my can dine. He was Furious and said, I understand I'm being taken off <mark>of</mark> this now and And Mike and I were completely confused. So we went to", "Start Time (s)": 655.2, "End Time (s)": 775.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "we're This is great. But what his his kind <mark>of</mark> cautionary Tale To Us was I'm just doing the shots that are called for you know what I mean? So there's not enough money to do what Mike and I had kind <mark>of</mark> pitched and so there was a which was we don't want it, you know, there are 17 shots <mark>of</mark> the Enterprise available or something aside from some episode specific things there weren't very many shots <mark>of</mark> it. And so that's what everyone was was thinking. This was everywhere going to running ways. Do episode specific shy exactly, right? That's what my it Mike and I wanted to we don't want 17 shots in the Android. We want 300 shots <mark>of</mark> the Enterprise ride differ all different angles and things we've never seen and you know, and so but Gary was like for this money, this is what you're going to get and we were like, okay wait that's you know, that's fair. So he sent us it was great. And then we were just about to start and Gary contacted my can dine. He was Furious and said, I understand I'm being taken off <mark>of</mark> this now and And Mike and I were completely confused. So we went to CBS and see what's going on and they said well a lawyer had found out that we were doing this and they said you have to pitch it to the in-house visual <mark>effects</mark> team at CBS. So you guys have to go do that first. We kill all the lawyers. Yeah, so we had to go pitch to CBS digital which was this unknown company. We didn't know anything about them and we told Gary to look just hold by we're going to we're going to come up with a plan to try and get her. Around this and so what we did was we put together a schedule that was so unachievable that when we pitched it to these guys. No one in their right mind would would take it. So we never go film never get so we walked into this room and it was the head <mark>of</mark> CBS digitales guy named Craig Weiss their visual <mark>effects</mark> supervisor, Neil Ray and then there was this other guy. I don't I don't remember his name, but he was an executive and he just stood in the doorway just kind <mark>of</mark> leaned into the", "Start Time (s)": 710.6, "End Time (s)": 830.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "And then we were just about to start and Gary contacted my can dine. He was Furious and said, I understand I'm being taken off <mark>of</mark> this now and And Mike and I were completely confused. So we went to CBS and see what's going on and they said well a lawyer had found out that we were doing this and they said you have to pitch it to the in-house visual <mark>effects</mark> team at CBS. So you guys have to go do that first. We kill all the lawyers. Yeah, so we had to go pitch to CBS digital which was this unknown company. We didn't know anything about them and we told Gary to look just hold by we're going to we're going to come up with a plan to try and get her. Around this and so what we did was we put together a schedule that was so unachievable that when we pitched it to these guys. No one in their right mind would would take it. So we never go film never get so we walked into this room and it was the head <mark>of</mark> CBS digitales guy named Craig Weiss their visual <mark>effects</mark> supervisor, Neil Ray and then there was this other guy. I don't I don't remember his name, but he was an executive and he just stood in the doorway just kind <mark>of</mark> leaned into the doorway and They're like smoking a cigarette he acts <mark>of</mark> cowardice a scene exactly. So we pitched this schedule and Neil Ray who is the supervisor at the time he looked at Craig like there's no way we could do this and Craig looked over at this guy at the door and I looked at the guy at the door and the guy looked at Craig and he just nodded his head silently just like and Craig went will do it. And I mean we were now we're in it right now. So we were completely taken aback and we were like men Luca Brasi contract on the table, right? Everything is more like the smoking man said the visualization either the visual <mark>effects</mark> or his brains would be to the", "Start Time (s)": 761.7, "End Time (s)": 881.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and it was the head <mark>of</mark> CBS digitales guy named Craig Weiss their visual <mark>effects</mark> supervisor, Neil Ray and then there was this other guy. I don't I don't remember his name, but he was an executive and he just stood in the doorway just kind <mark>of</mark> leaned into the doorway and They're like smoking a cigarette he acts <mark>of</mark> cowardice a scene exactly. So we pitched this schedule and Neil Ray who is the supervisor at the time he looked at Craig like there's no way we could do this and Craig looked over at this guy at the door and I looked at the guy at the door and the guy looked at Craig and he just nodded his head silently just like and Craig went will do it. And I mean we were now we're in it right now. So we were completely taken aback and we were like men Luca Brasi contract on the table, right? Everything is more like the smoking man said the visualization either the visual <mark>effects</mark> or his brains would be to the bathroom. There's a phaser and but the horse's head is CG and so we had to tell Gary. That's how it was going to go and these guys were going to do it. And and so we looked at their real, <mark>of</mark> course, you know, Gary had assets. I mean he had done this test <mark>of</mark> the Enterprise that was just gorgeous. I mean, we loved it and so they didn't have an Enterprise They had to start building from scratch and our first delivery was I think three weeks down the road or something. I mean it was like nuts and so what happened was and then you get there's a whole other side <mark>of</mark> it, which is yes you and Mike are going to Shepherd how this works with the following, you know a caveat is right. So our idea was you know, we want it to look like the Enterprise from the original series so as far as coloring and lighting and try, you know, we did a small test and they were like, no the executives like no no, no, the the", "Start Time (s)": 816.8, "End Time (s)": 936.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "so they didn't have an Enterprise They had to start building from scratch and our first delivery was I think three weeks down the road or something. I mean it was like nuts and so what happened was and then you get there's a whole other side <mark>of</mark> it, which is yes you and Mike are going to Shepherd how this works with the following, you know a caveat is right. So our idea was you know, we want it to look like the Enterprise from the original series so as far as coloring and lighting and try, you know, we did a small test and they were like, no the executives like no no, no, the the stations will never buy this you're giving them the exact same thing that they're the advertisers won't do that. You're giving them the exact same thing that they're blocking against this needs to look up the you know how ships look today in the you know, it needs to look like metal and it needs you know, We're like, okay, so it started this whole that was a whole process and the whole time running. I mean, they're working on other shots and they had to develop everything the Romulan ship that it was just it was Madness this first couple <mark>of</mark> months and and so they contact Mike new <mark>of</mark> fans somewhere. I don't remember the person's name who had created an Enterprise that digital Enterprise model. We bought it from him so that they could start using it but the problem was it wasn't built for production. It was so detailed like down to rivets that the rendering time for one shot was you know a day or two. Yeah, it was like in say was like, there's no way so they hired a whole new group <mark>of</mark> people to come in and just start building an Enterprise. And in the meantime, they had to use this this other woman is slow render times. And yeah, it was a it was crazy. And so I mean the budget was I think it was somewhere around $900,000 and episode. No. Okay told that's what I was afraid of. Yeah, and then remember my bid was like three times that", "Start Time (s)": 902.9, "End Time (s)": 1022.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Mike new <mark>of</mark> fans somewhere. I don't remember the person's name who had created an Enterprise that digital Enterprise model. We bought it from him so that they could start using it but the problem was it wasn't built for production. It was so detailed like down to rivets that the rendering time for one shot was you know a day or two. Yeah, it was like in say was like, there's no way so they hired a whole new group <mark>of</mark> people to come in and just start building an Enterprise. And in the meantime, they had to use this this other woman is slow render times. And yeah, it was a it was crazy. And so I mean the budget was I think it was somewhere around $900,000 and episode. No. Okay told that's what I was afraid of. Yeah, and then remember my bid was like three times that yeah your yeah. Exactly. It was like what there's there there's just no way, you know, and <mark>of</mark> course that was a reasonable bit. Right? Right. Yeah, and so so they just brought in a whole bunch <mark>of</mark> people and started well the contract because it was so ambiguous. You're going to replace the space shots and you're going to replace Planet shots and you're going to do whatever man. So there was no number associated with it. As far as how many shots you're going to be replacing. So right when we started Mike and I divide it up the shows, you know, he did even I did odds or something and so we'd sit down by ourselves watch the show, you know, the even ones are better. I had a lot <mark>of</mark> times that will tell you which ones I am. And so we would watch the shows and we just had to call out time codes and part <mark>of</mark> the the handcuffs was that we couldn't go further than the cut that existed. So if there's a three second cut <mark>of</mark> the Enterprise, that's what you have to fill and so we would go in right those in and out points and then start", "Start Time (s)": 967.6, "End Time (s)": 1086.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "then remember my bid was like three times that yeah your yeah. Exactly. It was like what there's there there's just no way, you know, and <mark>of</mark> course that was a reasonable bit. Right? Right. Yeah, and so so they just brought in a whole bunch <mark>of</mark> people and started well the contract because it was so ambiguous. You're going to replace the space shots and you're going to replace Planet shots and you're going to do whatever man. So there was no number associated with it. As far as how many shots you're going to be replacing. So right when we started Mike and I divide it up the shows, you know, he did even I did odds or something and so we'd sit down by ourselves watch the show, you know, the even ones are better. I had a lot <mark>of</mark> times that will tell you which ones I am. And so we would watch the shows and we just had to call out time codes and part <mark>of</mark> the the handcuffs was that we couldn't go further than the cut that existed. So if there's a three second cut <mark>of</mark> the Enterprise, that's what you have to fill and so we would go in right those in and out points and then start talking about, you know, we had a little Enterprise models and when you know, this is would be cool. If you could you know, we'd never seen it this way or that way or whatever and so we started turning these sheets in And every once in a while, we would slip something else in like hey, you know in this episode Scotty's firing a phaser at a bulkhead and there's no being coming out <mark>of</mark> the gun. What would it take for you guys to maybe just the beam, you know and Neil Ray he was the champion <mark>of</mark> this whole thing regardless <mark>of</mark> schedule and the final product which was you know, I mean it would they all did the absolute best they could under all these circumstances, but he understood what we were going for and So he would slide these things into his people and I mean they they started doing things like adding blinks to the Gorn when we asked it, you know Norman lifts up his shirt. Can we make it not look like a Sanyo", "Start Time (s)": 1020.2, "End Time (s)": 1139.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "whatever and so we started turning these sheets in And every once in a while, we would slip something else in like hey, you know in this episode Scotty's firing a phaser at a bulkhead and there's no being coming out <mark>of</mark> the gun. What would it take for you guys to maybe just the beam, you know and Neil Ray he was the champion <mark>of</mark> this whole thing regardless <mark>of</mark> schedule and the final product which was you know, I mean it would they all did the absolute best they could under all these circumstances, but he understood what we were going for and So he would slide these things into his people and I mean they they started doing things like adding blinks to the Gorn when we asked it, you know Norman lifts up his shirt. Can we make it not look like a Sanyo radio inside, you know, and so they started doing all these things. Well eventually that caught up to them and because our her call out sheets were you know, here's 60 shots <mark>of</mark> the enterprise. We not we want you to do and they were like no no, No, we can only do three. You know, we're only doing the and then we're going to reuse those in the next one. It was like no no. No, so it was this constant this constant rub where we were butting heads about it and and Neal was trying to get as much done as he could and to his credit. I mean we ended up with I don't know what a hundred fifty a hundred seventy five shots <mark>of</mark> the Enterprise or something which was it was great. But at some point we almost bankrupted their company and I remember David Lee Fontaine called me and said, okay listen see digital is meeting with the president <mark>of</mark> CBS Television City who runs their division and we need to be in that meeting because I think they're either going to cancel it or they're going to say you need to stop or you know, you've done your Max and now you're there just going to reuse all these the mayor <mark>of</mark> Television sitting there writing exactly Mayor McCheese and and so and David had me there because he knew I tended to get passionate when", "Start Time (s)": 1093.0, "End Time (s)": 1213.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "passionate when I would talk about this and so later on he told me that's why why I had you here. He said, you know Mike God bless him very technically the very yes, very measured and very young where his I knew you would get you know, but they've you get the crazy. I even we're sitting in this meeting and and Craig Weiss started going through the numbers and he was saying listen and the contract was so ambiguous. He said we assumed we were replacing 20 shots, you know, 35 shots something to that little these guys have already, you know, delivered a hundred shots or something and so I was like well, which what's your story? What do you what are you talking about? What are you why are you doing this? And I said, you know I gave some speech about are you risking? This is their business I have to say that's what I felt like, you know, and I was just like listen, you know, I sit down with kids who want to watch this show. And the first thing they do is Snicker when they see the Enterprise I said, we're trying to lengthen the life <mark>of</mark> this show. We're trying to bring people in so that is new product is made. You have a new generation <mark>of</mark> you know, and I just kind <mark>of</mark> went on this thing and he went okay, I got it. I got it and then he turned to Craig and I started to say something else and he's talking. He said listen kid. I got it. You'd stop talking. Okay. Now we're talking about clothes. David was like, you know, not Jimmy like, okay. Yeah, and so he turned to Craig and he said they get you know, whatever. It was 10 shots per episode moving forward and that's it. Everything else is a reuse. So that's what you that's what you have to work with and we were already into season maybe three or at the finishing season to that point. So it wasn't it. You know, we got a lot <mark>of</mark> <mark>effects</mark> we can for a lot done and we did get a money injection because at that time the battle for blu-ray versus HD DVD was going on and so the Toshiba company who was running HD DVD came to us and said", "Start Time (s)": 1212.4, "End Time (s)": 1330.3, "Clip Length (min)": 1.96, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Now we're talking about clothes. David was like, you know, not Jimmy like, okay. Yeah, and so he turned to Craig and he said they get you know, whatever. It was 10 shots per episode moving forward and that's it. Everything else is a reuse. So that's what you that's what you have to work with and we were already into season maybe three or at the finishing season to that point. So it wasn't it. You know, we got a lot <mark>of</mark> <mark>effects</mark> we can for a lot done and we did get a money injection because at that time the battle for blu-ray versus HD DVD was going on and so the Toshiba company who was running HD DVD came to us and said If you can finish like season one or season 2 or whatever it was at a certain time. We want that to be the first launch on HD DVD and so they injected another I don't know what I was maybe $500,000 or something. So then therefore Matt died. Thanks Dave. That's why I bought HDD all <mark>of</mark> us when it was clear that Blu-ray was going to win. See I didn't get out <mark>of</mark> laser. Just quick enough. But this time I'm like, I'm not gonna I put my HD D HD player and all my disks and it was like boom. So next day with Blu-rays boom just went out and bought a ton <mark>of</mark> stuff. Yeah, I don't training and we didn't even get him we had to buy him too. I mean, it's not like they're handing us be extinct DVD copy that is all fascinating stuff. I've never heard I want to take a second because they're a couple things that we sort <mark>of</mark> went through very quickly which for the audience who's not technically Savvy may not good. You talked about not being able to slip the cuts now the Reason for that is because you're not really mixing the sound so the image is need to match the existing Center on so even if you want to do a space battle, we're going to create a rhythm. It was same thing. He was dealing with on the motion picture to a certain extent. You can't do that. So it has to be the exact same duration. Yeah, you can do anything within that", "Start Time (s)": 1292.2, "End Time (s)": 1411.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "disks and it was like boom. So next day with Blu-rays boom just went out and bought a ton <mark>of</mark> stuff. Yeah, I don't training and we didn't even get him we had to buy him too. I mean, it's not like they're handing us be extinct DVD copy that is all fascinating stuff. I've never heard I want to take a second because they're a couple things that we sort <mark>of</mark> went through very quickly which for the audience who's not technically Savvy may not good. You talked about not being able to slip the cuts now the Reason for that is because you're not really mixing the sound so the image is need to match the existing Center on so even if you want to do a space battle, we're going to create a rhythm. It was same thing. He was dealing with on the motion picture to a certain extent. You can't do that. So it has to be the exact same duration. Yeah, you can do anything within that frame but it can't be longer. It can't be short as long as the sound matched. Right? So we were able to get away with it. There were a couple things that we did do You know I mentioned amok time, which is the one <mark>of</mark> the bigger ones because as I was I was actually in Chicago at a Star Trek convention to promote remastered and I was working on sitting in a diner working on watching that show and putting in the time coach now in that show, there's the red psych behind the set and it's just always so horrible. It's a giant red curtain and so I wrote every one <mark>of</mark> those down whenever you saw that background, I wrote it down with an in-and-out time and I ended up with like a hundred and ninety shots or something. Was like there's no way they would have to rotoscope all <mark>of</mark> that out. And there's just no way so I remember flying I'm on the plane flying back and it was really I was really bummed out about it because I just hate that read it just so silly that you don't see any <mark>of</mark> Vulcan in the background. It's just this whatever. Well, I fell a lot <mark>of</mark> all can t pal she's all <mark>of</mark> welkin in one bag. So I'm sitting in the plane and I'm looking out the window and all <mark>of</mark> a sudden it kind <mark>of</mark> dawned on me. Man on the wing.", "Start Time (s)": 1364.9, "End Time (s)": 1482.9, "Clip Length (min)": 1.97, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that we did do You know I mentioned amok time, which is the one <mark>of</mark> the bigger ones because as I was I was actually in Chicago at a Star Trek convention to promote remastered and I was working on sitting in a diner working on watching that show and putting in the time coach now in that show, there's the red psych behind the set and it's just always so horrible. It's a giant red curtain and so I wrote every one <mark>of</mark> those down whenever you saw that background, I wrote it down with an in-and-out time and I ended up with like a hundred and ninety shots or something. Was like there's no way they would have to rotoscope all <mark>of</mark> that out. And there's just no way so I remember flying I'm on the plane flying back and it was really I was really bummed out about it because I just hate that read it just so silly that you don't see any <mark>of</mark> Vulcan in the background. It's just this whatever. Well, I fell a lot <mark>of</mark> all can t pal she's all <mark>of</mark> welkin in one bag. So I'm sitting in the plane and I'm looking out the window and all <mark>of</mark> a sudden it kind <mark>of</mark> dawned on me. Man on the wing. Yeah, I just remember looking down and thinking well, there's the sky outside <mark>of</mark> this plane, but the city is actually below and I started thinking what if we could do something where this place where they are is elevated and you establish that early enough so that then you're not supposed to see anything you're at the top <mark>of</mark> some mountains using sky and you're just seeing sky. So interestingly enough and Star Trek 3 there is such a place. Yeah, exactly. Yeah, absolutely. I climb the steps. So so we found a shot that is a reaction shot <mark>of</mark> Sulu that does nothing for the show. It's just they cut to him most <mark>of</mark> his shots looking at the screen and tapping on those. I used to hate Bill Bill Shatner, but the real enemy is Dave Rosie.", "Start Time (s)": 1420.1, "End Time (s)": 1538.0, "Clip Length (min)": 1.97, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "where this place where they are is elevated and you establish that early enough so that then you're not supposed to see anything you're at the top <mark>of</mark> some mountains using sky and you're just seeing sky. So interestingly enough and Star Trek 3 there is such a place. Yeah, exactly. Yeah, absolutely. I climb the steps. So so we found a shot that is a reaction shot <mark>of</mark> Sulu that does nothing for the show. It's just they cut to him most <mark>of</mark> his shots looking at the screen and tapping on those. I used to hate Bill Bill Shatner, but the real enemy is Dave Rosie. He ruined it. I was supposed to be an ad. And that shot right? He's never coming on the show. Now, you know, all right. And so so what we were able to do was create this this from the point where Kirk Spock and McCoy being down to the point where they walk through this kind <mark>of</mark> Archway into the ceremonial area. We created this shot that took up the Sue Loop space that is them walking across this Rock Bridge. That's obviously very elevated and in the background below you can See the city and Mike had them model it on the set here. Yeah, exactly. So so that was one <mark>of</mark> the places where we gotta wait we might have done it one other place. I don't remember but I remember we talked about it. But you know it was the project was full <mark>of</mark> these little hidden surprises for us. Like do we see tractor beams and the upgrade right? Do we you know the next gen they're showing tractor he's do we show it. Do we not what color are the phasers? Right, right. Because they changed they were never the same color twice. He's in the season. So we do do we establish that so there were all these little kind of, you know things that popped up there we had to talk about and and there were, you know, a lot <mark>of</mark> heated debates about things and look we could have gone farther but", "Start Time (s)": 1499.3, "End Time (s)": 1618.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "from the point where Kirk Spock and McCoy being down to the point where they walk through this kind <mark>of</mark> Archway into the ceremonial area. We created this shot that took up the Sue Loop space that is them walking across this Rock Bridge. That's obviously very elevated and in the background below you can See the city and Mike had them model it on the set here. Yeah, exactly. So so that was one <mark>of</mark> the places where we gotta wait we might have done it one other place. I don't remember but I remember we talked about it. But you know it was the project was full <mark>of</mark> these little hidden surprises for us. Like do we see tractor beams and the upgrade right? Do we you know the next gen they're showing tractor he's do we show it. Do we not what color are the phasers? Right, right. Because they changed they were never the same color twice. He's in the season. So we do do we establish that so there were all these little kind of, you know things that popped up there we had to talk about and and there were, you know, a lot <mark>of</mark> heated debates about things and look we could have gone farther but are we kind <mark>of</mark> came to this pact with the three <mark>of</mark> me like and Denise that this should be to honor the original series. We never want to put in an effect that takes your mind off <mark>of</mark> What's happening in the story? Right? I mean it was so while I'm sure that those guys back in the 60s would have loved to have the capability to do the things that we could do today. We just weren't comfortable right letting ourselves because it's a slippery slope and the other thing I think it's important to point out because we didn't talk about this is you know, why Next Generation <mark>effects</mark> when they redid that was different that we YouTube is what you did was to create all new effects. What they did is they re composited the original Elements, so it was virtually the same shots. Now. The reason you couldn't do that is because the nature Optical printing at in the 60s and that those elements didn't exist. Can you talk a little bit about that", "Start Time (s)": 1554.0, "End Time (s)": 1672.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to this pact with the three <mark>of</mark> me like and Denise that this should be to honor the original series. We never want to put in an effect that takes your mind off <mark>of</mark> What's happening in the story? Right? I mean it was so while I'm sure that those guys back in the 60s would have loved to have the capability to do the things that we could do today. We just weren't comfortable right letting ourselves because it's a slippery slope and the other thing I think it's important to point out because we didn't talk about this is you know, why Next Generation <mark>effects</mark> when they redid that was different that we YouTube is what you did was to create all new effects. What they did is they re composited the original Elements, so it was virtually the same shots. Now. The reason you couldn't do that is because the nature Optical printing at in the 60s and that those elements didn't exist. Can you talk a little bit about that how you by necessity would need to clean up all these shots that there's really not a way. I mean, yeah. Now you could get rid <mark>of</mark> some <mark>of</mark> the Grain and some <mark>of</mark> the dirt like now and but you couldn't really that was a whole process that CBS had undertaken as well. So our portion <mark>of</mark> it was the stirring <mark>of</mark> the the only the <mark>effects</mark> that's all we dealt with but they had a whole number division going through and scrubbing all the film right so that they could do their their up-res process to get it into HD and so, you know the like all <mark>of</mark> our shots were created in 16 by 9. So there's added footage even though it ended up being in the normal TV aspect. So yeah, they did have another team going through and doing that process and and we actually added grain. To you know what? I mean? So initially the visual <mark>effects</mark> we added grain and things we added this kind <mark>of</mark> blur and anything we could do to kind <mark>of</mark> tone it down so that it fit as closely as possible to what the production and what's great is on the Blu-rays. You can toggle between your stuff from the restoration and then the", "Start Time (s)": 1620.6, "End Time (s)": 1740.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "portion <mark>of</mark> it was the stirring <mark>of</mark> the the only the <mark>effects</mark> that's all we dealt with but they had a whole number division going through and scrubbing all the film right so that they could do their their up-res process to get it into HD and so, you know the like all <mark>of</mark> our shots were created in 16 by 9. So there's added footage even though it ended up being in the normal TV aspect. So yeah, they did have another team going through and doing that process and and we actually added grain. To you know what? I mean? So initially the visual <mark>effects</mark> we added grain and things we added this kind <mark>of</mark> blur and anything we could do to kind <mark>of</mark> tone it down so that it fit as closely as possible to what the production and what's great is on the Blu-rays. You can toggle between your stuff from the restoration and then the original and and even those are slightly cleaned up. Yeah. So yeah, you can watch it in either one thing I version one thing I ran into redoing my version <mark>of</mark> the Doomsday Machine. That I realized was going to be a huge problem. If you don't have access to the original negatives the original a be negatives right dissolves normal, usually from live action. Yes, who visual visual effect? Yeah. And what do you do to your rock and roll the a side? Do you do slow it down what you I'm sure you did a bunch <mark>of</mark> different solutions. It's dependent on it was dependent on what what the b or a sign was that you were going to or from but yes, so in some cases A lot <mark>of</mark> that Ace. I just got wiped out. Right right. We just had to go over it with the <mark>effects</mark> to get there and and depending on what was the visual effect became a shorter right? I was your shorter piece <mark>of</mark> something, you know than what the slot was. But yeah, that was a that was that all the time that was a huge problem. In fact what you know, one <mark>of</mark> the first thing not to go in the a be thing, but one <mark>of</mark> the first things that that CBS digital asked us was what's the hardest shot. Give us the hardest shot right now. We need", "Start Time (s)": 1690.1, "End Time (s)": 1810.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "cleaned up. Yeah. So yeah, you can watch it in either one thing I version one thing I ran into redoing my version <mark>of</mark> the Doomsday Machine. That I realized was going to be a huge problem. If you don't have access to the original negatives the original a be negatives right dissolves normal, usually from live action. Yes, who visual visual effect? Yeah. And what do you do to your rock and roll the a side? Do you do slow it down what you I'm sure you did a bunch <mark>of</mark> different solutions. It's dependent on it was dependent on what what the b or a sign was that you were going to or from but yes, so in some cases A lot <mark>of</mark> that Ace. I just got wiped out. Right right. We just had to go over it with the <mark>effects</mark> to get there and and depending on what was the visual effect became a shorter right? I was your shorter piece <mark>of</mark> something, you know than what the slot was. But yeah, that was a that was that all the time that was a huge problem. In fact what you know, one <mark>of</mark> the first thing not to go in the a be thing, but one <mark>of</mark> the first things that that CBS digital asked us was what's the hardest shot. Give us the hardest shot right now. We need to start working on that and And Mike was immediately. Oh the kk2. Yeah, you're going to the doctor. They tell him going to the Dome and so we gave them that and they worked on. I mean they were a couple <mark>of</mark> people just sequestered off doing that the entire time I mean so they could they could do it because yeah, they were all so yeah, there was a lot <mark>of</mark> and sometimes they were delivering They were delivering the night. It was going to be beamed up to you know, I mean it was it was a that was going on the satellite behavior and how local Town it was a really tight run especially with shows like Doomsday Machine where you know, there's a there's a lot more effects. But you know, we were able to to we stretched it out as much as we thought was was kind to keeping it, you know in what it's saying, but but we did and we also had a lot <mark>of</mark> fun. I mean, you know, we put", "Start Time (s)": 1742.5, "End Time (s)": 1861.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in the a be thing, but one <mark>of</mark> the first things that that CBS digital asked us was what's the hardest shot. Give us the hardest shot right now. We need to start working on that and And Mike was immediately. Oh the kk2. Yeah, you're going to the doctor. They tell him going to the Dome and so we gave them that and they worked on. I mean they were a couple <mark>of</mark> people just sequestered off doing that the entire time I mean so they could they could do it because yeah, they were all so yeah, there was a lot <mark>of</mark> and sometimes they were delivering They were delivering the night. It was going to be beamed up to you know, I mean it was it was a that was going on the satellite behavior and how local Town it was a really tight run especially with shows like Doomsday Machine where you know, there's a there's a lot more effects. But you know, we were able to to we stretched it out as much as we thought was was kind to keeping it, you know in what it's saying, but but we did and we also had a lot <mark>of</mark> fun. I mean, you know, we put ourselves in shots we You know, there's a Starfleet Starbase 11 were kind <mark>of</mark> standing in the background in the shot with the horta. There's a scene as establishing scene <mark>of</mark> The Mining facility. And so there's people in Windows and things and it's all people from the shit's all either Executives in the the crew working on it and everything. So I got to be Captain Kirk in a shuttlecraft and the Menagerie and I don't think you can see me but but I got to sit there and do it. It's really fun. But so we had those kinds <mark>of</mark> things but but you know, it was also like the thing with the the tractor beam, you know, we decided no, we don't want to let's not let's not see it. But then how do you how do you sell a tractor beam? How do you sell what it's doing? You know, it's kind <mark>of</mark> a difficult thing because they don't really do it a lot. They showed a lot <mark>of</mark> the biggest one was the Botany Bay and so, you know, I came up with an idea <mark>of</mark> if it's", "Start Time (s)": 1800.7, "End Time (s)": 1920.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "was kind to keeping it, you know in what it's saying, but but we did and we also had a lot <mark>of</mark> fun. I mean, you know, we put ourselves in shots we You know, there's a Starfleet Starbase 11 were kind <mark>of</mark> standing in the background in the shot with the horta. There's a scene as establishing scene <mark>of</mark> The Mining facility. And so there's people in Windows and things and it's all people from the shit's all either Executives in the the crew working on it and everything. So I got to be Captain Kirk in a shuttlecraft and the Menagerie and I don't think you can see me but but I got to sit there and do it. It's really fun. But so we had those kinds <mark>of</mark> things but but you know, it was also like the thing with the the tractor beam, you know, we decided no, we don't want to let's not let's not see it. But then how do you how do you sell a tractor beam? How do you sell what it's doing? You know, it's kind <mark>of</mark> a difficult thing because they don't really do it a lot. They showed a lot <mark>of</mark> the biggest one was the Botany Bay and so, you know, I came up with an idea <mark>of</mark> if it's spinning and we have it continually spinning and then it Stops the Enterprise grabs it and then when the Enterprise lets it go it can cause it continues. It just starts like it's that kinetic energy is kind <mark>of</mark> started. So we're trying to figure out clever ways to to make it work without making it I popping and you know, yeah changing the structure <mark>of</mark> a too much. I you know when I look back at what you guys did. I mean, I think my absolute favorite part is the matte paintings. I think that the stunning, you know, because <mark>of</mark> course Star Trek famously like all those shows The air I mean Buck Rogers got recycled matte paintings a lot. You guys duration did in his early days. So, you know you created a lot <mark>of</mark> new environments in the ones that weren't that you had a lot <mark>of</mark> live action elements that you talked about and really beautiful. You know, what was there was a guy an artist they", "Start Time (s)": 1855.6, "End Time (s)": 1973.5, "Clip Length (min)": 1.97, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "then how do you how do you sell a tractor beam? How do you sell what it's doing? You know, it's kind <mark>of</mark> a difficult thing because they don't really do it a lot. They showed a lot <mark>of</mark> the biggest one was the Botany Bay and so, you know, I came up with an idea <mark>of</mark> if it's spinning and we have it continually spinning and then it Stops the Enterprise grabs it and then when the Enterprise lets it go it can cause it continues. It just starts like it's that kinetic energy is kind <mark>of</mark> started. So we're trying to figure out clever ways to to make it work without making it I popping and you know, yeah changing the structure <mark>of</mark> a too much. I you know when I look back at what you guys did. I mean, I think my absolute favorite part is the matte paintings. I think that the stunning, you know, because <mark>of</mark> course Star Trek famously like all those shows The air I mean Buck Rogers got recycled matte paintings a lot. You guys duration did in his early days. So, you know you created a lot <mark>of</mark> new environments in the ones that weren't that you had a lot <mark>of</mark> live action elements that you talked about and really beautiful. You know, what was there was a guy an artist they had named Max Gable who who was doing those and he was just brilliant and you know to their credit. I'm sure that their marching orders were don't give these guys. A time <mark>of</mark> day we're going to do what we're supposed to do and then you got to move on because we got other stuff. We got other fish to fry, but every one <mark>of</mark> those team members was just so giving <mark>of</mark> their time and I mean it it turned out the way it did because they were so helpful with that budget. There's no way to make it but you know decent without people being passionate. Yeah, they have to believe in it. Otherwise, you're not going to get for the you going to get shit. I think ultimately there was it was like Shots or something. I mean 400f for 930 unbelievable. Yeah, it's pretty crazy. This is what would have been difficult for me that the original series <mark>of</mark> facts even though they're", "Start Time (s)": 1905.7, "End Time (s)": 2025.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "ones that weren't that you had a lot <mark>of</mark> live action elements that you talked about and really beautiful. You know, what was there was a guy an artist they had named Max Gable who who was doing those and he was just brilliant and you know to their credit. I'm sure that their marching orders were don't give these guys. A time <mark>of</mark> day we're going to do what we're supposed to do and then you got to move on because we got other stuff. We got other fish to fry, but every one <mark>of</mark> those team members was just so giving <mark>of</mark> their time and I mean it it turned out the way it did because they were so helpful with that budget. There's no way to make it but you know decent without people being passionate. Yeah, they have to believe in it. Otherwise, you're not going to get for the you going to get shit. I think ultimately there was it was like Shots or something. I mean 400f for 930 unbelievable. Yeah, it's pretty crazy. This is what would have been difficult for me that the original series <mark>of</mark> facts even though they're dated now at the time they were fairly groundbreaking and you know, just you think about the the number <mark>of</mark> artists who work on any show whether it was Star Trek or Westworld or what have you and you know, you go back and you know, you redo the video. It affects or you create new matte paintings for me. I think I would have heard this little voice in the back <mark>of</mark> my head saying like I am feeling like I am erasing like art, you know, that's been done. I think that was probably my biggest problem with the the special editions <mark>of</mark> the Star Wars films and it's like there was this art that was created and now it feels a little gone even though you know, what you're doing is is also art it's coming from this place <mark>of</mark> <mark>of</mark> love for what those people created and what they did. I'm I don't know a lot <mark>of</mark> you we had all <mark>of</mark> those feelings and we had to kind <mark>of</mark> you know, I don't know if it's", "Start Time (s)": 1964.3, "End Time (s)": 2084.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "unbelievable. Yeah, it's pretty crazy. This is what would have been difficult for me that the original series <mark>of</mark> facts even though they're dated now at the time they were fairly groundbreaking and you know, just you think about the the number <mark>of</mark> artists who work on any show whether it was Star Trek or Westworld or what have you and you know, you go back and you know, you redo the video. It affects or you create new matte paintings for me. I think I would have heard this little voice in the back <mark>of</mark> my head saying like I am feeling like I am erasing like art, you know, that's been done. I think that was probably my biggest problem with the the special editions <mark>of</mark> the Star Wars films and it's like there was this art that was created and now it feels a little gone even though you know, what you're doing is is also art it's coming from this place <mark>of</mark> <mark>of</mark> love for what those people created and what they did. I'm I don't know a lot <mark>of</mark> you we had all <mark>of</mark> those feelings and we had to kind <mark>of</mark> you know, I don't know if it's drinking our own Kool-Aid but we had to get to the point where we said, you know, what we're not erasing this right the right. This will always be available. You can always watch this unlike Star Wars. Yeah, right and and so, you know, they early on they put us on a it was me and I think it was Jeff. Armed and Rod Roddenberry, they put us on the show called attack <mark>of</mark> the show that was on one <mark>of</mark> these like giant TV for something. It was Olivia Munn and yeah, sure somebody else whatever and with no other I was I forget the guy. Okay. Yeah, and so and it was like the debate thing, right? So Jeff was brought on as a, you know, a naysayer right to the garage easy to believe but it was funny. You know, it was all he would not have done well in that meeting at CBS,", "Start Time (s)": 2017.5, "End Time (s)": 2135.4, "Clip Length (min)": 1.97, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Yeah, right and and so, you know, they early on they put us on a it was me and I think it was Jeff. Armed and Rod Roddenberry, they put us on the show called attack <mark>of</mark> the show that was on one <mark>of</mark> these like giant TV for something. It was Olivia Munn and yeah, sure somebody else whatever and with no other I was I forget the guy. Okay. Yeah, and so and it was like the debate thing, right? So Jeff was brought on as a, you know, a naysayer right to the garage easy to believe but it was funny. You know, it was all he would not have done well in that meeting at CBS, you know, it was all a goof really, I mean Jeff pulled me aside before and was just like I yeah, they asked me to come be the negative guy could easily be a positive guy. So, you know, there was all they were trying to get all this hype for it. But but in a very real sense, we had a lot <mark>of</mark> a lot <mark>of</mark> gut checks about what we were doing and it's funny because now when people look at it, they say you should have gone farther. We wish you guys would have gone farther and done some more you don't listen to those people. We went as far as we thought is we thought what you want me we went farther and is plenty <mark>of</mark> that now. Yeah, I think look I think you know an answer when asked he was saying the reason ultimately I don't have you know a problem with it is one from a pragmatic point <mark>of</mark> view. You said the top <mark>of</mark> the show, they couldn't sell it in syndication. They needed new bells and whistles to you know, yeah, so is it better that it's not being shown or you know, exactly, you know, or you and the second thing is every you didn't okay because the originals are still available. Like that's that's why exactly that nobody three know. I love the fact on the Blu-rays. You can watch either version. I believe on Netflix you can or is that not true? Okay, I think at least on Blu-ray you can't so they exist. It's not like racing history like George Lucas know we destroyed the original negative. There's no way to you know, which is all Bs. But you know, it's kind <mark>of</mark> like not making that available", "Start Time (s)": 2094.2, "End Time (s)": 2214.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "we had a lot <mark>of</mark> a lot <mark>of</mark> gut checks about what we were doing and it's funny because now when people look at it, they say you should have gone farther. We wish you guys would have gone farther and done some more you don't listen to those people. We went as far as we thought is we thought what you want me we went farther and is plenty <mark>of</mark> that now. Yeah, I think look I think you know an answer when asked he was saying the reason ultimately I don't have you know a problem with it is one from a pragmatic point <mark>of</mark> view. You said the top <mark>of</mark> the show, they couldn't sell it in syndication. They needed new bells and whistles to you know, yeah, so is it better that it's not being shown or you know, exactly, you know, or you and the second thing is every you didn't okay because the originals are still available. Like that's that's why exactly that nobody three know. I love the fact on the Blu-rays. You can watch either version. I believe on Netflix you can or is that not true? Okay, I think at least on Blu-ray you can't so they exist. It's not like racing history like George Lucas know we destroyed the original negative. There's no way to you know, which is all Bs. But you know, it's kind <mark>of</mark> like not making that available let the, you know, it's like having all the versions <mark>of</mark> Blade Runner, you know, this is my directors version my final cut but you could still look at the theatrical cut you can so I love It's available because I will tell you depending on the episode. I will watch the original or the original going on. You know, what which one it is. Yeah, you know how successful I feel the new like tomorrow's yesterday. I will always watch your versions. You know, where as Doomsday Machine. I will probably watch the original but that's just me. Yeah, you know, so but you know, but again, I'm not the target audience for this, you know, I grew up on it. It's ingrained you were going to buy it. Anyway. Yeah, but I'll tell you that. That was something that went along. With my one weekend my wife and I were babysitting for a friend <mark>of</mark> ours had an 11 year old kid and he had never seen Star Trek before and I thought well, we'll kill some time doing this so we sat down and I put in Arena and I mean that was his first the first thing he said was this old is this you don't know it's", "Start Time (s)": 2153.4, "End Time (s)": 2272.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the versions <mark>of</mark> Blade Runner, you know, this is my directors version my final cut but you could still look at the theatrical cut you can so I love It's available because I will tell you depending on the episode. I will watch the original or the original going on. You know, what which one it is. Yeah, you know how successful I feel the new like tomorrow's yesterday. I will always watch your versions. You know, where as Doomsday Machine. I will probably watch the original but that's just me. Yeah, you know, so but you know, but again, I'm not the target audience for this, you know, I grew up on it. It's ingrained you were going to buy it. Anyway. Yeah, but I'll tell you that. That was something that went along. With my one weekend my wife and I were babysitting for a friend <mark>of</mark> ours had an 11 year old kid and he had never seen Star Trek before and I thought well, we'll kill some time doing this so we sat down and I put in Arena and I mean that was his first the first thing he said was this old is this you don't know it's like okay just just watch and then you know as the story kind <mark>of</mark> progressed. I I remember he turned to me and he said they'd sure talk a lot and you know, it's it was just indicative <mark>of</mark> this this Netiq kind <mark>of</mark> environment that they're in the kids are in today. The other people are in today that you know, everything's fast and you know, and that boy was JJ Abrams. No, I mean you either love those first 10 minutes Revenge <mark>of</mark> the Sith. We there's no you have no idea what's going on because everything's happening so fast and so many ships or you think is the worst thing ever, you know, we follow the canvas, I guess the words. Yeah, but you know for sure people grew up on video games, you know, like this is fantastic. Just want to start fresh. That's what they want. That's what feeds their thing. And but what was really gratifying about it is that at the end he was sitting on the edge <mark>of</mark> our sofa looking at the TV and he was going get him get him get him. He was right was just really into it and hope to see its gunpowder. It was but it was so", "Start Time (s)": 2215.7, "End Time (s)": 2335.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to me and he said they'd sure talk a lot and you know, it's it was just indicative <mark>of</mark> this this Netiq kind <mark>of</mark> environment that they're in the kids are in today. The other people are in today that you know, everything's fast and you know, and that boy was JJ Abrams. No, I mean you either love those first 10 minutes Revenge <mark>of</mark> the Sith. We there's no you have no idea what's going on because everything's happening so fast and so many ships or you think is the worst thing ever, you know, we follow the canvas, I guess the words. Yeah, but you know for sure people grew up on video games, you know, like this is fantastic. Just want to start fresh. That's what they want. That's what feeds their thing. And but what was really gratifying about it is that at the end he was sitting on the edge <mark>of</mark> our sofa looking at the TV and he was going get him get him get him. He was right was just really into it and hope to see its gunpowder. It was but it was so gratifying to see him kind <mark>of</mark> come around to being drawn into it and and and that so you're suggesting restraints are in order. Right. Why are they putting the such a good point because if kids are just exposed to this material the good stuff. Yeah chances are they'll appreciate it because you know what because it's good. Yeah. So exactly I have it a ten-year-old who I am gradually bringing along into becoming a geek so <mark>of</mark> the <mark>of</mark> the remastered episodes, what would you say are the essentials like the ones that you guys you feel like she just nailed it and like what's the road? You could call back. Well, you know, there are a lot <mark>of</mark> shots that I really loved. I don't know that I could say, you know, this episode was a standout. I'll say a month time is my favorite. Yeah. Yeah. Yeah cos great amok time is really stands up there. I love the I love the Doomsday Machine stuff that they did and", "Start Time (s)": 2277.2, "End Time (s)": 2396.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "being drawn into it and and and that so you're suggesting restraints are in order. Right. Why are they putting the such a good point because if kids are just exposed to this material the good stuff. Yeah chances are they'll appreciate it because you know what because it's good. Yeah. So exactly I have it a ten-year-old who I am gradually bringing along into becoming a geek so <mark>of</mark> the <mark>of</mark> the remastered episodes, what would you say are the essentials like the ones that you guys you feel like she just nailed it and like what's the road? You could call back. Well, you know, there are a lot <mark>of</mark> shots that I really loved. I don't know that I could say, you know, this episode was a standout. I'll say a month time is my favorite. Yeah. Yeah. Yeah cos great amok time is really stands up there. I love the I love the Doomsday Machine stuff that they did and you know, one <mark>of</mark> the I love one <mark>of</mark> the shots at the very beginning where we first think before they even beam over their In the constellation that's all destroyed and everything and I remember saying to Mike and Denise the ship is destroyed. Obviously, it's been beat up I said but I really want to see it. I really want people to feel bad for it. Not just that it's destroyed. I want to see it get kind <mark>of</mark> Racket when it's down so I know exactly what you're talking so I got with the yeah, so there's a little piece <mark>of</mark> planetary debris that just kind <mark>of</mark> floats in and shatters on the hall and just kind <mark>of</mark> bounces off and I was like, let's have the universe just kind <mark>of</mark> kick it while it's down it just it made me feel so sad to see this Majestic ship. Yeah, you know, so things like that. I really I really enjoyed but I think he just got to kind <mark>of</mark> go through them and find your favorite episodes and because that I find that feeds the way you'll yes Eve. What's the best", "Start Time (s)": 2338.6, "End Time (s)": 2457.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "amok time is really stands up there. I love the I love the Doomsday Machine stuff that they did and you know, one <mark>of</mark> the I love one <mark>of</mark> the shots at the very beginning where we first think before they even beam over their In the constellation that's all destroyed and everything and I remember saying to Mike and Denise the ship is destroyed. Obviously, it's been beat up I said but I really want to see it. I really want people to feel bad for it. Not just that it's destroyed. I want to see it get kind <mark>of</mark> Racket when it's down so I know exactly what you're talking so I got with the yeah, so there's a little piece <mark>of</mark> planetary debris that just kind <mark>of</mark> floats in and shatters on the hall and just kind <mark>of</mark> bounces off and I was like, let's have the universe just kind <mark>of</mark> kick it while it's down it just it made me feel so sad to see this Majestic ship. Yeah, you know, so things like that. I really I really enjoyed but I think he just got to kind <mark>of</mark> go through them and find your favorite episodes and because that I find that feeds the way you'll yes Eve. What's the best episodes <mark>of</mark> the show? Yeah, like mirror mirror. I think we did a good job. We did some fun little things that had you know, like we hands to the agony booth and you know things like that and in fact, I think the I think in the show we did the you know to do the transition <mark>of</mark> the Enterprise going to the mirror Enterprise. I think it's the only time in the Show the ship travels, correct, right you got away right to left. There's there's one more episode. I can't remember but yeah, absolutely and they use the old I'm pretty sure the old shots that were. Yeah shot for the main titles. Oh, yeah, and it's flopped. Yeah, because they had they had they flopped the ship but they knew that they would have to so they had reversed decals on the side when", "Start Time (s)": 2388.5, "End Time (s)": 2508.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "your favorite episodes and because that I find that feeds the way you'll yes Eve. What's the best episodes <mark>of</mark> the show? Yeah, like mirror mirror. I think we did a good job. We did some fun little things that had you know, like we hands to the agony booth and you know things like that and in fact, I think the I think in the show we did the you know to do the transition <mark>of</mark> the Enterprise going to the mirror Enterprise. I think it's the only time in the Show the ship travels, correct, right you got away right to left. There's there's one more episode. I can't remember but yeah, absolutely and they use the old I'm pretty sure the old shots that were. Yeah shot for the main titles. Oh, yeah, and it's flopped. Yeah, because they had they had they flopped the ship but they knew that they would have to so they had reversed decals on the side when they shot it right and it's just, you know, one <mark>of</mark> those things because that side Never finished, right? Yeah miniature. Yeah, but but yeah, you guys did a great and you and you made the made the Mirror Universe Enterprise slightly different. Yeah a little bit cool. Yeah, we added some different markets and Bob's to it and yeah to kind <mark>of</mark> change that was one <mark>of</mark> the things that CBS digital wanted to do was as we progressed through the show. They wanted to include elements from the motion picture Enterprise to slowly show, right they wanted to add a you know, the photon torpedo. ER and you know in the second season then the third season they wanted to include the dish and and we were like no. No, that's a slippery slope. Yeah, exactly, you know and and again, you know that Enterprise is my Enterprise right? It's my favorite thing. Is that a rocking your mission would have been spent in Dry Dock. Yeah, right. Thanks God to use, you know you guys there when you got to walk into the hold the line. Oh and uh, you know and and protect these bad decision because you know, there are other", "Start Time (s)": 2450.9, "End Time (s)": 2570.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "to it and yeah to kind <mark>of</mark> change that was one <mark>of</mark> the things that CBS digital wanted to do was as we progressed through the show. They wanted to include elements from the motion picture Enterprise to slowly show, right they wanted to add a you know, the photon torpedo. ER and you know in the second season then the third season they wanted to include the dish and and we were like no. No, that's a slippery slope. Yeah, exactly, you know and and again, you know that Enterprise is my Enterprise right? It's my favorite thing. Is that a rocking your mission would have been spent in Dry Dock. Yeah, right. Thanks God to use, you know you guys there when you got to walk into the hold the line. Oh and uh, you know and and protect these bad decision because you know, there are other shows maybe where there And people who respect Star Trek the way you guys do our science fiction and aren't there to protect these franchises because they don't care and they don't understand the history you and Mike and Denise, you know understand the importance <mark>of</mark> Star Trek how it made you feel as kids. And so you were you know on the front lines protecting it and you know, sometimes maybe you have the money or you know to be you know, you held the line and that's why you know, this stuff still holds up, you know, 20 years later and it was good having three <mark>of</mark> us because Cuz then there's always a vote breaker right when you get into a problem where you headed out to vote. You know, I mean something is simple like this. I think this conversation took about a week and it was at the beginning <mark>of</mark> the Original Series in the credits the Enterprise comes and does this hard turn and we all called it the bump that sort <mark>of</mark> them was calling it The Bump do we keep the bumper do we get rid <mark>of</mark> the bump we talked about this? I mean he agonized over it. I couldn't Ultimately, we said no the point <mark>of</mark> this is to smooth it out. That was obviously a problem with you know, how they were doing the movement <mark>of</mark> the model and the model and so we you know, we correct it, but it was agonizing. You know, it was a", "Start Time (s)": 2525.1, "End Time (s)": 2644.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "because they don't care and they don't understand the history you and Mike and Denise, you know understand the importance <mark>of</mark> Star Trek how it made you feel as kids. And so you were you know on the front lines protecting it and you know, sometimes maybe you have the money or you know to be you know, you held the line and that's why you know, this stuff still holds up, you know, 20 years later and it was good having three <mark>of</mark> us because Cuz then there's always a vote breaker right when you get into a problem where you headed out to vote. You know, I mean something is simple like this. I think this conversation took about a week and it was at the beginning <mark>of</mark> the Original Series in the credits the Enterprise comes and does this hard turn and we all called it the bump that sort <mark>of</mark> them was calling it The Bump do we keep the bumper do we get rid <mark>of</mark> the bump we talked about this? I mean he agonized over it. I couldn't Ultimately, we said no the point <mark>of</mark> this is to smooth it out. That was obviously a problem with you know, how they were doing the movement <mark>of</mark> the model and the model and so we you know, we correct it, but it was agonizing. You know, it was a another one was James are Kirk. Yeah, do you fix that did we fix it and be very easy and unfortunately the amount <mark>of</mark> times that you go to it prevented us from doing it on the schedule because all the Rota they could have done it, but Denis was very for Keeping it keeping it James our current and I was very fortunate to James T Kirk, right and we swear in my house and we were arguing back and forth and Mike was sitting between us and you know, it was married to Denise it so, you know, it's his best friend. Well initially Ste. It's his best friend. That's the madness. That's the metric is crazy enough. Don't forget the middle name. And so we had this, you know, we're going over Mike talking like just", "Start Time (s)": 2578.8, "End Time (s)": 2698.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the Rota they could have done it, but Denis was very for Keeping it keeping it James our current and I was very fortunate to James T Kirk, right and we swear in my house and we were arguing back and forth and Mike was sitting between us and you know, it was married to Denise it so, you know, it's his best friend. Well initially Ste. It's his best friend. That's the madness. That's the metric is crazy enough. Don't forget the middle name. And so we had this, you know, we're going over Mike talking like just sitting there quiet and so did he said? Okay, I'm gonna go to the bathroom. I'll be right back and we'll decide and she goes to the bathroom and I turned to Mike and I went you know, I write you know, I'm right you're married. That's hysterical and that's what we put CBS digital out <mark>of</mark> business. You're right. Exactly. Yeah over the middle initial no and they did like I got again. I cannot say enough how above and beyond what this contract was that they did for us because look the work we would have got from Gary hutsul would have been amazing, but it would but it would have been limited. Yeah, and so to do the things we were able to do really it's ironic because you know, we collect data, you know, they Started zoek but one <mark>of</mark> the frustrations why they ended up building their own <mark>effects</mark> company with Gary. We said that they could do more <mark>effects</mark> because it was too expensive. You know, they paint by the shot here are you doing but when you do it in house you have a lot more flexibility to add shots is be more stuff and say, oh we could use this week as you got a pool <mark>of</mark> people working. It's not just based on this and that was where Gary that's what comes from. So now it's like yeah, okay, you know you get this this and this and that's it. Yep, you know, and there was no more money so you weren't going to get any more. So it's an interesting trade-off, you know, I will say one <mark>of</mark> the things that I'm indebted to you know for", "Start Time (s)": 2657.1, "End Time (s)": 2776.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "hysterical and that's what we put CBS digital out <mark>of</mark> business. You're right. Exactly. Yeah over the middle initial no and they did like I got again. I cannot say enough how above and beyond what this contract was that they did for us because look the work we would have got from Gary hutsul would have been amazing, but it would but it would have been limited. Yeah, and so to do the things we were able to do really it's ironic because you know, we collect data, you know, they Started zoek but one <mark>of</mark> the frustrations why they ended up building their own <mark>effects</mark> company with Gary. We said that they could do more <mark>effects</mark> because it was too expensive. You know, they paint by the shot here are you doing but when you do it in house you have a lot more flexibility to add shots is be more stuff and say, oh we could use this week as you got a pool <mark>of</mark> people working. It's not just based on this and that was where Gary that's what comes from. So now it's like yeah, okay, you know you get this this and this and that's it. Yep, you know, and there was no more money so you weren't going to get any more. So it's an interesting trade-off, you know, I will say one <mark>of</mark> the things that I'm indebted to you know for this re-release in 2006 and a sense, which it probably been I don't know how many years since I watched all the episodes, you know, a lot <mark>of</mark> them. I was doing from memory from his kid watching my channel 11, you know, because once they come out on DVD, you kind <mark>of</mark> just go to the episode you like. Yeah, you know, or you know, we very rarely you go to something that's like, you know in the children shall lead. Why am I going to watch that? Yeah, and by then it's at the end like because at the beginning when mantrap first comes out you Because they just came out on DVD for the first time on Blu-ray, but the timing <mark>of</mark> the third season it's like whatever is goes on the Shelf. Maybe I opened the package. Maybe I did right so but when they came out in 2006, it was the first time to see Star Trek in an entirely new way. Yeah that I you know some shots that I had never seen. It was the way I felt like when Roddenberry volt came out which is extraordinary, right? So it was like, I watched all the episodes and it was great because it was like midnight here on channel 13. Yeah, and I would on Sunday.", "Start Time (s)": 2714.5, "End Time (s)": 2833.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "goes on the Shelf. Maybe I opened the package. Maybe I did right so but when they came out in 2006, it was the first time to see Star Trek in an entirely new way. Yeah that I you know some shots that I had never seen. It was the way I felt like when Roddenberry volt came out which is extraordinary, right? So it was like, I watched all the episodes and it was great because it was like midnight here on channel 13. Yeah, and I would on Sunday. Knights, you know Punk it sit down on the sofa and how my big-screen TV and there's also you know and I watch the episodes every Saturday Sunday night and it was like watching on Channel 11 is a kid again because I commercials and you didn't know what was coming. You didn't know right? Right. I mean if as the shots were as the show was going you didn't know how we were going to die, but he was totally I don't want doing this or doing that or doing whatever and so yeah, it was really fun to watch again. Yeah, I agree and you know, I got to tell you the internet was just I mean Never do a project and go on the internet and got the truth. Oh my God. I mean the amount <mark>of</mark> people who commented on than the cells the tips <mark>of</mark> the ne cells. It was like you'd blow your brains out. I mean it with the the people at CBS digital were, you know, they were so depressed. They were like, oh we went on and they you know, people are just saying how awful it is. I mean, we're like no no don't stop stop coming online reading this you gotta just What you got to do a these people are never going to understand how much time and how much money you had to do it, you know, the reality <mark>of</mark> it was closure. You might have been one <mark>of</mark> those know I'd look I'm just as guilty because honestly, you know at the time I think Trek movie it had me review a couple episodes. Mm and and and you know, I had things I love and a lot <mark>of</mark> quibbles on the things I really like and and you know, but it's absolutely true. It's like, you know walk a mile in my shoes and it's like, you know what you guys pulled off in retrospect knowing what that project should have cost and that the you know, the time look if we would have,", "Start Time (s)": 2810.4, "End Time (s)": 2930.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "online reading this you gotta just What you got to do a these people are never going to understand how much time and how much money you had to do it, you know, the reality <mark>of</mark> it was closure. You might have been one <mark>of</mark> those know I'd look I'm just as guilty because honestly, you know at the time I think Trek movie it had me review a couple episodes. Mm and and and you know, I had things I love and a lot <mark>of</mark> quibbles on the things I really like and and you know, but it's absolutely true. It's like, you know walk a mile in my shoes and it's like, you know what you guys pulled off in retrospect knowing what that project should have cost and that the you know, the time look if we would have, you know, had a yearly done time to prep everything and develop assets into but you know, like we're going to see the you know, Harry Mudd ship or we're going to see you know, what I mean Neil was just he was sketching that stuff on paper as we were talking about it and that would you know, he'd build it in SketchUp and then we'd look at it and kind <mark>of</mark> turn around make some notes and you know, I mean it was it was so fast the way we were working and it's that no one wants to work that well, there's also the fear that it was going to supplant the original and when you look at the original X and how groundbreaking and they were and and and you know for the time they were extraordinary. I think a lot <mark>of</mark> them really. Hold up great now. Yeah, there was that fear that it was the Lucas <mark>of</mark> keishon <mark>of</mark> Star Trek so that played into it as well. But you know, I will say for every you know judgment that may have been off we're too tight on the Enterprise or something. There's a great choice like putting the or ship in from the Animated Series in Ultimate computer. I mean, you know as opposed to reusing the Botany Bay model which made no sense which even as a kid you're like with us. Botany Bay, I mean, why would I be it's not like they would certainly be using that as an authorship, you know, and and so, you know or even Klingon and Romulan ships, which we couldn't yeah, it's just there's so much in there that you know, it's because it's people who are passionate about the show get the show, you know, these Easter eggs as they call fan services is now a dirty word,", "Start Time (s)": 2891.7, "End Time (s)": 3011.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "time they were extraordinary. I think a lot <mark>of</mark> them really. Hold up great now. Yeah, there was that fear that it was the Lucas <mark>of</mark> keishon <mark>of</mark> Star Trek so that played into it as well. But you know, I will say for every you know judgment that may have been off we're too tight on the Enterprise or something. There's a great choice like putting the or ship in from the Animated Series in Ultimate computer. I mean, you know as opposed to reusing the Botany Bay model which made no sense which even as a kid you're like with us. Botany Bay, I mean, why would I be it's not like they would certainly be using that as an authorship, you know, and and so, you know or even Klingon and Romulan ships, which we couldn't yeah, it's just there's so much in there that you know, it's because it's people who are passionate about the show get the show, you know, these Easter eggs as they call fan services is now a dirty word, but it's just wonderful it is and it was you know, in an episode, you know, like the Enterprise incident where you know live Are using Klingon design? Yeah, you know, he's used to bug the hell out <mark>of</mark> me. You think Klingon Miniatures because you can't find that other Romulan. So it was great to for us to be able to put a bird <mark>of</mark> prey in there because then it kind <mark>of</mark> at least ties it back. It's not just you know, all these goofy models and don't don't don't and they were like, you know, there's a great you can look at it online. There's a great moment where there was a lot <mark>of</mark> pressure on the Doomsday Machine that you guys are under a lot <mark>of</mark> pressure and They played a joke on Neil Ray that's online that you can see where they told him that they delivered the show and made the name <mark>of</mark> the ship the consolation oscillation. And so there's a scene where Craig is showing him. Hey what happened here? Because I got David La Fontaine on the phone and he is pissed and Neil sits down and looks at it and you just see if I mean, it's a great thing a great horrible horrible great not funny when you're to think <mark>of</mark> it you haven't slept in weeks. An hour, you know navigate because you're trying on a deadline and then it's not so funny.", "Start Time (s)": 2965.5, "End Time (s)": 3085.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the Enterprise incident where you know live Are using Klingon design? Yeah, you know, he's used to bug the hell out <mark>of</mark> me. You think Klingon Miniatures because you can't find that other Romulan. So it was great to for us to be able to put a bird <mark>of</mark> prey in there because then it kind <mark>of</mark> at least ties it back. It's not just you know, all these goofy models and don't don't don't and they were like, you know, there's a great you can look at it online. There's a great moment where there was a lot <mark>of</mark> pressure on the Doomsday Machine that you guys are under a lot <mark>of</mark> pressure and They played a joke on Neil Ray that's online that you can see where they told him that they delivered the show and made the name <mark>of</mark> the ship the consolation oscillation. And so there's a scene where Craig is showing him. Hey what happened here? Because I got David La Fontaine on the phone and he is pissed and Neil sits down and looks at it and you just see if I mean, it's a great thing a great horrible horrible great not funny when you're to think <mark>of</mark> it you haven't slept in weeks. An hour, you know navigate because you're trying on a deadline and then it's not so funny. Yeah, as you can probably attest it hot. Yeah. Oh you got jokes. Okay. Okay, you know you mentioned, you know, we always talk about the trouble troubles being, you know, sort <mark>of</mark> a gateway drug for kids. You know, I know your son is 10. My son's 10. His favorite is the Menagerie. He loves a menagerie, you know, he did something but I don't know what I don't know what it is about the Menagerie that he loves so much and it's the magic <mark>of</mark> mixing the earlier crew and the later crew. It's it's really nice to see them sort <mark>of</mark> both <mark>of</mark> the same time in the same episode. You know, we always say in trouble troubles, but I'm not sure trouble troubles is the right Gateway dreams. It's not really a typical Star Trek episode and you get funnier if you know the characters and you get the joy out <mark>of</mark> its fire if you know the character seeing them so out <mark>of</mark> character, you know and the comedic thing so it's my thought had been like balance <mark>of</mark> Terror Doomsday Machine, but I did show him sitting", "Start Time (s)": 3018.7, "End Time (s)": 3138.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and Neil sits down and looks at it and you just see if I mean, it's a great thing a great horrible horrible great not funny when you're to think <mark>of</mark> it you haven't slept in weeks. An hour, you know navigate because you're trying on a deadline and then it's not so funny. Yeah, as you can probably attest it hot. Yeah. Oh you got jokes. Okay. Okay, you know you mentioned, you know, we always talk about the trouble troubles being, you know, sort <mark>of</mark> a gateway drug for kids. You know, I know your son is 10. My son's 10. His favorite is the Menagerie. He loves a menagerie, you know, he did something but I don't know what I don't know what it is about the Menagerie that he loves so much and it's the magic <mark>of</mark> mixing the earlier crew and the later crew. It's it's really nice to see them sort <mark>of</mark> both <mark>of</mark> the same time in the same episode. You know, we always say in trouble troubles, but I'm not sure trouble troubles is the right Gateway dreams. It's not really a typical Star Trek episode and you get funnier if you know the characters and you get the joy out <mark>of</mark> its fire if you know the character seeing them so out <mark>of</mark> character, you know and the comedic thing so it's my thought had been like balance <mark>of</mark> Terror Doomsday Machine, but I did show him sitting on the trailer because he's a huge War World War II. Yeah, just like going out. I was like a he could he can understood the whole thing. You know, could we kill he really he really liked that a lot to which was which was good kids love the deadly ears really see that's what that is going to look. Like. You said I only hope they can take that old age makeup off with my son. Especially that moment where Kirk walks out <mark>of</mark> the turbolift at the end and takes over. He just loves that moment. So great. That is it's awesome. Yeah, that's how we that's how we feel man should be right, right, you know, and it's emasculated man. It's just Just that is like he comes out <mark>of</mark> that he strides on he is, you know, just totally in command and the testosterone is just dripping all over you. It's like he is, you know, I mean, it's you know, he's been completely emasculated, you know, he's been removed from command and then he comes back and takes over and he's", "Start Time (s)": 3070.0, "End Time (s)": 3189.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "know and the comedic thing so it's my thought had been like balance <mark>of</mark> Terror Doomsday Machine, but I did show him sitting on the trailer because he's a huge War World War II. Yeah, just like going out. I was like a he could he can understood the whole thing. You know, could we kill he really he really liked that a lot to which was which was good kids love the deadly ears really see that's what that is going to look. Like. You said I only hope they can take that old age makeup off with my son. Especially that moment where Kirk walks out <mark>of</mark> the turbolift at the end and takes over. He just loves that moment. So great. That is it's awesome. Yeah, that's how we that's how we feel man should be right, right, you know, and it's emasculated man. It's just Just that is like he comes out <mark>of</mark> that he strides on he is, you know, just totally in command and the testosterone is just dripping all over you. It's like he is, you know, I mean, it's you know, he's been completely emasculated, you know, he's been removed from command and then he comes back and takes over and he's smart and he's on top <mark>of</mark> things and just like code code to I mean that's really come out <mark>of</mark> last for longer than four hours. We talked about, you know on the on our car. I'm on Great Moments in Star Trek, you know two-part thing. We did over the holidays deadly years not a great episode. Right? Right, but that's a great scene as a great mom. It's a great great scene. He was scared to death. So let me ask you your because people are going to ask, you know, or they can ask on social and it's only did the inevitable question. Let's let's head it off at the pass tell us why this is not going to happen on Deep Space Nine and Voyager did the last two shows. Is that have not made the leap the high-def and why that is so complicated and why it's unlikely You'll Never Say Never but why it's unlikely that such a project would happen again. Well, I mean look guys this is this always boils down to this simple equation <mark>of</mark> his the juice worth the squeeze and so, you", "Start Time (s)": 3130.4, "End Time (s)": 3250.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "from command and then he comes back and takes over and he's smart and he's on top <mark>of</mark> things and just like code code to I mean that's really come out <mark>of</mark> last for longer than four hours. We talked about, you know on the on our car. I'm on Great Moments in Star Trek, you know two-part thing. We did over the holidays deadly years not a great episode. Right? Right, but that's a great scene as a great mom. It's a great great scene. He was scared to death. So let me ask you your because people are going to ask, you know, or they can ask on social and it's only did the inevitable question. Let's let's head it off at the pass tell us why this is not going to happen on Deep Space Nine and Voyager did the last two shows. Is that have not made the leap the high-def and why that is so complicated and why it's unlikely You'll Never Say Never but why it's unlikely that such a project would happen again. Well, I mean look guys this is this always boils down to this simple equation <mark>of</mark> his the juice worth the squeeze and so, you know, these these efforts to these are a hundred, you know, it's hundreds <mark>of</mark> episodes for a show and what look what they just went through on Next Generation. Amazing. It looks great, but it didn't sell very well then pay off for them. And also to now go back to them and say so now we'd like you to do it to do it on a show that's even less popular as I Geist. That's like I'd you know, and then Voyager, I mean it just goes down from there. I don't know how they would I thought they made a mistake, you know, obviously, it's not a mistake from a creative point <mark>of</mark> view, but not going one-eight-five with next Generation because people are not going to buy and one three three no matter how good It looks yeah because no one has looked at it there, you know, like will watch it. Right? Like I have that Galactica Blu-ray set <mark>of</mark> the original Galactica where they have both versions. They haven't the original one two, three, and they have a crop for 25. I watch it went 3-3 because I have no problem with the pillar bars. Yeah. Also, I think the cropping is", "Start Time (s)": 3186.1, "End Time (s)": 3305.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Say Never but why it's unlikely that such a project would happen again. Well, I mean look guys this is this always boils down to this simple equation <mark>of</mark> his the juice worth the squeeze and so, you know, these these efforts to these are a hundred, you know, it's hundreds <mark>of</mark> episodes for a show and what look what they just went through on Next Generation. Amazing. It looks great, but it didn't sell very well then pay off for them. And also to now go back to them and say so now we'd like you to do it to do it on a show that's even less popular as I Geist. That's like I'd you know, and then Voyager, I mean it just goes down from there. I don't know how they would I thought they made a mistake, you know, obviously, it's not a mistake from a creative point <mark>of</mark> view, but not going one-eight-five with next Generation because people are not going to buy and one three three no matter how good It looks yeah because no one has looked at it there, you know, like will watch it. Right? Like I have that Galactica Blu-ray set <mark>of</mark> the original Galactica where they have both versions. They haven't the original one two, three, and they have a crop for 25. I watch it went 3-3 because I have no problem with the pillar bars. Yeah. Also, I think the cropping is awful, you know, and but I think for Next Generation, I think it's the only way that or I think the only other way it happens is if CPS pulls it from all the s Von Avon platforms and makes it a S all access exclusive and then they need is sort <mark>of</mark> like what happened with you guys. They need something that makes it new and fresh and then it's funded internally, you know because they can justify it by saying this is exclusive content on our proprietary platform. But as long as it's available everywhere, I don't see that ever happening agree. This is it, you know, it's not like Home Videos going to come and save the day, right? Yeah. Nobody wants to put money into these things, right, you know, everybody wants the upside, but they don't want any <mark>of</mark> the risk, so That's the world only can do is bitch about how much money the studios are making, you know, right right,", "Start Time (s)": 3237.0, "End Time (s)": 3356.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "going to buy and one three three no matter how good It looks yeah because no one has looked at it there, you know, like will watch it. Right? Like I have that Galactica Blu-ray set <mark>of</mark> the original Galactica where they have both versions. They haven't the original one two, three, and they have a crop for 25. I watch it went 3-3 because I have no problem with the pillar bars. Yeah. Also, I think the cropping is awful, you know, and but I think for Next Generation, I think it's the only way that or I think the only other way it happens is if CPS pulls it from all the s Von Avon platforms and makes it a S all access exclusive and then they need is sort <mark>of</mark> like what happened with you guys. They need something that makes it new and fresh and then it's funded internally, you know because they can justify it by saying this is exclusive content on our proprietary platform. But as long as it's available everywhere, I don't see that ever happening agree. This is it, you know, it's not like Home Videos going to come and save the day, right? Yeah. Nobody wants to put money into these things, right, you know, everybody wants the upside, but they don't want any <mark>of</mark> the risk, so That's the world only can do is bitch about how much money the studios are making, you know, right right, so you don't want to do it for 4K. Yeah, sure. Oh that was yeah. Yeah, I mean so so to here so let's say you you finish these in 1080i presume. Yes. So there's no for it's the same for cognitive stuff that happened all Motion Picture, except you guys didn't even do it makes it even more. Yeah because you yeah, so so you would have to go back and redo the assets exist. But CBS digital doesn't exist anymore. Right? No. No. Neither did they do? Okay. Oh, yeah, all those assets are available. Okay. Yeah, it could be done. So what would entail? All to to bump it up to four cat you'd have to re-render. We'd have to read re these. I like Star Trek the money that's a much more complicated. That's a much more complicated thing. But I posit a different idea Darren's available. Well that too.", "Start Time (s)": 3288.5, "End Time (s)": 3406.7, "Clip Length (min)": 1.97, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "can do is bitch about how much money the studios are making, you know, right right, so you don't want to do it for 4K. Yeah, sure. Oh that was yeah. Yeah, I mean so so to here so let's say you you finish these in 1080i presume. Yes. So there's no for it's the same for cognitive stuff that happened all Motion Picture, except you guys didn't even do it makes it even more. Yeah because you yeah, so so you would have to go back and redo the assets exist. But CBS digital doesn't exist anymore. Right? No. No. Neither did they do? Okay. Oh, yeah, all those assets are available. Okay. Yeah, it could be done. So what would entail? All to to bump it up to four cat you'd have to re-render. We'd have to read re these. I like Star Trek the money that's a much more complicated. That's a much more complicated thing. But I posit a different idea Darren's available. Well that too. The Smithsonian display <mark>of</mark> the original Enterprise model. Hmm is not happening for another five years while they redo the exhibit hall. So it's it's in storage issued a live-action play you can shoot all them emotional. I'm just saying that'd be really cool. I'm just saying yeah, because I saw I think you took that footage from the Roddenberry Vault <mark>of</mark> all those Andre composite it and recompile. It looked amazing. It looked amazing. Yeah, I'm just saying you don't have to put metallic shit on this on the ship. Yeah, it's amazing and that's not as lie to you that's cited some other show the only yeah. Yeah. I mean look, I I'd love to see this keep going but it's, you know people in bigger chairs in me and it's you know, it's a big check. Yeah. Right, although I mean the reality is you know, the funny thing is cheaper for them now to put it on 4K with the original <mark>effects</mark> that it would be for them to do what we do all your", "Start Time (s)": 3351.4, "End Time (s)": 3470.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "The Smithsonian display <mark>of</mark> the original Enterprise model. Hmm is not happening for another five years while they redo the exhibit hall. So it's it's in storage issued a live-action play you can shoot all them emotional. I'm just saying that'd be really cool. I'm just saying yeah, because I saw I think you took that footage from the Roddenberry Vault <mark>of</mark> all those Andre composite it and recompile. It looked amazing. It looked amazing. Yeah, I'm just saying you don't have to put metallic shit on this on the ship. Yeah, it's amazing and that's not as lie to you that's cited some other show the only yeah. Yeah. I mean look, I I'd love to see this keep going but it's, you know people in bigger chairs in me and it's you know, it's a big check. Yeah. Right, although I mean the reality is you know, the funny thing is cheaper for them now to put it on 4K with the original <mark>effects</mark> that it would be for them to do what we do all your <mark>effects</mark> which will be it be interesting because I can't imagine that they're not going to want to but it would bore K release ultimately would be the same thing because you would have not much <mark>of</mark> a budget you would have horrific scheduled to hit <mark>of</mark> course and so it you know, the work always kind <mark>of</mark> suffers. I mean we did what we could but even you know, We're immensely proud <mark>of</mark> it and not trying to throw shade on anything. But certainly there are shots that if we would have had time to work on in massage and you know, it just would have been a it could have been elevated to an even anybody who works in this business who looks at their work and says everything was great. It's like they're lying or you know, they should or their store they suck or they actually don't worry in the business because you know one can look at their stuff and say, you know, we didn't. Yeah, we would more time or more money. It could have been better.", "Start Time (s)": 3408.3, "End Time (s)": 3519.3, "Clip Length (min)": 1.85, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "what we do all your <mark>effects</mark> which will be it be interesting because I can't imagine that they're not going to want to but it would bore K release ultimately would be the same thing because you would have not much <mark>of</mark> a budget you would have horrific scheduled to hit <mark>of</mark> course and so it you know, the work always kind <mark>of</mark> suffers. I mean we did what we could but even you know, We're immensely proud <mark>of</mark> it and not trying to throw shade on anything. But certainly there are shots that if we would have had time to work on in massage and you know, it just would have been a it could have been elevated to an even anybody who works in this business who looks at their work and says everything was great. It's like they're lying or you know, they should or their store they suck or they actually don't worry in the business because you know one can look at their stuff and say, you know, we didn't. Yeah, we would more time or more money. It could have been better. Let's face it, you know, so the fact that you could look back and be proud <mark>of</mark> what you did in there's a whole new generation that watches the original Star Trek. It's on you know, all these things. Yeah, there's some remarkable episodes that you guys did. I mean you can be very proud <mark>of</mark> the work you did and you protected it you guys protected it from Interlopers that could have ruined the show forever had they not been protecting what Star Trek. Giz, you know if we if it suddenly become you know for all intensive purposes start to 2009 with the advertisers, you know doing all the stuff. Yeah, yeah and fighter planes and you know all kinds <mark>of</mark> Fighters are the Enterprise doesn't move like an X-Wing, you know, exactly and that's what your that was. Well, you know in space there's no air and that's shut up. Whatever was in the show. That's the science. Yeah. Yeah, right and that was it, you know things like that are hard to to, you know, we had a again on such a short schedule you and you're trying to think. Your head you've got this ship holding 430 people. What does that look like when it gets hit right does it can't shake that fast. It can't you know, everybody be dead inside,", "Start Time (s)": 3469.8, "End Time (s)": 3589.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "know doing all the stuff. Yeah, yeah and fighter planes and you know all kinds <mark>of</mark> Fighters are the Enterprise doesn't move like an X-Wing, you know, exactly and that's what your that was. Well, you know in space there's no air and that's shut up. Whatever was in the show. That's the science. Yeah. Yeah, right and that was it, you know things like that are hard to to, you know, we had a again on such a short schedule you and you're trying to think. Your head you've got this ship holding 430 people. What does that look like when it gets hit right does it can't shake that fast. It can't you know, everybody be dead inside, right? You know, Chris not what the interview that happened. The reality is either they got to give you more money. Are they going to give you more time? Yeah, they can't give you no time and no money again, but they can and they do. Yeah, but the great thing is, you know, there's so many people out there who would Answer the call given time. We just had Bill George on her show. Wonderful, you know Darren, I mean obviously ton <mark>of</mark> people like them who I think you know to be part <mark>of</mark> this history and to you know, this is this is it we're at the end <mark>of</mark> the because let's face it. I mean the original unfortunately is because falling down the line judge <mark>of</mark> shows and now for a lot <mark>of</mark> people next generation is there Jam you see with younger audiences were the subsequent shows and we've talked about this before it was the most popular Star Trek Show on Netflix is Voyager. So it's depressed to dismiss it and we all you know the so worked on it I mean so but but the reality is you know it's like as a younger audience finds he shows it's not necessarily the original that they're embracing right yeah and you got to lead people to it yeah yeah which is you know and as far as like projects Go I mean look I got to I got to play with the Enterprise in a way that you know I mean it was it's the excuse me I regardless this is not this is not explicit show show me where you touch the other thing I would say", "Start Time (s)": 3555.5, "End Time (s)": 3675.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the reality is you know it's like as a younger audience finds he shows it's not necessarily the original that they're embracing right yeah and you got to lead people to it yeah yeah which is you know and as far as like projects Go I mean look I got to I got to play with the Enterprise in a way that you know I mean it was it's the excuse me I regardless this is not this is not explicit show show me where you touch the other thing I would say though I mean I can write because I remember when they brought out the Miniatures at foundation for Darren Star Trek the motion picture unit directors addition it was to hold in your hands touch the create touch it was remarkable it was so I remember when he said you should really come down here I said what a spark dead and he goes no we have them I'm like what do you have because the original miniatures You know and it was for the movies and it was extreme the worker bee the stupid work <mark>of</mark> be it was like so cool. Yeah, so I mean that's what I'm so grateful for about working this industry. It's like you got a call from friends like come down here. It's like we got the Enterprise. Yeah. I mean look, I I stumbled into this business. Yeah in a weird set <mark>of</mark> circumstances that I had. No, my inclination was not to work in this industry and so to look back at At the journey I've taken is just I mean, I know I'm hearing him talk with you. Look if you want to hear more about David's Journey go to listen to the original episode from last season where Dave was here. He talks about his incredible experience, you know coming on board were Next Generation voyageur Enterprise that you know, being there, you know through that amazing period <mark>of</mark> Star Trek history and it's a great episode, you know, being a fan I'd being a fan. I mean it's like, you know, yeah this and look I got to sit and Captain Picard. Karen I got to tour the engine room I guess but none <mark>of</mark> that compares to", "Start Time (s)": 3645.6, "End Time (s)": 3764.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the worker bee the stupid work <mark>of</mark> be it was like so cool. Yeah, so I mean that's what I'm so grateful for about working this industry. It's like you got a call from friends like come down here. It's like we got the Enterprise. Yeah. I mean look, I I stumbled into this business. Yeah in a weird set <mark>of</mark> circumstances that I had. No, my inclination was not to work in this industry and so to look back at At the journey I've taken is just I mean, I know I'm hearing him talk with you. Look if you want to hear more about David's Journey go to listen to the original episode from last season where Dave was here. He talks about his incredible experience, you know coming on board were Next Generation voyageur Enterprise that you know, being there, you know through that amazing period <mark>of</mark> Star Trek history and it's a great episode, you know, being a fan I'd being a fan. I mean it's like, you know, yeah this and look I got to sit and Captain Picard. Karen I got to tour the engine room I guess but none <mark>of</mark> that compares to working on the original series remastered just because it was it's when they say labor <mark>of</mark> love and passion project I mean that yeah it's that in the dictionary that's the picture well Dave this is so great I mean I you know and where we went over on our time I didn't know we would be able to fill in a whole episode and here we are and I kiss your tongue more questions but you know it's people are asking if people are asking seeing people ask you know why why are you always so concerned about time and it's like because you know these are on the electric surge video podcast and those can only be what commercials are only like 50 minutes so it's like we don't like to go over because we have to cut too much out you can still listen the audio podcast but for people are watching it the video versions we lose too much if we go too long so that that is that question and that statement alone will be cut out from so anyway we'll look Dave thank you for joining us again for English tracks words if you're a fan <mark>of</mark> the podcast you may want to check out Researches other podcast like the 4:30 movie every Friday", "Start Time (s)": 3703.4, "End Time (s)": 3822.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "got to sit and Captain Picard. Karen I got to tour the engine room I guess but none <mark>of</mark> that compares to working on the original series remastered just because it was it's when they say labor <mark>of</mark> love and passion project I mean that yeah it's that in the dictionary that's the picture well Dave this is so great I mean I you know and where we went over on our time I didn't know we would be able to fill in a whole episode and here we are and I kiss your tongue more questions but you know it's people are asking if people are asking seeing people ask you know why why are you always so concerned about time and it's like because you know these are on the electric surge video podcast and those can only be what commercials are only like 50 minutes so it's like we don't like to go over because we have to cut too much out you can still listen the audio podcast but for people are watching it the video versions we lose too much if we go too long so that that is that question and that statement alone will be cut out from so anyway we'll look Dave thank you for joining us again for English tracks words if you're a fan <mark>of</mark> the podcast you may want to check out Researches other podcast like the 4:30 movie every Friday Rev on the road to Star Wars podcast every Tuesday coming soon the to on who the new Doctor Who podcast and <mark>of</mark> course best movies ever made every other Monday. You can also watch our video podcast <mark>of</mark> all your favorite electric surge podcasts and electric now download the stirred distro TV or Zumo apps and soon the electric now app. Also if you enjoyed this podcast, please write as 5 stars and apple podcast, you know, and look if you want to see the visual <mark>effects</mark> in 4k Who should they who should they harass? Yeah, everybody everybody everybody. Yes everybody and thanks to Bill Ritter and everyone here at electric surge Network including producer now, we miss Kelly who suffers through our talk about track every week and we're grateful to her for that. And <mark>of</mark> course Dean Devlin without whom the show would not be possible so until next week,", "Start Time (s)": 3758.6, "End Time (s)": 3877.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "so anyway we'll look Dave thank you for joining us again for English tracks words if you're a fan <mark>of</mark> the podcast you may want to check out Researches other podcast like the 4:30 movie every Friday Rev on the road to Star Wars podcast every Tuesday coming soon the to on who the new Doctor Who podcast and <mark>of</mark> course best movies ever made every other Monday. You can also watch our video podcast <mark>of</mark> all your favorite electric surge podcasts and electric now download the stirred distro TV or Zumo apps and soon the electric now app. Also if you enjoyed this podcast, please write as 5 stars and apple podcast, you know, and look if you want to see the visual <mark>effects</mark> in 4k Who should they who should they harass? Yeah, everybody everybody everybody. Yes everybody and thanks to Bill Ritter and everyone here at electric surge Network including producer now, we miss Kelly who suffers through our talk about track every week and we're grateful to her for that. And <mark>of</mark> course Dean Devlin without whom the show would not be possible so until next week, keep on trekking in gloriously, <mark>of</mark> course engage This show is produced by Dean Devlin and Mark a Altman and is an electric surge Network production.", "Start Time (s)": 3814.4, "End Time (s)": 3925.9, "Clip Length (min)": 1.86, "show_uri": "spotify:show:6Z8atrr275PyoWXxGzdAdr", "show_name": "INGLORIOUS TREKSPERTS", "show_description": "Legendary Treksperts MARK A. ALTMAN (showrunner of the hit CW sci-fi series Pandora, author of the bestselling The Fifty-Year Mission, writer/producer Free Enterprise) and DAREN DOCHTERMAN (visual effects supervisor of Star Trek: The Motion Picture - Director's Edition) examine five decades of STAR TREK every Saturday along with special guests from across the Trek universe. Available wherever you listen to podcasts and on the free ELECTRIC NOW streaming app. @inglorioustrek on Twitter.   #StarTrek #TOS #TNG #DS9 #Voy #Ent #Disco #Picard #TAS #BSG #TheOrville #PandoraCW #Section31", "publisher": "Electric Surge Network", "episode_uri": "spotify:episode:6j5KdEv6sWy842SxYzFDbM", "episode_name": "THE RE-MAKING OF STAR TREK w/ DAVE ROSSI", "episode_description": "Over a decade ago, STAR TREK: THE ORIGINAL SERIES got a digital make-over with all-new visual effects. Now learn how and why it happened and the challenge of re-imagining Trek with producer DAVID ROSSI. Also featuring special geust writer/producer ASHLEY E. MILLER (writer; Thor, X-Men: First Class), Find out how STAR TREK got a brand new look and what it took to revisit the groundbreaking visual effects.\u00a0 Follow us on Twitter at @inglorioustrek, Instagram at @inglorioustreksperts and on Facebook at Electric Surge. Now you can watch INGLORIOUS TREKSPERTS and all your favorite Electric Surge podcasts on the Electric Now! streaming channel available on Stirr, Xumo and Distro TV and now on the free Electric Now app. Don't miss TWO ON WHO, the new Dr. Who podcast every other Thursday, now available wherever you listen to podcasts. #TOS #TNG #DS9 #VOY #ENT #StarTrekPicard #DISCO #LLAP ", "score": 5.059113, "explanation": "{\n  \"value\": 5.059113,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 3.9941494,\n      \"description\": \"weight(word_list:effects in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.9941494,\n          \"description\": \"score(LMDirichletSimilarity, freq=23.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 5.9621005,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 23.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.968315e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.968315e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.08111812,\n      \"description\": \"weight(word_list:of in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.08111812,\n          \"description\": \"score(LMDirichletSimilarity, freq=240.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0490694,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 240.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.9838455,\n      \"description\": \"weight(word_list:global in 10) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.9838455,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9517965,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 2.7562925e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.9679512,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 12312.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.7562925e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Hi and welcome to the law <mark>of</mark> positivism podcast. I'm your host to read and I'm the creator <mark>of</mark> Love positivism. I'm here to help you on your spiritual and healing journey. I am a certified yoga and meditation teacher a student <mark>of</mark> Chinese medicine a doula a Reiki practitioner and a passionate highly sensitive person. I want to use my knowledge. To channel information and messages for you to grow on all levels. Hi and welcome to this week's episode today. We will be doing meditation together which will ground you down into your body and also help you just become present and mindful In This Moment come into your body. And to just feel how you're feeling right", "Start Time (s)": 4.9, "End Time (s)": 66.3, "Clip Length (min)": 1.02, "show_uri": "spotify:show:0FspiIgx9NSCgOLcye5Dhs", "show_name": "Law of Positivism", "show_description": "A podcast that supports you on your spiritual and healing journey through uplifting and educational episodes.   I cover topics around spirituality, yoga, meditation, HSP, empathy, healing and so much more. Through inspiring guest I wish to enlighten you on your path.    Cover art by @amanda.lynn.hails ", "publisher": "Shereen \u00d6berg", "episode_uri": "spotify:episode:6FgJGwC3GFlWIMDRoFgcIA", "episode_name": "22. Guided Meditation: Grounding", "episode_description": "In this week\u2019s episode I will guide you through a meditation that is grounding and helping you to shift your awareness into your body, energy and sensations. This guided meditation can be listened to in the morning when you have just woken up, during the day to relax and take a break or in the evening before going to bed. Meditation is an ancient science and it is a great way to reach a higher state of awareness and consciousness. So take the time to relax and try this meditation, even if it\u2019s your very first time meditating. Visit Law of Positivism: Instagram: https://www.instagram.com/law_of_positivism/ Website: https://www.lawofpositivism.com/ Facebook: https://www.facebook.com/lawofpositivism/ ", "score": 4.5657067, "explanation": "{\n  \"value\": 4.5657067,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.37205422,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5657067,\n      \"description\": \"weight(word_list:warming in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5657067,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "feeling without labeling and take a deep breath in. And exhale through your mouth and release down even deeper. Take a deep inhale through your nose again and exhale through your mouth and dive deeper into yourself. and one more time inhale new energy into your body and exhale what no longer strengthens you were in Paris you And feel how weight is lifting off your body. And how you become more and more aware <mark>of</mark> the sensations in your body. Feel a deep relaxation from the top <mark>of</mark> your head your crown pouring down and relaxing your forehead and your eyebrows your eyes and eyelids your cheeks mouth and tongue. and Jaws feel how the relaxing sensation continues down to your throat shoulders your chest and your heart. Feel how it releases any tensions around your heart. And how", "Start Time (s)": 159.1, "End Time (s)": 277.2, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0FspiIgx9NSCgOLcye5Dhs", "show_name": "Law of Positivism", "show_description": "A podcast that supports you on your spiritual and healing journey through uplifting and educational episodes.   I cover topics around spirituality, yoga, meditation, HSP, empathy, healing and so much more. Through inspiring guest I wish to enlighten you on your path.    Cover art by @amanda.lynn.hails ", "publisher": "Shereen \u00d6berg", "episode_uri": "spotify:episode:6FgJGwC3GFlWIMDRoFgcIA", "episode_name": "22. Guided Meditation: Grounding", "episode_description": "In this week\u2019s episode I will guide you through a meditation that is grounding and helping you to shift your awareness into your body, energy and sensations. This guided meditation can be listened to in the morning when you have just woken up, during the day to relax and take a break or in the evening before going to bed. Meditation is an ancient science and it is a great way to reach a higher state of awareness and consciousness. So take the time to relax and try this meditation, even if it\u2019s your very first time meditating. Visit Law of Positivism: Instagram: https://www.instagram.com/law_of_positivism/ Website: https://www.lawofpositivism.com/ Facebook: https://www.facebook.com/lawofpositivism/ ", "score": 4.5657067, "explanation": "{\n  \"value\": 4.5657067,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.37205422,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5657067,\n      \"description\": \"weight(word_list:warming in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5657067,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "your cheeks mouth and tongue. and Jaws feel how the relaxing sensation continues down to your throat shoulders your chest and your heart. Feel how it releases any tensions around your heart. And how it starts opening up your heart. Feel the energy from the heart moving out into your arms into your hands and fingers and feel how your palms feel right now. Feel the energy that is flowing in and out <mark>of</mark> your palms energy that is flowing in through your palms are moving in towards your heart. And from your heart energy flows out through your palms as healing <mark>warming</mark> energy. Feel how you relax through your ribs and your whole stomach. Your whole back and your whole spine. Relax your hips. Your pelvis your thighs your knees your calves. Shin bones", "Start Time (s)": 247.0, "End Time (s)": 362.9, "Clip Length (min)": 1.93, "show_uri": "spotify:show:0FspiIgx9NSCgOLcye5Dhs", "show_name": "Law of Positivism", "show_description": "A podcast that supports you on your spiritual and healing journey through uplifting and educational episodes.   I cover topics around spirituality, yoga, meditation, HSP, empathy, healing and so much more. Through inspiring guest I wish to enlighten you on your path.    Cover art by @amanda.lynn.hails ", "publisher": "Shereen \u00d6berg", "episode_uri": "spotify:episode:6FgJGwC3GFlWIMDRoFgcIA", "episode_name": "22. Guided Meditation: Grounding", "episode_description": "In this week\u2019s episode I will guide you through a meditation that is grounding and helping you to shift your awareness into your body, energy and sensations. This guided meditation can be listened to in the morning when you have just woken up, during the day to relax and take a break or in the evening before going to bed. Meditation is an ancient science and it is a great way to reach a higher state of awareness and consciousness. So take the time to relax and try this meditation, even if it\u2019s your very first time meditating. Visit Law of Positivism: Instagram: https://www.instagram.com/law_of_positivism/ Website: https://www.lawofpositivism.com/ Facebook: https://www.facebook.com/lawofpositivism/ ", "score": 4.5657067, "explanation": "{\n  \"value\": 4.5657067,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.37205422,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5657067,\n      \"description\": \"weight(word_list:warming in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5657067,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in towards your heart. And from your heart energy flows out through your palms as healing <mark>warming</mark> energy. Feel how you relax through your ribs and your whole stomach. Your whole back and your whole spine. Relax your hips. Your pelvis your thighs your knees your calves. Shin bones your feet and your toes and feel the energy and sensation in the soles <mark>of</mark> your feet. Feel the energy that is Flowing from the center <mark>of</mark> the earth into your body. Feed our energy is pouring out and down through your feet into the core <mark>of</mark> Earth. You are interconnected. You're safe and grounded right now and always. Feel how your entire body is totally relaxed feel the weight under your body", "Start Time (s)": 314.7, "End Time (s)": 433.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0FspiIgx9NSCgOLcye5Dhs", "show_name": "Law of Positivism", "show_description": "A podcast that supports you on your spiritual and healing journey through uplifting and educational episodes.   I cover topics around spirituality, yoga, meditation, HSP, empathy, healing and so much more. Through inspiring guest I wish to enlighten you on your path.    Cover art by @amanda.lynn.hails ", "publisher": "Shereen \u00d6berg", "episode_uri": "spotify:episode:6FgJGwC3GFlWIMDRoFgcIA", "episode_name": "22. Guided Meditation: Grounding", "episode_description": "In this week\u2019s episode I will guide you through a meditation that is grounding and helping you to shift your awareness into your body, energy and sensations. This guided meditation can be listened to in the morning when you have just woken up, during the day to relax and take a break or in the evening before going to bed. Meditation is an ancient science and it is a great way to reach a higher state of awareness and consciousness. So take the time to relax and try this meditation, even if it\u2019s your very first time meditating. Visit Law of Positivism: Instagram: https://www.instagram.com/law_of_positivism/ Website: https://www.lawofpositivism.com/ Facebook: https://www.facebook.com/lawofpositivism/ ", "score": 4.5657067, "explanation": "{\n  \"value\": 4.5657067,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.37205422,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5657067,\n      \"description\": \"weight(word_list:warming in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5657067,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "You're safe and grounded right now and always. Feel how your entire body is totally relaxed feel the weight under your body and feel how the Earth is holding you up keeping you safe and grounded nurtured and loved always. Feel the sensation on your skin from the air around your body. And if a thought comes up Let it float away on a leaf in a stream <mark>of</mark> water. And just notice how the breath is moving in and out from your nose. Notice where the breath goes in your body. And how it feels when you're breathing in and out naturally. Release with every exhalation tensions that are still left in the body that exhalation release and softened the body.", "Start Time (s)": 407.0, "End Time (s)": 524.8, "Clip Length (min)": 1.96, "show_uri": "spotify:show:0FspiIgx9NSCgOLcye5Dhs", "show_name": "Law of Positivism", "show_description": "A podcast that supports you on your spiritual and healing journey through uplifting and educational episodes.   I cover topics around spirituality, yoga, meditation, HSP, empathy, healing and so much more. Through inspiring guest I wish to enlighten you on your path.    Cover art by @amanda.lynn.hails ", "publisher": "Shereen \u00d6berg", "episode_uri": "spotify:episode:6FgJGwC3GFlWIMDRoFgcIA", "episode_name": "22. Guided Meditation: Grounding", "episode_description": "In this week\u2019s episode I will guide you through a meditation that is grounding and helping you to shift your awareness into your body, energy and sensations. This guided meditation can be listened to in the morning when you have just woken up, during the day to relax and take a break or in the evening before going to bed. Meditation is an ancient science and it is a great way to reach a higher state of awareness and consciousness. So take the time to relax and try this meditation, even if it\u2019s your very first time meditating. Visit Law of Positivism: Instagram: https://www.instagram.com/law_of_positivism/ Website: https://www.lawofpositivism.com/ Facebook: https://www.facebook.com/lawofpositivism/ ", "score": 4.5657067, "explanation": "{\n  \"value\": 4.5657067,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.37205422,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5657067,\n      \"description\": \"weight(word_list:warming in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5657067,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "from your nose. Notice where the breath goes in your body. And how it feels when you're breathing in and out naturally. Release with every exhalation tensions that are still left in the body that exhalation release and softened the body. imagine How you're connected? through energy frequencies to the core <mark>of</mark> the earth and you can see how the core <mark>of</mark> the earth is a giant crystal that is just emitting energy and light to your body strengthening you healing you Keeping you safe and grounded right here. And right now you are safe and you are loved. And just feel the sensations within your body the crown <mark>of</mark> your head how it's opening up like", "Start Time (s)": 478.5, "End Time (s)": 597.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0FspiIgx9NSCgOLcye5Dhs", "show_name": "Law of Positivism", "show_description": "A podcast that supports you on your spiritual and healing journey through uplifting and educational episodes.   I cover topics around spirituality, yoga, meditation, HSP, empathy, healing and so much more. Through inspiring guest I wish to enlighten you on your path.    Cover art by @amanda.lynn.hails ", "publisher": "Shereen \u00d6berg", "episode_uri": "spotify:episode:6FgJGwC3GFlWIMDRoFgcIA", "episode_name": "22. Guided Meditation: Grounding", "episode_description": "In this week\u2019s episode I will guide you through a meditation that is grounding and helping you to shift your awareness into your body, energy and sensations. This guided meditation can be listened to in the morning when you have just woken up, during the day to relax and take a break or in the evening before going to bed. Meditation is an ancient science and it is a great way to reach a higher state of awareness and consciousness. So take the time to relax and try this meditation, even if it\u2019s your very first time meditating. Visit Law of Positivism: Instagram: https://www.instagram.com/law_of_positivism/ Website: https://www.lawofpositivism.com/ Facebook: https://www.facebook.com/lawofpositivism/ ", "score": 4.5657067, "explanation": "{\n  \"value\": 4.5657067,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.37205422,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5657067,\n      \"description\": \"weight(word_list:warming in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5657067,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "energy frequencies to the core <mark>of</mark> the earth and you can see how the core <mark>of</mark> the earth is a giant crystal that is just emitting energy and light to your body strengthening you healing you Keeping you safe and grounded right here. And right now you are safe and you are loved. And just feel the sensations within your body the crown <mark>of</mark> your head how it's opening up like a lotus flower receiving energy that is divine from the universe. Feel how your third eye is feeling how it brings you Clarity visions and dreams. Feel the energy in your throat and neck. the channel for truth feel how your heart feels the seat for unconditional love and healing. Feel your solar plexus your energy and drive. Field energy below your navel the seat <mark>of</mark> creation", "Start Time (s)": 534.0, "End Time (s)": 652.3, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0FspiIgx9NSCgOLcye5Dhs", "show_name": "Law of Positivism", "show_description": "A podcast that supports you on your spiritual and healing journey through uplifting and educational episodes.   I cover topics around spirituality, yoga, meditation, HSP, empathy, healing and so much more. Through inspiring guest I wish to enlighten you on your path.    Cover art by @amanda.lynn.hails ", "publisher": "Shereen \u00d6berg", "episode_uri": "spotify:episode:6FgJGwC3GFlWIMDRoFgcIA", "episode_name": "22. Guided Meditation: Grounding", "episode_description": "In this week\u2019s episode I will guide you through a meditation that is grounding and helping you to shift your awareness into your body, energy and sensations. This guided meditation can be listened to in the morning when you have just woken up, during the day to relax and take a break or in the evening before going to bed. Meditation is an ancient science and it is a great way to reach a higher state of awareness and consciousness. So take the time to relax and try this meditation, even if it\u2019s your very first time meditating. Visit Law of Positivism: Instagram: https://www.instagram.com/law_of_positivism/ Website: https://www.lawofpositivism.com/ Facebook: https://www.facebook.com/lawofpositivism/ ", "score": 4.5657067, "explanation": "{\n  \"value\": 4.5657067,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.37205422,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5657067,\n      \"description\": \"weight(word_list:warming in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5657067,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "within your body the crown <mark>of</mark> your head how it's opening up like a lotus flower receiving energy that is divine from the universe. Feel how your third eye is feeling how it brings you Clarity visions and dreams. Feel the energy in your throat and neck. the channel for truth feel how your heart feels the seat for unconditional love and healing. Feel your solar plexus your energy and drive. Field energy below your navel the seat <mark>of</mark> creation creativity sensuality. And feel the bottom <mark>of</mark> your spine your pelvis your route, which grounds you down into your body and onto this Earth and feel how energy is flowing through all <mark>of</mark> these chakras. energy Williams and how the colors red orange yellow green blue indigo blue and a white bright light is infusing throughout your whole body surrounding you and your aura. And", "Start Time (s)": 591.1, "End Time (s)": 710.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0FspiIgx9NSCgOLcye5Dhs", "show_name": "Law of Positivism", "show_description": "A podcast that supports you on your spiritual and healing journey through uplifting and educational episodes.   I cover topics around spirituality, yoga, meditation, HSP, empathy, healing and so much more. Through inspiring guest I wish to enlighten you on your path.    Cover art by @amanda.lynn.hails ", "publisher": "Shereen \u00d6berg", "episode_uri": "spotify:episode:6FgJGwC3GFlWIMDRoFgcIA", "episode_name": "22. Guided Meditation: Grounding", "episode_description": "In this week\u2019s episode I will guide you through a meditation that is grounding and helping you to shift your awareness into your body, energy and sensations. This guided meditation can be listened to in the morning when you have just woken up, during the day to relax and take a break or in the evening before going to bed. Meditation is an ancient science and it is a great way to reach a higher state of awareness and consciousness. So take the time to relax and try this meditation, even if it\u2019s your very first time meditating. Visit Law of Positivism: Instagram: https://www.instagram.com/law_of_positivism/ Website: https://www.lawofpositivism.com/ Facebook: https://www.facebook.com/lawofpositivism/ ", "score": 4.5657067, "explanation": "{\n  \"value\": 4.5657067,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:of in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.37205422,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.017749708,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.017749708,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 4.5657067,\n      \"description\": \"weight(word_list:warming in 17) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 4.5657067,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 4.9441433,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.588073e-06,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.37843645,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 920.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.588073e-06,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}]}