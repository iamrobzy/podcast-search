{"query": "How to become rich", "clip_length": 2, "selected_index": "LM Dirichlet", "results": [{"Clip Text": "You have not heard about anger. It's the easiest way <mark>to</mark> make a podcast. Let me explain. It's a proof. There are certain tools that allow you <mark>to</mark> record and edit your podcast, right you're from phone or computer anchor will distribute your podcast for you. So it can be heard on Spotify Apple podcast and many more you can make money from your podcast with no minimum listenership. It's everything you need <mark>to</mark> make a podcast in one place. Is arranged marriage a scary proposition last year three of my friends had terrible experiences involving arranged marriage in the first experience. The two parties are engaged and right before the wedding the girl told him that she loves somebody else in the second experience as a wedding date approached the girl ran away with her boyfriend in the third experience the two parties got married, but within a month my friend found out that she was still in touch with her ex-boyfriend and probably had an affair and asked he filed for divorce right away. Such experience has made me wonder what are the reasons that make people go for an arranged matters on man. One insights what the guy's profile generally says, the girl should have family", "Start Time (s)": 0.2, "End Time (s)": 63.4, "Clip Length (min)": 1.05, "show_uri": "spotify:show:5h42scKiyHFq2RnQkZOLwJ", "show_name": "Mensutra", "show_description": "If you are reading this, well, for you this is not just a Podcast, this is a community. When you click on the Follow button, you make this community, this group of glorious, victorious beings a little more stronger and better. And for doing that, on behalf of all my bros, I tip my hat to you, my friend.", "publisher": "Shwetabh Gangwar", "episode_uri": "spotify:episode:735G0Pf2AwY7rSRCmevY5s", "episode_name": "Listen This before Saying Yes To Arranged Marriage By Shwetabh Gangwar", "episode_description": "Why do people go for an arrange marriage?\u00a0 \u00a0This video tackles this question from every perspective it can, and also finally tries to answer the question, Why should two people marry each other?\u00a0 \u00a0\u00a0Written by Shwetabh Gangwar\u00a0 Message me on FB: https://www.facebook.com/mensutra Tweet me: https://www.twitter.com/mensutra\u00a0 Music: Big Bird's Date Night (Full) by Twin Musicom 1. It won't be easy: 2. Meetings can be bad and good: 3. There can be unrealistic expectations: 4. Pressure can be high: 5. Love takes time to enter: 6. It's beneficial for the couple not to hide your past: 7. Say yes, only when you are satisfied:  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app ", "score": 4.599193, "explanation": "{\n  \"value\": 4.599193,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.5807861,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.014276303,\n      \"description\": \"weight(word_list:to in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.014276303,\n          \"description\": \"score(LMDirichletSimilarity, freq=51.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6603319,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 51.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5672904,\n      \"description\": \"weight(word_list:become in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5672904,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.0176265,\n      \"description\": \"weight(word_list:rich in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0176265,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you need <mark>to</mark> make a podcast in one place. Is arranged marriage a scary proposition last year three of my friends had terrible experiences involving arranged marriage in the first experience. The two parties are engaged and right before the wedding the girl told him that she loves somebody else in the second experience as a wedding date approached the girl ran away with her boyfriend in the third experience the two parties got married, but within a month my friend found out that she was still in touch with her ex-boyfriend and probably had an affair and asked he filed for divorce right away. Such experience has made me wonder what are the reasons that make people go for an arranged matters on man. One insights what the guy's profile generally says, the girl should have family values be educated pretty kind religious traditional and so on and in the girls profiles important stuff mostly is money. We stable smart caring kind understanding and so forth. Now this is the broader picture everybody knows about but what goes into the minds of the two people involved the truth is both the parties have a list of imaginary expectations and their heads in my opinion. This is very scary because you're expecting from a stranger. Of course, you get a talk <mark>to</mark> them before actually deciding <mark>to</mark> marry or not. But the fact is it takes here. Ears <mark>to</mark> actually know someone for who they really are like the famous saying goes there are three personalities and a man first who he thinks he is second. We want you <mark>to</mark> think he is and third who he actually is and when he meets someone new people rarely show you who they really are and focus on showing the other two personalities. So when two strangers talk what they actually do is they emphasize on impressing each other think about if you're talking <mark>to</mark> a girl for the first time would you actually share your secrets defeats insecurities imperfections your temper you're drinking or smoking? Are you talking about yourself in a way that would make her think you're a cool guy. Basically when you talk <mark>to</mark> a girl before marriage unconsciously impress her which is very similar <mark>to</mark> the process when you meet a hot girl for the first time, but what you don't realize is he's going <mark>to</mark> be your wife, even though you're consciously aware of it. Here is an overview of some of the bizarre divorce cases Vikram was so busy with work that he could not find time <mark>to</mark> be intimate with his wife as much as she wanted <mark>to</mark> although he was an", "Start Time (s)": 26.6, "End Time (s)": 146.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5h42scKiyHFq2RnQkZOLwJ", "show_name": "Mensutra", "show_description": "If you are reading this, well, for you this is not just a Podcast, this is a community. When you click on the Follow button, you make this community, this group of glorious, victorious beings a little more stronger and better. And for doing that, on behalf of all my bros, I tip my hat to you, my friend.", "publisher": "Shwetabh Gangwar", "episode_uri": "spotify:episode:735G0Pf2AwY7rSRCmevY5s", "episode_name": "Listen This before Saying Yes To Arranged Marriage By Shwetabh Gangwar", "episode_description": "Why do people go for an arrange marriage?\u00a0 \u00a0This video tackles this question from every perspective it can, and also finally tries to answer the question, Why should two people marry each other?\u00a0 \u00a0\u00a0Written by Shwetabh Gangwar\u00a0 Message me on FB: https://www.facebook.com/mensutra Tweet me: https://www.twitter.com/mensutra\u00a0 Music: Big Bird's Date Night (Full) by Twin Musicom 1. It won't be easy: 2. Meetings can be bad and good: 3. There can be unrealistic expectations: 4. Pressure can be high: 5. Love takes time to enter: 6. It's beneficial for the couple not to hide your past: 7. Say yes, only when you are satisfied:  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app ", "score": 4.599193, "explanation": "{\n  \"value\": 4.599193,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.5807861,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.014276303,\n      \"description\": \"weight(word_list:to in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.014276303,\n          \"description\": \"score(LMDirichletSimilarity, freq=51.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6603319,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 51.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5672904,\n      \"description\": \"weight(word_list:become in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5672904,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.0176265,\n      \"description\": \"weight(word_list:rich in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0176265,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "scary because you're expecting from a stranger. Of course, you get a talk <mark>to</mark> them before actually deciding <mark>to</mark> marry or not. But the fact is it takes here. Ears <mark>to</mark> actually know someone for who they really are like the famous saying goes there are three personalities and a man first who he thinks he is second. We want you <mark>to</mark> think he is and third who he actually is and when he meets someone new people rarely show you who they really are and focus on showing the other two personalities. So when two strangers talk what they actually do is they emphasize on impressing each other think about if you're talking <mark>to</mark> a girl for the first time would you actually share your secrets defeats insecurities imperfections your temper you're drinking or smoking? Are you talking about yourself in a way that would make her think you're a cool guy. Basically when you talk <mark>to</mark> a girl before marriage unconsciously impress her which is very similar <mark>to</mark> the process when you meet a hot girl for the first time, but what you don't realize is he's going <mark>to</mark> be your wife, even though you're consciously aware of it. Here is an overview of some of the bizarre divorce cases Vikram was so busy with work that he could not find time <mark>to</mark> be intimate with his wife as much as she wanted <mark>to</mark> although he was an impotent they filed for divorce in three months. This is one clear example of what I'm talking about you. Don't talk about <mark>how</mark> much sex you want or in ways. You would want it with a stranger before getting married in the second case rummy who's a Defence Personnel found out of the marriage that his wife always wanted <mark>to</mark> marry a businessman. He immediately filed for divorce again if you wanted <mark>to</mark> marry a businessman, why did she marry a guy who would half of the time we post it somewhere else in another case? They just found out in three months of his marriage that his wife had a pre-existing affair with a married man. He recalls. She was always a little secretive and would never leave her phone unattended now not trying <mark>to</mark> And the blame on women because in most of the cases when certain conservative parents of girls find out that she's having an affair. They don't approve of the immediate response <mark>to</mark> that situation has get her married ASAP. And that is a very dangerous thing first. There is no guarantee should be over that guy second. There are huge challenges that the fair might rekindle after the marriage third you're rooting for the guy's life based on your stupid prejudices or high salary", "Start Time (s)": 82.9, "End Time (s)": 202.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5h42scKiyHFq2RnQkZOLwJ", "show_name": "Mensutra", "show_description": "If you are reading this, well, for you this is not just a Podcast, this is a community. When you click on the Follow button, you make this community, this group of glorious, victorious beings a little more stronger and better. And for doing that, on behalf of all my bros, I tip my hat to you, my friend.", "publisher": "Shwetabh Gangwar", "episode_uri": "spotify:episode:735G0Pf2AwY7rSRCmevY5s", "episode_name": "Listen This before Saying Yes To Arranged Marriage By Shwetabh Gangwar", "episode_description": "Why do people go for an arrange marriage?\u00a0 \u00a0This video tackles this question from every perspective it can, and also finally tries to answer the question, Why should two people marry each other?\u00a0 \u00a0\u00a0Written by Shwetabh Gangwar\u00a0 Message me on FB: https://www.facebook.com/mensutra Tweet me: https://www.twitter.com/mensutra\u00a0 Music: Big Bird's Date Night (Full) by Twin Musicom 1. It won't be easy: 2. Meetings can be bad and good: 3. There can be unrealistic expectations: 4. Pressure can be high: 5. Love takes time to enter: 6. It's beneficial for the couple not to hide your past: 7. Say yes, only when you are satisfied:  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app ", "score": 4.599193, "explanation": "{\n  \"value\": 4.599193,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.5807861,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.014276303,\n      \"description\": \"weight(word_list:to in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.014276303,\n          \"description\": \"score(LMDirichletSimilarity, freq=51.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6603319,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 51.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5672904,\n      \"description\": \"weight(word_list:become in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5672904,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.0176265,\n      \"description\": \"weight(word_list:rich in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0176265,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a little secretive and would never leave her phone unattended now not trying <mark>to</mark> And the blame on women because in most of the cases when certain conservative parents of girls find out that she's having an affair. They don't approve of the immediate response <mark>to</mark> that situation has get her married ASAP. And that is a very dangerous thing first. There is no guarantee should be over that guy second. There are huge challenges that the fair might rekindle after the marriage third you're rooting for the guy's life based on your stupid prejudices or high salary expectations. Now, let's talk about the divorce rates Family Court officials say that the number of diverse applications have doubled and even tripled in major cities over the past. five years more than 11,000 cases were filed in Mumbai, which is above 50 percent increase in the last four years polka dots around 8,000 cases, which is a 350 percent increase in a decade about 2,000 cases of file in Lucknow and 900 of them were young couples married less than a year The Advocates and the marriage dancers have cited certain reasons behind his growing number of divorce rate amongst young couples such as jealousy independence of women and evil now that is a very not an interpretation <mark>to</mark> say it's the ego rather than saying they are not compatible and it's because the men Our dear friend in marriage is founded upon the very idea of compromise. The thing that actually happens is when you live with someone for a year, you actually find quite a number of things or habits about each other that you cannot tolerate these things may range from basic hygiene <mark>to</mark> silly habits <mark>to</mark> likes and dislikes sense of humor choices and movies music books <mark>to</mark> fashion and lifestyle basically marriage isn't about showing each other <mark>how</mark> cool we are before the wedding making a promise or spending your entire life together with that person and <mark>to</mark> maintain that you must know everything about the behavioral patterns and habits. Girls find out that their husbands are jealous of other guys. So they don't approve of the clothes they wear and most guys get pissed off and the right said I want <mark>to</mark> do whatever I feel like doing hashtag my choice. Well, that's because you married a stranger you really thought you were going <mark>to</mark> tell you everything about her path and the two weeks of your conversation now some people get divorced but there's a huge population of guys and girls who follow the Indian traditional rule of marriage, which is even if the marriage is tedious monotonous Loveless and boring as", "Start Time (s)": 176.3, "End Time (s)": 296.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5h42scKiyHFq2RnQkZOLwJ", "show_name": "Mensutra", "show_description": "If you are reading this, well, for you this is not just a Podcast, this is a community. When you click on the Follow button, you make this community, this group of glorious, victorious beings a little more stronger and better. And for doing that, on behalf of all my bros, I tip my hat to you, my friend.", "publisher": "Shwetabh Gangwar", "episode_uri": "spotify:episode:735G0Pf2AwY7rSRCmevY5s", "episode_name": "Listen This before Saying Yes To Arranged Marriage By Shwetabh Gangwar", "episode_description": "Why do people go for an arrange marriage?\u00a0 \u00a0This video tackles this question from every perspective it can, and also finally tries to answer the question, Why should two people marry each other?\u00a0 \u00a0\u00a0Written by Shwetabh Gangwar\u00a0 Message me on FB: https://www.facebook.com/mensutra Tweet me: https://www.twitter.com/mensutra\u00a0 Music: Big Bird's Date Night (Full) by Twin Musicom 1. It won't be easy: 2. Meetings can be bad and good: 3. There can be unrealistic expectations: 4. Pressure can be high: 5. Love takes time to enter: 6. It's beneficial for the couple not to hide your past: 7. Say yes, only when you are satisfied:  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app ", "score": 4.599193, "explanation": "{\n  \"value\": 4.599193,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.5807861,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.014276303,\n      \"description\": \"weight(word_list:to in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.014276303,\n          \"description\": \"score(LMDirichletSimilarity, freq=51.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6603319,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 51.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5672904,\n      \"description\": \"weight(word_list:become in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5672904,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.0176265,\n      \"description\": \"weight(word_list:rich in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0176265,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and it's because the men Our dear friend in marriage is founded upon the very idea of compromise. The thing that actually happens is when you live with someone for a year, you actually find quite a number of things or habits about each other that you cannot tolerate these things may range from basic hygiene <mark>to</mark> silly habits <mark>to</mark> likes and dislikes sense of humor choices and movies music books <mark>to</mark> fashion and lifestyle basically marriage isn't about showing each other <mark>how</mark> cool we are before the wedding making a promise or spending your entire life together with that person and <mark>to</mark> maintain that you must know everything about the behavioral patterns and habits. Girls find out that their husbands are jealous of other guys. So they don't approve of the clothes they wear and most guys get pissed off and the right said I want <mark>to</mark> do whatever I feel like doing hashtag my choice. Well, that's because you married a stranger you really thought you were going <mark>to</mark> tell you everything about her path and the two weeks of your conversation now some people get divorced but there's a huge population of guys and girls who follow the Indian traditional rule of marriage, which is even if the marriage is tedious monotonous Loveless and boring as hell. You can't leave people stick <mark>to</mark> Loveless marriages no matter Lat and most of the times it's because they have kids and I understand that. I'm not urging you <mark>to</mark> leave. I'm talking about the root of the problem because in case you are in a Loveless marriage your entire life becomes sad, so what do people do when they find themselves stuck in Loveless marriages, they can't contain any more they cheat and in women and apparently arranged marriage is flooded the extramarital Affairs website Ashley Madison within only a few days of its launch in India arranging Affairs for arranged marriages in India has resulted in more than 50,000 users signing up within two days of a I'll launch with female members representing more than half of the signups. Here's another story when the 60 year old man approached the court seeking a paternity test. He found that his only daughter was not his biological child a test. Not only devastated the father and the daughter but also led <mark>to</mark> the end of the marriage according <mark>to</mark> investigating agencies and the Judiciary could rather courts more than 250 paternity test annually and 98% confirm cheating. Now, I'm not saying that men don't cheat in men's case if there is don't frequent online dating", "Start Time (s)": 239.0, "End Time (s)": 358.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5h42scKiyHFq2RnQkZOLwJ", "show_name": "Mensutra", "show_description": "If you are reading this, well, for you this is not just a Podcast, this is a community. When you click on the Follow button, you make this community, this group of glorious, victorious beings a little more stronger and better. And for doing that, on behalf of all my bros, I tip my hat to you, my friend.", "publisher": "Shwetabh Gangwar", "episode_uri": "spotify:episode:735G0Pf2AwY7rSRCmevY5s", "episode_name": "Listen This before Saying Yes To Arranged Marriage By Shwetabh Gangwar", "episode_description": "Why do people go for an arrange marriage?\u00a0 \u00a0This video tackles this question from every perspective it can, and also finally tries to answer the question, Why should two people marry each other?\u00a0 \u00a0\u00a0Written by Shwetabh Gangwar\u00a0 Message me on FB: https://www.facebook.com/mensutra Tweet me: https://www.twitter.com/mensutra\u00a0 Music: Big Bird's Date Night (Full) by Twin Musicom 1. It won't be easy: 2. Meetings can be bad and good: 3. There can be unrealistic expectations: 4. Pressure can be high: 5. Love takes time to enter: 6. It's beneficial for the couple not to hide your past: 7. Say yes, only when you are satisfied:  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app ", "score": 4.599193, "explanation": "{\n  \"value\": 4.599193,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.5807861,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.014276303,\n      \"description\": \"weight(word_list:to in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.014276303,\n          \"description\": \"score(LMDirichletSimilarity, freq=51.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6603319,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 51.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5672904,\n      \"description\": \"weight(word_list:become in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5672904,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.0176265,\n      \"description\": \"weight(word_list:rich in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0176265,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that. I'm not urging you <mark>to</mark> leave. I'm talking about the root of the problem because in case you are in a Loveless marriage your entire life becomes sad, so what do people do when they find themselves stuck in Loveless marriages, they can't contain any more they cheat and in women and apparently arranged marriage is flooded the extramarital Affairs website Ashley Madison within only a few days of its launch in India arranging Affairs for arranged marriages in India has resulted in more than 50,000 users signing up within two days of a I'll launch with female members representing more than half of the signups. Here's another story when the 60 year old man approached the court seeking a paternity test. He found that his only daughter was not his biological child a test. Not only devastated the father and the daughter but also led <mark>to</mark> the end of the marriage according <mark>to</mark> investigating agencies and the Judiciary could rather courts more than 250 paternity test annually and 98% confirm cheating. Now, I'm not saying that men don't cheat in men's case if there is don't frequent online dating websites. So why? Two people marry each other the answer is there is no reason <mark>to</mark> marry someone other than friendship. Think about it. You're going <mark>to</mark> spend your entire life with that person, which means after a certain time you will have <mark>to</mark> tolerate that person and who is a single person you happily tolerated your entire life. It's your friend German philosopher Friedrich. Nietzsche said about marriage when marrying ask yourself this question, do you believe that you'll be able <mark>to</mark> converse? Well with this person into your old age everything else in marriage is transitory a very basic question. Infer get sex forget her body forget everything just focus on her personality and ask yourself. Honestly. Do you like her personality? What is it that you like about her personality? What are the things that you dislike in our personality our the dislikes more than the likes forget her face forget <mark>how</mark> beautiful she is. Do you enjoy talking with this person or do you prefer your friends when you just want <mark>to</mark> talk? Why am I asking these questions? Because if you love or Fascination is strictly restricted <mark>to</mark> her beauty, you have <mark>to</mark> understand that her beauty will decline as you age at 30. I should be half as pretty as you used <mark>to</mark> be a 25. So the", "Start Time (s)": 303.3, "End Time (s)": 422.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5h42scKiyHFq2RnQkZOLwJ", "show_name": "Mensutra", "show_description": "If you are reading this, well, for you this is not just a Podcast, this is a community. When you click on the Follow button, you make this community, this group of glorious, victorious beings a little more stronger and better. And for doing that, on behalf of all my bros, I tip my hat to you, my friend.", "publisher": "Shwetabh Gangwar", "episode_uri": "spotify:episode:735G0Pf2AwY7rSRCmevY5s", "episode_name": "Listen This before Saying Yes To Arranged Marriage By Shwetabh Gangwar", "episode_description": "Why do people go for an arrange marriage?\u00a0 \u00a0This video tackles this question from every perspective it can, and also finally tries to answer the question, Why should two people marry each other?\u00a0 \u00a0\u00a0Written by Shwetabh Gangwar\u00a0 Message me on FB: https://www.facebook.com/mensutra Tweet me: https://www.twitter.com/mensutra\u00a0 Music: Big Bird's Date Night (Full) by Twin Musicom 1. It won't be easy: 2. Meetings can be bad and good: 3. There can be unrealistic expectations: 4. Pressure can be high: 5. Love takes time to enter: 6. It's beneficial for the couple not to hide your past: 7. Say yes, only when you are satisfied:  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app ", "score": 4.599193, "explanation": "{\n  \"value\": 4.599193,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.5807861,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.014276303,\n      \"description\": \"weight(word_list:to in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.014276303,\n          \"description\": \"score(LMDirichletSimilarity, freq=51.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6603319,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 51.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5672904,\n      \"description\": \"weight(word_list:become in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5672904,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.0176265,\n      \"description\": \"weight(word_list:rich in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0176265,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "don't cheat in men's case if there is don't frequent online dating websites. So why? Two people marry each other the answer is there is no reason <mark>to</mark> marry someone other than friendship. Think about it. You're going <mark>to</mark> spend your entire life with that person, which means after a certain time you will have <mark>to</mark> tolerate that person and who is a single person you happily tolerated your entire life. It's your friend German philosopher Friedrich. Nietzsche said about marriage when marrying ask yourself this question, do you believe that you'll be able <mark>to</mark> converse? Well with this person into your old age everything else in marriage is transitory a very basic question. Infer get sex forget her body forget everything just focus on her personality and ask yourself. Honestly. Do you like her personality? What is it that you like about her personality? What are the things that you dislike in our personality our the dislikes more than the likes forget her face forget <mark>how</mark> beautiful she is. Do you enjoy talking with this person or do you prefer your friends when you just want <mark>to</mark> talk? Why am I asking these questions? Because if you love or Fascination is strictly restricted <mark>to</mark> her beauty, you have <mark>to</mark> understand that her beauty will decline as you age at 30. I should be half as pretty as you used <mark>to</mark> be a 25. So the hotness for most of its parts will be gone and you will still be married <mark>to</mark> her personality and the girls who get fascinated by money, maybe the transition from middle class <mark>to</mark> a <mark>rich</mark> lifestyle might feel exciting <mark>to</mark> you at first, but for <mark>how</mark> long do you think you can prolong that excitement? There will come a time and that transition will <mark>become</mark> permanent and then would be used <mark>to</mark> being a <mark>rich</mark> person and being <mark>rich</mark> will <mark>become</mark> just as boring as it is being in any other Financial State if you are with a person you don't love people get blinded by hotness by money not that money is not important, but it shouldn't be only important thing in the world. And if you're so concerned about hotness anybody can be hot or does has nothing <mark>to</mark> do with looks it's all about your presence and your physique if you're 10 or overweight exercise get in the best shape of your life. You will <mark>become</mark> hot looks don't matter because when it comes <mark>to</mark> sex our brains still function on a private level women unconsciously respond creately you guys were muscular and in great shape. And so", "Start Time (s)": 355.3, "End Time (s)": 475.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:5h42scKiyHFq2RnQkZOLwJ", "show_name": "Mensutra", "show_description": "If you are reading this, well, for you this is not just a Podcast, this is a community. When you click on the Follow button, you make this community, this group of glorious, victorious beings a little more stronger and better. And for doing that, on behalf of all my bros, I tip my hat to you, my friend.", "publisher": "Shwetabh Gangwar", "episode_uri": "spotify:episode:735G0Pf2AwY7rSRCmevY5s", "episode_name": "Listen This before Saying Yes To Arranged Marriage By Shwetabh Gangwar", "episode_description": "Why do people go for an arrange marriage?\u00a0 \u00a0This video tackles this question from every perspective it can, and also finally tries to answer the question, Why should two people marry each other?\u00a0 \u00a0\u00a0Written by Shwetabh Gangwar\u00a0 Message me on FB: https://www.facebook.com/mensutra Tweet me: https://www.twitter.com/mensutra\u00a0 Music: Big Bird's Date Night (Full) by Twin Musicom 1. It won't be easy: 2. Meetings can be bad and good: 3. There can be unrealistic expectations: 4. Pressure can be high: 5. Love takes time to enter: 6. It's beneficial for the couple not to hide your past: 7. Say yes, only when you are satisfied:  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app ", "score": 4.599193, "explanation": "{\n  \"value\": 4.599193,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.5807861,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.014276303,\n      \"description\": \"weight(word_list:to in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.014276303,\n          \"description\": \"score(LMDirichletSimilarity, freq=51.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6603319,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 51.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5672904,\n      \"description\": \"weight(word_list:become in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5672904,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.0176265,\n      \"description\": \"weight(word_list:rich in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0176265,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Do you enjoy talking with this person or do you prefer your friends when you just want <mark>to</mark> talk? Why am I asking these questions? Because if you love or Fascination is strictly restricted <mark>to</mark> her beauty, you have <mark>to</mark> understand that her beauty will decline as you age at 30. I should be half as pretty as you used <mark>to</mark> be a 25. So the hotness for most of its parts will be gone and you will still be married <mark>to</mark> her personality and the girls who get fascinated by money, maybe the transition from middle class <mark>to</mark> a <mark>rich</mark> lifestyle might feel exciting <mark>to</mark> you at first, but for <mark>how</mark> long do you think you can prolong that excitement? There will come a time and that transition will <mark>become</mark> permanent and then would be used <mark>to</mark> being a <mark>rich</mark> person and being <mark>rich</mark> will <mark>become</mark> just as boring as it is being in any other Financial State if you are with a person you don't love people get blinded by hotness by money not that money is not important, but it shouldn't be only important thing in the world. And if you're so concerned about hotness anybody can be hot or does has nothing <mark>to</mark> do with looks it's all about your presence and your physique if you're 10 or overweight exercise get in the best shape of your life. You will <mark>become</mark> hot looks don't matter because when it comes <mark>to</mark> sex our brains still function on a private level women unconsciously respond creately you guys were muscular and in great shape. And so does Men We unconsciously focus and respond <mark>to</mark> the size of breast or the posterior of the girls. Why are you thinking for men are always muscular and almost all women have those implants because I know that people respond <mark>to</mark> seek more than just looks so guys <mark>to</mark> sum this up. I've only one thing I want you <mark>to</mark> consider. She might have the greatest pair of books in her shelves, but don't be impressed and planted by those books the color might look very interesting <mark>to</mark> you. But our day will come and you'd be bored of reading the same content again and again and then you'd be attracted <mark>to</mark> other books and you might want this secretly read another book very badly. If you do that the whole point of committing <mark>to</mark> those first books first pointless, and you wasted years of your life. Now, none of what I've said is absolute. I would love <mark>to</mark> learn from you as well. So do subscribe <mark>to</mark> this Channel and join in on the discussion and the comment box for now and for the many coming", "Start Time (s)": 405.6, "End Time (s)": 525.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:5h42scKiyHFq2RnQkZOLwJ", "show_name": "Mensutra", "show_description": "If you are reading this, well, for you this is not just a Podcast, this is a community. When you click on the Follow button, you make this community, this group of glorious, victorious beings a little more stronger and better. And for doing that, on behalf of all my bros, I tip my hat to you, my friend.", "publisher": "Shwetabh Gangwar", "episode_uri": "spotify:episode:735G0Pf2AwY7rSRCmevY5s", "episode_name": "Listen This before Saying Yes To Arranged Marriage By Shwetabh Gangwar", "episode_description": "Why do people go for an arrange marriage?\u00a0 \u00a0This video tackles this question from every perspective it can, and also finally tries to answer the question, Why should two people marry each other?\u00a0 \u00a0\u00a0Written by Shwetabh Gangwar\u00a0 Message me on FB: https://www.facebook.com/mensutra Tweet me: https://www.twitter.com/mensutra\u00a0 Music: Big Bird's Date Night (Full) by Twin Musicom 1. It won't be easy: 2. Meetings can be bad and good: 3. There can be unrealistic expectations: 4. Pressure can be high: 5. Love takes time to enter: 6. It's beneficial for the couple not to hide your past: 7. Say yes, only when you are satisfied:  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app ", "score": 4.599193, "explanation": "{\n  \"value\": 4.599193,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.5807861,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.014276303,\n      \"description\": \"weight(word_list:to in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.014276303,\n          \"description\": \"score(LMDirichletSimilarity, freq=51.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6603319,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 51.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5672904,\n      \"description\": \"weight(word_list:become in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5672904,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.0176265,\n      \"description\": \"weight(word_list:rich in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0176265,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "all about your presence and your physique if you're 10 or overweight exercise get in the best shape of your life. You will <mark>become</mark> hot looks don't matter because when it comes <mark>to</mark> sex our brains still function on a private level women unconsciously respond creately you guys were muscular and in great shape. And so does Men We unconsciously focus and respond <mark>to</mark> the size of breast or the posterior of the girls. Why are you thinking for men are always muscular and almost all women have those implants because I know that people respond <mark>to</mark> seek more than just looks so guys <mark>to</mark> sum this up. I've only one thing I want you <mark>to</mark> consider. She might have the greatest pair of books in her shelves, but don't be impressed and planted by those books the color might look very interesting <mark>to</mark> you. But our day will come and you'd be bored of reading the same content again and again and then you'd be attracted <mark>to</mark> other books and you might want this secretly read another book very badly. If you do that the whole point of committing <mark>to</mark> those first books first pointless, and you wasted years of your life. Now, none of what I've said is absolute. I would love <mark>to</mark> learn from you as well. So do subscribe <mark>to</mark> this Channel and join in on the discussion and the comment box for now and for the many coming videos as well and thank you for listening.", "Start Time (s)": 459.2, "End Time (s)": 528.0, "Clip Length (min)": 1.15, "show_uri": "spotify:show:5h42scKiyHFq2RnQkZOLwJ", "show_name": "Mensutra", "show_description": "If you are reading this, well, for you this is not just a Podcast, this is a community. When you click on the Follow button, you make this community, this group of glorious, victorious beings a little more stronger and better. And for doing that, on behalf of all my bros, I tip my hat to you, my friend.", "publisher": "Shwetabh Gangwar", "episode_uri": "spotify:episode:735G0Pf2AwY7rSRCmevY5s", "episode_name": "Listen This before Saying Yes To Arranged Marriage By Shwetabh Gangwar", "episode_description": "Why do people go for an arrange marriage?\u00a0 \u00a0This video tackles this question from every perspective it can, and also finally tries to answer the question, Why should two people marry each other?\u00a0 \u00a0\u00a0Written by Shwetabh Gangwar\u00a0 Message me on FB: https://www.facebook.com/mensutra Tweet me: https://www.twitter.com/mensutra\u00a0 Music: Big Bird's Date Night (Full) by Twin Musicom 1. It won't be easy: 2. Meetings can be bad and good: 3. There can be unrealistic expectations: 4. Pressure can be high: 5. Love takes time to enter: 6. It's beneficial for the couple not to hide your past: 7. Say yes, only when you are satisfied:  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app ", "score": 4.599193, "explanation": "{\n  \"value\": 4.599193,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.5807861,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.014276303,\n      \"description\": \"weight(word_list:to in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.014276303,\n          \"description\": \"score(LMDirichletSimilarity, freq=51.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.6603319,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 51.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5672904,\n      \"description\": \"weight(word_list:become in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5672904,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.0176265,\n      \"description\": \"weight(word_list:rich in 20) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.0176265,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.6460556,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 1816.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Well, either freaks, it's your boy Marty been here <mark>to</mark> introduce this flash episode of Tales from the Crypt sat down with our good friend Bitcoin Tina <mark>to</mark> talk about the perfect storm of things that are happening in the world that are bullish for Bitcoin a lot going on right now particularly this week in American markets globally with the coronavirus reading I think you guys are gonna like it quick one always bullish bullish as always with our good friend Tina. This episode is brought <mark>to</mark> you by the cash yet freaks are null. Um, I was actually had a friend reach out <mark>to</mark> me the yesterday the other not the other day yesterday. He was like, ah, let's see easiest way <mark>to</mark> buy Bitcoin. Remember you told me download that what was it the cash yet? That's what I said. It's the easiest way <mark>to</mark> buy Bitcoin. He had <mark>to</mark> be refreshed his memory had <mark>to</mark> be refreshed yesterday did a little video on my cell phone showing them <mark>how</mark> <mark>to</mark> buy Bitcoin. I did that thing where you record your screen went <mark>to</mark> the cash app scroll over <mark>to</mark> the squiggly line the art over <mark>to</mark> bitcoin", "Start Time (s)": 0.5, "End Time (s)": 61.6, "Clip Length (min)": 1.02, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Well, either freaks, it's your boy Marty been here <mark>to</mark> introduce this flash episode of Tales from the Crypt sat down with our good friend Bitcoin Tina <mark>to</mark> talk about the perfect storm of things that are happening in the world that are bullish for Bitcoin a lot going on right now particularly this week in American markets globally with the coronavirus reading I think you guys are gonna like it quick one always bullish bullish as always with our good friend Tina. This episode is brought <mark>to</mark> you by the cash yet freaks are null. Um, I was actually had a friend reach out <mark>to</mark> me the yesterday the other not the other day yesterday. He was like, ah, let's see easiest way <mark>to</mark> buy Bitcoin. Remember you told me download that what was it the cash yet? That's what I said. It's the easiest way <mark>to</mark> buy Bitcoin. He had <mark>to</mark> be refreshed his memory had <mark>to</mark> be refreshed yesterday did a little video on my cell phone showing them <mark>how</mark> <mark>to</mark> buy Bitcoin. I did that thing where you record your screen went <mark>to</mark> the cash app scroll over <mark>to</mark> the squiggly line the art over <mark>to</mark> bitcoin hit it up about $50 hit $50 wanna buy $50 hit by help my fingerprint down hit confirm. Boom $50 worth of bitcoin in my cash app was able <mark>to</mark> send it right off <mark>to</mark> a hardware wallet and basically get my financial sovereignty in less than 30 seconds. It was crazy. All right, so they're letting Stacks at still letting you send SATs receive sets and then on top of that the links tax live with us. If you want <mark>to</mark> you guys have heard about it already, but if you haven't catch up investing is now here if you have a stock that you want <mark>to</mark> invest in a stock you can buy as little as one dollar with it. If it's a little too expensive. You don't have <mark>to</mark> buy the whole thing by a sliver of a stock now because your account is connected <mark>to</mark> your bank account your cash app account is directly connected <mark>to</mark> your bank account. You want <mark>to</mark> wait four <mark>to</mark>", "Start Time (s)": 0.5, "End Time (s)": 113.1, "Clip Length (min)": 1.88, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "way <mark>to</mark> buy Bitcoin. He had <mark>to</mark> be refreshed his memory had <mark>to</mark> be refreshed yesterday did a little video on my cell phone showing them <mark>how</mark> <mark>to</mark> buy Bitcoin. I did that thing where you record your screen went <mark>to</mark> the cash app scroll over <mark>to</mark> the squiggly line the art over <mark>to</mark> bitcoin hit it up about $50 hit $50 wanna buy $50 hit by help my fingerprint down hit confirm. Boom $50 worth of bitcoin in my cash app was able <mark>to</mark> send it right off <mark>to</mark> a hardware wallet and basically get my financial sovereignty in less than 30 seconds. It was crazy. All right, so they're letting Stacks at still letting you send SATs receive sets and then on top of that the links tax live with us. If you want <mark>to</mark> you guys have heard about it already, but if you haven't catch up investing is now here if you have a stock that you want <mark>to</mark> invest in a stock you can buy as little as one dollar with it. If it's a little too expensive. You don't have <mark>to</mark> buy the whole thing by a sliver of a stock now because your account is connected <mark>to</mark> your bank account your cash app account is directly connected <mark>to</mark> your bank account. You want <mark>to</mark> wait four <mark>to</mark> five days. You start investing today cash up investing is a subsidiary Square remember s IPC as Always use the code stacking sets. You're going <mark>to</mark> get $10 when you sign up and ten dollars going <mark>to</mark> go <mark>to</mark> our good friends at owls lacrosse. That's owls lacrosse. Enjoy this episode with a good friend Tina. I know I certainly did. Okay. You've had a dynamic where money has <mark>become</mark> Freer than free. Can you talk about a Fed just gone nuts? All the central bank's going nuts. So it's all acting like Safe Haven. I believe that in a world where central Bankers are tripping over themselves <mark>to</mark> devalue their currency Bitcoin wins in the world of Fiat", "Start Time (s)": 44.3, "End Time (s)": 164.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "as little as one dollar with it. If it's a little too expensive. You don't have <mark>to</mark> buy the whole thing by a sliver of a stock now because your account is connected <mark>to</mark> your bank account your cash app account is directly connected <mark>to</mark> your bank account. You want <mark>to</mark> wait four <mark>to</mark> five days. You start investing today cash up investing is a subsidiary Square remember s IPC as Always use the code stacking sets. You're going <mark>to</mark> get $10 when you sign up and ten dollars going <mark>to</mark> go <mark>to</mark> our good friends at owls lacrosse. That's owls lacrosse. Enjoy this episode with a good friend Tina. I know I certainly did. Okay. You've had a dynamic where money has <mark>become</mark> Freer than free. Can you talk about a Fed just gone nuts? All the central bank's going nuts. So it's all acting like Safe Haven. I believe that in a world where central Bankers are tripping over themselves <mark>to</mark> devalue their currency Bitcoin wins in the world of Fiat currencies Bitcoin is the Victor remember? Part of the bull case for Bitcoin. You're not paying attention. You probably should be. What is a freaks welcome back <mark>to</mark> Tales from the Crypt at your boy Marty bent here? The flash episode had her good friend repeat guests reach out <mark>to</mark> me over DMS and say hey, we need <mark>to</mark> talk. I'd like <mark>to</mark> introduce you freaks again <mark>to</mark> bitcoin Tina Tina. <mark>How</mark> are we great everyday is a good day in Bitcoin. Ha ha that's what you're saying. Every all news is good news for Bitcoin. Well news is good news for Bitcoin. All obstacles are overcome by the social layer of the Point because Bitcoin is by its nature antifragile. Yes, and <mark>to</mark> preface this episode. We're not fear mongering. All right. This is an optimistic episode. We were just laying the land giving a lay of the land and explaining <mark>how</mark>", "Start Time (s)": 101.2, "End Time (s)": 220.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "All the central bank's going nuts. So it's all acting like Safe Haven. I believe that in a world where central Bankers are tripping over themselves <mark>to</mark> devalue their currency Bitcoin wins in the world of Fiat currencies Bitcoin is the Victor remember? Part of the bull case for Bitcoin. You're not paying attention. You probably should be. What is a freaks welcome back <mark>to</mark> Tales from the Crypt at your boy Marty bent here? The flash episode had her good friend repeat guests reach out <mark>to</mark> me over DMS and say hey, we need <mark>to</mark> talk. I'd like <mark>to</mark> introduce you freaks again <mark>to</mark> bitcoin Tina Tina. <mark>How</mark> are we great everyday is a good day in Bitcoin. Ha ha that's what you're saying. Every all news is good news for Bitcoin. Well news is good news for Bitcoin. All obstacles are overcome by the social layer of the Point because Bitcoin is by its nature antifragile. Yes, and <mark>to</mark> preface this episode. We're not fear mongering. All right. This is an optimistic episode. We were just laying the land giving a lay of the land and explaining <mark>how</mark> it may or may not affect Bitcoin going <mark>to</mark> the Future. So it's been a pretty chaotic week in the markets in the world coronavirus you are describing is the perfect storm for Bitcoin as gonna be the title of this episode. Why do you think this? Okay, this is the perfect storm for Bitcoin. Now. First of all Bitcoin is not there a risk on Nora risk-off asset Bitcoin is the core <mark>to</mark> an emerging economic Paradigm in my opinion for what it's worth. I had believed and continue <mark>to</mark> believe that in the 2020s will see negative rates at a minimum will see Zero rates and we'll see massive government spending. I believe that there's a very good chance. There's a", "Start Time (s)": 151.2, "End Time (s)": 270.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "explaining <mark>how</mark> it may or may not affect Bitcoin going <mark>to</mark> the Future. So it's been a pretty chaotic week in the markets in the world coronavirus you are describing is the perfect storm for Bitcoin as gonna be the title of this episode. Why do you think this? Okay, this is the perfect storm for Bitcoin. Now. First of all Bitcoin is not there a risk on Nora risk-off asset Bitcoin is the core <mark>to</mark> an emerging economic Paradigm in my opinion for what it's worth. I had believed and continue <mark>to</mark> believe that in the 2020s will see negative rates at a minimum will see Zero rates and we'll see massive government spending. I believe that there's a very good chance. There's a very good chance that the coronavirus may have accelerated this timetable. I don't know <mark>how</mark> corrupt plays out. It's very hard <mark>to</mark> say. There's a lot of data. We don't know yet and I don't know exactly <mark>how</mark> it will play out, but I think that It becomes an excuse for government spending that governments want <mark>to</mark> do anyway, because governments like <mark>to</mark> spend money. So it becomes a very easy excuse <mark>to</mark> spend it becomes very easy excuse for central banks <mark>to</mark> cut rates because they kind of want <mark>to</mark> cut rates. Anyway, regardless of what they say, they still like <mark>to</mark> cut rates and they know they need <mark>to</mark> so it's not even their fault for cutting rates so they don't even have <mark>to</mark> take the blame because there are always the Entities who want <mark>to</mark> go after them saying they shouldn't cut rates. Central banks can throw up his hands it when we we can't control this thing. Now some will say that cutting rates doesn't help.", "Start Time (s)": 219.7, "End Time (s)": 339.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "don't know exactly <mark>how</mark> it will play out, but I think that It becomes an excuse for government spending that governments want <mark>to</mark> do anyway, because governments like <mark>to</mark> spend money. So it becomes a very easy excuse <mark>to</mark> spend it becomes very easy excuse for central banks <mark>to</mark> cut rates because they kind of want <mark>to</mark> cut rates. Anyway, regardless of what they say, they still like <mark>to</mark> cut rates and they know they need <mark>to</mark> so it's not even their fault for cutting rates so they don't even have <mark>to</mark> take the blame because there are always the Entities who want <mark>to</mark> go after them saying they shouldn't cut rates. Central banks can throw up his hands it when we we can't control this thing. Now some will say that cutting rates doesn't help. Deal with a virus and no cutting rates doesn't but the thing is if markets were <mark>to</mark> crash and I don't know if markets will crash or Not Crash. I am very up in the air on that. I had set a while ago. That I expect stocks <mark>to</mark> be essentially flat for a decade. I continue <mark>to</mark> feel that way. I was somewhat doubtful of that view not that long ago when things were just soaring but it seems that events have taken a turn that has reeled in that possibility again that we may be flat essentially for a decade and I think we're sort of in this push-me pull-you environment where it's tug of war. Or between what gets done so even though maybe stock should decline because of events if governments spend like crazy and central banks by assets. Then things don't go down. We have certain things which are", "Start Time (s)": 288.4, "End Time (s)": 406.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "That I expect stocks <mark>to</mark> be essentially flat for a decade. I continue <mark>to</mark> feel that way. I was somewhat doubtful of that view not that long ago when things were just soaring but it seems that events have taken a turn that has reeled in that possibility again that we may be flat essentially for a decade and I think we're sort of in this push-me pull-you environment where it's tug of war. Or between what gets done so even though maybe stock should decline because of events if governments spend like crazy and central banks by assets. Then things don't go down. We have certain things which are immutable and demographics is immutable. Although some told me today that who knows. Maybe this thing is a A plan <mark>to</mark> get rid of Aging Boomers. I don't know if that's true or not. I certainly hope not but I actually don't think it's a plan <mark>to</mark> get rid of Adrian Boomers and those who are older than Boomers. I think if I had <mark>to</mark> guess that Nobody planned this thing. This one's completely unplanned and I don't know if it's nature or anything else but not for your sake too. Huh said I would offer my stick <mark>to</mark> thanks. I appreciate that. Well the problem is that even even if you don't die from it. I heard recently that. You could wind up with permanent lung damage. So, you know, even if you're 25 years old permanent lung damage for the rest of your life. It's really not something <mark>to</mark> look forward <mark>to</mark> so you really don't want <mark>to</mark> get sick and I don't know that's you know, the band strain or the not bad strain, but I think because it becomes this event which will encourage massive governmental spending", "Start Time (s)": 358.0, "End Time (s)": 476.4, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I don't know if that's true or not. I certainly hope not but I actually don't think it's a plan <mark>to</mark> get rid of Adrian Boomers and those who are older than Boomers. I think if I had <mark>to</mark> guess that Nobody planned this thing. This one's completely unplanned and I don't know if it's nature or anything else but not for your sake too. Huh said I would offer my stick <mark>to</mark> thanks. I appreciate that. Well the problem is that even even if you don't die from it. I heard recently that. You could wind up with permanent lung damage. So, you know, even if you're 25 years old permanent lung damage for the rest of your life. It's really not something <mark>to</mark> look forward <mark>to</mark> so you really don't want <mark>to</mark> get sick and I don't know that's you know, the band strain or the not bad strain, but I think because it becomes this event which will encourage massive governmental spending and I think you know, I think we're going <mark>to</mark> have huge spending regardless. I don't think it would matter who's in office. I that you'd see spending either an infrastructure project or green deal or any different ways that you would see just enormous spending and I think that the central bank's the FED would will expand their balance sheet <mark>to</mark> keep that spending and the debt issuance from driving rates much higher. It's a very weird. It's a very weird environment. But if that view is correct on my part, it becomes incredibly bullish for Bitcoin crashing stocks at the end of the day is not bullish for Bitcoin. I mean if the water in the bathtub goes down your little sailboat that you have floating on the top of the water is likely <mark>to</mark> go down with it. It's not going <mark>to</mark> be helpful <mark>to</mark> have stocks. Let's say get cut in half", "Start Time (s)": 420.1, "End Time (s)": 538.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "which will encourage massive governmental spending and I think you know, I think we're going <mark>to</mark> have huge spending regardless. I don't think it would matter who's in office. I that you'd see spending either an infrastructure project or green deal or any different ways that you would see just enormous spending and I think that the central bank's the FED would will expand their balance sheet <mark>to</mark> keep that spending and the debt issuance from driving rates much higher. It's a very weird. It's a very weird environment. But if that view is correct on my part, it becomes incredibly bullish for Bitcoin crashing stocks at the end of the day is not bullish for Bitcoin. I mean if the water in the bathtub goes down your little sailboat that you have floating on the top of the water is likely <mark>to</mark> go down with it. It's not going <mark>to</mark> be helpful <mark>to</mark> have stocks. Let's say get cut in half so Could it happen sure could happen. I don't know whether or not stocks will get hit dramatically, but I think that you will see. Actions taken by Central government's actions taken by central banks that will look <mark>to</mark> prevent that whereas in Prior periods. These various entities were always reactive. I think they're going <mark>to</mark> be far more proactive because we've been living in an environment for the last decade where Everything is Bubblicious out there. So if Capital markets come down very hard namely stocks that becomes a pretty big problem for everybody because money conditions get tight when money conditions get tight credit conditions get tight and that becomes very hard for the", "Start Time (s)": 473.5, "End Time (s)": 592.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Everything is Bubblicious out there. So if Capital markets come down very hard namely stocks that becomes a pretty big problem for everybody because money conditions get tight when money conditions get tight credit conditions get tight and that becomes very hard for the real economy. So, net net I mean this may be a crazy point of view, but I think that we will see an environment that becomes perfect for Bitcoin when you throw in the having with what I think will be the backdrop for Very easy money. Additionally there may be things happening like you saw with Germany, and now may be announced today with France and India you have a lot of you have a positive backdrop for Bitcoin. And so <mark>to</mark> me, this becomes The Perfect Storm by Perfect Storm. I mean like a really great thing that you're going <mark>to</mark> see all kinds of forces come together that cause this thing <mark>to</mark> go possibly higher than numbers that I have said I have guessed that you see a massive overshoot. The overshoot comes related <mark>to</mark> stock <mark>to</mark> flow with the projection is $100,000 and I have always thought that from a psychological perspective getting <mark>to</mark> $100,000 causes a lot of people who are highly skeptical and critical. <mark>To</mark> change their mind and look at this thing very differently and want <mark>to</mark> jump on board. You know, you get a guy who listened <mark>to</mark> Jamie dimon listen <mark>to</mark> Warren Buffett listen <mark>to</mark> whoever was critical and negative on bitcoin and they look at a price of 50 60 70 80 $100,000. They said themselves.", "Start Time (s)": 571.7, "End Time (s)": 690.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "India you have a lot of you have a positive backdrop for Bitcoin. And so <mark>to</mark> me, this becomes The Perfect Storm by Perfect Storm. I mean like a really great thing that you're going <mark>to</mark> see all kinds of forces come together that cause this thing <mark>to</mark> go possibly higher than numbers that I have said I have guessed that you see a massive overshoot. The overshoot comes related <mark>to</mark> stock <mark>to</mark> flow with the projection is $100,000 and I have always thought that from a psychological perspective getting <mark>to</mark> $100,000 causes a lot of people who are highly skeptical and critical. <mark>To</mark> change their mind and look at this thing very differently and want <mark>to</mark> jump on board. You know, you get a guy who listened <mark>to</mark> Jamie dimon listen <mark>to</mark> Warren Buffett listen <mark>to</mark> whoever was critical and negative on bitcoin and they look at a price of 50 60 70 80 $100,000. They said themselves. Oh I thought this thing was going <mark>to</mark> go away and then it's sitting at prices that they think are crazy and they start <mark>to</mark> say I gotta get me some of that and I think you're going <mark>to</mark> hear a lot of people saying I got <mark>to</mark> own me some of that and I have said for a while and I continue <mark>to</mark> say just by 1% You know, it's 1% won't hurt you. Now, that's not Financial advice but realistically If you fall off the curb on the sidewalk and it's only like an inch or two. It's really hard <mark>to</mark> get really hurt. I mean sure you could fall down and break your hip if you're really old or really clumsy, but that's not going <mark>to</mark> happen <mark>to</mark> most people and it's really hard <mark>to</mark> do with one percent.", "Start Time (s)": 622.0, "End Time (s)": 740.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "You know, you get a guy who listened <mark>to</mark> Jamie dimon listen <mark>to</mark> Warren Buffett listen <mark>to</mark> whoever was critical and negative on bitcoin and they look at a price of 50 60 70 80 $100,000. They said themselves. Oh I thought this thing was going <mark>to</mark> go away and then it's sitting at prices that they think are crazy and they start <mark>to</mark> say I gotta get me some of that and I think you're going <mark>to</mark> hear a lot of people saying I got <mark>to</mark> own me some of that and I have said for a while and I continue <mark>to</mark> say just by 1% You know, it's 1% won't hurt you. Now, that's not Financial advice but realistically If you fall off the curb on the sidewalk and it's only like an inch or two. It's really hard <mark>to</mark> get really hurt. I mean sure you could fall down and break your hip if you're really old or really clumsy, but that's not going <mark>to</mark> happen <mark>to</mark> most people and it's really hard <mark>to</mark> do with one percent. It's only one percent of your net worth and I think it's a highly reasonable thing. I think by the end of this decade we can see truly insane numbers and so the risk reward profile on that. Is just outstanding. So if I'm at all right about the backdrop for this thing. Then it's just <mark>become</mark> a much much better investment. And all of these things are coming together. Hence the term The Perfect Storm again, not in a bad way, but in a really good way it really optimistic really positive way and let me think about that governments starting <mark>to</mark> <mark>become</mark> more accepting. Really easy money. And what was the other thing that I said?", "Start Time (s)": 676.8, "End Time (s)": 794.2, "Clip Length (min)": 1.96, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "if I'm at all right about the backdrop for this thing. Then it's just <mark>become</mark> a much much better investment. And all of these things are coming together. Hence the term The Perfect Storm again, not in a bad way, but in a really good way it really optimistic really positive way and let me think about that governments starting <mark>to</mark> <mark>become</mark> more accepting. Really easy money. And what was the other thing that I said? Stagnant stock markets for no. No - yeah, you know really easy money governments coming together and the government's becoming more accepting now. I forgot what I said some OS so my letters fomo after certain level but no no that was the backdrop. I have <mark>to</mark> go listen <mark>to</mark> what I said remember interest rates falling below zero. Well that relates <mark>to</mark> the easy money. Well that and that will push people into wanting <mark>to</mark> own Bitcoin. So listen what I said remember what I said well, but it creates it creates a very positive backdrop though. Those those various those various things that are happening. And so one thing you haven't you got that you having you have very easy money, which I think is very likely plus you have growing acceptance. Governments, I mean what more could you ask for <mark>to</mark> me? That's what you call an absolutely perfect environment. And I think that people really underestimate this I have said for a long time all surprises and Bitcoin will be on the upside and I think people who try <mark>to</mark> get cute with this the try <mark>to</mark> trade it", "Start Time (s)": 759.5, "End Time (s)": 878.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the backdrop. I have <mark>to</mark> go listen <mark>to</mark> what I said remember interest rates falling below zero. Well that relates <mark>to</mark> the easy money. Well that and that will push people into wanting <mark>to</mark> own Bitcoin. So listen what I said remember what I said well, but it creates it creates a very positive backdrop though. Those those various those various things that are happening. And so one thing you haven't you got that you having you have very easy money, which I think is very likely plus you have growing acceptance. Governments, I mean what more could you ask for <mark>to</mark> me? That's what you call an absolutely perfect environment. And I think that people really underestimate this I have said for a long time all surprises and Bitcoin will be on the upside and I think people who try <mark>to</mark> get cute with this the try <mark>to</mark> trade it and try <mark>to</mark> sell it. Oh, one of the things that really have a lot of impact on me recently is as having conversation. Without of the Bitcoin or who was trading TLT options because he wanted <mark>to</mark> make a bet on long-dated paper long-dated treasuries. And you know, I told him I was a little concerned. I thought it was a great idea. I think we took a lot lower but he he owns some April paper and some a papers if you know who knows it could take a while and then race were like 150 at the time and the 10-year yield as we speak is point seven four five. So it just got cut in half. In like a little more than two weeks. So I feel like I feel like a real idiot, but this stuff can happen really fast. So that's that's something I want <mark>to</mark> that's what I want <mark>to</mark> dive into it is it feels like the FED markets have been blindsided and they're scrambling right now the FED had an emergency", "Start Time (s)": 816.3, "End Time (s)": 935.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "really underestimate this I have said for a long time all surprises and Bitcoin will be on the upside and I think people who try <mark>to</mark> get cute with this the try <mark>to</mark> trade it and try <mark>to</mark> sell it. Oh, one of the things that really have a lot of impact on me recently is as having conversation. Without of the Bitcoin or who was trading TLT options because he wanted <mark>to</mark> make a bet on long-dated paper long-dated treasuries. And you know, I told him I was a little concerned. I thought it was a great idea. I think we took a lot lower but he he owns some April paper and some a papers if you know who knows it could take a while and then race were like 150 at the time and the 10-year yield as we speak is point seven four five. So it just got cut in half. In like a little more than two weeks. So I feel like I feel like a real idiot, but this stuff can happen really fast. So that's that's something I want <mark>to</mark> that's what I want <mark>to</mark> dive into it is it feels like the FED markets have been blindsided and they're scrambling right now the FED had an emergency 50 bit cut earlier this week like like you just mentioned people are are funneling into <mark>to</mark> treasuries driving. Down those yields and that's like the FED cut seem very bearish <mark>to</mark> me because it had a like a five-minute Market rally after the initial after the cut initially hit the market and then markets began tanking immediately again. And the one thing about this virus is it's really highlighting the the pain points and our supply chain and and the pain points are Global is goal of globalization and sort of the the Situation America has put itself in particularly. Can you print your way out of this or do you think there's a chance that there's a total and this is something I'm sort of leaning towards", "Start Time (s)": 866.1, "End Time (s)": 986.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and they're scrambling right now the FED had an emergency 50 bit cut earlier this week like like you just mentioned people are are funneling into <mark>to</mark> treasuries driving. Down those yields and that's like the FED cut seem very bearish <mark>to</mark> me because it had a like a five-minute Market rally after the initial after the cut initially hit the market and then markets began tanking immediately again. And the one thing about this virus is it's really highlighting the the pain points and our supply chain and and the pain points are Global is goal of globalization and sort of the the Situation America has put itself in particularly. Can you print your way out of this or do you think there's a chance that there's a total and this is something I'm sort of leaning towards there's a total crisis of confidence in the institutions mainly the FED that they're able <mark>to</mark> control this stuff. I don't disagree with anything. You just said but I do think that cutting rates will be supportive of markets. I do think if markets were <mark>to</mark> simply just crash that that can create the environment that makes it a self-fulfilling prophecy if markets just get taken down very hard. I believe that we are in a world and have been in a world for a long time. Are the real economy has <mark>become</mark> the tail and the markets have <mark>become</mark> dog. And so I think that if the stock market crashes at the global stock markets crash he wind up with overall tighter Financial conditions and Tighter Financial conditions make for a more difficult environment. I think these were bad policies from the beginning but it doesn't matter what", "Start Time (s)": 932.5, "End Time (s)": 1051.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "with anything. You just said but I do think that cutting rates will be supportive of markets. I do think if markets were <mark>to</mark> simply just crash that that can create the environment that makes it a self-fulfilling prophecy if markets just get taken down very hard. I believe that we are in a world and have been in a world for a long time. Are the real economy has <mark>become</mark> the tail and the markets have <mark>become</mark> dog. And so I think that if the stock market crashes at the global stock markets crash he wind up with overall tighter Financial conditions and Tighter Financial conditions make for a more difficult environment. I think these were bad policies from the beginning but it doesn't matter what I think it matters where we are. It doesn't matter <mark>how</mark> we got here. It matters that we're here now. It doesn't matter if the rock breaks the glass pitcher or the pitcher hits the rock. It's going <mark>to</mark> be bad for the picture. It doesn't matter if the stocks crater. If they do it's going <mark>to</mark> be bad for the real economy and it's going <mark>to</mark> be a problem. I agree with you that there's a lot of weakness and Supply chains. There are a lot of fragilities in the economy, but adding one more problem <mark>to</mark> the mixture doesn't make it better. So no cutting rates in and of themselves. does not fix the underlying problems, but if stocks crashed in conjunction with the other problems happening It doesn't make that cocktail a better cocktail for solving these problems at this point. It probably makes it worse and I don't think these good", "Start Time (s)": 995.2, "End Time (s)": 1114.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "or the pitcher hits the rock. It's going <mark>to</mark> be bad for the picture. It doesn't matter if the stocks crater. If they do it's going <mark>to</mark> be bad for the real economy and it's going <mark>to</mark> be a problem. I agree with you that there's a lot of weakness and Supply chains. There are a lot of fragilities in the economy, but adding one more problem <mark>to</mark> the mixture doesn't make it better. So no cutting rates in and of themselves. does not fix the underlying problems, but if stocks crashed in conjunction with the other problems happening It doesn't make that cocktail a better cocktail for solving these problems at this point. It probably makes it worse and I don't think these good policies. I haven't thought these were good policies for many many many many years, but it's where we are. Now. I'm not trying <mark>to</mark> say that you believe that no, no answer that. I don't think you're trying <mark>to</mark> say that I do you do you envision a possibility in which the policies are completely ineffective. this time around like they pump a bunch of money in but not even that can keep stock market stasis. markets are dependent on earnings as well as price earnings multiples. I don't know if multiples can expand. That's why I kind of believe that you're going <mark>to</mark> see this push-me pull-you because you could have a tough earnings environment and it can be a tough earnings environment for a while which keeps pressure on stocks. But the same time you get all kinds of support from fiscal policies that <mark>become</mark> supportive of those earnings and if you have Central Looking", "Start Time (s)": 1063.1, "End Time (s)": 1182.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "many many many many years, but it's where we are. Now. I'm not trying <mark>to</mark> say that you believe that no, no answer that. I don't think you're trying <mark>to</mark> say that I do you do you envision a possibility in which the policies are completely ineffective. this time around like they pump a bunch of money in but not even that can keep stock market stasis. markets are dependent on earnings as well as price earnings multiples. I don't know if multiples can expand. That's why I kind of believe that you're going <mark>to</mark> see this push-me pull-you because you could have a tough earnings environment and it can be a tough earnings environment for a while which keeps pressure on stocks. But the same time you get all kinds of support from fiscal policies that <mark>become</mark> supportive of those earnings and if you have Central Looking <mark>to</mark> control the shape of the curve and keeping rates. Down by keeping bond prices from selling off then you create an environment where multiples can remain high. So that's why you wind up with this really strange environment of being able <mark>to</mark> maintain relatively high prices, even though maybe it shouldn't be I think we're in a world today which is different from the world of the last 90 years because I think that we having been through these crises already. The response has <mark>become</mark> far more activist rather than reactive and so it's not good that we got here. But we're going <mark>to</mark> do more of the same <mark>to</mark> keep the thing going and that becomes very positive for Bitcoin and", "Start Time (s)": 1117.7, "End Time (s)": 1236.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you get all kinds of support from fiscal policies that <mark>become</mark> supportive of those earnings and if you have Central Looking <mark>to</mark> control the shape of the curve and keeping rates. Down by keeping bond prices from selling off then you create an environment where multiples can remain high. So that's why you wind up with this really strange environment of being able <mark>to</mark> maintain relatively high prices, even though maybe it shouldn't be I think we're in a world today which is different from the world of the last 90 years because I think that we having been through these crises already. The response has <mark>become</mark> far more activist rather than reactive and so it's not good that we got here. But we're going <mark>to</mark> do more of the same <mark>to</mark> keep the thing going and that becomes very positive for Bitcoin and ultimately in my view Bitcoin will be the thing that takes us <mark>to</mark> that next economic Paradigm and it has <mark>to</mark> <mark>become</mark> a lot bigger for that <mark>to</mark> happen. And I think we're in that environment where Bitcoin is going <mark>to</mark> <mark>become</mark> enormous in the course of the 2020s, and I think it's going <mark>to</mark> go <mark>to</mark> levels that people. Cannot possibly imagine I'd be very reluctant <mark>to</mark> part with my Bitcoin if I were if I were whoever's listening <mark>to</mark> this, I'd be very reluctant <mark>to</mark> part with it. You're not margin trading it right now. Now I never margin trade it I sit with fully owned and sit with fully on bitcoin. I also own gbtc and that I do have for the purpose of selling because I do have <mark>to</mark> pay my bills and and I like <mark>to</mark> eat and I like <mark>to</mark> have a roof over my head. So I do have gbtc who's whose sole purpose is <mark>to</mark> sell", "Start Time (s)": 1171.5, "End Time (s)": 1290.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "rather than reactive and so it's not good that we got here. But we're going <mark>to</mark> do more of the same <mark>to</mark> keep the thing going and that becomes very positive for Bitcoin and ultimately in my view Bitcoin will be the thing that takes us <mark>to</mark> that next economic Paradigm and it has <mark>to</mark> <mark>become</mark> a lot bigger for that <mark>to</mark> happen. And I think we're in that environment where Bitcoin is going <mark>to</mark> <mark>become</mark> enormous in the course of the 2020s, and I think it's going <mark>to</mark> go <mark>to</mark> levels that people. Cannot possibly imagine I'd be very reluctant <mark>to</mark> part with my Bitcoin if I were if I were whoever's listening <mark>to</mark> this, I'd be very reluctant <mark>to</mark> part with it. You're not margin trading it right now. Now I never margin trade it I sit with fully owned and sit with fully on bitcoin. I also own gbtc and that I do have for the purpose of selling because I do have <mark>to</mark> pay my bills and and I like <mark>to</mark> eat and I like <mark>to</mark> have a roof over my head. So I do have gbtc who's whose sole purpose is <mark>to</mark> sell because I will need <mark>to</mark> sell some but I'm hopeful that I'll have some good prices <mark>to</mark> sell it at and I think I'll be right about that. I don't think enough people really understand why this asset will benefit from the environment there weren't looking worst case scenario. when we saw Cyprus in when we saw Cyprus in 2011-12 2011-2012, you know 2012 you don't own your money in the bank. You don't own the money at your brokerages. Those are held by the institutions. We saw that with MF Global if these institutions go belly-up and I'm not suggesting that they do but if they do go belly-up they can do whatever they want your", "Start Time (s)": 1224.2, "End Time (s)": 1344.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "don't think enough people really understand why this asset will benefit from the environment there weren't looking worst case scenario. when we saw Cyprus in when we saw Cyprus in 2011-12 2011-2012, you know 2012 you don't own your money in the bank. You don't own the money at your brokerages. Those are held by the institutions. We saw that with MF Global if these institutions go belly-up and I'm not suggesting that they do but if they do go belly-up they can do whatever they want your money. Essentially if you hold your own private Keys, you actually control your own money. If you have an extremely aggressive inflation, I believe and I'm not suggesting. We have a very extremely aggressive inflation. Although I think we're setting the stage for that <mark>to</mark> happen down. The one that could take three four five six seven years. I don't know <mark>how</mark> long that takes but that could take a while, but it can be a very aggressive inflation having an asset which is Fixed and Supply as well as Supply inelastic. is very much a beneficiary of of an inflating the money supply where money will chase that asset because of its natural qualities in addition <mark>to</mark> its scarcity. Becomes an asset that you want <mark>to</mark> own so I think it becomes the ideal thing <mark>to</mark> own for the 2020s and I think this is a really interesting kickoff and this really started with a bang right in January of 2020. And I think I'd have thought for a while. The 2020s are going <mark>to</mark> be a truly", "Start Time (s)": 1300.6, "End Time (s)": 1420.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the stage for that <mark>to</mark> happen down. The one that could take three four five six seven years. I don't know <mark>how</mark> long that takes but that could take a while, but it can be a very aggressive inflation having an asset which is Fixed and Supply as well as Supply inelastic. is very much a beneficiary of of an inflating the money supply where money will chase that asset because of its natural qualities in addition <mark>to</mark> its scarcity. Becomes an asset that you want <mark>to</mark> own so I think it becomes the ideal thing <mark>to</mark> own for the 2020s and I think this is a really interesting kickoff and this really started with a bang right in January of 2020. And I think I'd have thought for a while. The 2020s are going <mark>to</mark> be a truly spectacular decade. I would not be surprised <mark>to</mark> see Bitcoin up in the three <mark>to</mark> five million dollars. Inch by 2030 somewhere between 2020 and 2030 <mark>to</mark> so I'm that my guess is a 300 <mark>to</mark> 500 x return from $10,000 would be higher from $7,000. I think the numbers will be absolutely spectacular and I think today's dollars something really insane. But by 5 <mark>to</mark> 8 million dollars in today's dollars three <mark>to</mark> five million three <mark>to</mark> five you bit three If you bid me up money, I'll take the loads out of that the three <mark>to</mark> five million. I think it's going <mark>to</mark> be some really crazy stuff and I think that I'd actually would like most people think that's completely off the charts nuts. I'd really prefer they", "Start Time (s)": 1359.5, "End Time (s)": 1479.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>to</mark> see Bitcoin up in the three <mark>to</mark> five million dollars. Inch by 2030 somewhere between 2020 and 2030 <mark>to</mark> so I'm that my guess is a 300 <mark>to</mark> 500 x return from $10,000 would be higher from $7,000. I think the numbers will be absolutely spectacular and I think today's dollars something really insane. But by 5 <mark>to</mark> 8 million dollars in today's dollars three <mark>to</mark> five million three <mark>to</mark> five you bit three If you bid me up money, I'll take the loads out of that the three <mark>to</mark> five million. I think it's going <mark>to</mark> be some really crazy stuff and I think that I'd actually would like most people think that's completely off the charts nuts. I'd really prefer they think that rather than thinking it's possible. So probably do I'm going <mark>to</mark> I think I'm comfortable enough <mark>to</mark> say that they probably do people listen as the guy you're actually a lot of people listening was probably believe you but Outsiders definitely they totally think I'm crazy and I'm really okay with that. I think, you know, they're crazy numbers, but I think that If the world is yes, I think in today's I think in today's buying power. I think if you have a very resident place in the numbers would just be whatever. No I think in today's buying power if you had one Bitcoin today, it'll buy you what three million dollars would buy you today. That's what's going <mark>to</mark> happen <mark>to</mark> the value of that for five million dollars what it buys you today, which means if you have 10 Bitcoin, you know, you're talking about being like a A small whale and if you have a hundred coin you are well and I think a lot of I think a lot of the oh jeez. A lot of them I think will lose their Bitcoin along the way which I'm really happy about it because I think many of them", "Start Time (s)": 1423.5, "End Time (s)": 1542.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and I'm really okay with that. I think, you know, they're crazy numbers, but I think that If the world is yes, I think in today's I think in today's buying power. I think if you have a very resident place in the numbers would just be whatever. No I think in today's buying power if you had one Bitcoin today, it'll buy you what three million dollars would buy you today. That's what's going <mark>to</mark> happen <mark>to</mark> the value of that for five million dollars what it buys you today, which means if you have 10 Bitcoin, you know, you're talking about being like a A small whale and if you have a hundred coin you are well and I think a lot of I think a lot of the oh jeez. A lot of them I think will lose their Bitcoin along the way which I'm really happy about it because I think many of them underestimate the asset that they have they've held it what for them feels like so long, they're like all all nervous. You're not using this as a medium of exchange yet. And oh my God, it's not going <mark>to</mark> really work out. You got <mark>to</mark> push it for me <mark>to</mark> exchange their they feel like these 11 years is like this eternity and I look at the 11 years like it's nothing and the thing Grew From from 0 <mark>to</mark> today. What are we at a hundred and seventy hundred eight? We are we today Market Catholic $165 75 billion, I would imagine so that's strange that's enormous. And and I think you know, it's going <mark>to</mark> grow exponentially in this decade in my opinion with the will turn be as big as from zero <mark>to</mark> a hundred sixty billion. No, I'm in but In absolute dollars. The numbers are going <mark>to</mark> be off the charts spectacular and and it's going <mark>to</mark> be really big really huge money and everything is pushing it that way. No, I agree. I mean the world is insane right now and I think at least <mark>to</mark> me I tweeted it out this morning Bitcoins engaged in a war of attrition. Just gotta", "Start Time (s)": 1493.1, "End Time (s)": 1612.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "they're like all all nervous. You're not using this as a medium of exchange yet. And oh my God, it's not going <mark>to</mark> really work out. You got <mark>to</mark> push it for me <mark>to</mark> exchange their they feel like these 11 years is like this eternity and I look at the 11 years like it's nothing and the thing Grew From from 0 <mark>to</mark> today. What are we at a hundred and seventy hundred eight? We are we today Market Catholic $165 75 billion, I would imagine so that's strange that's enormous. And and I think you know, it's going <mark>to</mark> grow exponentially in this decade in my opinion with the will turn be as big as from zero <mark>to</mark> a hundred sixty billion. No, I'm in but In absolute dollars. The numbers are going <mark>to</mark> be off the charts spectacular and and it's going <mark>to</mark> be really big really huge money and everything is pushing it that way. No, I agree. I mean the world is insane right now and I think at least <mark>to</mark> me I tweeted it out this morning Bitcoins engaged in a war of attrition. Just gotta Outlast the incumbent Financial system and then comment Financial Paradigm old us <mark>to</mark> do is keep producing blocks and it's a good segue into another ingredient of The Perfect Storm. They were talking about again the regulation and countries around the world. You mentioned France Germany India Rabbit Hole recap yesterday. Matt and I were talking about <mark>How</mark> we think the German and I believe similarly the French regulations or new laws are bearish but you're saying it's bullish even though it may be restrictive for companies <mark>to</mark> start. This is overall good for Bitcoin along run. Why do you think that it's bullish as can be because the key <mark>to</mark> bitcoin ultimately becoming the money that we use is being large enough <mark>to</mark> be able <mark>to</mark> grow and create an internal Market that enables us <mark>to</mark> do things that whirring, you know, you hide in", "Start Time (s)": 1548.5, "End Time (s)": 1668.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "everything is pushing it that way. No, I agree. I mean the world is insane right now and I think at least <mark>to</mark> me I tweeted it out this morning Bitcoins engaged in a war of attrition. Just gotta Outlast the incumbent Financial system and then comment Financial Paradigm old us <mark>to</mark> do is keep producing blocks and it's a good segue into another ingredient of The Perfect Storm. They were talking about again the regulation and countries around the world. You mentioned France Germany India Rabbit Hole recap yesterday. Matt and I were talking about <mark>How</mark> we think the German and I believe similarly the French regulations or new laws are bearish but you're saying it's bullish even though it may be restrictive for companies <mark>to</mark> start. This is overall good for Bitcoin along run. Why do you think that it's bullish as can be because the key <mark>to</mark> bitcoin ultimately becoming the money that we use is being large enough <mark>to</mark> be able <mark>to</mark> grow and create an internal Market that enables us <mark>to</mark> do things that whirring, you know, you hide in the crowd. Let's face facts. We live in a world where lots of people use cash <mark>to</mark> do things that They don't pay taxes on so <mark>how</mark> many times have you heard? Somebody say, you know give you cash for a discount and they get the discount. So everybody knows what they're going <mark>to</mark> do and if the crowd is large enough and if the techniques are there, they're going <mark>to</mark> be too many transactions <mark>to</mark> <mark>to</mark> keep track of so, I am not bothered by these regulations. I think that when you have 50 million people 70 million people in America 70 million Americans using it some people will coin and some people will use lightning will Pro years lightning", "Start Time (s)": 1600.4, "End Time (s)": 1719.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and they get the discount. So everybody knows what they're going <mark>to</mark> do and if the crowd is large enough and if the techniques are there, they're going <mark>to</mark> be too many transactions <mark>to</mark> <mark>to</mark> keep track of so, I am not bothered by these regulations. I think that when you have 50 million people 70 million people in America 70 million Americans using it some people will coin and some people will use lightning will Pro years lightning probably pretty much everywhere coin or many many will will do it you end up hiding a crowd. I think what you'll end up seeing at some point along the way is the tax laws will get changed because bitcoiners will be smart and they will create political action committees. They will donate two Pax Pax will donate two congressmen and senators and we'll end up getting favorable laws passed at $500,000 Bitcoin. Are we going <mark>to</mark> be people who should be giving some money <mark>to</mark> support politicians who support our point of view who support favorable tax laws for Bitcoin? I think it'd be crazy not <mark>to</mark> UPenn Bitcoin. It's half a million dollars that's five million dollars. That's a lot of money. So you can afford <mark>to</mark> give a few thousand dollars <mark>to</mark> politicians and you do it with, you know, another 50,000 bitcoiners becomes a lot of money and politicians will speak, you know will do will support your point of view when you give the money. That's <mark>how</mark> this works. We live in a world where where money talks and I think that it will be a very positive - I'm not at all Disturbed. We just need <mark>to</mark> see number go up and anything which promotes number go up and enables people <mark>to</mark> come into Bitcoin is positive.", "Start Time (s)": 1687.3, "End Time (s)": 1807.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "we'll end up getting favorable laws passed at $500,000 Bitcoin. Are we going <mark>to</mark> be people who should be giving some money <mark>to</mark> support politicians who support our point of view who support favorable tax laws for Bitcoin? I think it'd be crazy not <mark>to</mark> UPenn Bitcoin. It's half a million dollars that's five million dollars. That's a lot of money. So you can afford <mark>to</mark> give a few thousand dollars <mark>to</mark> politicians and you do it with, you know, another 50,000 bitcoiners becomes a lot of money and politicians will speak, you know will do will support your point of view when you give the money. That's <mark>how</mark> this works. We live in a world where where money talks and I think that it will be a very positive - I'm not at all Disturbed. We just need <mark>to</mark> see number go up and anything which promotes number go up and enables people <mark>to</mark> come into Bitcoin is positive. So even though regulation so that this regulation means you're not Banning it. Regulating it. You don't ban it if you're going <mark>to</mark> ban it you ban it he don't regulate it <mark>to</mark> ban it because you just ban it. So regulation is positive. It's not negative regulation enables people who look at this and say I don't want <mark>to</mark> buy Bitcoin because the government's are going <mark>to</mark> ban it and say well dummy they just regulated it. So they're obviously not Banning it so you can now invest in this thing. You can be comfortable. This is just like what you're comfortable with so when you can can say <mark>to</mark> people who have a lot more money than we do guys who may be in my age of people that this is regulated and you can feel comfortable owning this they watch it going up. What are they going <mark>to</mark> do? They're going <mark>to</mark> buy it and they're going <mark>to</mark> help Drive the price higher so you let something like that,", "Start Time (s)": 1740.0, "End Time (s)": 1859.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it will be a very positive - I'm not at all Disturbed. We just need <mark>to</mark> see number go up and anything which promotes number go up and enables people <mark>to</mark> come into Bitcoin is positive. So even though regulation so that this regulation means you're not Banning it. Regulating it. You don't ban it if you're going <mark>to</mark> ban it you ban it he don't regulate it <mark>to</mark> ban it because you just ban it. So regulation is positive. It's not negative regulation enables people who look at this and say I don't want <mark>to</mark> buy Bitcoin because the government's are going <mark>to</mark> ban it and say well dummy they just regulated it. So they're obviously not Banning it so you can now invest in this thing. You can be comfortable. This is just like what you're comfortable with so when you can can say <mark>to</mark> people who have a lot more money than we do guys who may be in my age of people that this is regulated and you can feel comfortable owning this they watch it going up. What are they going <mark>to</mark> do? They're going <mark>to</mark> buy it and they're going <mark>to</mark> help Drive the price higher so you let something like that, huh, that's going <mark>to</mark> say let's hone in on that. What do you think? A lot of boomers are thinking right now, especially this week in the stock market a lot of people your rager. There are they not thinking about Bitcoin are they worried about the retirement funds and they're worried about their retirement funds right now everybody worries about their money in the stock market when the stock market goes down unless they're short who doesn't worry about the stocks that they own when the stock market is going down. Well, I guess better question is <mark>how</mark> overextended is your generation in stocks. I have no idea. It's so hard <mark>to</mark> say because you know, you can't everybody's different. You know, you have some people who have a lot of money and they may be overextending the stocks. But I know a guy who likes <mark>to</mark> brag <mark>to</mark> me that he fought a lot of stocks and 2009. So he's up a lot in those stocks. I mean realistically", "Start Time (s)": 1794.8, "End Time (s)": 1914.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "age of people that this is regulated and you can feel comfortable owning this they watch it going up. What are they going <mark>to</mark> do? They're going <mark>to</mark> buy it and they're going <mark>to</mark> help Drive the price higher so you let something like that, huh, that's going <mark>to</mark> say let's hone in on that. What do you think? A lot of boomers are thinking right now, especially this week in the stock market a lot of people your rager. There are they not thinking about Bitcoin are they worried about the retirement funds and they're worried about their retirement funds right now everybody worries about their money in the stock market when the stock market goes down unless they're short who doesn't worry about the stocks that they own when the stock market is going down. Well, I guess better question is <mark>how</mark> overextended is your generation in stocks. I have no idea. It's so hard <mark>to</mark> say because you know, you can't everybody's different. You know, you have some people who have a lot of money and they may be overextending the stocks. But I know a guy who likes <mark>to</mark> brag <mark>to</mark> me that he fought a lot of stocks and 2009. So he's up a lot in those stocks. I mean realistically you're pretty close <mark>to</mark> the all-time highs up here. So, you know, if you bought stocks the S&P it seven or eight hundred and the SP is now at 2,900 <mark>how</mark> much can you be hurting? You're still all right, you're not happy that it's down I mean, but but but you're up. Multiples and depending on stocks you own you could be up an awful lot. So it depends on who we're talking about. I think it's hard <mark>to</mark> generalize. I think people like <mark>to</mark> generalize there's some people where the average retirement amounts are in the neighborhood of 200 thousand dollars. There have been people speaking of late that the using those kinds of numbers. $200,000 is probably not enough <mark>to</mark> retire on at the age of 65", "Start Time (s)": 1847.1, "End Time (s)": 1965.5, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "overextending the stocks. But I know a guy who likes <mark>to</mark> brag <mark>to</mark> me that he fought a lot of stocks and 2009. So he's up a lot in those stocks. I mean realistically you're pretty close <mark>to</mark> the all-time highs up here. So, you know, if you bought stocks the S&P it seven or eight hundred and the SP is now at 2,900 <mark>how</mark> much can you be hurting? You're still all right, you're not happy that it's down I mean, but but but you're up. Multiples and depending on stocks you own you could be up an awful lot. So it depends on who we're talking about. I think it's hard <mark>to</mark> generalize. I think people like <mark>to</mark> generalize there's some people where the average retirement amounts are in the neighborhood of 200 thousand dollars. There have been people speaking of late that the using those kinds of numbers. $200,000 is probably not enough <mark>to</mark> retire on at the age of 65 <mark>how</mark> much they own in stocks? I don't know. I think that even a retiree who 65 should today own 1% in Bitcoin, even if you had only $200,000 1% in Bitcoin will make sense. The odds of them buying it under 20,000. I think are close <mark>to</mark> zero the odds and buying it under a hundred thousand. I think are not much more than zero. And people tend <mark>to</mark> chase price. That's just <mark>how</mark> we are. Most bitcoiners come <mark>to</mark> bitcoin they get inoculated the first time they hear about Bitcoin they say, oh that that's crap. They don't do anything and then the prices up 5 or 10 X or some number from where they first heard about it and they say, oh, yeah. I think I'm interested in I don't want <mark>to</mark> buy it. This happens all the time. This happens with probably most people in Bitcoin there. There's only a handful of people", "Start Time (s)": 1903.5, "End Time (s)": 2023.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "speaking of late that the using those kinds of numbers. $200,000 is probably not enough <mark>to</mark> retire on at the age of 65 <mark>how</mark> much they own in stocks? I don't know. I think that even a retiree who 65 should today own 1% in Bitcoin, even if you had only $200,000 1% in Bitcoin will make sense. The odds of them buying it under 20,000. I think are close <mark>to</mark> zero the odds and buying it under a hundred thousand. I think are not much more than zero. And people tend <mark>to</mark> chase price. That's just <mark>how</mark> we are. Most bitcoiners come <mark>to</mark> bitcoin they get inoculated the first time they hear about Bitcoin they say, oh that that's crap. They don't do anything and then the prices up 5 or 10 X or some number from where they first heard about it and they say, oh, yeah. I think I'm interested in I don't want <mark>to</mark> buy it. This happens all the time. This happens with probably most people in Bitcoin there. There's only a handful of people who heard about it and bought it right away. at least that's from the stories that I hear and people can correct that if they know different but I think that the upside is enormous and even if you pay $100,000 if I'm right on the numbers and I believe that I will be then your slope tremendous upside. So that's really going <mark>to</mark> be okay. So people will come into this in the course of the next few years. I think this will be the first mainstream bull market and there's a good chance that like that first big bull market you had early on not who won in 2016 and 2017. That this will be quite surprising <mark>to</mark> where it goes because there's a global tsunami of money that's going <mark>to</mark> start coming into Bitcoin. It's going <mark>to</mark> come in as a trickle", "Start Time (s)": 1957.0, "End Time (s)": 2076.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "They don't do anything and then the prices up 5 or 10 X or some number from where they first heard about it and they say, oh, yeah. I think I'm interested in I don't want <mark>to</mark> buy it. This happens all the time. This happens with probably most people in Bitcoin there. There's only a handful of people who heard about it and bought it right away. at least that's from the stories that I hear and people can correct that if they know different but I think that the upside is enormous and even if you pay $100,000 if I'm right on the numbers and I believe that I will be then your slope tremendous upside. So that's really going <mark>to</mark> be okay. So people will come into this in the course of the next few years. I think this will be the first mainstream bull market and there's a good chance that like that first big bull market you had early on not who won in 2016 and 2017. That this will be quite surprising <mark>to</mark> where it goes because there's a global tsunami of money that's going <mark>to</mark> start coming into Bitcoin. It's going <mark>to</mark> come in as a trickle everything in economics seems <mark>to</mark> be Gradually, then suddenly that's <mark>how</mark> markets tend <mark>to</mark> work gradually than sudden and I gradually takes a while exponential curves look linear in the early stages. That's the gradually part. They hit a critical point and then suddenly happens and I think Bitcoin will be no different. I think we'll go through a series of these things and I think the next year <mark>to</mark> three possibly four years or quite shocking take us two numbers that are really Like crazy. I don't know what the next they are Market looks like I think the next bull market, which we may be in the early stages of will end up being quite spectacular because the psychology which is set up and that's a big factor <mark>to</mark> so you have all these positive force is happening", "Start Time (s)": 2008.1, "End Time (s)": 2127.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "That this will be quite surprising <mark>to</mark> where it goes because there's a global tsunami of money that's going <mark>to</mark> start coming into Bitcoin. It's going <mark>to</mark> come in as a trickle everything in economics seems <mark>to</mark> be Gradually, then suddenly that's <mark>how</mark> markets tend <mark>to</mark> work gradually than sudden and I gradually takes a while exponential curves look linear in the early stages. That's the gradually part. They hit a critical point and then suddenly happens and I think Bitcoin will be no different. I think we'll go through a series of these things and I think the next year <mark>to</mark> three possibly four years or quite shocking take us two numbers that are really Like crazy. I don't know what the next they are Market looks like I think the next bull market, which we may be in the early stages of will end up being quite spectacular because the psychology which is set up and that's a big factor <mark>to</mark> so you have all these positive force is happening and you have this massive buildup of negative psychology. It'll be like a dam bursting as people know what they heard about Bitcoin. They know about the negative you I mean <mark>how</mark> many people I talk <mark>to</mark> people and they think I'm crazy. I talked <mark>to</mark> a lot of Yabba. No not if people think you're crazy. Yeah. No, I'm not really I'm not interested in nothing. Don't don't bother me. Oh the Bitcoin guy. Oh my God Gotta Get Away gotta get away from that guy. It's a Bitcoin guy. He's nothing but trouble I mean people make jokes about this, but it's true. We're annoying. I'm really annoying. I don't say that. Oh, I'm sure. Like that, but well you're touching on something that I'm very interested in and something I think about a lot <mark>to</mark> is after the next bull market or x amount of bull markets. What is the the correction look like is it as intense and", "Start Time (s)": 2065.0, "End Time (s)": 2184.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "which we may be in the early stages of will end up being quite spectacular because the psychology which is set up and that's a big factor <mark>to</mark> so you have all these positive force is happening and you have this massive buildup of negative psychology. It'll be like a dam bursting as people know what they heard about Bitcoin. They know about the negative you I mean <mark>how</mark> many people I talk <mark>to</mark> people and they think I'm crazy. I talked <mark>to</mark> a lot of Yabba. No not if people think you're crazy. Yeah. No, I'm not really I'm not interested in nothing. Don't don't bother me. Oh the Bitcoin guy. Oh my God Gotta Get Away gotta get away from that guy. It's a Bitcoin guy. He's nothing but trouble I mean people make jokes about this, but it's true. We're annoying. I'm really annoying. I don't say that. Oh, I'm sure. Like that, but well you're touching on something that I'm very interested in and something I think about a lot <mark>to</mark> is after the next bull market or x amount of bull markets. What is the the correction look like is it as intense and psychologically what is a threshold at which people are like? All right. This is serious isn't going anywhere and we don't see an 80 <mark>to</mark> 90% crash again after maybe we Plateau fall 50% Okay, so you have misquoted me from from our first podcast. In January of 2019 you have misquoted make when I said that volatility will subdue IE downside volatility will <mark>become</mark> less and but upside volatility will remain insane. So I think that there's a good likelihood that at some point maybe the next bear Market more than likely definitely the one after that that the downside will be greatly diminished from what we've seen now. I'll give you a caveat. If we were <mark>to</mark> go <mark>to</mark> a million-dollar Bitcoin in the next four years, I don't know what it looks like.", "Start Time (s)": 2116.7, "End Time (s)": 2235.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Like that, but well you're touching on something that I'm very interested in and something I think about a lot <mark>to</mark> is after the next bull market or x amount of bull markets. What is the the correction look like is it as intense and psychologically what is a threshold at which people are like? All right. This is serious isn't going anywhere and we don't see an 80 <mark>to</mark> 90% crash again after maybe we Plateau fall 50% Okay, so you have misquoted me from from our first podcast. In January of 2019 you have misquoted make when I said that volatility will subdue IE downside volatility will <mark>become</mark> less and but upside volatility will remain insane. So I think that there's a good likelihood that at some point maybe the next bear Market more than likely definitely the one after that that the downside will be greatly diminished from what we've seen now. I'll give you a caveat. If we were <mark>to</mark> go <mark>to</mark> a million-dollar Bitcoin in the next four years, I don't know what it looks like. Thanks for if Bitcoin were <mark>to</mark> go from where it is now for a series of moves up <mark>to</mark> a million dollars. I don't know what crash would or would not look like. It's very hard <mark>to</mark> guess if we really overshoot where I think we should go and I think we should go <mark>to</mark> that <mark>to</mark> or $400,000 range which people think it's crazy. But we really overshoot could we crash down <mark>to</mark> one or two? Thousand dollars maybe and I actually don't want <mark>to</mark> see million dollar Bitcoin in the next three or four years. I'd rather only see. I know people think that's crazy Bitcoin going <mark>to</mark> you know <mark>to</mark> <mark>to</mark> $400,000 because if you if you if you dropped from a peak of 400,000 <mark>to</mark> 150, which is not nearly as bad as what we've seen then lots of people feel comfortable coming in at 150. If you went <mark>to</mark> a million in this massive Spike,", "Start Time (s)": 2171.2, "End Time (s)": 2290.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "If we were <mark>to</mark> go <mark>to</mark> a million-dollar Bitcoin in the next four years, I don't know what it looks like. Thanks for if Bitcoin were <mark>to</mark> go from where it is now for a series of moves up <mark>to</mark> a million dollars. I don't know what crash would or would not look like. It's very hard <mark>to</mark> guess if we really overshoot where I think we should go and I think we should go <mark>to</mark> that <mark>to</mark> or $400,000 range which people think it's crazy. But we really overshoot could we crash down <mark>to</mark> one or two? Thousand dollars maybe and I actually don't want <mark>to</mark> see million dollar Bitcoin in the next three or four years. I'd rather only see. I know people think that's crazy Bitcoin going <mark>to</mark> you know <mark>to</mark> <mark>to</mark> $400,000 because if you if you if you dropped from a peak of 400,000 <mark>to</mark> 150, which is not nearly as bad as what we've seen then lots of people feel comfortable coming in at 150. If you went <mark>to</mark> a million in this massive Spike, we're like in the last month or two you went from five hundred thousand dollars up <mark>to</mark> a million. You potentially have a lot of people who just got blown out. Really high prices. So <mark>how</mark> long that takes <mark>to</mark> correct? It could take a really long time <mark>to</mark> correct? I don't want <mark>to</mark> see something like that. Could we see it? It's possible. We could see it. I don't want <mark>to</mark> see it. I think that would be incredibly hard environment. I think it'd be very hard <mark>to</mark> trade. I think it'd be very hard <mark>to</mark> sell. I think the chain would <mark>become</mark> probably heavily bogged down. We'd have a hard time moving Bitcoin <mark>to</mark> sell because I don't want <mark>to</mark> see that. I don't want <mark>to</mark> see that and actually it brings up a good point. I forget who said it core developer recently said that the the pace of development at the protocol level is pacing nicely with the price right now. So Bitcoin is usable at this price at this. Option level and it'll be interesting <mark>to</mark>", "Start Time (s)": 2230.5, "End Time (s)": 2348.7, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>to</mark> a million in this massive Spike, we're like in the last month or two you went from five hundred thousand dollars up <mark>to</mark> a million. You potentially have a lot of people who just got blown out. Really high prices. So <mark>how</mark> long that takes <mark>to</mark> correct? It could take a really long time <mark>to</mark> correct? I don't want <mark>to</mark> see something like that. Could we see it? It's possible. We could see it. I don't want <mark>to</mark> see it. I think that would be incredibly hard environment. I think it'd be very hard <mark>to</mark> trade. I think it'd be very hard <mark>to</mark> sell. I think the chain would <mark>become</mark> probably heavily bogged down. We'd have a hard time moving Bitcoin <mark>to</mark> sell because I don't want <mark>to</mark> see that. I don't want <mark>to</mark> see that and actually it brings up a good point. I forget who said it core developer recently said that the the pace of development at the protocol level is pacing nicely with the price right now. So Bitcoin is usable at this price at this. Option level and it'll be interesting <mark>to</mark> see <mark>how</mark> development Paces with the price going forward. Especially if markets continue doing what they're doing an animal spirits take over. Do you think the protocol is better position for a bull run moving forward? Is better position than what than it was three years ago 27th the protocol like the the technology. I'm not I'm not an expert on the protocol. I'm not going <mark>to</mark> I'm not going <mark>to</mark> speculate on that. I'm not knowledgeable enough there. I think there's a lot of great things happening, but that's really a question of other people not for me. I think that the infrastructure background is is friendly or towards massive amounts of money coming in and will continue <mark>to</mark> accelerate and we'll see More money coming into developing potential scaling layers and businesses trying <mark>to</mark> find their way. Look we see that with somebody like square", "Start Time (s)": 2288.7, "End Time (s)": 2408.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "level and it'll be interesting <mark>to</mark> see <mark>how</mark> development Paces with the price going forward. Especially if markets continue doing what they're doing an animal spirits take over. Do you think the protocol is better position for a bull run moving forward? Is better position than what than it was three years ago 27th the protocol like the the technology. I'm not I'm not an expert on the protocol. I'm not going <mark>to</mark> I'm not going <mark>to</mark> speculate on that. I'm not knowledgeable enough there. I think there's a lot of great things happening, but that's really a question of other people not for me. I think that the infrastructure background is is friendly or towards massive amounts of money coming in and will continue <mark>to</mark> accelerate and we'll see More money coming into developing potential scaling layers and businesses trying <mark>to</mark> find their way. Look we see that with somebody like square a company like square that is supporting core developers that is doing a lot of really really positive things. I would expect with Rising prices will see at least. I hope we do more companies that are like Square we have delta T that's doing stuff. I think that we'll see a lot of investment where companies are trying <mark>to</mark> build their own businesses and benefit from from using Bitcoin and are supportive of the values of Bitcoin and I'm hopeful that we'll see that as far as the protocol goes that was over and above my head and I'm not an expert in that I won't comment I think for the infrastructure, I think we've built a lot of infrastructure in the last few years and I think that will continue <mark>to</mark> happen. Will allow for more money flows come in was the cash app around in 2017. Towards the tail end I", "Start Time (s)": 2345.4, "End Time (s)": 2464.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and we'll see More money coming into developing potential scaling layers and businesses trying <mark>to</mark> find their way. Look we see that with somebody like square a company like square that is supporting core developers that is doing a lot of really really positive things. I would expect with Rising prices will see at least. I hope we do more companies that are like Square we have delta T that's doing stuff. I think that we'll see a lot of investment where companies are trying <mark>to</mark> build their own businesses and benefit from from using Bitcoin and are supportive of the values of Bitcoin and I'm hopeful that we'll see that as far as the protocol goes that was over and above my head and I'm not an expert in that I won't comment I think for the infrastructure, I think we've built a lot of infrastructure in the last few years and I think that will continue <mark>to</mark> happen. Will allow for more money flows come in was the cash app around in 2017. Towards the tail end I believe they started were where anybody using it not as many people as they're using it today. So people always losing it widely. So cash app is is phenomenal on board on boarding tool and so there are there are a lot of things that I'm going <mark>to</mark> you've got give Bitcoin out there that becomes a number there are a lot of things that are out there that are building their a lot of things that were not there in 2017, which would be supportive. If things <mark>become</mark> truly crazy and you're dealing with a very fixed asset, it depends on what hollers do <mark>how</mark> much they release at what price is they release that it becomes really hard <mark>to</mark> imagine people <mark>become</mark> crazy when prices go up. They really do we saw this in the late 90s and in", "Start Time (s)": 2395.5, "End Time (s)": 2515.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I think for the infrastructure, I think we've built a lot of infrastructure in the last few years and I think that will continue <mark>to</mark> happen. Will allow for more money flows come in was the cash app around in 2017. Towards the tail end I believe they started were where anybody using it not as many people as they're using it today. So people always losing it widely. So cash app is is phenomenal on board on boarding tool and so there are there are a lot of things that I'm going <mark>to</mark> you've got give Bitcoin out there that becomes a number there are a lot of things that are out there that are building their a lot of things that were not there in 2017, which would be supportive. If things <mark>become</mark> truly crazy and you're dealing with a very fixed asset, it depends on what hollers do <mark>how</mark> much they release at what price is they release that it becomes really hard <mark>to</mark> imagine people <mark>become</mark> crazy when prices go up. They really do we saw this in the late 90s and in the.com bubble, so it's hard <mark>to</mark> know. I find as much as I say these things. I don't actually believe what I say and I'll give you 400 LOL. Nah, let me let me let me tell you I'll give you a perfect example if I'm in my own personal life. So in two thousand three and four I was talking about gold and I was saying, you know, they're gonna be all these problems and and and So I bought like two gold coins. It's like nothing and then 2008 happened and they did tarp and I said <mark>to</mark> myself. Oh my God, the banking system almost just shut down. So then I started buying gold. This thing can really happen the banking system can actually shut down. So when I say, I don't believe what I say, I say it but then it's like oh,", "Start Time (s)": 2448.2, "End Time (s)": 2567.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it's hard <mark>to</mark> know. I find as much as I say these things. I don't actually believe what I say and I'll give you 400 LOL. Nah, let me let me let me tell you I'll give you a perfect example if I'm in my own personal life. So in two thousand three and four I was talking about gold and I was saying, you know, they're gonna be all these problems and and and So I bought like two gold coins. It's like nothing and then 2008 happened and they did tarp and I said <mark>to</mark> myself. Oh my God, the banking system almost just shut down. So then I started buying gold. This thing can really happen the banking system can actually shut down. So when I say, I don't believe what I say, I say it but then it's like oh, I don't go load up on Golden 2000 2002 2003 when I showed up in doing that. So I thought rates are going <mark>to</mark> go down and then like two weeks later they get cut in half. So yeah, I think rates can go down but I don't think rates are gonna go down in two weeks. So when I say, I don't believe what I say aye I can be right about something but yet I'm also surprised at <mark>how</mark> aggressive it is and <mark>how</mark> right I might be in something so Your ideas write the timings off a little bit. Well, it's just like You believe it but it's like it's when you're talking about things which are really hard <mark>to</mark> believe. It's sometimes even hard <mark>to</mark> believe it yourself that. If Bitcoin is sitting at $400,000, I'm going <mark>to</mark> be like I said, I'm gonna $400,000 but man I didn't think it would really go <mark>to</mark> $400,000 this fast and and we won't it's going <mark>to</mark> be hard <mark>to</mark> believe. I promise you because <mark>to</mark> $400,000 you will not believe it and neither one most other people and if it goes", "Start Time (s)": 2518.9, "End Time (s)": 2637.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "2002 2003 when I showed up in doing that. So I thought rates are going <mark>to</mark> go down and then like two weeks later they get cut in half. So yeah, I think rates can go down but I don't think rates are gonna go down in two weeks. So when I say, I don't believe what I say aye I can be right about something but yet I'm also surprised at <mark>how</mark> aggressive it is and <mark>how</mark> right I might be in something so Your ideas write the timings off a little bit. Well, it's just like You believe it but it's like it's when you're talking about things which are really hard <mark>to</mark> believe. It's sometimes even hard <mark>to</mark> believe it yourself that. If Bitcoin is sitting at $400,000, I'm going <mark>to</mark> be like I said, I'm gonna $400,000 but man I didn't think it would really go <mark>to</mark> $400,000 this fast and and we won't it's going <mark>to</mark> be hard <mark>to</mark> believe. I promise you because <mark>to</mark> $400,000 you will not believe it and neither one most other people and if it goes higher we're going <mark>to</mark> be really Bonkers and the whole world will be Bonkers. They're very we can say these things but actually watching it happen. You still sad. You still stand there with your mouth open just in astonishment and I think it should happen but actually watching the thing actually happen. I'm astonished that the tenure paper is at point. Seven four eight right. Now. I'm astonished I look at the yield curve. The curve is all on pretty much not not the 30-year all under one percent. These are astonishing numbers. I did not live in a world like this. I mean I saw sure post post 2000. 2008 but in the 90s you had rates that were what we considered normal rates in the five and six percent range numbers and these numbers are crazy.", "Start Time (s)": 2570.5, "End Time (s)": 2690.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "with your mouth open just in astonishment and I think it should happen but actually watching the thing actually happen. I'm astonished that the tenure paper is at point. Seven four eight right. Now. I'm astonished I look at the yield curve. The curve is all on pretty much not not the 30-year all under one percent. These are astonishing numbers. I did not live in a world like this. I mean I saw sure post post 2000. 2008 but in the 90s you had rates that were what we considered normal rates in the five and six percent range numbers and these numbers are crazy. I mean we regularly had money markets were five and six percent we had, you know, two-year three-year five-year treasury paper 5% 6% tenure paper in numbers like that. It's just really Hard <mark>to</mark> imagine when things really do happen and so talking about it is one thing and then seeing it happen is really very different. I am comfortable in My Views, but even though I'm saying all these things will still be shocked when it happens because these are shocking things and they Can't you can't deny your your human instinct? Right or everybody has a hard time imagining a world that's different from the one they know and that includes me. It's very hard <mark>to</mark> imagine a world that you don't know yet and yet yes, I believe it. Yes. I think it's going <mark>to</mark> happen. But when it happens, it will be astonishing. It will astonish even those of us who believe it will happen. Does that make any sense? I know I know you look at you. You got really", "Start Time (s)": 2649.2, "End Time (s)": 2768.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "thing and then seeing it happen is really very different. I am comfortable in My Views, but even though I'm saying all these things will still be shocked when it happens because these are shocking things and they Can't you can't deny your your human instinct? Right or everybody has a hard time imagining a world that's different from the one they know and that includes me. It's very hard <mark>to</mark> imagine a world that you don't know yet and yet yes, I believe it. Yes. I think it's going <mark>to</mark> happen. But when it happens, it will be astonishing. It will astonish even those of us who believe it will happen. Does that make any sense? I know I know you look at you. You got really nervous when I said that you got really nervous. I can see the line across him is like what the hell is this? I thought you were going <mark>to</mark> contradict yourself, but I completely understand what you're saying. I felt that way in 2017. Like I couldn't believe it got the 20,000 when I got there and like you I've been I've been saying that I think it will hit millions of dollars one day. What year did you buy Bitcoin? That's a very personal question right approximately. Okay, I'm approximately what price did you buy Bitcoin approximate range my do not I bought it <mark>to</mark> the height of the last bubble before the A bubble, but did you buy lower than that to? Yes, I did. Okay. So when you bought lower than that, did you really think I was going <mark>to</mark> hit 20,000? I mean I thought so yes, but when it had were you amazed when I got there? Yeah having it like this is a PSA at all. You freaks out there like make sure you have especially stuff that you have in your own custody down like lockdown because that that treasure this Hardware while it's get very heavy when that price starts <mark>to</mark>", "Start Time (s)": 2716.3, "End Time (s)": 2836.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "going <mark>to</mark> contradict yourself, but I completely understand what you're saying. I felt that way in 2017. Like I couldn't believe it got the 20,000 when I got there and like you I've been I've been saying that I think it will hit millions of dollars one day. What year did you buy Bitcoin? That's a very personal question right approximately. Okay, I'm approximately what price did you buy Bitcoin approximate range my do not I bought it <mark>to</mark> the height of the last bubble before the A bubble, but did you buy lower than that to? Yes, I did. Okay. So when you bought lower than that, did you really think I was going <mark>to</mark> hit 20,000? I mean I thought so yes, but when it had were you amazed when I got there? Yeah having it like this is a PSA at all. You freaks out there like make sure you have especially stuff that you have in your own custody down like lockdown because that that treasure this Hardware while it's get very heavy when that price starts <mark>to</mark> rise. I'm no but my point is my point is if you see something if you're buying Bitcoins at $300 and you see it at ten thousand dollars and it's not that many years later. It's pretty astonishing. I have <mark>to</mark> add this one thing before we go Bitcoin is the key <mark>to</mark> a long life. Why do you say this? Because it may not be any longer but watching it every day. It sure seems like it's a lot longer, right? Yeah. Yeah, it's been a very long two years. Well her it's going too far as long as it's been a fun two years. I didn't say it isn't fun. I just as long we watch this thing 24/7 right even everything about say they don't look huh? You ever think about taking a vacation from watching this stuff? 24/7 <mark>how</mark> do you take a", "Start Time (s)": 2776.1, "End Time (s)": 2895.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "heavy when that price starts <mark>to</mark> rise. I'm no but my point is my point is if you see something if you're buying Bitcoins at $300 and you see it at ten thousand dollars and it's not that many years later. It's pretty astonishing. I have <mark>to</mark> add this one thing before we go Bitcoin is the key <mark>to</mark> a long life. Why do you say this? Because it may not be any longer but watching it every day. It sure seems like it's a lot longer, right? Yeah. Yeah, it's been a very long two years. Well her it's going too far as long as it's been a fun two years. I didn't say it isn't fun. I just as long we watch this thing 24/7 right even everything about say they don't look huh? You ever think about taking a vacation from watching this stuff? 24/7 <mark>how</mark> do you take a vacation from it? It's everywhere. You can't you can't help yourself. I like <mark>to</mark> walk it I didn't but I don't but I don't trade it. I just sit and watch it. Is that drive you crazy at all? I mean, you're already crazy. Not really. Not really. No. I look I'd be happier right now of Bitcoin was sitting at 25,000. I think it's dumb at this price. I think $9,000 is stupid cheap. I mean I did not think Bitcoin was going <mark>to</mark> get rekt from six <mark>to</mark> three thousand. I just didn't think that was going <mark>to</mark> happen. I wasn't happy when it happened. I felt when it got wrecked <mark>to</mark> People saying what's going on 1000 that was just stupid, and that's why I wanted <mark>to</mark> talk <mark>to</mark> you back in January 2019. I think this is just a very large base that we're tracing out that will give us an enormous.", "Start Time (s)": 2835.1, "End Time (s)": 2954.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "think Bitcoin was going <mark>to</mark> get rekt from six <mark>to</mark> three thousand. I just didn't think that was going <mark>to</mark> happen. I wasn't happy when it happened. I felt when it got wrecked <mark>to</mark> People saying what's going on 1000 that was just stupid, and that's why I wanted <mark>to</mark> talk <mark>to</mark> you back in January 2019. I think this is just a very large base that we're tracing out that will give us an enormous. What's-her-name Levine's amount of says the bigger the base the higher in space. So we just have this huge thing that we're tracing out here that we're only people who really believe in this thing and holding onto it because they ride through the ups and downs, which this has been very beneficial for the class of 2017 <mark>to</mark> 2020. It's been a very beneficial time for them <mark>to</mark> load up on on bitcoin. And I think that they'll be people who are our dollar cost averaging into it today who if they are able <mark>to</mark> hold on <mark>to</mark> what they have if you're 25 or 30 years old when you're 50 or 60 years old. You're going <mark>to</mark> be very very rich. I think even one Bitcoin will make you very very very rich. I talked <mark>to</mark> a guy the other day told me you only has 53 million SATs and he's trying know trying <mark>to</mark> <mark>become</mark> a whole corner. And I said, you know keep keep keep doing that keep working on that. I think even 53 million sets will be a staggering amount of money many people will have sold well before the numbers that I think it will get <mark>to</mark> in 20 <mark>to</mark> 30 years, but if you're able <mark>to</mark>", "Start Time (s)": 2923.2, "End Time (s)": 3043.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "this has been very beneficial for the class of 2017 <mark>to</mark> 2020. It's been a very beneficial time for them <mark>to</mark> load up on on bitcoin. And I think that they'll be people who are our dollar cost averaging into it today who if they are able <mark>to</mark> hold on <mark>to</mark> what they have if you're 25 or 30 years old when you're 50 or 60 years old. You're going <mark>to</mark> be very very rich. I think even one Bitcoin will make you very very very rich. I talked <mark>to</mark> a guy the other day told me you only has 53 million SATs and he's trying know trying <mark>to</mark> <mark>become</mark> a whole corner. And I said, you know keep keep keep doing that keep working on that. I think even 53 million sets will be a staggering amount of money many people will have sold well before the numbers that I think it will get <mark>to</mark> in 20 <mark>to</mark> 30 years, but if you're able <mark>to</mark> hold on <mark>to</mark> that Million sites will be a lot of money and that seems crazy and we think oh my God, <mark>how</mark> can that possibly be? But if you bought Bitcoin at a dollar and you bought 10,000 of them, it's only $10,000 which is not a lot of money. I mean ten thousand dollars just in the world of investing is nothing. It may be a lot of money <mark>to</mark> do certain things with but that today is <mark>how</mark> much is that today? Which is 10,000. It's 90 million dollars. <mark>How</mark> much is that? 10,000 Bitcoins. I mean, it's 90 million, right? Yeah. We don't we don't want <mark>to</mark> make that steak that woman made ten MSNBC who said that who said that million dollars and everyone could have had a million dollars from that little bit. We don't want <mark>to</mark> make that mistake right here. I'll look it up right now 10,000", "Start Time (s)": 2978.9, "End Time (s)": 3096.5, "Clip Length (min)": 1.96, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "amount of money many people will have sold well before the numbers that I think it will get <mark>to</mark> in 20 <mark>to</mark> 30 years, but if you're able <mark>to</mark> hold on <mark>to</mark> that Million sites will be a lot of money and that seems crazy and we think oh my God, <mark>how</mark> can that possibly be? But if you bought Bitcoin at a dollar and you bought 10,000 of them, it's only $10,000 which is not a lot of money. I mean ten thousand dollars just in the world of investing is nothing. It may be a lot of money <mark>to</mark> do certain things with but that today is <mark>how</mark> much is that today? Which is 10,000. It's 90 million dollars. <mark>How</mark> much is that? 10,000 Bitcoins. I mean, it's 90 million, right? Yeah. We don't we don't want <mark>to</mark> make that steak that woman made ten MSNBC who said that who said that million dollars and everyone could have had a million dollars from that little bit. We don't want <mark>to</mark> make that mistake right here. I'll look it up right now 10,000 Times nine million nine hundred ninety million dollars. So who the fuck $10,000 could <mark>become</mark> 90 million dollars. That's crazy. And I think that you know, I think that 30 years and that's a long time 30 years from now 20 years from now that one Bitcoin at $9,000 today who will be worth an enormous amount of money. So because a lot of people will sell they'll end up Distributing out that Bitcoin <mark>to</mark> other people the gini coefficient will keep You growing the be very few people are able <mark>to</mark> really hold on as these things go up. If we watch it go <mark>to</mark> two three four hundred thousand dollars. If you own 10 Bitcoin today, you gotta go no care. We don't end the coin today and it's at $300,000. That's three million dollars. So that's a lot of money", "Start Time (s)": 3033.1, "End Time (s)": 3152.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "here. I'll look it up right now 10,000 Times nine million nine hundred ninety million dollars. So who the fuck $10,000 could <mark>become</mark> 90 million dollars. That's crazy. And I think that you know, I think that 30 years and that's a long time 30 years from now 20 years from now that one Bitcoin at $9,000 today who will be worth an enormous amount of money. So because a lot of people will sell they'll end up Distributing out that Bitcoin <mark>to</mark> other people the gini coefficient will keep You growing the be very few people are able <mark>to</mark> really hold on as these things go up. If we watch it go <mark>to</mark> two three four hundred thousand dollars. If you own 10 Bitcoin today, you gotta go no care. We don't end the coin today and it's at $300,000. That's three million dollars. So that's a lot of money and it's a lot of money goes <mark>to</mark> 3 million dollars in 10 years and Bitcoin. Is 30 million dollars that's an enormous amount of money. So it'll be hard <mark>to</mark> hold on <mark>to</mark> our stash because we'll always be scared of <mark>how</mark> it trades. It's going <mark>to</mark> be difficult people will spend and people have <mark>to</mark> live, you know, you got <mark>to</mark> pay your expenses. So if you have a job, you'll be earning an income. But your stash may <mark>become</mark> worth a lot of money and you want <mark>to</mark> you want <mark>to</mark> take nice vacations. You want <mark>to</mark> buy a car you want <mark>to</mark> do things with so people All do things but they will also want <mark>to</mark> enjoy that money as well. So people will probably spend some of it some will spend more than others. A lot of people won't hold anywhere near the amount of Bitcoin the number of Bitcoin that they have in 10 and 20 and 30 years. I agree. I see I mean we've seen it happen", "Start Time (s)": 3094.7, "End Time (s)": 3214.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a job, you'll be earning an income. But your stash may <mark>become</mark> worth a lot of money and you want <mark>to</mark> you want <mark>to</mark> take nice vacations. You want <mark>to</mark> buy a car you want <mark>to</mark> do things with so people All do things but they will also want <mark>to</mark> enjoy that money as well. So people will probably spend some of it some will spend more than others. A lot of people won't hold anywhere near the amount of Bitcoin the number of Bitcoin that they have in 10 and 20 and 30 years. I agree. I see I mean we've seen it happen time and time again already. That's all I'm saying. Yeah, and I guess we can end it with talking about like the perfect storm. And another thing that I thought was very very one thing. I thought was very interesting this week again playing into fundamentals and then going back <mark>to</mark> your comments earlier about getting Capitol Hill involved in lobbyist involved is Bitcoin mining becoming a function of power plants and we're seeing more oil and gas companies get into it too. So a lot of people are depending on the coin centers and you were describing like a bitcoiners pack in the future. I think we were able <mark>to</mark> Trojan Horse our way in through the energy sector particularly oil and gas companies that I think that's actually brilliant. I think that taking people might be negative on this, but think about out Bitcoin has tremendous incentives built into it for energy Innovation Energy Efficiency. Some people complain that utilities mining bitcoins and negative but one of the things I believe and so I'm not an expert here. So give me a little leeway.", "Start Time (s)": 3177.1, "End Time (s)": 3296.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of the things I believe and so I'm not an expert here. So give me a little leeway. One of the things I believe is that energy producers like utilities Electric utilities have a problem with is Peak load issues and stabilizing their production of power. If you're mining Bitcoin and you can say, okay, we'll turn the Bitcoin off the power level is whatever you can better predict the loads. You're operating at because that becomes a variable item that you can either use or not use and now you can stabilize that load you can plan your energy production in a much more precise way and my guess is and I'm not an electrical engineer. I'm not an expert in utilities, but being able <mark>to</mark> pre-plan the load that is being produced. deuced Is probably enormously beneficial <mark>to</mark> utility. So I think there are a lot of really good things that come out of that and people say oh no, this is a terrible thing, but it's probably it probably means that you can re-evaluate your investments in the latest technology produce energy more efficiently produce energy with less Solutions. That you know, I think that's yeah and get some music going on in the background there. I don't know what it was. I trying <mark>to</mark> figure out what it was. It could be. No, I didn't sell I could be an ad going off one year when your tabs it's open or something like that. I have multiple computers here can't find the mouse. That's weird. Anyway, so I think that", "Start Time (s)": 3291.1, "End Time (s)": 3410.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "load that is being produced. deuced Is probably enormously beneficial <mark>to</mark> utility. So I think there are a lot of really good things that come out of that and people say oh no, this is a terrible thing, but it's probably it probably means that you can re-evaluate your investments in the latest technology produce energy more efficiently produce energy with less Solutions. That you know, I think that's yeah and get some music going on in the background there. I don't know what it was. I trying <mark>to</mark> figure out what it was. It could be. No, I didn't sell I could be an ad going off one year when your tabs it's open or something like that. I have multiple computers here can't find the mouse. That's weird. Anyway, so I think that it becomes very beneficial <mark>to</mark> the utility sector. I think it tends <mark>to</mark> draw I think will tend <mark>to</mark> drive Innovation. And I think that that will be a very very good thing and I think that we'll see a lot of positive stuff. Come from that. I completely agree. That's like one of the things I'm most passionate about right now. The Bitcoin narrative is trying <mark>to</mark> change that energy narrative particularly. I think it is changing in it will <mark>become</mark> more obvious that Bitcoin really helps fix in efficiencies in the energy sector particularly and in a glaringly obvious way once you once you actually see like this this power plant that went live and up. New York are consuming 40 megawatts a day. That's insane. Well, if being able <mark>to</mark> have a stable amount of production, I believe", "Start Time (s)": 3352.7, "End Time (s)": 3472.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Anyway, so I think that it becomes very beneficial <mark>to</mark> the utility sector. I think it tends <mark>to</mark> draw I think will tend <mark>to</mark> drive Innovation. And I think that that will be a very very good thing and I think that we'll see a lot of positive stuff. Come from that. I completely agree. That's like one of the things I'm most passionate about right now. The Bitcoin narrative is trying <mark>to</mark> change that energy narrative particularly. I think it is changing in it will <mark>become</mark> more obvious that Bitcoin really helps fix in efficiencies in the energy sector particularly and in a glaringly obvious way once you once you actually see like this this power plant that went live and up. New York are consuming 40 megawatts a day. That's insane. Well, if being able <mark>to</mark> have a stable amount of production, I believe and you'll need somebody who knows more about this than I do, but I think that's actually a really positive thing for an energy producer rather than having this huge fluctuation. And I think you wind up with fluctuations on the basis of on the basis of the time of day as well as seasonality in the year, but I think it's those shorter term production Cycles which <mark>become</mark> difficult for utilities and being able <mark>to</mark> smooth that out. Probably is very beneficial <mark>to</mark> running those utilities, but you'll need <mark>to</mark> talk <mark>to</mark> somebody knows a lot more about it than I do. Well, I actually one of the First episodes we had on this podcast is with somebody who works at an energy company at a facility and he Saying Joe Luna Charles djou loony, he was saying I don't know if it was his particular facility", "Start Time (s)": 3409.5, "End Time (s)": 3527.2, "Clip Length (min)": 1.96, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "year, but I think it's those shorter term production Cycles which <mark>become</mark> difficult for utilities and being able <mark>to</mark> smooth that out. Probably is very beneficial <mark>to</mark> running those utilities, but you'll need <mark>to</mark> talk <mark>to</mark> somebody knows a lot more about it than I do. Well, I actually one of the First episodes we had on this podcast is with somebody who works at an energy company at a facility and he Saying Joe Luna Charles djou loony, he was saying I don't know if it was his particular facility or another around him, but they were basically putting water in like train cars and pushing it up a hill and dropping it down the hill which then had turbines that would pick up the water and sort of reproduce the energy so they had like a net zero energy consumption overnight when the load was later. So they keep the factory on but now just being able <mark>to</mark> use that energy <mark>to</mark> mind Bitcoin instead. You can make money that way and not have <mark>to</mark> do that redundant useless task. So just it just makes a lot of sense there would be fantastic. Yeah, and then good really be fantastic Oil and Gas Energy Lobby seems <mark>to</mark> be one of the biggest in the world. Like we may not even have <mark>to</mark> depend on coin Center. It may help them out so much that they go <mark>to</mark> bat for Bitcoin on Capitol Hill. That'd be great. That would be really great. And and and I think we'll see a lot of innovation. In the space. I don't I'm not an expert in energy and so incentives are really economic incentives are better ways <mark>to</mark> drive Behavior than our regulation or moral imperatives. You may think something is going <mark>to</mark> court", "Start Time (s)": 3492.7, "End Time (s)": 3612.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "just being able <mark>to</mark> use that energy <mark>to</mark> mind Bitcoin instead. You can make money that way and not have <mark>to</mark> do that redundant useless task. So just it just makes a lot of sense there would be fantastic. Yeah, and then good really be fantastic Oil and Gas Energy Lobby seems <mark>to</mark> be one of the biggest in the world. Like we may not even have <mark>to</mark> depend on coin Center. It may help them out so much that they go <mark>to</mark> bat for Bitcoin on Capitol Hill. That'd be great. That would be really great. And and and I think we'll see a lot of innovation. In the space. I don't I'm not an expert in energy and so incentives are really economic incentives are better ways <mark>to</mark> drive Behavior than our regulation or moral imperatives. You may think something is going <mark>to</mark> court the right thing <mark>to</mark> do. But if you benefit from it economically by doing it you really tend <mark>to</mark> want <mark>to</mark> do it anyway, so That just I think you can economic incentives are very powerful drivers for human behavior many of My Views around Bitcoin all revolve around price. And what price does and price is incredibly important maybe the most important thing in an economy price causes consumers and producers <mark>to</mark> make choices and if price drives Individuals and entities <mark>to</mark> do things that are net positives then that becomes a good thing. So Bitcoin becomes something which creates incentives <mark>to</mark> drive behavior that is is beneficial.", "Start Time (s)": 3552.3, "End Time (s)": 3671.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "You may think something is going <mark>to</mark> court the right thing <mark>to</mark> do. But if you benefit from it economically by doing it you really tend <mark>to</mark> want <mark>to</mark> do it anyway, so That just I think you can economic incentives are very powerful drivers for human behavior many of My Views around Bitcoin all revolve around price. And what price does and price is incredibly important maybe the most important thing in an economy price causes consumers and producers <mark>to</mark> make choices and if price drives Individuals and entities <mark>to</mark> do things that are net positives then that becomes a good thing. So Bitcoin becomes something which creates incentives <mark>to</mark> drive behavior that is is beneficial. That probably sounds what's up. Yeah, that's beautiful know I've I wholeheartedly believe that the incentives are such this are at second third order incentives outside of the direct Network are are beneficial as well. And people are just starting <mark>to</mark> notice this it's a perfect storm. It seems like it's all coming together. Everything was good for Bitcoin. All bad news. All good news is good for Bitcoin. Obstacles are nothing but things <mark>to</mark> be overcome by the social layer of Bitcoin. Bitcoins inevitable party I think so as well and I guess let's end it last note. <mark>How</mark> strong is the social layer Bitcoin right now? It's gotten stronger in this bear Market. I think so. But I mean, I'm just one person. I mean I only see what's on Twitter and", "Start Time (s)": 3610.7, "End Time (s)": 3728.1, "Clip Length (min)": 1.96, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "It seems like it's all coming together. Everything was good for Bitcoin. All bad news. All good news is good for Bitcoin. Obstacles are nothing but things <mark>to</mark> be overcome by the social layer of Bitcoin. Bitcoins inevitable party I think so as well and I guess let's end it last note. <mark>How</mark> strong is the social layer Bitcoin right now? It's gotten stronger in this bear Market. I think so. But I mean, I'm just one person. I mean I only see what's on Twitter and I think that maybe it may just be a limited window but The social are is created by the incentives of Bitcoin. So turns out Marty that you don't change Bitcoin Bitcoin changes you. And we're going <mark>to</mark> add that on that peace and love freaks.", "Start Time (s)": 3692.5, "End Time (s)": 3753.5, "Clip Length (min)": 1.02, "show_uri": "spotify:show:0Vd8E5vWnCfB4xucu87WNZ", "show_name": "Tales from the Crypt: A Bitcoin Podcast", "show_description": "\"Tales from the Crypt is a podcast hosted by Marty Bent about Bitcoin. Join Marty, Editor in Chief of \"\"the best newsletter in Bitcoin\"\", as he sits down to discuss Bitcoin with interesting people.\"", "publisher": "Marty Bent", "episode_uri": "spotify:episode:3pd9Ak7rGhCbU4dBI9U54U", "episode_name": "\"#138: BitcoinTINA \"\"The Perfect Storm\"\"\"", "episode_description": "\"Join Marty as he sits down with BitcoinTINA to discuss how the macro factors lining up in the world right now are a perfect storm for Bitcoin in the medium to long-term. Follow BitcoinTINA on Twitter Shoutout to this week's sponsors. Cash App. Start #stackingsats today. Use the promo code: \"\"stackingsats\"\" to receive $10 and contribute $10 to OWLS Lacrosse you download the app. \"", "score": 4.045242, "explanation": "{\n  \"value\": 4.045242,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.116634145,\n      \"description\": \"weight(word_list:how in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.116634145,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.20074412,\n      \"description\": \"weight(word_list:to in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.20074412,\n          \"description\": \"score(LMDirichletSimilarity, freq=320.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.9270757,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 320.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1832407,\n      \"description\": \"weight(word_list:become in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1832407,\n          \"description\": \"score(LMDirichletSimilarity, freq=18.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9095724,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 18.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5446229,\n      \"description\": \"weight(word_list:rich in 141) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5446229,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.7263317,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 9240.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the 9th and 10th Commandments Thou shalt not covet thy neighbor's house Thou shalt not covet thy neighbor's wife nor his manservant nor his maidservant nor his cattle nor anything that is his These two Commandments are given quite exclusively <mark>to</mark> the Jews nevertheless in part. They also concern us for they do not interpret them as referring <mark>to</mark> unchastity or theft because these are sufficiently forbidden above they also thought that they had kept all those when they had done or not done. The external act. Therefore God has added these two Commandments in order that it be esteemed as Sin and forbidden <mark>to</mark> Fire or in any way <mark>to</mark> aim at getting our neighbor's wife or possessions and especially because under the Jewish government man servants and Maid servants were not free as now <mark>to</mark> serve for wages as long as they pleased but were their Master's property with their body and all they had as cattle and other possessions. Moreover every man had power over his wife <mark>to</mark> put her away publicly by giving her a bill of divorce and <mark>to</mark> take another. Therefore they were in constant", "Start Time (s)": 7.6, "End Time (s)": 87.1, "Clip Length (min)": 1.32, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "nor anything that is his These two Commandments are given quite exclusively <mark>to</mark> the Jews nevertheless in part. They also concern us for they do not interpret them as referring <mark>to</mark> unchastity or theft because these are sufficiently forbidden above they also thought that they had kept all those when they had done or not done. The external act. Therefore God has added these two Commandments in order that it be esteemed as Sin and forbidden <mark>to</mark> Fire or in any way <mark>to</mark> aim at getting our neighbor's wife or possessions and especially because under the Jewish government man servants and Maid servants were not free as now <mark>to</mark> serve for wages as long as they pleased but were their Master's property with their body and all they had as cattle and other possessions. Moreover every man had power over his wife <mark>to</mark> put her away publicly by giving her a bill of divorce and <mark>to</mark> take another. Therefore they were in constant danger among each other that if one took a fancy <mark>to</mark> another's wife, he might allege any reason both <mark>to</mark> dismiss his own wife and two estranged the others wife from him that he might obtain her under a pretext of right that was not considered a discuss in nor disgrace with them as little as now with hired help when a proprietor dismisses his manservant or maidservant. Or takes another servants from him in any way. Therefore I say they thus interpreted these Commandments and that rightly although their scope reaches somewhat farther and higher that no one think or purpose <mark>to</mark> obtain what belongs <mark>to</mark> another such as his wife Servants house and estate land Meadows cattle", "Start Time (s)": 20.5, "End Time (s)": 139.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "property with their body and all they had as cattle and other possessions. Moreover every man had power over his wife <mark>to</mark> put her away publicly by giving her a bill of divorce and <mark>to</mark> take another. Therefore they were in constant danger among each other that if one took a fancy <mark>to</mark> another's wife, he might allege any reason both <mark>to</mark> dismiss his own wife and two estranged the others wife from him that he might obtain her under a pretext of right that was not considered a discuss in nor disgrace with them as little as now with hired help when a proprietor dismisses his manservant or maidservant. Or takes another servants from him in any way. Therefore I say they thus interpreted these Commandments and that rightly although their scope reaches somewhat farther and higher that no one think or purpose <mark>to</mark> obtain what belongs <mark>to</mark> another such as his wife Servants house and estate land Meadows cattle even with a show of right or by a sub. huge yet with injury <mark>to</mark> his neighbor For above and the seventh commandment the vice is forbidden where one rests <mark>to</mark> himself the possessions of others or with holds them from his neighbor, which he cannot do by right but here it is also forbidden <mark>to</mark> alienate anything from your neighbor, even though you could do so with honor in the eyes of the world so that no one could accuse or blame you as though you had obtained it wrongfully. For we are so inclined by Nature that no one desires <mark>to</mark> see another have as much as himself and each one acquires as much as he can the other Mayfair as best he can and yet we pretend <mark>to</mark> be Godly know <mark>how</mark> <mark>to</mark> Adorn ourselves most finally", "Start Time (s)": 70.9, "End Time (s)": 190.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and higher that no one think or purpose <mark>to</mark> obtain what belongs <mark>to</mark> another such as his wife Servants house and estate land Meadows cattle even with a show of right or by a sub. huge yet with injury <mark>to</mark> his neighbor For above and the seventh commandment the vice is forbidden where one rests <mark>to</mark> himself the possessions of others or with holds them from his neighbor, which he cannot do by right but here it is also forbidden <mark>to</mark> alienate anything from your neighbor, even though you could do so with honor in the eyes of the world so that no one could accuse or blame you as though you had obtained it wrongfully. For we are so inclined by Nature that no one desires <mark>to</mark> see another have as much as himself and each one acquires as much as he can the other Mayfair as best he can and yet we pretend <mark>to</mark> be Godly know <mark>how</mark> <mark>to</mark> Adorn ourselves most finally and conceal our rascality resort <mark>to</mark> and invent a Droid devices and deceitful artifices such as now our daily most ingeniously contrived. Though they were derived from the law codes. Yay. We even dare impertinently <mark>to</mark> refer <mark>to</mark> it and boast of it and will not have it called rascality but shrewdness and caution in this lawyers and jurists assist who twist and stretch the law <mark>to</mark> suited <mark>to</mark> their cause stress words and use them for a subterfuge irrespective of equity or their neighbors necessity. And in short whoever is the most expert and cunning and these Affairs finds most help in law as they themselves say we keen on taboos uraza between you and that is the laws favor the watchful. This last", "Start Time (s)": 127.2, "End Time (s)": 246.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and invent a Droid devices and deceitful artifices such as now our daily most ingeniously contrived. Though they were derived from the law codes. Yay. We even dare impertinently <mark>to</mark> refer <mark>to</mark> it and boast of it and will not have it called rascality but shrewdness and caution in this lawyers and jurists assist who twist and stretch the law <mark>to</mark> suited <mark>to</mark> their cause stress words and use them for a subterfuge irrespective of equity or their neighbors necessity. And in short whoever is the most expert and cunning and these Affairs finds most help in law as they themselves say we keen on taboos uraza between you and that is the laws favor the watchful. This last commandment therefore is given not for Rogues in the eyes of the world. But just for the most Pious who wish <mark>to</mark> be praised and be called honest and upright people since they have not offended against this former Commander the former Commandments as especially the Jews claim <mark>to</mark> be and even now many great nobleman gentlemen and princes for the other common masses belong yet farther down under the seventh commandment as those who are not not much concern whether they acquire their possessions with honor and right now this occurs most frequently in cases that are brought into court where it is the purpose <mark>to</mark> get something from our neighbor and <mark>to</mark> force him out of his own as <mark>to</mark> give examples when people quarrel and Wrangle about a large inheritance real estate Etc. They Avail themselves of and resort <mark>to</mark> whatever has the appearance of right so dressing and adorning. That the law must favor their side and they keep the property with such title that no one can make complaint or lay claim their <mark>to</mark>", "Start Time (s)": 194.1, "End Time (s)": 313.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "who wish <mark>to</mark> be praised and be called honest and upright people since they have not offended against this former Commander the former Commandments as especially the Jews claim <mark>to</mark> be and even now many great nobleman gentlemen and princes for the other common masses belong yet farther down under the seventh commandment as those who are not not much concern whether they acquire their possessions with honor and right now this occurs most frequently in cases that are brought into court where it is the purpose <mark>to</mark> get something from our neighbor and <mark>to</mark> force him out of his own as <mark>to</mark> give examples when people quarrel and Wrangle about a large inheritance real estate Etc. They Avail themselves of and resort <mark>to</mark> whatever has the appearance of right so dressing and adorning. That the law must favor their side and they keep the property with such title that no one can make complaint or lay claim their <mark>to</mark> in like manner if anyone desire <mark>to</mark> have a castle City duchy or any other great thing. He practices so much Finance searing through relationships. And by any means he can that the other is judicially deprived of it and it is adjudicated <mark>to</mark> him and confirmed with deed and seal. And declared <mark>to</mark> have been acquired by princely title and honestly. Likewise also in common trade where one dexterously slipped something out of another's hand so that he must look after it or surprises and defrauds him in a manner which he sees advantage and benefit for himself. So that the latter perhaps on account of distress or debt cannot regain or redeem it without injury and the former games the half or even more and yet this must not be considered as acquired by fraud or Colin but", "Start Time (s)": 253.5, "End Time (s)": 372.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "or any other great thing. He practices so much Finance searing through relationships. And by any means he can that the other is judicially deprived of it and it is adjudicated <mark>to</mark> him and confirmed with deed and seal. And declared <mark>to</mark> have been acquired by princely title and honestly. Likewise also in common trade where one dexterously slipped something out of another's hand so that he must look after it or surprises and defrauds him in a manner which he sees advantage and benefit for himself. So that the latter perhaps on account of distress or debt cannot regain or redeem it without injury and the former games the half or even more and yet this must not be considered as acquired by fraud or Colin but honestly bought here they say first come first served and everyone must look <mark>to</mark> his own interest let another get what he can and who can be so smart as <mark>to</mark> think of all the ways in which one can get many things into his possession by such species protects this the world does not consider wrong and will not see that the neighbor is thereby placed at a disadvantage and must sacrifice what he cannot spare without injury yet. There is no one who wishes this <mark>to</mark> be done <mark>to</mark> him. From which we can easily perceive that such devices and pretexts are false. The said was done formally with respect <mark>to</mark> wives. They knew such devices that if one were pleased with another woman, he personally or through others as there were many ways and means <mark>to</mark> be invented caused her husband <mark>to</mark> conceive a displeasure toward her or had her resist him and so conduct herself that he was obliged <mark>to</mark> dismiss her and leave her <mark>to</mark> the other that sort of thing", "Start Time (s)": 319.8, "End Time (s)": 439.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "as acquired by fraud or Colin but honestly bought here they say first come first served and everyone must look <mark>to</mark> his own interest let another get what he can and who can be so smart as <mark>to</mark> think of all the ways in which one can get many things into his possession by such species protects this the world does not consider wrong and will not see that the neighbor is thereby placed at a disadvantage and must sacrifice what he cannot spare without injury yet. There is no one who wishes this <mark>to</mark> be done <mark>to</mark> him. From which we can easily perceive that such devices and pretexts are false. The said was done formally with respect <mark>to</mark> wives. They knew such devices that if one were pleased with another woman, he personally or through others as there were many ways and means <mark>to</mark> be invented caused her husband <mark>to</mark> conceive a displeasure toward her or had her resist him and so conduct herself that he was obliged <mark>to</mark> dismiss her and leave her <mark>to</mark> the other that sort of thing undoubtedly prevailed much under the law as also we read in the gospel of King Herod that he Took his brother's wife while he was yet living and yet wish <mark>to</mark> be thought as an honorable Pious man as Saint Mark also testifies of him. But such an example, I trust will not occur among us because in the New Testament those who are married are forbidden <mark>to</mark> be divorced except in such a case where one by some stratagem takes away a <mark>rich</mark> bride from another but it is not a rare thing with us that one estranges or alienates another's manservant for maidservant or entices them away by flattering words. In whatever way such things happen. We must know that God does not wish that you deprive your neighbor of", "Start Time (s)": 370.0, "End Time (s)": 489.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "toward her or had her resist him and so conduct herself that he was obliged <mark>to</mark> dismiss her and leave her <mark>to</mark> the other that sort of thing undoubtedly prevailed much under the law as also we read in the gospel of King Herod that he Took his brother's wife while he was yet living and yet wish <mark>to</mark> be thought as an honorable Pious man as Saint Mark also testifies of him. But such an example, I trust will not occur among us because in the New Testament those who are married are forbidden <mark>to</mark> be divorced except in such a case where one by some stratagem takes away a <mark>rich</mark> bride from another but it is not a rare thing with us that one estranges or alienates another's manservant for maidservant or entices them away by flattering words. In whatever way such things happen. We must know that God does not wish that you deprive your neighbor of anything that belongs <mark>to</mark> him so that he suffer the loss and you gratify your avarice with it. Even if you could keep it honorably before the world for it is a secret and Insidious imposition practiced under the Hat as we say that it may not be observed. For although you go your way as if you had done no one any wrong, you have nevertheless injured your neighbor and if it is not called stealing and cheating yet. It is called coveting. Your neighbor's property that is aiming at possession of it enticing it away from him without his will and being unwilling <mark>to</mark> see him enjoy what God has granted him. And although the judge and everyone must leave you in possession of it yet. God will not leave you there in for he sees the deceitful heart and the malice of the world, which is sure <mark>to</mark> take an L. In addition wherever you yield <mark>to</mark> her in a fingers breadth and at length public wrong and", "Start Time (s)": 431.2, "End Time (s)": 550.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "way such things happen. We must know that God does not wish that you deprive your neighbor of anything that belongs <mark>to</mark> him so that he suffer the loss and you gratify your avarice with it. Even if you could keep it honorably before the world for it is a secret and Insidious imposition practiced under the Hat as we say that it may not be observed. For although you go your way as if you had done no one any wrong, you have nevertheless injured your neighbor and if it is not called stealing and cheating yet. It is called coveting. Your neighbor's property that is aiming at possession of it enticing it away from him without his will and being unwilling <mark>to</mark> see him enjoy what God has granted him. And although the judge and everyone must leave you in possession of it yet. God will not leave you there in for he sees the deceitful heart and the malice of the world, which is sure <mark>to</mark> take an L. In addition wherever you yield <mark>to</mark> her in a fingers breadth and at length public wrong and violence follow. Therefore we allow these Commandments <mark>to</mark> remain in their ordinary meaning that it is commanded first that we do not desire our neighbors damage nor even assist nor give occasion for it, but gladly wish and leave him what he has and besides advance and preserve for him what maybe for his profit and Service as we should wish <mark>to</mark> be treated. Thus these Commandments are especially directed against envy and miserable. Avarice. God wishes <mark>to</mark> remove all causes and sources whence arises everything by which we do injury <mark>to</mark> our neighbor. And therefore he expresses it in plain words Thou shalt not covet Etc. For he would especially have the heart pure", "Start Time (s)": 483.1, "End Time (s)": 602.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "wherever you yield <mark>to</mark> her in a fingers breadth and at length public wrong and violence follow. Therefore we allow these Commandments <mark>to</mark> remain in their ordinary meaning that it is commanded first that we do not desire our neighbors damage nor even assist nor give occasion for it, but gladly wish and leave him what he has and besides advance and preserve for him what maybe for his profit and Service as we should wish <mark>to</mark> be treated. Thus these Commandments are especially directed against envy and miserable. Avarice. God wishes <mark>to</mark> remove all causes and sources whence arises everything by which we do injury <mark>to</mark> our neighbor. And therefore he expresses it in plain words Thou shalt not covet Etc. For he would especially have the heart pure although we shall never attain <mark>to</mark> that as long as we live here so that this commandment will remain like all the rest one that will constantly accuse us and show <mark>how</mark> Godly we are in the sight of God. conclusion of the Ten Commandments thus we have the Ten Commandments a compendium of divine Doctrine as <mark>to</mark> what we are <mark>to</mark> do in order that our whole life may be pleasing <mark>to</mark> God and the true Fountain and channel from and in which everything must arise and flow that is <mark>to</mark> be a good work. So that outside of the Ten Commandments no work or thing can be good or pleasing <mark>to</mark> God. However, great or precious it be in the eyes of the world. Let us see now what our great Saints can boast of their spiritual orders and they're great and Grievous works with which they have invented and set up while they let these pass as though they were far too", "Start Time (s)": 544.9, "End Time (s)": 664.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "conclusion of the Ten Commandments thus we have the Ten Commandments a compendium of divine Doctrine as <mark>to</mark> what we are <mark>to</mark> do in order that our whole life may be pleasing <mark>to</mark> God and the true Fountain and channel from and in which everything must arise and flow that is <mark>to</mark> be a good work. So that outside of the Ten Commandments no work or thing can be good or pleasing <mark>to</mark> God. However, great or precious it be in the eyes of the world. Let us see now what our great Saints can boast of their spiritual orders and they're great and Grievous works with which they have invented and set up while they let these pass as though they were far too insignificant or had long ago been perfectly fulfilled. I am of opinion indeed that here one will find his hands full <mark>to</mark> do <mark>to</mark> observe these namely meekness patience and love towards enemies Chastity kindness Etc. And what such virtues imply. But such works are not a value and make no display in the eyes of the world for they are not peculiar and conceited works and restricted <mark>to</mark> particular times places rites and Customs but our common everyday domestic Works which one neighbor can practice toward another therefore. They are not of high esteem. But the other works cause people <mark>to</mark> open their eyes and ears wide and Men Aid <mark>to</mark> this effect by the great display expense and magnificent buildings with which they Adorn them so that everything shines and Glitters there. They walked in sense. They sing and ring bells they light tapers and candles so that nothing else can be seen or heard for when a priest stands there", "Start Time (s)": 618.8, "End Time (s)": 735.3, "Clip Length (min)": 1.94, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of high esteem. But the other works cause people <mark>to</mark> open their eyes and ears wide and Men Aid <mark>to</mark> this effect by the great display expense and magnificent buildings with which they Adorn them so that everything shines and Glitters there. They walked in sense. They sing and ring bells they light tapers and candles so that nothing else can be seen or heard for when a priest stands there in a surplice embroidered with guilt or a Layman continues all day upon his He's in church that is regarded as a most precious work which no one can sufficiently praise but when a poor girl tends a little child and Faithfully does what she is told that is considered nothing for for else. What should monks and nuns seek in their Cloisters? But C is not that accursed presumption of those desperate Saints who dare <mark>to</mark> invent a higher and better life and estate than the Ten Commandments teach pretending as we have said that this is an ordinary life for the common man, but that there's is for Saints and perfect ones. And the miserable blind people do not see that no man can get so far as <mark>to</mark> keep one of the Ten Commandments as it should be kept but both the Apostles Creed and the Lord's Prayer must come <mark>to</mark> our Aid as we shall hear by which that is sought and prayed for and received continually. Therefore all they're boasting amounts <mark>to</mark> as much as if I boasted and said <mark>to</mark> be sure I have not a penny <mark>to</mark> make payment with but I confidently undertake <mark>to</mark> pay ten florins. All this I say and urge in order that men might <mark>become</mark> rid of the sad misuse which has taken such deep root and still Cleaves <mark>to</mark>", "Start Time (s)": 708.2, "End Time (s)": 827.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "But C is not that accursed presumption of those desperate Saints who dare <mark>to</mark> invent a higher and better life and estate than the Ten Commandments teach pretending as we have said that this is an ordinary life for the common man, but that there's is for Saints and perfect ones. And the miserable blind people do not see that no man can get so far as <mark>to</mark> keep one of the Ten Commandments as it should be kept but both the Apostles Creed and the Lord's Prayer must come <mark>to</mark> our Aid as we shall hear by which that is sought and prayed for and received continually. Therefore all they're boasting amounts <mark>to</mark> as much as if I boasted and said <mark>to</mark> be sure I have not a penny <mark>to</mark> make payment with but I confidently undertake <mark>to</mark> pay ten florins. All this I say and urge in order that men might <mark>become</mark> rid of the sad misuse which has taken such deep root and still Cleaves <mark>to</mark> everybody and in all Estates upon Earth <mark>become</mark> used <mark>to</mark> looking hither only and <mark>to</mark> being concerned about these matters. For it will be a long time before they will produce a Doctrine or a state's equal <mark>to</mark> the Ten Commandments because they are so high that no one can attain <mark>to</mark> them by human power. And whoever does attain <mark>to</mark> them is a Heavenly Angelic man far above all Holiness of the world only occupy yourself with them and try your best apply all power and ability. And you will find so much <mark>to</mark> do that. You will neither seek nor steam any other work or holiness. Let this be sufficient concerning the first part of the common Christian doctrine both for teaching and urging what is necessary in conclusion. However, we must repeat the text which belongs here", "Start Time (s)": 763.4, "End Time (s)": 881.6, "Clip Length (min)": 1.97, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and in all Estates upon Earth <mark>become</mark> used <mark>to</mark> looking hither only and <mark>to</mark> being concerned about these matters. For it will be a long time before they will produce a Doctrine or a state's equal <mark>to</mark> the Ten Commandments because they are so high that no one can attain <mark>to</mark> them by human power. And whoever does attain <mark>to</mark> them is a Heavenly Angelic man far above all Holiness of the world only occupy yourself with them and try your best apply all power and ability. And you will find so much <mark>to</mark> do that. You will neither seek nor steam any other work or holiness. Let this be sufficient concerning the first part of the common Christian doctrine both for teaching and urging what is necessary in conclusion. However, we must repeat the text which belongs here of which we have treated already in the first commandment in order that we may learn what pains God requires <mark>to</mark> the end that we may learn <mark>to</mark> inculcate and practice the Ten Commandments. For I the Lord thy God am a jealous God visiting the iniquity of the father's upon the children <mark>to</mark> the third unto the third and fourth generation of them that hate me and showing Mercy unto thousands of them that love me and keep my Commandments. Although as we have heard above this appendix was primarily attached <mark>to</mark> the first commandment. It was nevertheless laid down for the sake of all the Commandments as all of them are <mark>to</mark> be referred and directed <mark>to</mark> it. Therefore I have said that this too should be presented <mark>to</mark> an inculcated upon the young that they may learn and remember it in order <mark>to</mark> see what is <mark>to</mark> urge and compel us <mark>to</mark> keep these 10 commandments and it is <mark>to</mark> be regarded as though this part worse. Specially added <mark>to</mark> each so that in an it inheres in and", "Start Time (s)": 829.0, "End Time (s)": 947.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "However, we must repeat the text which belongs here of which we have treated already in the first commandment in order that we may learn what pains God requires <mark>to</mark> the end that we may learn <mark>to</mark> inculcate and practice the Ten Commandments. For I the Lord thy God am a jealous God visiting the iniquity of the father's upon the children <mark>to</mark> the third unto the third and fourth generation of them that hate me and showing Mercy unto thousands of them that love me and keep my Commandments. Although as we have heard above this appendix was primarily attached <mark>to</mark> the first commandment. It was nevertheless laid down for the sake of all the Commandments as all of them are <mark>to</mark> be referred and directed <mark>to</mark> it. Therefore I have said that this too should be presented <mark>to</mark> an inculcated upon the young that they may learn and remember it in order <mark>to</mark> see what is <mark>to</mark> urge and compel us <mark>to</mark> keep these 10 commandments and it is <mark>to</mark> be regarded as though this part worse. Specially added <mark>to</mark> each so that in an it inheres in and pervades them all. now there is comprehended in these words as said before both an angry word of threatening and a friendly promise <mark>to</mark> terrify and warn us and moreover <mark>to</mark> induce and encourage us <mark>to</mark> receive and highly esteem his word as a matter of divine earnestness because he himself declares <mark>how</mark> much he is concerned about it and <mark>how</mark> rigidly he will enforce it namely that he will horribly and terribly punish all who despised and transgress his And again <mark>how</mark> richly he will reward bless and do good <mark>to</mark> those who hold them in high esteem and gladly do and live according <mark>to</mark> them. Thus he demands that all our works proceed from a heart which fears and regards God alone and from such", "Start Time (s)": 878.1, "End Time (s)": 997.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "presented <mark>to</mark> an inculcated upon the young that they may learn and remember it in order <mark>to</mark> see what is <mark>to</mark> urge and compel us <mark>to</mark> keep these 10 commandments and it is <mark>to</mark> be regarded as though this part worse. Specially added <mark>to</mark> each so that in an it inheres in and pervades them all. now there is comprehended in these words as said before both an angry word of threatening and a friendly promise <mark>to</mark> terrify and warn us and moreover <mark>to</mark> induce and encourage us <mark>to</mark> receive and highly esteem his word as a matter of divine earnestness because he himself declares <mark>how</mark> much he is concerned about it and <mark>how</mark> rigidly he will enforce it namely that he will horribly and terribly punish all who despised and transgress his And again <mark>how</mark> richly he will reward bless and do good <mark>to</mark> those who hold them in high esteem and gladly do and live according <mark>to</mark> them. Thus he demands that all our works proceed from a heart which fears and regards God alone and from such fear of avoids everything that is contrary <mark>to</mark> his will lest. It should move him <mark>to</mark> wrath and on the other hand also trusts in him alone and from love <mark>to</mark> him does all he wishes because he speaks <mark>to</mark> us as a friendly as friendly as a father and offers us all Grace and every good Just this is also the meaning and true interpretation of the first and chief commandment from which all the others must flow and proceed so that this word thou shalt have no other gods before me in its simplest meaning States. Nothing else than this demand Thou shalt fear love and trust in me as thine only true God for where there is a heart thus disposed towards God the same has fulfilled this and all the other Commandments. On the other hand, whoever", "Start Time (s)": 929.6, "End Time (s)": 1049.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "so that this word thou shalt have no other gods before me in its simplest meaning States. Nothing else than this demand Thou shalt fear love and trust in me as thine only true God for where there is a heart thus disposed towards God the same has fulfilled this and all the other Commandments. On the other hand, whoever fears and loves anything else in heaven and upon Earth will keep neither this nor any thus the entire scriptures have everywhere preached and inculcated this commandment aiming always at these two things fear of God and trust in him. And especially the prophet David throughout the Psalms as when he says the lord taketh pleasure in them that fear Him in those that hope in him in his Mercy. As if the entire commandment were explained by one verse as much as <mark>to</mark> say the lord taketh pleasure in those who have no other gods. Thus the first commandment is <mark>to</mark> shine and imparted Splendor <mark>to</mark> all the others. Therefore. You must let this declaration run through all the Commandments like a hoop in a wreath joining the end <mark>to</mark> the beginning and holding them all together that it be continually repeated and not forgotten as namely in the second commandment that we fear God and do not take his name in vain for cursing lying deceiving and other modes of Leading Men astray or rascality, but make proper and good you. Of it by calling upon him in prayer praise and thanksgiving derived from Love and Trust according <mark>to</mark> the first commandment in like manner such fear love and trust is <mark>to</mark> urge and force us not <mark>to</mark> despise his word but gladly <mark>to</mark> learn here and esteem at Holy and honor it. Thus continuing through all the following", "Start Time (s)": 1026.5, "End Time (s)": 1145.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in those that hope in him in his Mercy. As if the entire commandment were explained by one verse as much as <mark>to</mark> say the lord taketh pleasure in those who have no other gods. Thus the first commandment is <mark>to</mark> shine and imparted Splendor <mark>to</mark> all the others. Therefore. You must let this declaration run through all the Commandments like a hoop in a wreath joining the end <mark>to</mark> the beginning and holding them all together that it be continually repeated and not forgotten as namely in the second commandment that we fear God and do not take his name in vain for cursing lying deceiving and other modes of Leading Men astray or rascality, but make proper and good you. Of it by calling upon him in prayer praise and thanksgiving derived from Love and Trust according <mark>to</mark> the first commandment in like manner such fear love and trust is <mark>to</mark> urge and force us not <mark>to</mark> despise his word but gladly <mark>to</mark> learn here and esteem at Holy and honor it. Thus continuing through all the following Commandments toward our neighbor likewise everything is <mark>to</mark> proceed by virtue of the first commandment <mark>to</mark> wit that we honor father and mother Masters and all an authority and be subject <mark>to</mark> an obedient <mark>to</mark> them not on their own account. But for God's sake for you are not <mark>to</mark> regard or fear father or mother or from love of them do or omit anything but see <mark>to</mark> that which God would have you do and what we want. Will quite surely demand of you if you omit that you have an angry judge, but on the contrary case a gracious father. Again that you do know your neighbor no harm injury or violence nor in any wise encroach upon him as touching his body wife property honor or rights as all these things are commanded in their order, even though", "Start Time (s)": 1078.2, "End Time (s)": 1197.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "at Holy and honor it. Thus continuing through all the following Commandments toward our neighbor likewise everything is <mark>to</mark> proceed by virtue of the first commandment <mark>to</mark> wit that we honor father and mother Masters and all an authority and be subject <mark>to</mark> an obedient <mark>to</mark> them not on their own account. But for God's sake for you are not <mark>to</mark> regard or fear father or mother or from love of them do or omit anything but see <mark>to</mark> that which God would have you do and what we want. Will quite surely demand of you if you omit that you have an angry judge, but on the contrary case a gracious father. Again that you do know your neighbor no harm injury or violence nor in any wise encroach upon him as touching his body wife property honor or rights as all these things are commanded in their order, even though you have opportunity and cause <mark>to</mark> do so and no man would reprove you but that you do good <mark>to</mark> all men help them and promote their interest howsoever and wherever wherever you can purely from love of God. And in order <mark>to</mark> please him in the confidence that he will abundantly reward you for everything. Thus you see <mark>how</mark> the first commandment is the chief source and Fountainhead which flows into all the rest and again all return <mark>to</mark> that and depend upon it so that beginning and end are fastened and bound <mark>to</mark> each other. This I say it is profitable and necessary always <mark>to</mark> teach <mark>to</mark> the young people <mark>to</mark> admonish them and <mark>to</mark> remind them of it that they may be brought up not only with blows and compulsion like cattle but in the fear and reverence of God for where this is considered and lead <mark>to</mark> heart that these things are not human Trifles, but the Commandments that of of the Divine", "Start Time (s)": 1140.1, "End Time (s)": 1259.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "things are commanded in their order, even though you have opportunity and cause <mark>to</mark> do so and no man would reprove you but that you do good <mark>to</mark> all men help them and promote their interest howsoever and wherever wherever you can purely from love of God. And in order <mark>to</mark> please him in the confidence that he will abundantly reward you for everything. Thus you see <mark>how</mark> the first commandment is the chief source and Fountainhead which flows into all the rest and again all return <mark>to</mark> that and depend upon it so that beginning and end are fastened and bound <mark>to</mark> each other. This I say it is profitable and necessary always <mark>to</mark> teach <mark>to</mark> the young people <mark>to</mark> admonish them and <mark>to</mark> remind them of it that they may be brought up not only with blows and compulsion like cattle but in the fear and reverence of God for where this is considered and lead <mark>to</mark> heart that these things are not human Trifles, but the Commandments that of of the Divine Majesty who insists upon them with such earnestness is angry with and punishes those who despise them. And on the other hand abundantly rewards those who keep them. There will be a spontaneous impulse and desire gladly <mark>to</mark> do the will of God. Therefore it is not in vain that it is commanded in the Old Testament <mark>to</mark> write the Ten Commandments on all walls and Corners. Yes, even on the garments not for the sake of merely having them written these places and making a show of them as did the Jews but that we might have our eyes constantly fixed upon them and have them always in our memory and that we might practice them in all our actions and ways and everyone make them his daily exercise in all cases in every business and Action as though they were written in every place wherever he would look ye wherever he walks or stands.", "Start Time (s)": 1194.2, "End Time (s)": 1313.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "who insists upon them with such earnestness is angry with and punishes those who despise them. And on the other hand abundantly rewards those who keep them. There will be a spontaneous impulse and desire gladly <mark>to</mark> do the will of God. Therefore it is not in vain that it is commanded in the Old Testament <mark>to</mark> write the Ten Commandments on all walls and Corners. Yes, even on the garments not for the sake of merely having them written these places and making a show of them as did the Jews but that we might have our eyes constantly fixed upon them and have them always in our memory and that we might practice them in all our actions and ways and everyone make them his daily exercise in all cases in every business and Action as though they were written in every place wherever he would look ye wherever he walks or stands. Thus there would be occasion enough both at home in our own house and abroad with our neighbors <mark>to</mark> practice the 10 commandments that no one need run far for them. From this it again appears <mark>how</mark> highly these Ten Commandments are <mark>to</mark> be exalted and extolled above all Estates Commandments and works which are taught and practiced aside from them. For here, we can boast and say let all the whys and Saints step forth and produce if they can a work like these Commandments upon which God insists with such earnestness and which he enjoins with his greatest wrath and Punishment and besides add such glorious promises that he will pour out upon us all good things and blessings. Therefore they should be taught above all others and be esteemed precious and dear as the highest treasure given by God. Part II of the Creed", "Start Time (s)": 1260.5, "End Time (s)": 1377.7, "Clip Length (min)": 1.95, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "From this it again appears <mark>how</mark> highly these Ten Commandments are <mark>to</mark> be exalted and extolled above all Estates Commandments and works which are taught and practiced aside from them. For here, we can boast and say let all the whys and Saints step forth and produce if they can a work like these Commandments upon which God insists with such earnestness and which he enjoins with his greatest wrath and Punishment and besides add such glorious promises that he will pour out upon us all good things and blessings. Therefore they should be taught above all others and be esteemed precious and dear as the highest treasure given by God. Part II of the Creed thus far we have heard the first part of Christian doctrine in which we have seen all that God wishes us <mark>to</mark> do or <mark>to</mark> leave undone. Now they're properly follows the Creed which sets forth <mark>to</mark> us everything that we must expect and receive from God and <mark>to</mark> stated quite briefly teaches us <mark>to</mark> know him fully and this is intended <mark>to</mark> help us do that which according <mark>to</mark> the Ten Commandments we ought <mark>to</mark> do for as said above they are set so high that all human ability is far too feeble and weak <mark>to</mark> keep them. Therefore it is necessary <mark>to</mark> learn this part as the former in order that we may know <mark>how</mark> <mark>to</mark> attain their <mark>to</mark> When sin whereby <mark>to</mark> obtain such power for if we could buy our own powers keep the Ten Commandments as they are <mark>to</mark> be kept we would need nothing further. Neither the Creed nor the Lord's Prayer, but before we explain this advantage and necessity of the Creed, it is sufficient at first for the simple-minded that they learn <mark>to</mark> comprehend and understand", "Start Time (s)": 1327.5, "End Time (s)": 1447.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "we have seen all that God wishes us <mark>to</mark> do or <mark>to</mark> leave undone. Now they're properly follows the Creed which sets forth <mark>to</mark> us everything that we must expect and receive from God and <mark>to</mark> stated quite briefly teaches us <mark>to</mark> know him fully and this is intended <mark>to</mark> help us do that which according <mark>to</mark> the Ten Commandments we ought <mark>to</mark> do for as said above they are set so high that all human ability is far too feeble and weak <mark>to</mark> keep them. Therefore it is necessary <mark>to</mark> learn this part as the former in order that we may know <mark>how</mark> <mark>to</mark> attain their <mark>to</mark> When sin whereby <mark>to</mark> obtain such power for if we could buy our own powers keep the Ten Commandments as they are <mark>to</mark> be kept we would need nothing further. Neither the Creed nor the Lord's Prayer, but before we explain this advantage and necessity of the Creed, it is sufficient at first for the simple-minded that they learn <mark>to</mark> comprehend and understand the it itself. In the first place. The Creed has hitherto been divided into twelve articles, although if all points which are written in the scriptures and which belonged <mark>to</mark> the Creed were <mark>to</mark> be distinctly set forth. There would be far more articles nor could they all be clearly expressed in so few words, but that it may be most easily and clearly understood as it is <mark>to</mark> be taught <mark>to</mark> children. We shall briefly sum up the entire Creed in three Chief articles according <mark>to</mark> the three persons in the godhead <mark>to</mark> whom everything that we believe is related. So that the first article of God the Father explains creation the second article of the sun Redemption and the third of the Holy Ghost sanctification Just as though the Creed were briefly comprehended in", "Start Time (s)": 1385.5, "End Time (s)": 1505.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So that the first article of God the Father explains creation the second article of the sun Redemption and the third of the Holy Ghost sanctification Just as though the Creed were briefly comprehended in so many words. I believe in God the Father who has created me. I believe in God the son who has redeemed me. I believe in the Holy Ghost who sanctifies me. One God and one Faith but three persons therefore also three articles or confessions. Let us briefly run over the words. Article 1 I believe in God the Father Almighty maker of heaven and Earth. This portrays and sets forth most briefly. What is the essence will activity and work of God the Father for since the Ten Commandments have taught that we are <mark>to</mark> have not more than one God. The question might be asked what kind of a person is God. What does he do? <mark>How</mark> can we praise or portray in describe him that he may be known? Now that is taught in this and the following article so that the Creed is nothing else than the answer and confession of Christians arranged with respect <mark>to</mark> the first commandment as if you were <mark>to</mark> ask a a little child my dear what sort of a God have you what do you know of him? He could say this is my God first the father who has created heaven and earth besides this the only one I regard nothing else as God. For there is no one else who could create Heaven and Earth. But for the learned' and those who are somewhat Advanced these three articles may all be expanded and divided into as many parts as there are words. But now for Young", "Start Time (s)": 1488.0, "End Time (s)": 1607.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "God. The question might be asked what kind of a person is God. What does he do? <mark>How</mark> can we praise or portray in describe him that he may be known? Now that is taught in this and the following article so that the Creed is nothing else than the answer and confession of Christians arranged with respect <mark>to</mark> the first commandment as if you were <mark>to</mark> ask a a little child my dear what sort of a God have you what do you know of him? He could say this is my God first the father who has created heaven and earth besides this the only one I regard nothing else as God. For there is no one else who could create Heaven and Earth. But for the learned' and those who are somewhat Advanced these three articles may all be expanded and divided into as many parts as there are words. But now for Young Scholars, let it suffice <mark>to</mark> indicate the most necessary points namely as we have said that this article refers <mark>to</mark> the creation that we emphasize the words creator of Heaven and Earth. But what is the force of this or what do you mean by these words? I believe in God the Father Almighty maker etcetera. Answer this is what I mean and believe that I am a creature of God that is that he has given me and constantly preserves <mark>to</mark> me my body soul and life members Great and Small all my senses reason and understanding and so on food and drink clothing and support wife and children domestics house and home Etc. Besides he causes All Creatures <mark>to</mark> serve for the uses and necessities of life sun moon and stars in the firmament day and night air water fire earth", "Start Time (s)": 1549.4, "End Time (s)": 1668.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "air water fire earth and whatever it bears and produces birds and flatfishes beasts grain and all kinds of produce and whatever else there is of bodily and temporal Goods good government. Peace security. Thus we learn from this article that none of us has of himself nor can preserve his life nor anything that is here enumerated or can be enumerated. However, small and unimportant a thing that might be for all is comprehended in the word creator. Moreover we also confess that God the father has not only given us all that. We haven't see before our eyes but daily preserves and defends us against all evil and his fortune averts all sorts of danger and Calamity and that he does all this out of pure love and goodness without our Merit as a benevolent father who cares for us that no evil befall us but <mark>to</mark> speak more of this belongs in the other two parts of this article where we say father almighty, Now since all that we possess and moreover whatever in addition is in heaven and upon the Earth is daily given preserved and kept for us by God. It is readily inferred and concluded that it is our duty <mark>to</mark> love praise and thank him for it without ceasing and in short <mark>to</mark> serve him with all these things as he demands and has enjoined in the Ten Commandments here. We could say much if we were <mark>to</mark> expatiate <mark>how</mark> few there are that believe this. Oracle for we all pass over it hear it and say it but neither see nor consider what the words teach us for if we believed it with the heart. We would also act accordingly and Knots talk about proudly act defiantly and boast as though we had life riches power and honour Etc of ourselves. So that others", "Start Time (s)": 1666.5, "End Time (s)": 1785.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "us by God. It is readily inferred and concluded that it is our duty <mark>to</mark> love praise and thank him for it without ceasing and in short <mark>to</mark> serve him with all these things as he demands and has enjoined in the Ten Commandments here. We could say much if we were <mark>to</mark> expatiate <mark>how</mark> few there are that believe this. Oracle for we all pass over it hear it and say it but neither see nor consider what the words teach us for if we believed it with the heart. We would also act accordingly and Knots talk about proudly act defiantly and boast as though we had life riches power and honour Etc of ourselves. So that others must fear and serve us as is the practice of The Wretched perverts World, which is drowned in blindness and abuses all the good things and gifts of God. Only for its own Pride avarice lust and luxury and never once regards God. So as <mark>to</mark> thank him or acknowledge Him as Lord and creator. Therefore this article ought <mark>to</mark> humble and terrify us all if we believed it for we sin daily with eyes ears hands Body and Soul money and possessions and with everything we have especially those who even fight against the word of God yet Christian Christians have this advantage that they acknowledge themselves in Duty bound <mark>to</mark> serve God for all these things and <mark>to</mark> be obedient <mark>to</mark> him. We ought therefore daily <mark>to</mark> practice this article impress it upon our mind and <mark>to</mark> remember it in all that meets our eyes and in all good that falls <mark>to</mark> our lat and wherever we escaped from Calamity or danger that it is God who gives and does all these things that they're in we sense and see his paternal heart and is transcendent love toward us there by the heart would be warmed enkindled <mark>to</mark> be thankful", "Start Time (s)": 1742.3, "End Time (s)": 1862.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So as <mark>to</mark> thank him or acknowledge Him as Lord and creator. Therefore this article ought <mark>to</mark> humble and terrify us all if we believed it for we sin daily with eyes ears hands Body and Soul money and possessions and with everything we have especially those who even fight against the word of God yet Christian Christians have this advantage that they acknowledge themselves in Duty bound <mark>to</mark> serve God for all these things and <mark>to</mark> be obedient <mark>to</mark> him. We ought therefore daily <mark>to</mark> practice this article impress it upon our mind and <mark>to</mark> remember it in all that meets our eyes and in all good that falls <mark>to</mark> our lat and wherever we escaped from Calamity or danger that it is God who gives and does all these things that they're in we sense and see his paternal heart and is transcendent love toward us there by the heart would be warmed enkindled <mark>to</mark> be thankful and <mark>to</mark> employ all such good things <mark>to</mark> the honor and praise of God. God Thus we have most briefly presented the meaning of this article as much as it first necessary for the most simple <mark>to</mark> learn both as <mark>to</mark> what we have and receive from God and what we owe and return which is a most excellent knowledge but a far greater treasure. For here, we see <mark>how</mark> the father has given himself <mark>to</mark> us together with all creatures. And as most richly provided for us in this life besides that he is overwhelmed us with unspeakable Eternal Treasures By His Son and the Holy Ghost as we shall hear. Article 2 and in Jesus Christ his only son our Lord who was conceived by the Holy Ghost born of the Virgin Mary suffered under Pontius Pilate was crucified dead and buried he descended into hell the third day he", "Start Time (s)": 1801.9, "End Time (s)": 1921.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "presented the meaning of this article as much as it first necessary for the most simple <mark>to</mark> learn both as <mark>to</mark> what we have and receive from God and what we owe and return which is a most excellent knowledge but a far greater treasure. For here, we see <mark>how</mark> the father has given himself <mark>to</mark> us together with all creatures. And as most richly provided for us in this life besides that he is overwhelmed us with unspeakable Eternal Treasures By His Son and the Holy Ghost as we shall hear. Article 2 and in Jesus Christ his only son our Lord who was conceived by the Holy Ghost born of the Virgin Mary suffered under Pontius Pilate was crucified dead and buried he descended into hell the third day he rose again from the dead. He ascended into heaven and sitteth on the right hand of God the Father Almighty from thence. He shall come <mark>to</mark> judge the quick and the dead Here we learn <mark>to</mark> know the second person of the godhead so that we see what we have from God over and above the temporal Goods aforementioned namely <mark>how</mark> he has completely poured forth himself and withheld, nothing from us that he has not given us. Now this article is very <mark>rich</mark> and Broad, but in order <mark>to</mark> expounded also briefly and in a childlike way, we shall take up one word and some up in that the entire article namely as we have said that we may hear learn <mark>how</mark> we have been redeemed and we shall base this on these words in Jesus Christ Our Lord. If now you are asked what do you believe in the second article of Jesus Christ answer briefly. I believe that Jesus Christ true. Son of God has", "Start Time (s)": 1869.8, "End Time (s)": 1989.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>to</mark> judge the quick and the dead Here we learn <mark>to</mark> know the second person of the godhead so that we see what we have from God over and above the temporal Goods aforementioned namely <mark>how</mark> he has completely poured forth himself and withheld, nothing from us that he has not given us. Now this article is very <mark>rich</mark> and Broad, but in order <mark>to</mark> expounded also briefly and in a childlike way, we shall take up one word and some up in that the entire article namely as we have said that we may hear learn <mark>how</mark> we have been redeemed and we shall base this on these words in Jesus Christ Our Lord. If now you are asked what do you believe in the second article of Jesus Christ answer briefly. I believe that Jesus Christ true. Son of God has <mark>become</mark> my Lord. But what is it <mark>to</mark> <mark>become</mark> Lord it is this that he has redeemed me from sin from the devil from Death and All evil for before. I had no Lord nor King but was captive under the power of the devil condemned <mark>to</mark> death in meshed and sin and blindness. For when we had been created by God the father and had received from him all manner of good the devil came and let us into Disobedience sin death and all evil so that we fell under his wrath and displeasure and were doomed <mark>to</mark> Eternal damnation as we had merited and deserved. There was no council help or Comfort until this only and eternal Son of God in his unfathomable goodness had compassion upon our misery and wretchedness and came from Heaven <mark>to</mark> help us. Those tyrants and jailers, then are all expelled now and in", "Start Time (s)": 1929.5, "End Time (s)": 2049.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "briefly. I believe that Jesus Christ true. Son of God has <mark>become</mark> my Lord. But what is it <mark>to</mark> <mark>become</mark> Lord it is this that he has redeemed me from sin from the devil from Death and All evil for before. I had no Lord nor King but was captive under the power of the devil condemned <mark>to</mark> death in meshed and sin and blindness. For when we had been created by God the father and had received from him all manner of good the devil came and let us into Disobedience sin death and all evil so that we fell under his wrath and displeasure and were doomed <mark>to</mark> Eternal damnation as we had merited and deserved. There was no council help or Comfort until this only and eternal Son of God in his unfathomable goodness had compassion upon our misery and wretchedness and came from Heaven <mark>to</mark> help us. Those tyrants and jailers, then are all expelled now and in their place as come Jesus Christ Lord of Life righteousness, every blessing and salvation and has delivered us poor lost men from the jaws of hell as one US made us free and brought us again into the favor and Grace of the father and has taken us as his own property under his shelter and protection that he may govern Us by his righteousness wisdom power life and blessedness. Let this then be the sum of this article that the little word Lord signifies simply as much as Redeemer. That is he who has brought us from Satan <mark>to</mark> God from Death <mark>to</mark> life from sin <mark>to</mark> righteousness and who preserves Us in the same. But all the points would follow an order in this article serve no other end than <mark>to</mark> explain an Express this", "Start Time (s)": 1984.0, "End Time (s)": 2103.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and came from Heaven <mark>to</mark> help us. Those tyrants and jailers, then are all expelled now and in their place as come Jesus Christ Lord of Life righteousness, every blessing and salvation and has delivered us poor lost men from the jaws of hell as one US made us free and brought us again into the favor and Grace of the father and has taken us as his own property under his shelter and protection that he may govern Us by his righteousness wisdom power life and blessedness. Let this then be the sum of this article that the little word Lord signifies simply as much as Redeemer. That is he who has brought us from Satan <mark>to</mark> God from Death <mark>to</mark> life from sin <mark>to</mark> righteousness and who preserves Us in the same. But all the points would follow an order in this article serve no other end than <mark>to</mark> explain an Express this Redemption <mark>how</mark> and where by it was accomplished that is <mark>how</mark> much it cost him and what he spent and risked that he might win us and bring us under his Dominion namely that he became man conceived and born without sin of the Holy Ghost and of the Virgin Mary that he might overcome sin moreover that he suffered. I did and was buried that he might make satisfaction for me and pay what I owe not with silver nor gold. But with his own precious blood. And all this in order <mark>to</mark> <mark>become</mark> my Lord for he did none of these for himself nor had he any need of it and after that he rose again from the dead swallowed up and devoured death and finally ascended into heaven and assume the government at the father's right hand so that the devil and all powers must be subject <mark>to</mark> him and lion his feet until finally at the last", "Start Time (s)": 2042.7, "End Time (s)": 2162.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "would follow an order in this article serve no other end than <mark>to</mark> explain an Express this Redemption <mark>how</mark> and where by it was accomplished that is <mark>how</mark> much it cost him and what he spent and risked that he might win us and bring us under his Dominion namely that he became man conceived and born without sin of the Holy Ghost and of the Virgin Mary that he might overcome sin moreover that he suffered. I did and was buried that he might make satisfaction for me and pay what I owe not with silver nor gold. But with his own precious blood. And all this in order <mark>to</mark> <mark>become</mark> my Lord for he did none of these for himself nor had he any need of it and after that he rose again from the dead swallowed up and devoured death and finally ascended into heaven and assume the government at the father's right hand so that the devil and all powers must be subject <mark>to</mark> him and lion his feet until finally at the last day. He will completely part and separate us from the Wicked World the devil. Sin, Etc. But <mark>to</mark> explain all these simple single point separately belongs not <mark>to</mark> brief sermons for children, but rather <mark>to</mark> the ampler sermons that extend throughout the entire year, especially at those times which are appointed for the purpose of treating at length each article of the birth sufferings Resurrection Ascension of Christ at cetera. I the entire gospel, which we preach is based on this that we properly understand this article as that upon which our salvation and all our happiness rest and which is so <mark>rich</mark> in comprehensive that we can never learn it fully article 3. I believe in the Holy Ghost the holy Christian Church, the communion of saints the Forgiveness of sins the", "Start Time (s)": 2098.6, "End Time (s)": 2218.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Sin, Etc. But <mark>to</mark> explain all these simple single point separately belongs not <mark>to</mark> brief sermons for children, but rather <mark>to</mark> the ampler sermons that extend throughout the entire year, especially at those times which are appointed for the purpose of treating at length each article of the birth sufferings Resurrection Ascension of Christ at cetera. I the entire gospel, which we preach is based on this that we properly understand this article as that upon which our salvation and all our happiness rest and which is so <mark>rich</mark> in comprehensive that we can never learn it fully article 3. I believe in the Holy Ghost the holy Christian Church, the communion of saints the Forgiveness of sins the resurrection of the body and the life Everlasting. Amen. This article as I have said, I cannot relate better than <mark>to</mark> sanctification that through the same Holy Ghost with his office is declared and depicted namely that he makes us holy therefore we must take our stand upon the word Holy Ghost because it is so precise and comprehensive that we cannot find another. For there are besides many kinds of spirits mentioned in the Holy scriptures as the spirit of man Heavenly spirits and evil spirits, but the spirit of God Alone is called. Holy ghost. That is he who has Sanctified and still sanctifies us. For as the father is called Creator the sun Redeemer. So the holy ghost from his work must be called sanctifier or one that makes holy. But <mark>how</mark> is such sanctifying done answer just as the sun obtains Dominion, whereby he wins us through his birth death Resurrection", "Start Time (s)": 2167.7, "End Time (s)": 2287.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the resurrection of the body and the life Everlasting. Amen. This article as I have said, I cannot relate better than <mark>to</mark> sanctification that through the same Holy Ghost with his office is declared and depicted namely that he makes us holy therefore we must take our stand upon the word Holy Ghost because it is so precise and comprehensive that we cannot find another. For there are besides many kinds of spirits mentioned in the Holy scriptures as the spirit of man Heavenly spirits and evil spirits, but the spirit of God Alone is called. Holy ghost. That is he who has Sanctified and still sanctifies us. For as the father is called Creator the sun Redeemer. So the holy ghost from his work must be called sanctifier or one that makes holy. But <mark>how</mark> is such sanctifying done answer just as the sun obtains Dominion, whereby he wins us through his birth death Resurrection Etc. So also the Holy Ghost effects our sanctification by the following parts namely by the communion of Saints or the Christian Church, the Forgiveness of sins the resurrection of the body and the life Everlasting that is he first leads us into his holy congregation and places us. The bosom of the church, whereby he preaches <mark>to</mark> us and brings us <mark>to</mark> Christ. For neither you nor I could ever know anything of Christ or believe on him and obtain him for our Lord unless it were offered <mark>to</mark> us and granted <mark>to</mark> our hearts by the Holy Ghost through the preaching of the Gospel. The work is done in accomplished for Christ is acquired and gained the treasure for us by his suffering death Resurrection Etc. But if the work remained concealed so that no one knew of it", "Start Time (s)": 2218.2, "End Time (s)": 2337.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Etc. So also the Holy Ghost effects our sanctification by the following parts namely by the communion of Saints or the Christian Church, the Forgiveness of sins the resurrection of the body and the life Everlasting that is he first leads us into his holy congregation and places us. The bosom of the church, whereby he preaches <mark>to</mark> us and brings us <mark>to</mark> Christ. For neither you nor I could ever know anything of Christ or believe on him and obtain him for our Lord unless it were offered <mark>to</mark> us and granted <mark>to</mark> our hearts by the Holy Ghost through the preaching of the Gospel. The work is done in accomplished for Christ is acquired and gained the treasure for us by his suffering death Resurrection Etc. But if the work remained concealed so that no one knew of it then it would be in vain and lost that this treasure. Therefore might not lie buried. Read but be appropriated and enjoyed God has caused the word <mark>to</mark> go forth and be proclaimed in which he gives the Holy Ghost <mark>to</mark> bring this treasure home and appropriated <mark>to</mark> us. Therefore sanctifying is nothing else than bringing us <mark>to</mark> Christ <mark>to</mark> receive this good <mark>to</mark> which we could not attain of ourselves. Learn then <mark>to</mark> understand this article most clearly if you are asked what do you mean by the words? I believe in the Holy Ghost. You can answer. I believe that the Holy Ghost makes be holy as his name implies, but we're by does he accomplished this or what are his method and means <mark>to</mark> this end answer by the Christian Church the Forgiveness of sins the resurrection of the body and the life Everlasting. For in the first place. He has a peculiar congregation in the world, which is the mother that begets and bears every Christian through the word of God, which he reveals and preaches. He illumines and in Kindles hearts that they understand accepted cling <mark>to</mark> it", "Start Time (s)": 2287.2, "End Time (s)": 2406.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the word <mark>to</mark> go forth and be proclaimed in which he gives the Holy Ghost <mark>to</mark> bring this treasure home and appropriated <mark>to</mark> us. Therefore sanctifying is nothing else than bringing us <mark>to</mark> Christ <mark>to</mark> receive this good <mark>to</mark> which we could not attain of ourselves. Learn then <mark>to</mark> understand this article most clearly if you are asked what do you mean by the words? I believe in the Holy Ghost. You can answer. I believe that the Holy Ghost makes be holy as his name implies, but we're by does he accomplished this or what are his method and means <mark>to</mark> this end answer by the Christian Church the Forgiveness of sins the resurrection of the body and the life Everlasting. For in the first place. He has a peculiar congregation in the world, which is the mother that begets and bears every Christian through the word of God, which he reveals and preaches. He illumines and in Kindles hearts that they understand accepted cling <mark>to</mark> it and persevere in it. For where he does not cause it <mark>to</mark> be preached and made alive in the heart so that it is understood. It is lost as was the case under the papacy where Faith was entirely put under the bench and no one recognized Christ as his Lord or the Holy Ghost as his sanctifier. That is no one believed that Christ is our Lord in the sense that he has acquired this treasure for us without our works and Merit and made us acceptable <mark>to</mark> the father. What then was lacking this that the Holy Ghost was not there <mark>to</mark> reveal it and cause it <mark>to</mark> be preached but men and evil spirits were there who taught us <mark>to</mark> obtain Grace and be saved by our works? Therefore it is not a Christian church. Either for where Christ is not preached. There is no Holy Ghost who creates calls and gathers the Christian Church Without which no one can come <mark>to</mark> Christ the lord. Let this suffice concerning the", "Start Time (s)": 2345.8, "End Time (s)": 2465.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and in Kindles hearts that they understand accepted cling <mark>to</mark> it and persevere in it. For where he does not cause it <mark>to</mark> be preached and made alive in the heart so that it is understood. It is lost as was the case under the papacy where Faith was entirely put under the bench and no one recognized Christ as his Lord or the Holy Ghost as his sanctifier. That is no one believed that Christ is our Lord in the sense that he has acquired this treasure for us without our works and Merit and made us acceptable <mark>to</mark> the father. What then was lacking this that the Holy Ghost was not there <mark>to</mark> reveal it and cause it <mark>to</mark> be preached but men and evil spirits were there who taught us <mark>to</mark> obtain Grace and be saved by our works? Therefore it is not a Christian church. Either for where Christ is not preached. There is no Holy Ghost who creates calls and gathers the Christian Church Without which no one can come <mark>to</mark> Christ the lord. Let this suffice concerning the some of this article, but because the parts which are here in numerated are not quite clear <mark>to</mark> the simple. We shall run over them. Also, the Creed denominates the holy Christian Church communion em some sanctorum a communion of saints for both Expressions taken together are identical, but formerly, the one expression was not there and it has been poorly and unintelligibly translated into And I nag a mine shaft there. Hi Logan a communion of saints. If it is <mark>to</mark> be rendered plainly, it must be expressed quite differently in the German idiom for the word. Ecclesia properly means in German. I never Za Moon and assembly but we are accustomed <mark>to</mark> the word church by which the simple do not understand and assembled multitude, but the consecrated house or building", "Start Time (s)": 2401.9, "End Time (s)": 2520.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "for where Christ is not preached. There is no Holy Ghost who creates calls and gathers the Christian Church Without which no one can come <mark>to</mark> Christ the lord. Let this suffice concerning the some of this article, but because the parts which are here in numerated are not quite clear <mark>to</mark> the simple. We shall run over them. Also, the Creed denominates the holy Christian Church communion em some sanctorum a communion of saints for both Expressions taken together are identical, but formerly, the one expression was not there and it has been poorly and unintelligibly translated into And I nag a mine shaft there. Hi Logan a communion of saints. If it is <mark>to</mark> be rendered plainly, it must be expressed quite differently in the German idiom for the word. Ecclesia properly means in German. I never Za Moon and assembly but we are accustomed <mark>to</mark> the word church by which the simple do not understand and assembled multitude, but the consecrated house or building although the house ought not <mark>to</mark> be called a church, except only for the reason that the multitude assembles there. For we who assemble their make and choose for ourselves a particular place and give a name <mark>to</mark> the house according <mark>to</mark> the assembly. Thus the word kirika church means really nothing else than a common assembly and is not German by idiom. But Greek as is also the word ekklesia for in their own language. They call it curia as in Latin it is called Korea. Therefore in genuine German in our mother tongue in ought <mark>to</mark> be called a Christian congregation or assembly and at least like a Commando or Azam Loom or best of all and most clearly holy Christendom Ina heilige Kristen height.", "Start Time (s)": 2453.3, "End Time (s)": 2573.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but the consecrated house or building although the house ought not <mark>to</mark> be called a church, except only for the reason that the multitude assembles there. For we who assemble their make and choose for ourselves a particular place and give a name <mark>to</mark> the house according <mark>to</mark> the assembly. Thus the word kirika church means really nothing else than a common assembly and is not German by idiom. But Greek as is also the word ekklesia for in their own language. They call it curia as in Latin it is called Korea. Therefore in genuine German in our mother tongue in ought <mark>to</mark> be called a Christian congregation or assembly and at least like a Commando or Azam Loom or best of all and most clearly holy Christendom Ina heilige Kristen height. So also the word Cuneo which is added ought not <mark>to</mark> be rendered communion <mark>to</mark> mine shaft but congregation combined and it is nothing else than in interpretation or explanation by which someone meant <mark>to</mark> explain what the Christian church is this our people who understood neither Latin or German have rendered gemeinschaft are hi Logan communion of saints, although no German language. Eeks, the Snore understands that thus but <mark>to</mark> speak correct German it ought <mark>to</mark> be ienaga minded are heilig on a Congregation of saints that is a congregation made up purely of Saints or <mark>to</mark> speak yet more plainly Ina heilige minder a holy congregation. I say this in order that the words combined shaft are heilig on communion of saints may be understood because the expression has <mark>become</mark> so established by custom that it cannot well be eradicated and it is treated almost as", "Start Time (s)": 2518.4, "End Time (s)": 2636.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Ina heilige Kristen height. So also the word Cuneo which is added ought not <mark>to</mark> be rendered communion <mark>to</mark> mine shaft but congregation combined and it is nothing else than in interpretation or explanation by which someone meant <mark>to</mark> explain what the Christian church is this our people who understood neither Latin or German have rendered gemeinschaft are hi Logan communion of saints, although no German language. Eeks, the Snore understands that thus but <mark>to</mark> speak correct German it ought <mark>to</mark> be ienaga minded are heilig on a Congregation of saints that is a congregation made up purely of Saints or <mark>to</mark> speak yet more plainly Ina heilige minder a holy congregation. I say this in order that the words combined shaft are heilig on communion of saints may be understood because the expression has <mark>become</mark> so established by custom that it cannot well be eradicated and it is treated almost as heresy. If one should attempt <mark>to</mark> change a word. But this is the meaning and substance of this addition. I believe that there is upon Earth a little holy group and Congregation of pure Saints under one head even Christ call together by the holy ghost in One Faith one mind and understanding with manifold gifts yet agreeing in love without sex or systems. I am also a part and member of the same a sharer and Joint owner of all the goods that possesses brought <mark>to</mark> it and incorporated into it by the Holy Ghost by having heard and continuing <mark>to</mark> hear the word of God, which is the beginning of entering it. For formerly before we had attained <mark>to</mark> this we were all together of the devil knowing nothing of God and of Christ thus until the last day the Holy Ghost", "Start Time (s)": 2571.3, "End Time (s)": 2691.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "this in order that the words combined shaft are heilig on communion of saints may be understood because the expression has <mark>become</mark> so established by custom that it cannot well be eradicated and it is treated almost as heresy. If one should attempt <mark>to</mark> change a word. But this is the meaning and substance of this addition. I believe that there is upon Earth a little holy group and Congregation of pure Saints under one head even Christ call together by the holy ghost in One Faith one mind and understanding with manifold gifts yet agreeing in love without sex or systems. I am also a part and member of the same a sharer and Joint owner of all the goods that possesses brought <mark>to</mark> it and incorporated into it by the Holy Ghost by having heard and continuing <mark>to</mark> hear the word of God, which is the beginning of entering it. For formerly before we had attained <mark>to</mark> this we were all together of the devil knowing nothing of God and of Christ thus until the last day the Holy Ghost abides with the Holy congregation or Christendom by means of which he fetches us <mark>to</mark> Christ and which he employs <mark>to</mark> teach and preach <mark>to</mark> us the word whereby he works and promotes sanctification causing a daily <mark>to</mark> grow and <mark>become</mark> strong in the faith and it's fruits which he produces. We further believe that in this Christian church, we have forgiveness of sins, which is wrought through the holy sacraments and Absolution moreover through all manner of consolatory promises of the entire gospel. Therefore whatever is <mark>to</mark> be preached concerning the sacraments belongs here and in short the whole gospel and all the offices of Christianity, which also must be preached and taught without ceasing for although the grace of God is secured through Christ. And sanctification is wrought through by the Holy Ghost through the", "Start Time (s)": 2623.4, "End Time (s)": 2743.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and which he employs <mark>to</mark> teach and preach <mark>to</mark> us the word whereby he works and promotes sanctification causing a daily <mark>to</mark> grow and <mark>become</mark> strong in the faith and it's fruits which he produces. We further believe that in this Christian church, we have forgiveness of sins, which is wrought through the holy sacraments and Absolution moreover through all manner of consolatory promises of the entire gospel. Therefore whatever is <mark>to</mark> be preached concerning the sacraments belongs here and in short the whole gospel and all the offices of Christianity, which also must be preached and taught without ceasing for although the grace of God is secured through Christ. And sanctification is wrought through by the Holy Ghost through the word of God in the unity of the Christian church yet on account of our flesh which we bear about with us. We are never without sin. Everything therefore in the Christian church is ordered <mark>to</mark> the and that we shall daily obtain their nothing but the forgiveness of sin through the word and signs <mark>to</mark> comfort and encourage our consciences as long as we live here. Thus although we have sins the Holy Ghost does not allow them <mark>to</mark> injure us because we are in the Christian church where there is nothing but forgiveness of sin both in that God forgives us and in that we forgive bear with and help each other But outside of this Christian Church where the gospel is not there is no forgiveness as also there can be no Holiness there for all who seek and wish <mark>to</mark> Merit Holiness not through the gospel and forgiveness of sin, but by their Works have expelled and severed themselves. Meanwhile, however, while sanctification has begun and is growing daily, we expect that our flesh will be destroyed and buried with all its uncleanness and will come forth gloriously and arise <mark>to</mark> entire and", "Start Time (s)": 2697.3, "End Time (s)": 2817.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "ordered <mark>to</mark> the and that we shall daily obtain their nothing but the forgiveness of sin through the word and signs <mark>to</mark> comfort and encourage our consciences as long as we live here. Thus although we have sins the Holy Ghost does not allow them <mark>to</mark> injure us because we are in the Christian church where there is nothing but forgiveness of sin both in that God forgives us and in that we forgive bear with and help each other But outside of this Christian Church where the gospel is not there is no forgiveness as also there can be no Holiness there for all who seek and wish <mark>to</mark> Merit Holiness not through the gospel and forgiveness of sin, but by their Works have expelled and severed themselves. Meanwhile, however, while sanctification has begun and is growing daily, we expect that our flesh will be destroyed and buried with all its uncleanness and will come forth gloriously and arise <mark>to</mark> entire and perfect Holiness in a new eternal life. For now, we are only half pure and holy so that the Holy Ghost has ever <mark>to</mark> continue his work in us through the word and daily <mark>to</mark> dispense forgiveness until we attain <mark>to</mark> that life where there will be no more forgiveness, but only perfectly pure and holy people full of godliness and righteousness removed and free from sin death and all evil in a new Immortal and glorified body. Behold all this is <mark>to</mark> be the office and work of the Holy Ghost that he begin and daily increase Holiness upon Earth by means of these two things the Christian church and the Forgiveness of sins, but in our disillusion, he will accomplish it all together in an instant and will forever preserve us there in by the last two parts. But the term I'll Fair stay home does flashes resurrection of the", "Start Time (s)": 2756.2, "End Time (s)": 2876.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "life. For now, we are only half pure and holy so that the Holy Ghost has ever <mark>to</mark> continue his work in us through the word and daily <mark>to</mark> dispense forgiveness until we attain <mark>to</mark> that life where there will be no more forgiveness, but only perfectly pure and holy people full of godliness and righteousness removed and free from sin death and all evil in a new Immortal and glorified body. Behold all this is <mark>to</mark> be the office and work of the Holy Ghost that he begin and daily increase Holiness upon Earth by means of these two things the Christian church and the Forgiveness of sins, but in our disillusion, he will accomplish it all together in an instant and will forever preserve us there in by the last two parts. But the term I'll Fair stay home does flashes resurrection of the flesh here employed is not according <mark>to</mark> good German idiom for when we Germans hear the word fleisch flesh. We think no farther than of the shambles, but in good German idiom, we would say Al first whom does libous or like Noms resurrection of the body? However, it is not a matter of such moment if we only understand the words are right. This now is the article which must ever be and remain in operation for creation. We have received Redemption <mark>to</mark> is finished. But the Holy Ghost carries on his work without ceasing <mark>to</mark> the last day and for that purpose. He has appointed a congregation upon Earth by which he speaks and does everything. Where he has not yet brought together all his Christian Church nor dispensed forgiveness. Therefore we believe in him who through the word daily brings us into the fellowship of this Christian church and through the same word and", "Start Time (s)": 2819.2, "End Time (s)": 2939.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but in good German idiom, we would say Al first whom does libous or like Noms resurrection of the body? However, it is not a matter of such moment if we only understand the words are right. This now is the article which must ever be and remain in operation for creation. We have received Redemption <mark>to</mark> is finished. But the Holy Ghost carries on his work without ceasing <mark>to</mark> the last day and for that purpose. He has appointed a congregation upon Earth by which he speaks and does everything. Where he has not yet brought together all his Christian Church nor dispensed forgiveness. Therefore we believe in him who through the word daily brings us into the fellowship of this Christian church and through the same word and forgiveness of sins bestows increases and strengthens faith. In order that when he is accomplished at all, and we abide therein and died <mark>to</mark> the world and <mark>to</mark> all evil. He may finally make us perfectly and forever. Holy which now we expect in faith through the word. Behold here. You have the entire Divine Essence will and work depicted and most exquisitely in quite short and yet <mark>Rich</mark> words. We're in consists all our wisdom which surpasses and exceeds the wisdom mind and reason of all men for although the whole world with all diligence has endeavored <mark>to</mark> ascertain what God is what he has in mind and does yet has she never been able <mark>to</mark> attain <mark>to</mark> any of these things? But here we have everything in Rich's measure for here in all three articles. He has himself revealed and opened the deepest abyss of his paternal heart and of his pure unutterable love for he has created us for this very object that he might redeem and sanctify us and in addition <mark>to</mark> giving and imparting <mark>to</mark> us everything in heaven and", "Start Time (s)": 2888.7, "End Time (s)": 3008.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "at all, and we abide therein and died <mark>to</mark> the world and <mark>to</mark> all evil. He may finally make us perfectly and forever. Holy which now we expect in faith through the word. Behold here. You have the entire Divine Essence will and work depicted and most exquisitely in quite short and yet <mark>Rich</mark> words. We're in consists all our wisdom which surpasses and exceeds the wisdom mind and reason of all men for although the whole world with all diligence has endeavored <mark>to</mark> ascertain what God is what he has in mind and does yet has she never been able <mark>to</mark> attain <mark>to</mark> any of these things? But here we have everything in Rich's measure for here in all three articles. He has himself revealed and opened the deepest abyss of his paternal heart and of his pure unutterable love for he has created us for this very object that he might redeem and sanctify us and in addition <mark>to</mark> giving and imparting <mark>to</mark> us everything in heaven and upon Earth. He has given <mark>to</mark> us even His Son and the Holy Ghost by whom <mark>to</mark> bring us <mark>to</mark> himself. For as explained above we could never attain <mark>to</mark> the knowledge of the grace and favor of the father except through the Lord Christ who is a mirror of the paternal heart outside of whom we see nothing but an angry and terrible judge. But of Christ we could know nothing either unless it had been revealed by the Holy Ghost. These articles of the Creed therefore divide and separate us Christians from all other people upon Earth. For all outside of Christianity whether Heathen Turks Jews or false Christians and hypocrites, although they believe in and worship only one true. God yet know not what his mind toward them is and cannot expect any love or blessing from him. Therefore they abide in Eternal wrath and Damnation.", "Start Time (s)": 2945.5, "End Time (s)": 3065.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "through the Lord Christ who is a mirror of the paternal heart outside of whom we see nothing but an angry and terrible judge. But of Christ we could know nothing either unless it had been revealed by the Holy Ghost. These articles of the Creed therefore divide and separate us Christians from all other people upon Earth. For all outside of Christianity whether Heathen Turks Jews or false Christians and hypocrites, although they believe in and worship only one true. God yet know not what his mind toward them is and cannot expect any love or blessing from him. Therefore they abide in Eternal wrath and Damnation. For they have not the Lord Christ and besides are not illumined and favored by any gifts of the Holy Ghost. From this you perceive that the Creed is a Doctrine quite different from the Ten Commandments for the latter teaches indeed what we ought <mark>to</mark> do, but the former tells what God does for us and gives <mark>to</mark> us. Moreover apart from this The Ten Commandments are written in the hearts of all men the Creed however, no human wisdom can comprehend, but it must be taught by the Holy Ghost alone. The latter Doctrine therefore makes no Christian for the Wrath and displeasure of God abides upon us still because we cannot keep what God demands of us, but this brings pure grace and makes us Godly and acceptable <mark>to</mark> God. For by this knowledge. We obtain love and Delight in all the Commandments of God because here we see that God gives himself entire <mark>to</mark> us with all that he has and is able <mark>to</mark> do <mark>to</mark> Aid in direct us in keeping the Ten Commandments the father All Creatures the son his entire work and the Holy Ghost all his gifts. Let this suffice concerning the Creed <mark>to</mark> lay a foundation for the simple", "Start Time (s)": 3021.3, "End Time (s)": 3140.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "for the latter teaches indeed what we ought <mark>to</mark> do, but the former tells what God does for us and gives <mark>to</mark> us. Moreover apart from this The Ten Commandments are written in the hearts of all men the Creed however, no human wisdom can comprehend, but it must be taught by the Holy Ghost alone. The latter Doctrine therefore makes no Christian for the Wrath and displeasure of God abides upon us still because we cannot keep what God demands of us, but this brings pure grace and makes us Godly and acceptable <mark>to</mark> God. For by this knowledge. We obtain love and Delight in all the Commandments of God because here we see that God gives himself entire <mark>to</mark> us with all that he has and is able <mark>to</mark> do <mark>to</mark> Aid in direct us in keeping the Ten Commandments the father All Creatures the son his entire work and the Holy Ghost all his gifts. Let this suffice concerning the Creed <mark>to</mark> lay a foundation for the simple that they may not be burdened so that if they understand the substance of it, they themselves May afterwards strive <mark>to</mark> acquire more and <mark>to</mark> refer <mark>to</mark> these parts, whatever they learn in the scriptures and may ever grow and increase in richer understanding for as long as we live here. We shall daily have enough <mark>to</mark> do <mark>to</mark> preach and <mark>to</mark> learn this.", "Start Time (s)": 3079.0, "End Time (s)": 3161.6, "Clip Length (min)": 1.38, "show_uri": "spotify:show:2uH5vfq1AZMadBavVigsm2", "show_name": "Steadfast Lutherans Confessions Readthrough", "show_description": "The audio version of the Steadfast Lutherans Lent Readthrough group, for those who prefer an audio recording. Note that due to copyright restrictions the reading is from the Concordia Triglotta translation.", "publisher": "Rev. Daniel A. Hinton", "episode_uri": "spotify:episode:54xfMw2EAX6kfbhBdExeAq", "episode_name": "Monday, March 2", "episode_description": "Day 5, Monday of Invocabit: Luther's Large Catechism:   The Ninth and Tenth Commandments  Conclusion of the Ten Commandments   Part Second: Of the Creed   Article I   Article II   Article III  ", "score": 3.9711418, "explanation": "{\n  \"value\": 3.9711418,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=16.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4230534,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 16.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.1888595,\n      \"description\": \"weight(word_list:to in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.1888595,\n          \"description\": \"score(LMDirichletSimilarity, freq=265.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7682505,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 265.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.4167392,\n      \"description\": \"weight(word_list:become in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.4167392,\n          \"description\": \"score(LMDirichletSimilarity, freq=7.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.9961302,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 7.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.3655431,\n      \"description\": \"weight(word_list:rich in 179) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.3655431,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9449341,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.579391,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 7704.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Hey, what's going on guys? Welcome at the gym. This guy friends podcast rid of show coming <mark>to</mark> you on this Friday afternoon with an episode heavily requested by many of you and we're going <mark>to</mark> title it books. I recommend or top reads for 2020 something like that because a lot of you have asked a Jeremy what books would you recommend for finance with books you recommend for personal development? Well books <mark>to</mark> recommend for nutrition. So I'm going <mark>to</mark> share with you at least the ones that have had the biggest impact on me or the ones that are In the Forefront of my mind right now nagase can't sure every book that I've read and listened <mark>to</mark> over the past 10 years, but I'll give you guys a pretty good list and I did a version of this a long time ago, which is somewhere on the blog and my goal is <mark>to</mark> put these onto the blog as well here probably in the next two weeks or so. I just have a lot of real I say quote unquote real work <mark>to</mark> do but I will get <mark>to</mark> this but if you hear me say something and you didn't catch it all just stop the podcast and scrub back, you know, 15 <mark>to</mark> 30 seconds. And write down the title. And if you do have a question hit me up. I'm happy <mark>to</mark>", "Start Time (s)": 0.6, "End Time (s)": 63.5, "Clip Length (min)": 1.05, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Hey, what's going on guys? Welcome at the gym. This guy friends podcast rid of show coming <mark>to</mark> you on this Friday afternoon with an episode heavily requested by many of you and we're going <mark>to</mark> title it books. I recommend or top reads for 2020 something like that because a lot of you have asked a Jeremy what books would you recommend for finance with books you recommend for personal development? Well books <mark>to</mark> recommend for nutrition. So I'm going <mark>to</mark> share with you at least the ones that have had the biggest impact on me or the ones that are In the Forefront of my mind right now nagase can't sure every book that I've read and listened <mark>to</mark> over the past 10 years, but I'll give you guys a pretty good list and I did a version of this a long time ago, which is somewhere on the blog and my goal is <mark>to</mark> put these onto the blog as well here probably in the next two weeks or so. I just have a lot of real I say quote unquote real work <mark>to</mark> do but I will get <mark>to</mark> this but if you hear me say something and you didn't catch it all just stop the podcast and scrub back, you know, 15 <mark>to</mark> 30 seconds. And write down the title. And if you do have a question hit me up. I'm happy <mark>to</mark> answer in point you guys in the right direction and I'll try <mark>to</mark> say the titles in the author's and not butcher the names but I read like a three-year-old as best I can. What that said? I'm going <mark>to</mark> try <mark>to</mark> this podcast a little bit quicker because I still have a terrible leg workout. I have <mark>to</mark> hop into and it's just one of those weeks where I've worked a ton of hours and I'm just tired and I don't really want <mark>to</mark> do lunges and split squats and push a sled and hop on the assault bike and that's what I have <mark>to</mark> look forward <mark>to</mark> in about 30 40 minutes from right now and on a side note. I am actually going out <mark>to</mark> dinner tonight with a client of ours here in my wife and his partner were all going <mark>to</mark> get together. Who is taking us <mark>to</mark> one of his favorite places which I've never been because it's a little bit fancier. And if you guys know me, I'm not a huge amount of real not real fancy person what pretty basic dude but he was actually my first personal training", "Start Time (s)": 0.6, "End Time (s)": 119.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in the author's and not butcher the names but I read like a three-year-old as best I can. What that said? I'm going <mark>to</mark> try <mark>to</mark> this podcast a little bit quicker because I still have a terrible leg workout. I have <mark>to</mark> hop into and it's just one of those weeks where I've worked a ton of hours and I'm just tired and I don't really want <mark>to</mark> do lunges and split squats and push a sled and hop on the assault bike and that's what I have <mark>to</mark> look forward <mark>to</mark> in about 30 40 minutes from right now and on a side note. I am actually going out <mark>to</mark> dinner tonight with a client of ours here in my wife and his partner were all going <mark>to</mark> get together. Who is taking us <mark>to</mark> one of his favorite places which I've never been because it's a little bit fancier. And if you guys know me, I'm not a huge amount of real not real fancy person what pretty basic dude but he was actually my first personal training client here over 10 years ago and I work with people before that from moved here, but he was my first personal training client when I basically decided <mark>to</mark> go out on my own and not when I was in this facility here not when I was in our old warehouse for seven and a half years before that. He was the first guy. I worked with an independent facility because when I started out I didn't have any money and have any resources. I don't know anything. So what I did was I wrote a letter and I sent emails of the emails. I could find <mark>to</mark> every like Boutique mom and pop gym in a probably a 10 mile radius from my house and said, hey, I'm a young kid name is Jeremy. I'm starting out. I want <mark>to</mark> get into fitness. I want <mark>to</mark> train people. Here's my certifications. Here's everything. I have here's what I've done in the past, but I don't have anywhere <mark>to</mark> go. Can I come training your facility? Maybe like we do a Cheering split maybe I give you part of the money for each person that train and long story short this place Peak Performance, which I believed and still is at Peak right now P performance said yeah Jeremy come on in and we'll do that and I only had well shit one client and that one client was Roll and Roll is the guy that is taking us out <mark>to</mark> dinner tonight and oddly enough. He was also our realtor", "Start Time (s)": 68.2, "End Time (s)": 187.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "was my first personal training client when I basically decided <mark>to</mark> go out on my own and not when I was in this facility here not when I was in our old warehouse for seven and a half years before that. He was the first guy. I worked with an independent facility because when I started out I didn't have any money and have any resources. I don't know anything. So what I did was I wrote a letter and I sent emails of the emails. I could find <mark>to</mark> every like Boutique mom and pop gym in a probably a 10 mile radius from my house and said, hey, I'm a young kid name is Jeremy. I'm starting out. I want <mark>to</mark> get into fitness. I want <mark>to</mark> train people. Here's my certifications. Here's everything. I have here's what I've done in the past, but I don't have anywhere <mark>to</mark> go. Can I come training your facility? Maybe like we do a Cheering split maybe I give you part of the money for each person that train and long story short this place Peak Performance, which I believed and still is at Peak right now P performance said yeah Jeremy come on in and we'll do that and I only had well shit one client and that one client was Roll and Roll is the guy that is taking us out <mark>to</mark> dinner tonight and oddly enough. He was also our realtor Who Sold us our house about 7 years ago. So needless <mark>to</mark> say he has seen the progression of me over the past decade plus and I I've seen that of him and we are obviously into you know, completely different stages of life and we've <mark>become</mark> good friends with them and they <mark>become</mark> friends with us and it's it's a super neat thing <mark>to</mark> see that and that's I share that because it's about the relationships that you cultivate with people. You can go anywhere for training you can go anywhere from nutrition advice and I'm not saying, you know, my training style is the same as the guy right next door and the guy behind me here in the girl down the street, but if they're doing it correctly. Clearly there's a lot of similarities does that make sense that even if my style of training is different than let's say somebody on the internet if they're doing it correctly. You can get results both ways. So there's multiple options and we know that but people are choosing <mark>to</mark> stay with us because it's deeper than that. It's not just about sets and Reps", "Start Time (s)": 123.9, "End Time (s)": 243.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "one client and that one client was Roll and Roll is the guy that is taking us out <mark>to</mark> dinner tonight and oddly enough. He was also our realtor Who Sold us our house about 7 years ago. So needless <mark>to</mark> say he has seen the progression of me over the past decade plus and I I've seen that of him and we are obviously into you know, completely different stages of life and we've <mark>become</mark> good friends with them and they <mark>become</mark> friends with us and it's it's a super neat thing <mark>to</mark> see that and that's I share that because it's about the relationships that you cultivate with people. You can go anywhere for training you can go anywhere from nutrition advice and I'm not saying, you know, my training style is the same as the guy right next door and the guy behind me here in the girl down the street, but if they're doing it correctly. Clearly there's a lot of similarities does that make sense that even if my style of training is different than let's say somebody on the internet if they're doing it correctly. You can get results both ways. So there's multiple options and we know that but people are choosing <mark>to</mark> stay with us because it's deeper than that. It's not just about sets and Reps and I hope you guys understand that when you pick a coach when you pick a communion of people that you work with it goes a lot deeper than that and I feel it that way and I like becoming friends with the people who are here. I like doing nice things for them. I Like them feeling comfortable. So not only can they obviously get the best results possible but they come <mark>to</mark> a place where they feel like, they're not judge and they can tell us things that we can share things that we can all kind of grow together. That's what I try <mark>to</mark> do with this business in this life and real is a you know, he is the epitome of that even though him and I have <mark>to</mark> share this because he's going <mark>to</mark> listen <mark>to</mark> this as humans. We are completely different we both come from nothing and no money backgrounds grinded our faces off. He runs, you know much bigger age. See the Naidu for sure and he's much fancier than me. I'll say that you know, he rocks a Mercedes. I drive my O8 Accord. I'm a T-shirt and jeans guy. He's probably going <mark>to</mark> wear a five thousand dollar jean jacket out <mark>to</mark> dinner tonight,", "Start Time (s)": 179.3, "End Time (s)": 299.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "options and we know that but people are choosing <mark>to</mark> stay with us because it's deeper than that. It's not just about sets and Reps and I hope you guys understand that when you pick a coach when you pick a communion of people that you work with it goes a lot deeper than that and I feel it that way and I like becoming friends with the people who are here. I like doing nice things for them. I Like them feeling comfortable. So not only can they obviously get the best results possible but they come <mark>to</mark> a place where they feel like, they're not judge and they can tell us things that we can share things that we can all kind of grow together. That's what I try <mark>to</mark> do with this business in this life and real is a you know, he is the epitome of that even though him and I have <mark>to</mark> share this because he's going <mark>to</mark> listen <mark>to</mark> this as humans. We are completely different we both come from nothing and no money backgrounds grinded our faces off. He runs, you know much bigger age. See the Naidu for sure and he's much fancier than me. I'll say that you know, he rocks a Mercedes. I drive my O8 Accord. I'm a T-shirt and jeans guy. He's probably going <mark>to</mark> wear a five thousand dollar jean jacket out <mark>to</mark> dinner tonight, but it works because you know humble beginnings and even though he likes the nicer things in life and if you can afford it, you know respect. It works it would <mark>become</mark> very good friends over time in a very appreciative of him and what he's done for us in my family over the year. So that is what I'm doing tonight and I share that just so you guys understand it's about people it really is I wouldn't do this podcast fitting get the feedback from you guys. I wouldn't have it in person business. I can go on the internet and just do it make my money there all day, but the people here matter the community matters our relationships matter and I get something out of it much more than just, you know, hey, here's a check for because Can train a lot of people know it cuts a lot deeper than that and tonight is just another example of that. You know, it's I don't look at it as like, oh, I'm going out <mark>to</mark> dinner with some clients know it's like we're just going out <mark>to</mark> dinner with some friends who happen <mark>to</mark> be the first person. I worked with here a decade ago and happened <mark>to</mark> be the same guy who sold us our house and he just wants <mark>to</mark>", "Start Time (s)": 236.9, "End Time (s)": 356.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "he's much fancier than me. I'll say that you know, he rocks a Mercedes. I drive my O8 Accord. I'm a T-shirt and jeans guy. He's probably going <mark>to</mark> wear a five thousand dollar jean jacket out <mark>to</mark> dinner tonight, but it works because you know humble beginnings and even though he likes the nicer things in life and if you can afford it, you know respect. It works it would <mark>become</mark> very good friends over time in a very appreciative of him and what he's done for us in my family over the year. So that is what I'm doing tonight and I share that just so you guys understand it's about people it really is I wouldn't do this podcast fitting get the feedback from you guys. I wouldn't have it in person business. I can go on the internet and just do it make my money there all day, but the people here matter the community matters our relationships matter and I get something out of it much more than just, you know, hey, here's a check for because Can train a lot of people know it cuts a lot deeper than that and tonight is just another example of that. You know, it's I don't look at it as like, oh, I'm going out <mark>to</mark> dinner with some clients know it's like we're just going out <mark>to</mark> dinner with some friends who happen <mark>to</mark> be the first person. I worked with here a decade ago and happened <mark>to</mark> be the same guy who sold us our house and he just wants <mark>to</mark> celebrate us for paying it off which I thought was a super nice gesture and pretty cool. So that's on my docket tonight, but enough of my personal ramblings here we're going <mark>to</mark> get into The books that I would suggest for you guys <mark>to</mark> read and the ones that have had the biggest impact on me and my life over the past decade now before I dropped the first title. I need <mark>to</mark> say this I consume about a hundred books per year. And people are listening going. Holy shit. You're me that's a ton of books and it is but I don't read most of them. I read probably two <mark>to</mark> three books here at the most now. I will say this. I do read a ton of content a lot of Articles a lot of Snippets a lot of blogs. There's a lot of people I subscribe <mark>to</mark> a certain things and some days. I'll read", "Start Time (s)": 288.5, "End Time (s)": 407.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "out <mark>to</mark> dinner with some clients know it's like we're just going out <mark>to</mark> dinner with some friends who happen <mark>to</mark> be the first person. I worked with here a decade ago and happened <mark>to</mark> be the same guy who sold us our house and he just wants <mark>to</mark> celebrate us for paying it off which I thought was a super nice gesture and pretty cool. So that's on my docket tonight, but enough of my personal ramblings here we're going <mark>to</mark> get into The books that I would suggest for you guys <mark>to</mark> read and the ones that have had the biggest impact on me and my life over the past decade now before I dropped the first title. I need <mark>to</mark> say this I consume about a hundred books per year. And people are listening going. Holy shit. You're me that's a ton of books and it is but I don't read most of them. I read probably two <mark>to</mark> three books here at the most now. I will say this. I do read a ton of content a lot of Articles a lot of Snippets a lot of blogs. There's a lot of people I subscribe <mark>to</mark> a certain things and some days. I'll read nothing and some days. I'll read for an hour. It just depends on my schedule, but Audible Has <mark>become</mark> my best friend for sure over the past probably six years now and I'll do a lot of podcasts <mark>to</mark> and I'll share my podcast list later with you guys on a different episode my podcast tend <mark>to</mark> be pretty vanilla and Bland. I don't I don't like a lot of the Roush it and I don't need <mark>to</mark> be motivated. That's just not who I am. I like more tactical stuff personally and things on philosophy. I'm just about life, but there's only so much that you can consume right but I digress the reason I consume about A hundred books a year is and I've talked about this car a lot over the past, you know, probably a couple of years but as you guys know, I drive a 2008 Honda Accord. It's got a hundred forty-four thousand miles on it. Now. I mean, you know going <mark>to</mark> ride that bad boy and you know, as long as I can but probably five or six years ago the battery died which in Arizona if you guys are here your batteries died probably like", "Start Time (s)": 345.2, "End Time (s)": 465.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and things on philosophy. I'm just about life, but there's only so much that you can consume right but I digress the reason I consume about A hundred books a year is and I've talked about this car a lot over the past, you know, probably a couple of years but as you guys know, I drive a 2008 Honda Accord. It's got a hundred forty-four thousand miles on it. Now. I mean, you know going <mark>to</mark> ride that bad boy and you know, as long as I can but probably five or six years ago the battery died which in Arizona if you guys are here your batteries died probably like once a year like every other year because when it's a hundred Seventeen inches fries of shit out of them and so my battery died and so I take it. Into like either way, these are Jiffy Lube or somewhere just replace the battery for me. And once they swept with the battery. I don't have the code anymore for my radio are my CD player because I again I drive a no 8 you guys I do not have a back up camera. I've never had a backup camera my car by the way, and I'm 36 years old, which is pretty soon <mark>to</mark> be embarrassing <mark>to</mark> say but it's not like playing like there's no blue tooth in here. There's no like MP3 anything. There's no I'm going <mark>to</mark> do Apple sink. Its It's a CD player and radio but I lost the code many many years ago. So in my car when I get in there, there is no noise. There's nothing there's no option for sound whatsoever. And some days. I mean they'll drive <mark>to</mark> work and I won't have anything on I just that's kind of like my, you know, 10 <mark>to</mark> 15 minutes of like just mandatory mindfulness where it's quiet and I can just kind of you know, relax let my central nervous system chill before I get into here and rip it but for all the other times I'm driving especially home. Or when I'm running errands or if I do get stuck in traffic. I listen <mark>to</mark> audio books and I got in the habit of doing that now when I'm at the grocery store if I go <mark>to</mark> the post office if I'm walking I'm always listening <mark>to</mark> an audiobook and that's <mark>how</mark> it came about. And so I have <mark>to</mark> thank my car radio dying and not having the code for me <mark>to</mark> be able <mark>to</mark> listen <mark>to</mark> this many books per year and it", "Start Time (s)": 433.7, "End Time (s)": 553.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I drive a no 8 you guys I do not have a back up camera. I've never had a backup camera my car by the way, and I'm 36 years old, which is pretty soon <mark>to</mark> be embarrassing <mark>to</mark> say but it's not like playing like there's no blue tooth in here. There's no like MP3 anything. There's no I'm going <mark>to</mark> do Apple sink. Its It's a CD player and radio but I lost the code many many years ago. So in my car when I get in there, there is no noise. There's nothing there's no option for sound whatsoever. And some days. I mean they'll drive <mark>to</mark> work and I won't have anything on I just that's kind of like my, you know, 10 <mark>to</mark> 15 minutes of like just mandatory mindfulness where it's quiet and I can just kind of you know, relax let my central nervous system chill before I get into here and rip it but for all the other times I'm driving especially home. Or when I'm running errands or if I do get stuck in traffic. I listen <mark>to</mark> audio books and I got in the habit of doing that now when I'm at the grocery store if I go <mark>to</mark> the post office if I'm walking I'm always listening <mark>to</mark> an audiobook and that's <mark>how</mark> it came about. And so I have <mark>to</mark> thank my car radio dying and not having the code for me <mark>to</mark> be able <mark>to</mark> listen <mark>to</mark> this many books per year and it really has changed my life in terms of the amount of knowledge. I'm able <mark>to</mark> consume and acquire and understand and <mark>how</mark> I think and <mark>how</mark> I talk and always speak a lot of that has a Routed <mark>to</mark> me just taking in so much information over the past six years before that. I'm not saying it didn't read books, but nowhere near the level it is today, and I just I literally by about 10 and a time and sometimes I'll finish a whole one before I start the next one. But sometimes I'll do two or three simultaneously depending on what type of mood I'm in I think of it as like kind of Netflix like you might watch one show at a time, but some of you guys probably watched two or three shows depending on what type of mood you're in and now do the same thing with audiobooks. And so that is why I rip off about a hundred Year, so with that said the first book on my list the go-getter by Peter kind. I think it's Peter kind. I actually read the go-getter cover-to-cover. Like", "Start Time (s)": 484.4, "End Time (s)": 604.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "And so I have <mark>to</mark> thank my car radio dying and not having the code for me <mark>to</mark> be able <mark>to</mark> listen <mark>to</mark> this many books per year and it really has changed my life in terms of the amount of knowledge. I'm able <mark>to</mark> consume and acquire and understand and <mark>how</mark> I think and <mark>how</mark> I talk and always speak a lot of that has a Routed <mark>to</mark> me just taking in so much information over the past six years before that. I'm not saying it didn't read books, but nowhere near the level it is today, and I just I literally by about 10 and a time and sometimes I'll finish a whole one before I start the next one. But sometimes I'll do two or three simultaneously depending on what type of mood I'm in I think of it as like kind of Netflix like you might watch one show at a time, but some of you guys probably watched two or three shows depending on what type of mood you're in and now do the same thing with audiobooks. And so that is why I rip off about a hundred Year, so with that said the first book on my list the go-getter by Peter kind. I think it's Peter kind. I actually read the go-getter cover-to-cover. Like I read it. I didn't just listen <mark>to</mark> it. But I've also listen <mark>to</mark> it on Audible. It's a great listen. Long story short the go-getter is just a motivational tale of if you want <mark>to</mark> get shit done. You got <mark>to</mark> be willing <mark>to</mark> put in the work overtime. And it's it's a classic. It's super old. I don't have the numbers in front of me. I believe that books probably around for like 50 years, maybe even more and I've listened <mark>to</mark> it more than once. It's just a really good example of like resolved and if you want <mark>to</mark> get something done just go do it. So the go-getter is one of my favorite books of all time. The next one The Undefeated mind Alex. Liquor man The Undefeated mind is cool. If you're into kind of personal development and free thinking he goes into they'll talk on some religion stuff. I'm not going <mark>to</mark> sit here and preach <mark>to</mark> you guys of what you should believe because I believe you know, whatever makes you happy and whatever you believe in is, you know your truth, but he talks a lot about just having an open mind in terms of that and it's either Psychiatry or psychology patients speaking from that", "Start Time (s)": 545.9, "End Time (s)": 665.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Long story short the go-getter is just a motivational tale of if you want <mark>to</mark> get shit done. You got <mark>to</mark> be willing <mark>to</mark> put in the work overtime. And it's it's a classic. It's super old. I don't have the numbers in front of me. I believe that books probably around for like 50 years, maybe even more and I've listened <mark>to</mark> it more than once. It's just a really good example of like resolved and if you want <mark>to</mark> get something done just go do it. So the go-getter is one of my favorite books of all time. The next one The Undefeated mind Alex. Liquor man The Undefeated mind is cool. If you're into kind of personal development and free thinking he goes into they'll talk on some religion stuff. I'm not going <mark>to</mark> sit here and preach <mark>to</mark> you guys of what you should believe because I believe you know, whatever makes you happy and whatever you believe in is, you know your truth, but he talks a lot about just having an open mind in terms of that and it's either Psychiatry or psychology patients speaking from that perspective and they'll dig into like nichiren Buddhism. Just kind of like <mark>how</mark> that goes about like <mark>how</mark> he changed religions from like what he grew up was of his kid <mark>to</mark> what he believes now and on that same I do think that is a thing where you know, sometimes we grew up a certain way. We don't question things. We just take them as they are because our mom did it in our dad didn't or Grandpa did it and there's nothing wrong with that having the tradition in the Legacy, but there's also something <mark>to</mark> be said about being a free thinker and when I look at my own, you know beliefs of you know religion in the world and Source energy in the universe and fucking unicorn tears and all the things Leave in I do think there's a lot of good things like that the nichiren Buddhism practice applies <mark>to</mark> real life into me the easy example, I give it's just about being a good person but it does talk about mindset quite a bit. And there's The Undefeated mind about Alex flickerman is a great read next one one minute mindfulness by Donald Altman. It's a good book quick read if you're a person who gets too busy working. In their", "Start Time (s)": 609.9, "End Time (s)": 729.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "about like <mark>how</mark> he changed religions from like what he grew up was of his kid <mark>to</mark> what he believes now and on that same I do think that is a thing where you know, sometimes we grew up a certain way. We don't question things. We just take them as they are because our mom did it in our dad didn't or Grandpa did it and there's nothing wrong with that having the tradition in the Legacy, but there's also something <mark>to</mark> be said about being a free thinker and when I look at my own, you know beliefs of you know religion in the world and Source energy in the universe and fucking unicorn tears and all the things Leave in I do think there's a lot of good things like that the nichiren Buddhism practice applies <mark>to</mark> real life into me the easy example, I give it's just about being a good person but it does talk about mindset quite a bit. And there's The Undefeated mind about Alex flickerman is a great read next one one minute mindfulness by Donald Altman. It's a good book quick read if you're a person who gets too busy working. In their life, they don't get <mark>to</mark> work on their life. I would suggest this for you. It's it's just leaves little practices that you can do every single day <mark>to</mark> be mindful when I say mindful. It's like you never know people there somewhere, but they're not really there. Like I'll get example like when I was in school like I'd be sitting in math class, but I wasn't really in math class. Right? Like I'm sitting there like my body is there but my brain is nowhere near there and the teacher can be looking right at me saying some shit and I can be looking. At her and I didn't hear a single word. She said because I'm thinking about Tupac lyrics and you know, Michael Jordan fadeaways or whatever is on my brain or probably girls at the time and so I'm in class them saying there but I'm not really there. My mind is somewhere else that mindfulness is like when you're actually like, you know, eating an orange. You're actually eating an orange like you smell it the texture of the taste you take a bite of it. You really just you take it all in for just being in that moment. You're not thinking about work or your kids or Or some other", "Start Time (s)": 670.5, "End Time (s)": 790.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "It's like you never know people there somewhere, but they're not really there. Like I'll get example like when I was in school like I'd be sitting in math class, but I wasn't really in math class. Right? Like I'm sitting there like my body is there but my brain is nowhere near there and the teacher can be looking right at me saying some shit and I can be looking. At her and I didn't hear a single word. She said because I'm thinking about Tupac lyrics and you know, Michael Jordan fadeaways or whatever is on my brain or probably girls at the time and so I'm in class them saying there but I'm not really there. My mind is somewhere else that mindfulness is like when you're actually like, you know, eating an orange. You're actually eating an orange like you smell it the texture of the taste you take a bite of it. You really just you take it all in for just being in that moment. You're not thinking about work or your kids or Or some other shit. You're just thinking about eating that orange in the moment or like when you're having sex, you're just having sex. You're not thinking about work, you know thinking about you know, what you have <mark>to</mark> do tomorrow. You're just thinking about the feeling in the moment and being mindful of every touch and every feeling you're having some make sense. Like it's a book of those little practices <mark>to</mark> be <mark>to</mark> take a minute <mark>to</mark> just be mindful every single day. This can be gratitude things. They can be perspective things. They can be stimulus things. It's a great read. I also do read a lot of on that. Therapy books here in books on <mark>how</mark> <mark>to</mark> talk <mark>to</mark> and understand people and <mark>how</mark> <mark>to</mark> help them <mark>how</mark> <mark>to</mark> empathize with them such as like the mindfulness toolbox, which is like this 50, you know tips and tools handouts for anxiety depression stress and pain which is also written by Donald Altman. I do read a lot of that stuff. Those are the books. I actually do have here like if you ever come visit me <mark>to</mark> say Jeremy what books you talking about? They're in my desk right here. I'll pop them out and I just roll through them and <mark>how</mark> I need <mark>to</mark> say this before I keep going. <mark>How</mark> I make decisions on what books are read are basically two choices one what it's going <mark>to</mark> help the people. I work with the", "Start Time (s)": 738.9, "End Time (s)": 858.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "other shit. You're just thinking about eating that orange in the moment or like when you're having sex, you're just having sex. You're not thinking about work, you know thinking about you know, what you have <mark>to</mark> do tomorrow. You're just thinking about the feeling in the moment and being mindful of every touch and every feeling you're having some make sense. Like it's a book of those little practices <mark>to</mark> be <mark>to</mark> take a minute <mark>to</mark> just be mindful every single day. This can be gratitude things. They can be perspective things. They can be stimulus things. It's a great read. I also do read a lot of on that. Therapy books here in books on <mark>how</mark> <mark>to</mark> talk <mark>to</mark> and understand people and <mark>how</mark> <mark>to</mark> help them <mark>how</mark> <mark>to</mark> empathize with them such as like the mindfulness toolbox, which is like this 50, you know tips and tools handouts for anxiety depression stress and pain which is also written by Donald Altman. I do read a lot of that stuff. Those are the books. I actually do have here like if you ever come visit me <mark>to</mark> say Jeremy what books you talking about? They're in my desk right here. I'll pop them out and I just roll through them and <mark>how</mark> I need <mark>to</mark> say this before I keep going. <mark>How</mark> I make decisions on what books are read are basically two choices one what it's going <mark>to</mark> help the people. I work with the most. What am I going <mark>to</mark> read in here that I can give back <mark>to</mark> them or speak <mark>to</mark> them or talk about a problem a scenario or dilemma that's going <mark>to</mark> help me either understand them better listen <mark>to</mark> them better or give them some advice that they can take and make their life a little bit, you know, healthy happier or a little bit easier and the second thing is, you know, what person is going <mark>to</mark> make my life better and Those are almost one in the same. Sometimes they're not but I believe it's I am so much like all of you. I'm a normal fucking dude. I cannot say that enough. There's things that I do that are probably weird and strange and unlike many of you guys but at our core I think so many of us spend so much time trying <mark>to</mark> be unique. We're all the same like we all have the same humanistic needs. We really do if you're cold you want <mark>to</mark> be warm if you're warm you want <mark>to</mark> be cool, you know, if you're hungry you need eat if", "Start Time (s)": 790.2, "End Time (s)": 910.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and <mark>how</mark> I need <mark>to</mark> say this before I keep going. <mark>How</mark> I make decisions on what books are read are basically two choices one what it's going <mark>to</mark> help the people. I work with the most. What am I going <mark>to</mark> read in here that I can give back <mark>to</mark> them or speak <mark>to</mark> them or talk about a problem a scenario or dilemma that's going <mark>to</mark> help me either understand them better listen <mark>to</mark> them better or give them some advice that they can take and make their life a little bit, you know, healthy happier or a little bit easier and the second thing is, you know, what person is going <mark>to</mark> make my life better and Those are almost one in the same. Sometimes they're not but I believe it's I am so much like all of you. I'm a normal fucking dude. I cannot say that enough. There's things that I do that are probably weird and strange and unlike many of you guys but at our core I think so many of us spend so much time trying <mark>to</mark> be unique. We're all the same like we all have the same humanistic needs. We really do if you're cold you want <mark>to</mark> be warm if you're warm you want <mark>to</mark> be cool, you know, if you're hungry you need eat if you're thirsty, you have <mark>to</mark> drink if you're horny, you have <mark>to</mark> have sex like we all have these, you know basic animalistic needs and yeah, we might have different careers and we might like different types of music and things but we all like music we all have careers, you know, I'm saying like we're all were all so similar and I'm just like you but when I do something <mark>to</mark> help myself, I think in some weird way it would hope most of you as well since we all are so similar. So if I read a book on Personal Finance <mark>to</mark> help me, I'm not telling you what <mark>to</mark> do with your money. I'm going <mark>to</mark> share with you what I did for myself and if you want <mark>to</mark> do something similar, you could model the behavior that I used. I hope you're following me so long. So I do read a ton of books like that which most of you probably wouldn't be into that but I do have <mark>to</mark> say that is a huge part of my career and my personal Development in terms of if you are a business owner or you want <mark>to</mark> start a small business or you're", "Start Time (s)": 847.1, "End Time (s)": 965.8, "Clip Length (min)": 1.98, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I think so many of us spend so much time trying <mark>to</mark> be unique. We're all the same like we all have the same humanistic needs. We really do if you're cold you want <mark>to</mark> be warm if you're warm you want <mark>to</mark> be cool, you know, if you're hungry you need eat if you're thirsty, you have <mark>to</mark> drink if you're horny, you have <mark>to</mark> have sex like we all have these, you know basic animalistic needs and yeah, we might have different careers and we might like different types of music and things but we all like music we all have careers, you know, I'm saying like we're all were all so similar and I'm just like you but when I do something <mark>to</mark> help myself, I think in some weird way it would hope most of you as well since we all are so similar. So if I read a book on Personal Finance <mark>to</mark> help me, I'm not telling you what <mark>to</mark> do with your money. I'm going <mark>to</mark> share with you what I did for myself and if you want <mark>to</mark> do something similar, you could model the behavior that I used. I hope you're following me so long. So I do read a ton of books like that which most of you probably wouldn't be into that but I do have <mark>to</mark> say that is a huge part of my career and my personal Development in terms of if you are a business owner or you want <mark>to</mark> start a small business or you're thinking about it or you work in a small business or you work in any company or organization? You want <mark>to</mark> understand it better the e-myth by Michael Gerber or the e-myth Revisited. He has a whole, you know kind of e-myth series but the e-myth is just about being an entrepreneur and he goes into detail about if you're in a small business such as myself if you're you know the owner if you're the manager or if you're the technician and they break down those roles inside of multiple businesses and they explain it <mark>to</mark> you. And that's I listened <mark>to</mark> that probably 10 years ago. Probably the maybe probably the second Euros in business give or take and it changed the scope of <mark>how</mark> I thought about things and now I'll always be the owner here as long as it's you know, my name on the door, and I'm also you know the", "Start Time (s)": 896.7, "End Time (s)": 1016.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "model the behavior that I used. I hope you're following me so long. So I do read a ton of books like that which most of you probably wouldn't be into that but I do have <mark>to</mark> say that is a huge part of my career and my personal Development in terms of if you are a business owner or you want <mark>to</mark> start a small business or you're thinking about it or you work in a small business or you work in any company or organization? You want <mark>to</mark> understand it better the e-myth by Michael Gerber or the e-myth Revisited. He has a whole, you know kind of e-myth series but the e-myth is just about being an entrepreneur and he goes into detail about if you're in a small business such as myself if you're you know the owner if you're the manager or if you're the technician and they break down those roles inside of multiple businesses and they explain it <mark>to</mark> you. And that's I listened <mark>to</mark> that probably 10 years ago. Probably the maybe probably the second Euros in business give or take and it changed the scope of <mark>how</mark> I thought about things and now I'll always be the owner here as long as it's you know, my name on the door, and I'm also you know the manager a lot of times and a lot of times. The technician and I know <mark>how</mark> <mark>to</mark> separate those roles. We have other people here where Monica can manage and Jacob can be the technician and so can other people we can shift roles and things but if you're going <mark>to</mark> start a business and you want <mark>to</mark> I think the e-myth by Michael Gerber is an amazing book and I think all of you should read it even if you think you know everything there's going <mark>to</mark> be a lot of great takeaways in there that will help you. I guess kind of unblurred the lines of what you do in your job. And obviously if you start a small business, you're everything up front your you know, I was never the CPA but in or the financial planner, but for those two things like I Was the janitor, you know, I was every other role inside of that. Yeah. I was the bookkeeper even though I never filed the taxes. I kept course of everything. So it is a great book the other one. I think if you're a business owner Or you want <mark>to</mark> start a", "Start Time (s)": 947.7, "End Time (s)": 1067.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of <mark>how</mark> I thought about things and now I'll always be the owner here as long as it's you know, my name on the door, and I'm also you know the manager a lot of times and a lot of times. The technician and I know <mark>how</mark> <mark>to</mark> separate those roles. We have other people here where Monica can manage and Jacob can be the technician and so can other people we can shift roles and things but if you're going <mark>to</mark> start a business and you want <mark>to</mark> I think the e-myth by Michael Gerber is an amazing book and I think all of you should read it even if you think you know everything there's going <mark>to</mark> be a lot of great takeaways in there that will help you. I guess kind of unblurred the lines of what you do in your job. And obviously if you start a small business, you're everything up front your you know, I was never the CPA but in or the financial planner, but for those two things like I Was the janitor, you know, I was every other role inside of that. Yeah. I was the bookkeeper even though I never filed the taxes. I kept course of everything. So it is a great book the other one. I think if you're a business owner Or you want <mark>to</mark> start a small business or you're a hustler The Reluctant entrepreneur by Michael Madison The Reluctant entrepreneur by Michael Madison is just a smarter way <mark>to</mark> start your own business or the smarter way <mark>to</mark> start a side hustle or a passion project and I don't know if there's anything earth-shattering in there. The funny thing is a lot of these books. Some of the things I didn't do but a lot of them are already did naturally and when you say reluctant entrepreneurs the person who does it the right way like you just don't like you're not a person who's making $150,000 a year and you got three kids and you come home Friday and you tell your wife you're quitting your job and you're going <mark>to</mark> go, you know start a snow cone stand like that's not a reluctant entrepreneur. That's a dumbass entrepreneur. You don't want <mark>to</mark> be that I'm not saying I was that but again, I'll give you context I think. I feel I was even though I will say this when I started this business I had no business training. I had no skills. I had no", "Start Time (s)": 1007.3, "End Time (s)": 1127.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a lot of them are already did naturally and when you say reluctant entrepreneurs the person who does it the right way like you just don't like you're not a person who's making $150,000 a year and you got three kids and you come home Friday and you tell your wife you're quitting your job and you're going <mark>to</mark> go, you know start a snow cone stand like that's not a reluctant entrepreneur. That's a dumbass entrepreneur. You don't want <mark>to</mark> be that I'm not saying I was that but again, I'll give you context I think. I feel I was even though I will say this when I started this business I had no business training. I had no skills. I had no money. I don't know what the fuck I was doing and I honestly didn't have a current active client at the time. So that would fall under the dumbass entrepreneur category and that's exactly what I did on the same sentence. My wife had a job making about two dollars so we could survive on the two dollars and we ran the numbers and we knew that we lived in my one-bedroom sit condo, which I still think is amazing <mark>to</mark> this day, which I got a Smokin deal on because I bought it when the economy completely collapse. So I got it for pennies on the dollar. So the cheapest rent we could ever pay I had a paid off old used car. My wife had a paid off old used car and I was 25 years old. What did I have <mark>to</mark> lose? Right? I can always go back and get another shitty. For job and I be just fine and at the time I think I had total of I think we had $5,000 total tour name. So I had $5,000 or burn through. So I did again when you don't have a lot <mark>to</mark> lose. I do feel like that's like The Reluctant entrepreneur route, but if you guys are in a different boat, I think you should read this book before you think about quitting your job. If you do have a bigger mortgage or car payments or responsibilities with kids and family, but again, the e-myth Revisited and reluctant entrepreneur both great books if you're looking <mark>to</mark> <mark>To</mark> be an entrepreneur or somebody wants <mark>to</mark> do something outside of just the you know, corporate structure next one extreme ownership by Jackal and lafe great", "Start Time (s)": 1091.3, "End Time (s)": 1211.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "so we could survive on the two dollars and we ran the numbers and we knew that we lived in my one-bedroom sit condo, which I still think is amazing <mark>to</mark> this day, which I got a Smokin deal on because I bought it when the economy completely collapse. So I got it for pennies on the dollar. So the cheapest rent we could ever pay I had a paid off old used car. My wife had a paid off old used car and I was 25 years old. What did I have <mark>to</mark> lose? Right? I can always go back and get another shitty. For job and I be just fine and at the time I think I had total of I think we had $5,000 total tour name. So I had $5,000 or burn through. So I did again when you don't have a lot <mark>to</mark> lose. I do feel like that's like The Reluctant entrepreneur route, but if you guys are in a different boat, I think you should read this book before you think about quitting your job. If you do have a bigger mortgage or car payments or responsibilities with kids and family, but again, the e-myth Revisited and reluctant entrepreneur both great books if you're looking <mark>to</mark> <mark>To</mark> be an entrepreneur or somebody wants <mark>to</mark> do something outside of just the you know, corporate structure next one extreme ownership by Jackal and lafe great book. They tell a lot of stories about their military days and basically just as the title says taking extreme ownership for everything goes wrong in your life and your business. I got a lot out of this I did it probably 90% And when I listen <mark>to</mark> that book, I just went a hundred percent all in and said anything that's wrong here is my fault anything that anybody does here. It's my fault. It's my responsibility and I have <mark>to</mark> clean it up and you just you learn <mark>to</mark> not make excuses and you learn <mark>to</mark> just not have a shitty attitude understand that everything in your life is up <mark>to</mark> you, you know, and obviously bad things are going <mark>to</mark> happen <mark>to</mark> you. I can't that's the Universe. I can't equate for that. But everything else if you take extreme ownership and accountability for your efforts and your actions things get pretty good really fast because you have nobody else <mark>to</mark> fucking blame but yourself and then you figure it out and that's when stuff gets really amazing next one", "Start Time (s)": 1143.8, "End Time (s)": 1262.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Revisited and reluctant entrepreneur both great books if you're looking <mark>to</mark> <mark>To</mark> be an entrepreneur or somebody wants <mark>to</mark> do something outside of just the you know, corporate structure next one extreme ownership by Jackal and lafe great book. They tell a lot of stories about their military days and basically just as the title says taking extreme ownership for everything goes wrong in your life and your business. I got a lot out of this I did it probably 90% And when I listen <mark>to</mark> that book, I just went a hundred percent all in and said anything that's wrong here is my fault anything that anybody does here. It's my fault. It's my responsibility and I have <mark>to</mark> clean it up and you just you learn <mark>to</mark> not make excuses and you learn <mark>to</mark> just not have a shitty attitude understand that everything in your life is up <mark>to</mark> you, you know, and obviously bad things are going <mark>to</mark> happen <mark>to</mark> you. I can't that's the Universe. I can't equate for that. But everything else if you take extreme ownership and accountability for your efforts and your actions things get pretty good really fast because you have nobody else <mark>to</mark> fucking blame but yourself and then you figure it out and that's when stuff gets really amazing next one rhinoceros success by Scott Alexander. This is another book. I read actually cover <mark>to</mark> cover. It's a great book. It's like I have a lot of pictures in it too. It's like a little kids book. I'm good with books that would fit like a 6th grader because I feel like that's about my my reading I don't want <mark>to</mark> be reading level because it's not right but my reading interest is about like the sixth grade level books like Everybody Poops. Also a great book because no Reddit and rhinoceros success by Scott all There is a great book just talked about being a rhinoceros and the rhinoceros is like a metaphor for a person who is motivated and wants <mark>to</mark> go get stuff done and just talks about kind of like <mark>to</mark> Swagger you'd have if you were like a badass Rhino, right? Like if you think like whatever your favorite animal is like a bear or an alligator or a rhinoceros, for example, it talks about living your life that way not living your life like a sheep actually going out and getting the things you want having thick skin, you know having a short memory", "Start Time (s)": 1197.2, "End Time (s)": 1317.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "blame but yourself and then you figure it out and that's when stuff gets really amazing next one rhinoceros success by Scott Alexander. This is another book. I read actually cover <mark>to</mark> cover. It's a great book. It's like I have a lot of pictures in it too. It's like a little kids book. I'm good with books that would fit like a 6th grader because I feel like that's about my my reading I don't want <mark>to</mark> be reading level because it's not right but my reading interest is about like the sixth grade level books like Everybody Poops. Also a great book because no Reddit and rhinoceros success by Scott all There is a great book just talked about being a rhinoceros and the rhinoceros is like a metaphor for a person who is motivated and wants <mark>to</mark> go get stuff done and just talks about kind of like <mark>to</mark> Swagger you'd have if you were like a badass Rhino, right? Like if you think like whatever your favorite animal is like a bear or an alligator or a rhinoceros, for example, it talks about living your life that way not living your life like a sheep actually going out and getting the things you want having thick skin, you know having a short memory when it comes <mark>to</mark> bad things in your life. It really is it's all stuff, you know. No, but it's done in a really tasteful fun way. So check that one out. Next one Think Like a Freak Steven Levitt and I think somebody else put that out too. But think like a freak. They also have a podcast Think Like a Freak is is a good book about thinking about things differently and <mark>how</mark> sometimes like the world and the media pulls the wool over your eyes and makes you believe certain things kind of like what's going on now with the world in the news of you know, freaking people out and all the stuff that they're Cheering with the things that are going on but the Think Like a Freak book. The one thing I remember is they have you think about like fat loss and weight loss differently in the example. I remember in the book specifically and I'll never forget this they're talking about like gastric bypass or like the lap band surgeries where they actually, you know, cut your body open, you know, put the lap band down or they shrink your stomach down they make it, you know, super small. So, you know by forces You by Nature you can't eat", "Start Time (s)": 1257.4, "End Time (s)": 1377.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it's done in a really tasteful fun way. So check that one out. Next one Think Like a Freak Steven Levitt and I think somebody else put that out too. But think like a freak. They also have a podcast Think Like a Freak is is a good book about thinking about things differently and <mark>how</mark> sometimes like the world and the media pulls the wool over your eyes and makes you believe certain things kind of like what's going on now with the world in the news of you know, freaking people out and all the stuff that they're Cheering with the things that are going on but the Think Like a Freak book. The one thing I remember is they have you think about like fat loss and weight loss differently in the example. I remember in the book specifically and I'll never forget this they're talking about like gastric bypass or like the lap band surgeries where they actually, you know, cut your body open, you know, put the lap band down or they shrink your stomach down they make it, you know, super small. So, you know by forces You by Nature you can't eat so much because the stomach volume fills up and you'll lose weight over time. Which is a pretty invasive thing <mark>to</mark> cut your body open in and plant something inside your body when you think about it, that's pretty drastic. Right? Well the example he gives the book is he was What If instead of doing gastric bypass, we had you puke in a jar and we're that jar around your neck and every time you were hungry you unscrew the jar and you give it a real strong with do you think that would deter you from eating well shit you out. Well, that's pretty disgusting. And people like oh my God, that's so drastic that so crazy. Is that crazier than you cutting open your body and implanting something in there and doing a major life changing surgery. I would argue puking in a jar AS way less invasive way less dangerous and way easier <mark>to</mark> come back from do you agree the other example, he gave him the book was if you're not down with the puke jar scenario What If instead of doing like lap ban or gastric bypass or Thing <mark>to</mark> kind", "Start Time (s)": 1321.8, "End Time (s)": 1441.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "thing <mark>to</mark> cut your body open in and plant something inside your body when you think about it, that's pretty drastic. Right? Well the example he gives the book is he was What If instead of doing gastric bypass, we had you puke in a jar and we're that jar around your neck and every time you were hungry you unscrew the jar and you give it a real strong with do you think that would deter you from eating well shit you out. Well, that's pretty disgusting. And people like oh my God, that's so drastic that so crazy. Is that crazier than you cutting open your body and implanting something in there and doing a major life changing surgery. I would argue puking in a jar AS way less invasive way less dangerous and way easier <mark>to</mark> come back from do you agree the other example, he gave him the book was if you're not down with the puke jar scenario What If instead of doing like lap ban or gastric bypass or Thing <mark>to</mark> kind of cure or curb this, you know, eating stuff. What if you just gave your lips like 20 paper cuts in the top and bottom and every time you are hungry and want <mark>to</mark> put food in your mouth would be so painful for you <mark>to</mark> eat you would stop and people that's crazy and insane again. I would argue having small paper cuts on your lips as far less invasive than like this lap band or gastric bypass surgery. So again, it's just it's giving you different ways <mark>to</mark> think about problems and <mark>how</mark> <mark>to</mark> go about them and all be at like, I know that both those things Crazy, but when you really step back from it are those things not less drastic than these major surgeries out argue. They are so there's a lot of things in the book where makes you think about things differently and maybe see things in a different light. So Think Like a Freak good read next one's just Fitness stuff in a lot of you guys have asked about like Fitness books and those things honestly, I've went through a ton over the years A lot of them are technical books like the things we have <mark>to</mark> read here for, you know certifications and continuing education credits. I", "Start Time (s)": 1381.6, "End Time (s)": 1500.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "What If instead of doing like lap ban or gastric bypass or Thing <mark>to</mark> kind of cure or curb this, you know, eating stuff. What if you just gave your lips like 20 paper cuts in the top and bottom and every time you are hungry and want <mark>to</mark> put food in your mouth would be so painful for you <mark>to</mark> eat you would stop and people that's crazy and insane again. I would argue having small paper cuts on your lips as far less invasive than like this lap band or gastric bypass surgery. So again, it's just it's giving you different ways <mark>to</mark> think about problems and <mark>how</mark> <mark>to</mark> go about them and all be at like, I know that both those things Crazy, but when you really step back from it are those things not less drastic than these major surgeries out argue. They are so there's a lot of things in the book where makes you think about things differently and maybe see things in a different light. So Think Like a Freak good read next one's just Fitness stuff in a lot of you guys have asked about like Fitness books and those things honestly, I've went through a ton over the years A lot of them are technical books like the things we have <mark>to</mark> read here for, you know certifications and continuing education credits. I do, you know trade stuff with a lot of my friends and colleagues in the space. That's where I get a lot of my information from if I don't know something. I'll reach out <mark>to</mark> like Mike or BJ or you know, whoever it is and I'll say hey, what do you think of this and we'll go back and forth or our doctor friends as well, but it starts with food Melissa and Alyce Hartwig is a good book. It's kind of like a take on the Whole 30 basically and so they kind of talked about just eating real food and their experiences with it. I don't believe there's a hundred percent truths and in He you know specific book. There's a lot of gray area for people in nutrition is the hardest thing right because everybody's so different what what so guys asked me yesterday. Hey Jeremy, what do you do for your what are your calories? And what are your Macros and like, I don't know. I don't track them anymore tracked him for years and years and years, but I don't anymore I go by <mark>how</mark> I feel number one and <mark>how</mark> I look and what my schedules like so some days I eat once a day some some days. I eat twice a day and", "Start Time (s)": 1437.1, "End Time (s)": 1556.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "one's just Fitness stuff in a lot of you guys have asked about like Fitness books and those things honestly, I've went through a ton over the years A lot of them are technical books like the things we have <mark>to</mark> read here for, you know certifications and continuing education credits. I do, you know trade stuff with a lot of my friends and colleagues in the space. That's where I get a lot of my information from if I don't know something. I'll reach out <mark>to</mark> like Mike or BJ or you know, whoever it is and I'll say hey, what do you think of this and we'll go back and forth or our doctor friends as well, but it starts with food Melissa and Alyce Hartwig is a good book. It's kind of like a take on the Whole 30 basically and so they kind of talked about just eating real food and their experiences with it. I don't believe there's a hundred percent truths and in He you know specific book. There's a lot of gray area for people in nutrition is the hardest thing right because everybody's so different what what so guys asked me yesterday. Hey Jeremy, what do you do for your what are your calories? And what are your Macros and like, I don't know. I don't track them anymore tracked him for years and years and years, but I don't anymore I go by <mark>how</mark> I feel number one and <mark>how</mark> I look and what my schedules like so some days I eat once a day some some days. I eat twice a day and if I feel good, and I think I don't look like a complete turd. I'm okay with it, but the biggest thing is just <mark>how</mark> I feel so I don't track the macros, but I don't need <mark>to</mark> either I have a pretty good estimate of what they are, but they can fluctuate and that works for me. I wouldn't recommend that for everybody else. I also eat in about a four-hour window most days so I eat from like let's say, you know, three or four o'clock until like eight or nine o'clock and that's probably it and some days if I eat one meal I eat like a one-hour window. So again, I'm not recommending that <mark>to</mark> you guys listening, but that works for me, but the it starts with food Does give a lot of basic information <mark>to</mark> you guys in terms of food and <mark>how</mark> <mark>to</mark> eat it and what they did in their experiences are and then obviously you you know, you beg borrow and steal in nutrition. Right? Like you don't have <mark>to</mark> you wouldn't take my diet and make it your diet just like I wouldn't take my wife's", "Start Time (s)": 1486.9, "End Time (s)": 1606.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I don't track them anymore tracked him for years and years and years, but I don't anymore I go by <mark>how</mark> I feel number one and <mark>how</mark> I look and what my schedules like so some days I eat once a day some some days. I eat twice a day and if I feel good, and I think I don't look like a complete turd. I'm okay with it, but the biggest thing is just <mark>how</mark> I feel so I don't track the macros, but I don't need <mark>to</mark> either I have a pretty good estimate of what they are, but they can fluctuate and that works for me. I wouldn't recommend that for everybody else. I also eat in about a four-hour window most days so I eat from like let's say, you know, three or four o'clock until like eight or nine o'clock and that's probably it and some days if I eat one meal I eat like a one-hour window. So again, I'm not recommending that <mark>to</mark> you guys listening, but that works for me, but the it starts with food Does give a lot of basic information <mark>to</mark> you guys in terms of food and <mark>how</mark> <mark>to</mark> eat it and what they did in their experiences are and then obviously you you know, you beg borrow and steal in nutrition. Right? Like you don't have <mark>to</mark> you wouldn't take my diet and make it your diet just like I wouldn't take my wife's diet and make it my diet but there's things that she does better beneficial that I should do it. Like my wife naturally would eat way more vegetables <mark>to</mark> me. So I gravitate towards her and pretty vegetables like she does I know. We'll probably bigger into you know. You protein then she is and she'll she'll be like gravitate towards, you know, eating, you know, more cuts of fish and those things like than I would and so we we steal from each other if you want <mark>to</mark> think these are what these books are for the next one Supple Leopard by Kelly Starrett. If you're looking for injury prevention or athletic performance Kelly is a genius. He is the best in terms of Mobility on the planet. I don't even think that's arguable and supple upper is a good book if you're looking <mark>to</mark> get into that the other one the the first probably book book. I read encyclopedia bodybuilding by Arnold. That's probably my first like legit lifting book other than like Men's Health and", "Start Time (s)": 1542.6, "End Time (s)": 1662.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it my diet but there's things that she does better beneficial that I should do it. Like my wife naturally would eat way more vegetables <mark>to</mark> me. So I gravitate towards her and pretty vegetables like she does I know. We'll probably bigger into you know. You protein then she is and she'll she'll be like gravitate towards, you know, eating, you know, more cuts of fish and those things like than I would and so we we steal from each other if you want <mark>to</mark> think these are what these books are for the next one Supple Leopard by Kelly Starrett. If you're looking for injury prevention or athletic performance Kelly is a genius. He is the best in terms of Mobility on the planet. I don't even think that's arguable and supple upper is a good book if you're looking <mark>to</mark> get into that the other one the the first probably book book. I read encyclopedia bodybuilding by Arnold. That's probably my first like legit lifting book other than like Men's Health and muscle and fitness and those things but encyclopedia bodybuilding is the old school like <mark>how</mark> <mark>to</mark> just pick up and put down weight and <mark>how</mark> <mark>to</mark> do it in a very bodybuilding format. Obviously, we've come a long way since then but definitely a good read if you don't know anything and some of the stuff, you know at this stage of life. I probably wouldn't do and don't agree with everything but there is a Really good truce in there and just it's a good read for sure <mark>to</mark> learn the basic Foundation movements, especially if you're into body building and building up your physique, the other ones just off the top like Warrior Diet. I went through years ago lean gains. Even for Body by Tim Ferriss put that out again just different ways that people go about eating and training that some of you guys might, you know, take some things from and throw those out there next one minimalism. By Josh and Ryan and they have a podcast <mark>to</mark> call the minimalist there like the two prime most famous minimalist. There are on the planet minimalism is a good book If you're trying <mark>to</mark> Have less shit in your life", "Start Time (s)": 1607.5, "End Time (s)": 1727.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and fitness and those things but encyclopedia bodybuilding is the old school like <mark>how</mark> <mark>to</mark> just pick up and put down weight and <mark>how</mark> <mark>to</mark> do it in a very bodybuilding format. Obviously, we've come a long way since then but definitely a good read if you don't know anything and some of the stuff, you know at this stage of life. I probably wouldn't do and don't agree with everything but there is a Really good truce in there and just it's a good read for sure <mark>to</mark> learn the basic Foundation movements, especially if you're into body building and building up your physique, the other ones just off the top like Warrior Diet. I went through years ago lean gains. Even for Body by Tim Ferriss put that out again just different ways that people go about eating and training that some of you guys might, you know, take some things from and throw those out there next one minimalism. By Josh and Ryan and they have a podcast <mark>to</mark> call the minimalist there like the two prime most famous minimalist. There are on the planet minimalism is a good book If you're trying <mark>to</mark> Have less shit in your life literally like less material stuff for sure and they're not about just giving up everything is something you can't have an iPhone and you can't have a car and all this crazy stuff, but it just kind of talks about living with less and not being so wrapped up in the material things that we have in the world. And I think if you look around your house, you probably have way more stuff than you need in terms of clothes and shoes and you have junk drawers like filled with pens and chargers and markers and all kinds of other shit. We just We collect over time and it kind of talks about decluttering your life <mark>to</mark> just be more clearly clear like more free and just a little bit happier. Next book The obstacle is the way Ryan holiday. This is a great book as well a lot of stories in here, but overcoming and persevering and literally as the title says it just keeps reiterating. The obstacle is the way I think", "Start Time (s)": 1662.9, "End Time (s)": 1782.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the material things that we have in the world. And I think if you look around your house, you probably have way more stuff than you need in terms of clothes and shoes and you have junk drawers like filled with pens and chargers and markers and all kinds of other shit. We just We collect over time and it kind of talks about decluttering your life <mark>to</mark> just be more clearly clear like more free and just a little bit happier. Next book The obstacle is the way Ryan holiday. This is a great book as well a lot of stories in here, but overcoming and persevering and literally as the title says it just keeps reiterating. The obstacle is the way I think we as a culture now specifically get really hung up on the end goal and the end result, you know, like, oh we want this house. We want this car. We want this salary want this body and that's great. And we don't necessarily always want <mark>to</mark> do the work that's involved <mark>to</mark> get there. But the obstacle is the way and without that adversity without that roadblock with all that shit you had <mark>to</mark> Wade through <mark>to</mark> get there. It wouldn't really feel like you're earned it when you got <mark>to</mark> the end and sometimes it's that adversity that struggle that creates the thing you want like when you're in the gym and you're struggling through split squats and your legs are burning and it's just as miserable horrible feeling and you can't breathe and you're sweating and it's uncomfortable. That's what makes those legs grow. That's what develops the glute and the hamstring and the quads so your butt and legs look and move and feel the way that you want them <mark>to</mark> the obstacle is the pain is the agony is the lack of oxygen but that is the way <mark>to</mark> get what you want. I do resonate with things like that because when you train the physical body you learn a lot of things about yourself and life a you know, <mark>how</mark> deep is your pain cave, you know <mark>how</mark> far into the ocean of pain are you willing <mark>to</mark> swim before you have <mark>to</mark> get back to? Sure, but", "Start Time (s)": 1740.3, "End Time (s)": 1860.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "house. We want this car. We want this salary want this body and that's great. And we don't necessarily always want <mark>to</mark> do the work that's involved <mark>to</mark> get there. But the obstacle is the way and without that adversity without that roadblock with all that shit you had <mark>to</mark> Wade through <mark>to</mark> get there. It wouldn't really feel like you're earned it when you got <mark>to</mark> the end and sometimes it's that adversity that struggle that creates the thing you want like when you're in the gym and you're struggling through split squats and your legs are burning and it's just as miserable horrible feeling and you can't breathe and you're sweating and it's uncomfortable. That's what makes those legs grow. That's what develops the glute and the hamstring and the quads so your butt and legs look and move and feel the way that you want them <mark>to</mark> the obstacle is the pain is the agony is the lack of oxygen but that is the way <mark>to</mark> get what you want. I do resonate with things like that because when you train the physical body you learn a lot of things about yourself and life a you know, <mark>how</mark> deep is your pain cave, you know <mark>how</mark> far into the ocean of pain are you willing <mark>to</mark> swim before you have <mark>to</mark> get back to? Sure, but that's <mark>how</mark> we do everything in life. <mark>How</mark> you <mark>become</mark> great at anything is pretty much <mark>how</mark> you <mark>become</mark> great at everything. It's putting in the consistent effort energy and work overtime and willing <mark>to</mark> endure in sacrifice certain things <mark>to</mark> get what you want. If you look at anybody who excels that anything in life, they've been some people are naturally gifted in certain areas for sure, but you take like LeBron James it's not like LeBron doesn't work and putting the time <mark>to</mark> his diet and his recovery and <mark>to</mark> sleep. And is craft every single day. So you take this talent and you mix it with this amazing work ethic over time and you get one of the all-time greats. You guys are no different next one. You're a badass by Jensen chair. Oh, this is a great book <mark>to</mark> Jen is a character for sure and obviously", "Start Time (s)": 1791.9, "End Time (s)": 1911.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you train the physical body you learn a lot of things about yourself and life a you know, <mark>how</mark> deep is your pain cave, you know <mark>how</mark> far into the ocean of pain are you willing <mark>to</mark> swim before you have <mark>to</mark> get back to? Sure, but that's <mark>how</mark> we do everything in life. <mark>How</mark> you <mark>become</mark> great at anything is pretty much <mark>how</mark> you <mark>become</mark> great at everything. It's putting in the consistent effort energy and work overtime and willing <mark>to</mark> endure in sacrifice certain things <mark>to</mark> get what you want. If you look at anybody who excels that anything in life, they've been some people are naturally gifted in certain areas for sure, but you take like LeBron James it's not like LeBron doesn't work and putting the time <mark>to</mark> his diet and his recovery and <mark>to</mark> sleep. And is craft every single day. So you take this talent and you mix it with this amazing work ethic over time and you get one of the all-time greats. You guys are no different next one. You're a badass by Jensen chair. Oh, this is a great book <mark>to</mark> Jen is a character for sure and obviously if the title of your book is you're a badass she's going <mark>to</mark> kick it <mark>to</mark> you real and there's a lot of real good truce in there. I think you can apply <mark>to</mark> a lot of areas. Your life so I do like that next one the big leap by gay Hendricks. This one as well is about you obviously taking a leap in your life <mark>to</mark> Great personal development book about making decisions. And you know when <mark>to</mark> take the proverbial jump if you will next one The Compound Effect Darren Hardy again, if you guys are familiar with compound interest, which if you listen <mark>to</mark> me you for surely know what that is at this point. It's just about <mark>how</mark> the, you know the daily efforts and actions you have and over time <mark>to</mark> create a pretty amazing life whether that be in your career your relationships or your finances or your physical body, but <mark>to</mark> The Compound Effect by Darren Hardy easy read and nice <mark>to</mark> follow next one take the stairs by Rory Vaden again along the same lines The Compound Effect kind of", "Start Time (s)": 1846.2, "End Time (s)": 1966.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "guys are no different next one. You're a badass by Jensen chair. Oh, this is a great book <mark>to</mark> Jen is a character for sure and obviously if the title of your book is you're a badass she's going <mark>to</mark> kick it <mark>to</mark> you real and there's a lot of real good truce in there. I think you can apply <mark>to</mark> a lot of areas. Your life so I do like that next one the big leap by gay Hendricks. This one as well is about you obviously taking a leap in your life <mark>to</mark> Great personal development book about making decisions. And you know when <mark>to</mark> take the proverbial jump if you will next one The Compound Effect Darren Hardy again, if you guys are familiar with compound interest, which if you listen <mark>to</mark> me you for surely know what that is at this point. It's just about <mark>how</mark> the, you know the daily efforts and actions you have and over time <mark>to</mark> create a pretty amazing life whether that be in your career your relationships or your finances or your physical body, but <mark>to</mark> The Compound Effect by Darren Hardy easy read and nice <mark>to</mark> follow next one take the stairs by Rory Vaden again along the same lines The Compound Effect kind of that, you know, take the stairs mentality <mark>to</mark> reaching your goals not always taking the easy way out next one Natural Born Heroes Christopher McDougall now this Is an interesting read this is the long book for sure. They're going way back in the day. Like, you know, we're talking like the Nazi days of them like trying <mark>to</mark> invade, you know, crate you're talking like the Greek Islands. It's a it's a history book, but it talks about perseverance and people beIN together and just different scenarios and life as well. I'll let you guys dig into it if you choose <mark>to</mark> but Natural Born Heroes by Christopher McDougall is a is a good read along But it's good. Next one. If you're talking business stuff people by you by Jeb blunt is an old book and this is one that's", "Start Time (s)": 1898.5, "End Time (s)": 2018.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "by Rory Vaden again along the same lines The Compound Effect kind of that, you know, take the stairs mentality <mark>to</mark> reaching your goals not always taking the easy way out next one Natural Born Heroes Christopher McDougall now this Is an interesting read this is the long book for sure. They're going way back in the day. Like, you know, we're talking like the Nazi days of them like trying <mark>to</mark> invade, you know, crate you're talking like the Greek Islands. It's a it's a history book, but it talks about perseverance and people beIN together and just different scenarios and life as well. I'll let you guys dig into it if you choose <mark>to</mark> but Natural Born Heroes by Christopher McDougall is a is a good read along But it's good. Next one. If you're talking business stuff people by you by Jeb blunt is an old book and this is one that's kind of shaped. <mark>How</mark> I do things more so than a lot of other probably tactical books and things along the way and the title kind of Explains It All People by you and I soon as I heard that I'm like, yep there that's right. It made sense. It's true. Now, they're certain products I resonate with for sure because it made my life easier like uber like I don't give a shit who my Uber driver is I just I want the service but for a lot of other things in my life, I buy the person now they can't suck at the Service, they can't suck at their craft and be a horrible technician of what they're doing, but people buy you and they by you every single day by the decisions they make if they choose <mark>to</mark> be friends with you if they choose <mark>to</mark> work with you if they choose <mark>to</mark> hang out with you like it is everything we do is us as people. That's why I try <mark>to</mark> make everything relationship base and not transactional based and I just figure if I'm the best person I can be and I show up and I work hard I try <mark>to</mark> do right by people things are going <mark>to</mark> work out for me. And this is a book that goes into great detail. Tale", "Start Time (s)": 1961.5, "End Time (s)": 2080.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "by Jeb blunt is an old book and this is one that's kind of shaped. <mark>How</mark> I do things more so than a lot of other probably tactical books and things along the way and the title kind of Explains It All People by you and I soon as I heard that I'm like, yep there that's right. It made sense. It's true. Now, they're certain products I resonate with for sure because it made my life easier like uber like I don't give a shit who my Uber driver is I just I want the service but for a lot of other things in my life, I buy the person now they can't suck at the Service, they can't suck at their craft and be a horrible technician of what they're doing, but people buy you and they by you every single day by the decisions they make if they choose <mark>to</mark> be friends with you if they choose <mark>to</mark> work with you if they choose <mark>to</mark> hang out with you like it is everything we do is us as people. That's why I try <mark>to</mark> make everything relationship base and not transactional based and I just figure if I'm the best person I can be and I show up and I work hard I try <mark>to</mark> do right by people things are going <mark>to</mark> work out for me. And this is a book that goes into great detail. Tale about that. So people buy you by Jeb blunt in terms of finances. A lot of you guys have asked me that again. I'm at a financial advisor. I'm just a dude who was once completely dead broke with a negative net worth and now here I said today and really basic stuff. I'm not a get-rich-quick person. I'm not a person who takes huge risks, even though you know some people from the outside probably think that way Having already described from you quitting my corporate job with no money and no clients. No resources and no education's maybe maybe I am the guy who takes big risks and does stupid stuff. But when I make decisions with money, I always ask myself, you know, if the world went <mark>to</mark> Black would I be able <mark>to</mark> survive and make it out of this and would my you know family be? Okay and what I be? Okay, and if the answer is no then typically don't do that financial decisions. So someone came <mark>to</mark> me and said hey Jeremy, will you invest in", "Start Time (s)": 2015.2, "End Time (s)": 2135.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and I show up and I work hard I try <mark>to</mark> do right by people things are going <mark>to</mark> work out for me. And this is a book that goes into great detail. Tale about that. So people buy you by Jeb blunt in terms of finances. A lot of you guys have asked me that again. I'm at a financial advisor. I'm just a dude who was once completely dead broke with a negative net worth and now here I said today and really basic stuff. I'm not a get-rich-quick person. I'm not a person who takes huge risks, even though you know some people from the outside probably think that way Having already described from you quitting my corporate job with no money and no clients. No resources and no education's maybe maybe I am the guy who takes big risks and does stupid stuff. But when I make decisions with money, I always ask myself, you know, if the world went <mark>to</mark> Black would I be able <mark>to</mark> survive and make it out of this and would my you know family be? Okay and what I be? Okay, and if the answer is no then typically don't do that financial decisions. So someone came <mark>to</mark> me and said hey Jeremy, will you invest in this thing for you know fill in the blank? Thousand dollars and if I knew me giving him a hundred fifty K would you know crippled my family financially or bankrupt me or do something, you know? Negative I wouldn't do the deal right like so when I look at certain things I look for the standpoint of like I'm willing <mark>to</mark> invest this money in this but if I lose it as everything going <mark>to</mark> be okay, and if the answer is yeah then I tend <mark>to</mark> do the deal if I've done the diligent research on the front end. So I'm a very basic person. I'm not a huge believer in debt. Obviously if you guys listen <mark>to</mark> me, you know that I don't want <mark>to</mark> owe anybody anything that's why we paid her house off as quick as we did so I could live without the burden of that in my life having <mark>to</mark> you know, make payments <mark>to</mark> the bank and With it such as mine. They don't got <mark>to</mark> stress about it. I'm also a believer in real estate if you can pay for it in cash or if you can obviously, you know, get a super Smokin deal on it and it's not going <mark>to</mark> hurt you if you have <mark>to</mark> make", "Start Time (s)": 2073.5, "End Time (s)": 2192.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "decisions. So someone came <mark>to</mark> me and said hey Jeremy, will you invest in this thing for you know fill in the blank? Thousand dollars and if I knew me giving him a hundred fifty K would you know crippled my family financially or bankrupt me or do something, you know? Negative I wouldn't do the deal right like so when I look at certain things I look for the standpoint of like I'm willing <mark>to</mark> invest this money in this but if I lose it as everything going <mark>to</mark> be okay, and if the answer is yeah then I tend <mark>to</mark> do the deal if I've done the diligent research on the front end. So I'm a very basic person. I'm not a huge believer in debt. Obviously if you guys listen <mark>to</mark> me, you know that I don't want <mark>to</mark> owe anybody anything that's why we paid her house off as quick as we did so I could live without the burden of that in my life having <mark>to</mark> you know, make payments <mark>to</mark> the bank and With it such as mine. They don't got <mark>to</mark> stress about it. I'm also a believer in real estate if you can pay for it in cash or if you can obviously, you know, get a super Smokin deal on it and it's not going <mark>to</mark> hurt you if you have <mark>to</mark> make payments if you're doing rental properties and nobody can rent them and then over time those things can cash flow and make you money. I'm a huge fan of that. I'm a huge fan of the stock market mutual funds SP if you qualify for a Roth IRA or the traditionals or any kind of 401k profit sharing set plan you have at your job. If you're self-employed, I believe if you believe in America, you put your money in the stock market you're going <mark>to</mark> make money over time. It's essentially I want <mark>to</mark> say passive income because I really believe in that term but it is a thing where if you set your money somewhere and it gives you six <mark>to</mark> ten percent over the course of you know, I don't know the next 30 Years, you're probably going <mark>to</mark> be a millionaire and if the percentages work in your favor if you have money in a 401k or IRA and your money, you know doubles every seven years give or take the You know interested pays you you're going <mark>to</mark> be doing all right over time. So I'm a big believer of being conservative but being smart with your money and taking, you know reluctant and calculate a risk since the", "Start Time (s)": 2131.9, "End Time (s)": 2251.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I'm also a believer in real estate if you can pay for it in cash or if you can obviously, you know, get a super Smokin deal on it and it's not going <mark>to</mark> hurt you if you have <mark>to</mark> make payments if you're doing rental properties and nobody can rent them and then over time those things can cash flow and make you money. I'm a huge fan of that. I'm a huge fan of the stock market mutual funds SP if you qualify for a Roth IRA or the traditionals or any kind of 401k profit sharing set plan you have at your job. If you're self-employed, I believe if you believe in America, you put your money in the stock market you're going <mark>to</mark> make money over time. It's essentially I want <mark>to</mark> say passive income because I really believe in that term but it is a thing where if you set your money somewhere and it gives you six <mark>to</mark> ten percent over the course of you know, I don't know the next 30 Years, you're probably going <mark>to</mark> be a millionaire and if the percentages work in your favor if you have money in a 401k or IRA and your money, you know doubles every seven years give or take the You know interested pays you you're going <mark>to</mark> be doing all right over time. So I'm a big believer of being conservative but being smart with your money and taking, you know reluctant and calculate a risk since the books that I grew up on the told Money Makeover obviously by Dave Ramsey. If you guys don't know Dave he's you know, he's the debt-free king big part of why we decided <mark>to</mark> get out of debt. It's because I believe in a lot of the stuff. He says maybe not everything. I don't have <mark>to</mark> agree with them on it, but it's very Common Sense things that your grandma or Grandpa would tell you so The Total Money Makeover is a basic book. It walks you guys for the baby steps of <mark>how</mark> <mark>to</mark> pay off your debt and <mark>how</mark> <mark>to</mark> you know, invest for your future and retirement and <mark>how</mark> <mark>to</mark> make decisions and purchases. It's super basic but it is helpful. If you're financially illiterate. You don't know anything. I would urge you <mark>to</mark> pick it up sooner than later and give it a read you probably finish it in one or two nights and if you can talk your husband or wife into it, it can change the scope of your life financially next one The Millionaire Next Door. By Thomas J Stanley. I read", "Start Time (s)": 2182.9, "End Time (s)": 2302.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of your life financially next one The Millionaire Next Door. By Thomas J Stanley. I read probably seven or eight years ago. And the newer version is everyday millionaires by Chris Hogan, which is Chris is part of the Dave Ramsey team, but the Millionaire Next Door is an old book some of the stuff, you know, probably not as applicable today it is but in terms of like when they give examples right like the example one of the gives like this couple who bought, you know each bought a pack of cigarettes every single day for like 30 years and if they just would have took that same money invested into it. Herman account they both would have been millionaires but they didn't they bought cigarettes instead. And so not only are you killing yourself cause you're smoking cigarettes like an idiot, but now you have no fucking money and that's again that's not for everybody. But the Miller Next Door is for the person who's like who's like me the / if you grew up like I did it all if you grew up with the family and with no money and no resources and they didn't really know anything about finance and stuff and no one in your family was able <mark>to</mark> <mark>become</mark> a millionaire. Nobody in your family had in excess of wealth if you were <mark>To</mark> listen <mark>to</mark> that book and take some of those principles and apply them you could easily be the first millionaire in your family and it kind of walks you through like what a millionaire looks like just like the everyday millionaires book by Chris Hogan. They did the biggest independent study on millionaires in North America. I believe think they pulled ten thousand Millionaires and ask them like very basic questions. Like hey, you know, what are you know, <mark>how</mark> did you get your money? Did you inherit it and I think 97% did inherit a scent they worked for their money regardless of what people believe. Holding a lot of people think oh, someone says a millionaire the inherited from the <mark>rich</mark> parents that that wasn't the case for me or my wife. Either of us. We everything we've learned we've done it ourselves and that's a lot of people out there. But <mark>how</mark> did they do it? Well, they lived in homes that were modest like the homes probably in your neighborhood. They're probably your next door neighbor. There is a guy like me who lives next <mark>to</mark> you, but doesn't have a house payment. They probably also drive", "Start Time (s)": 2295.1, "End Time (s)": 2414.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and they didn't really know anything about finance and stuff and no one in your family was able <mark>to</mark> <mark>become</mark> a millionaire. Nobody in your family had in excess of wealth if you were <mark>To</mark> listen <mark>to</mark> that book and take some of those principles and apply them you could easily be the first millionaire in your family and it kind of walks you through like what a millionaire looks like just like the everyday millionaires book by Chris Hogan. They did the biggest independent study on millionaires in North America. I believe think they pulled ten thousand Millionaires and ask them like very basic questions. Like hey, you know, what are you know, <mark>how</mark> did you get your money? Did you inherit it and I think 97% did inherit a scent they worked for their money regardless of what people believe. Holding a lot of people think oh, someone says a millionaire the inherited from the <mark>rich</mark> parents that that wasn't the case for me or my wife. Either of us. We everything we've learned we've done it ourselves and that's a lot of people out there. But <mark>how</mark> did they do it? Well, they lived in homes that were modest like the homes probably in your neighborhood. They're probably your next door neighbor. There is a guy like me who lives next <mark>to</mark> you, but doesn't have a house payment. They probably also drive an older car like when you look at like the number 1 car millionaires drivable. It was a Toyota Camry. Like a Toyota brand car and it was used it wasn't bought brand-new IE Honda Accord things like that. So it gives you <mark>to</mark> me when I read it years ago and it didn't have any money in anything it gave me. Hope that I could One Day <mark>become</mark> a millionaire. I could One Day <mark>become</mark> debt-free. I one day could <mark>become</mark> financially independent. If I was just smart with my money early on and invest it and did things that paid me interest and didn't pay out interest. And so those are two really good books the other one, I would say That'll give you a little bit of a different point of view is there is money Master of the game by Tony Robbins again, I don't agree with everything in the book in any time you listen <mark>to</mark> anything. Everybody has an agenda always like it's just is like they whether its buying their product or services or pushing you <mark>to</mark> believe what they believe", "Start Time (s)": 2351.3, "End Time (s)": 2471.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a guy like me who lives next <mark>to</mark> you, but doesn't have a house payment. They probably also drive an older car like when you look at like the number 1 car millionaires drivable. It was a Toyota Camry. Like a Toyota brand car and it was used it wasn't bought brand-new IE Honda Accord things like that. So it gives you <mark>to</mark> me when I read it years ago and it didn't have any money in anything it gave me. Hope that I could One Day <mark>become</mark> a millionaire. I could One Day <mark>become</mark> debt-free. I one day could <mark>become</mark> financially independent. If I was just smart with my money early on and invest it and did things that paid me interest and didn't pay out interest. And so those are two really good books the other one, I would say That'll give you a little bit of a different point of view is there is money Master of the game by Tony Robbins again, I don't agree with everything in the book in any time you listen <mark>to</mark> anything. Everybody has an agenda always like it's just is like they whether its buying their product or services or pushing you <mark>to</mark> believe what they believe or that are sharing their information, which does have some bias because it's coming from them but money Master the game by Tony Robbins is a super long read. Again, I don't agree with every single thing. He says in there. He's a billionaire. I am not so he can probably tell me <mark>to</mark> go fuck myself if he doesn't like what I'm saying here, but it is a good book. It's a good listen. I say that because there's a lot of stories in there and they do a lot. He does a lot of interviews, you know from guys like, you know <mark>to</mark> T Boone Pickens rest in peace, you know on down <mark>to</mark> a lot of the most successful investors and some of the most financially successful people who've ever lived and the the two things that stuck out for me from there one is They asked each person or each person. They interviewed, you know, these are billionaires rights people have billions of dollars. So and hopefully you understand what I say is if you have billion dollars you have more than nine hundred ninety nine million dollars.", "Start Time (s)": 2409.6, "End Time (s)": 2528.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but money Master the game by Tony Robbins is a super long read. Again, I don't agree with every single thing. He says in there. He's a billionaire. I am not so he can probably tell me <mark>to</mark> go fuck myself if he doesn't like what I'm saying here, but it is a good book. It's a good listen. I say that because there's a lot of stories in there and they do a lot. He does a lot of interviews, you know from guys like, you know <mark>to</mark> T Boone Pickens rest in peace, you know on down <mark>to</mark> a lot of the most successful investors and some of the most financially successful people who've ever lived and the the two things that stuck out for me from there one is They asked each person or each person. They interviewed, you know, these are billionaires rights people have billions of dollars. So and hopefully you understand what I say is if you have billion dollars you have more than nine hundred ninety nine million dollars. Like you have a billion dollars. These are multi billionaires, right and they asked each one of them. <mark>How</mark> much is enough? And <mark>how</mark> much do you need <mark>to</mark> feel safe and all of them? It's never enough that number always shifts and change with them. It always goes up. That's the crazy things anybody listening with their things if I just had a hundred thousand dollars if I just had 500k have a just had 750 of just had a million dollars in ad feel <mark>rich</mark> and safe and secure know you won't that is something internally with you that's not something money can give you and do you can feel a certain security of a certain amount of money but it's never absolute if you're that person already and if you listen <mark>to</mark> this book that's what you'll take away from it also it talks about fees of your investment accounts retirement accounts just so we're clear anybody listening if you have an IRA or a 401k except whatever it is there's fees with it it's not free like you're paying program fees you're paying a fiduciary hyeri fee you're playing a flat 1% fee or you're paying fees for the trading whatever it is it is not free so just", "Start Time (s)": 2475.7, "End Time (s)": 2595.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that is something internally with you that's not something money can give you and do you can feel a certain security of a certain amount of money but it's never absolute if you're that person already and if you listen <mark>to</mark> this book that's what you'll take away from it also it talks about fees of your investment accounts retirement accounts just so we're clear anybody listening if you have an IRA or a 401k except whatever it is there's fees with it it's not free like you're paying program fees you're paying a fiduciary hyeri fee you're playing a flat 1% fee or you're paying fees for the trading whatever it is it is not free so just knowing you have an advisor or a brokerage house or whoever you're working or has your money they're not holding it completely for free they're taking either flat percentage or they're taking little rips off it as you go just be clear that does dig into your overall savings and money over time so knowing the fiza where you go is kind of crucial but those are great you know so little money books and reads very common sense This thing's not going <mark>to</mark> you know, show you <mark>how</mark> <mark>to</mark> go day trade and do a bunch of crazy stuff, which I don't think you're equipped for anyway, because you're competing with people who are far better and know far more things and can lose way more money than you can lose. But if you're talking about, you know, kind of grandmas basic money advice. Those are ones are going <mark>to</mark> give you a nice, you know well-rounded picture of you know, what you can do with your money over time and <mark>how</mark> <mark>to</mark> best, you know, kind of save it spend it, you know, give it and you know invested I guess. Last couple books here on the list for let you guys go love yourself live your life Kamal rev can't love yourself live your life Kamal RAF can't listen <mark>to</mark> inaudible is voice is a little bit different but it's a good book just talking about self-love and <mark>how</mark> we speak <mark>to</mark> ourselves and the language you use and <mark>how</mark> we talk <mark>to</mark> ourselves every single day and then you guys can get a lot out of that next 115 laws of growth by John C Maxwell. Jhansi Maxwell has like a trillion bucks. A lot", "Start Time (s)": 2559.4, "End Time (s)": 2679.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "think you're equipped for anyway, because you're competing with people who are far better and know far more things and can lose way more money than you can lose. But if you're talking about, you know, kind of grandmas basic money advice. Those are ones are going <mark>to</mark> give you a nice, you know well-rounded picture of you know, what you can do with your money over time and <mark>how</mark> <mark>to</mark> best, you know, kind of save it spend it, you know, give it and you know invested I guess. Last couple books here on the list for let you guys go love yourself live your life Kamal rev can't love yourself live your life Kamal RAF can't listen <mark>to</mark> inaudible is voice is a little bit different but it's a good book just talking about self-love and <mark>how</mark> we speak <mark>to</mark> ourselves and the language you use and <mark>how</mark> we talk <mark>to</mark> ourselves every single day and then you guys can get a lot out of that next 115 laws of growth by John C Maxwell. Jhansi Maxwell has like a trillion bucks. A lot of them are really good the 15 laws of growth. I found <mark>to</mark> be educational. So I do think that's a good read if you want <mark>to</mark> pick that up. Next one Seth Godin Seth actually sends out a ton of emails probably more emails than me Seth has written a shit ton of books. The two books Seth has written that I would recommend off the top are linchpin. If you work for a company or organization, your goal would be <mark>to</mark> come the linchpin the person that is indispensable the person that if they got rid of them the company would I'm not saying fold like a lawn. not sure but they would struggle <mark>to</mark> replace you because you're so awesome and that can be for any organization whether it be a family school setting a team or obviously a corporation so linchpin by Seth Godin is a great read and also tribes by Seth Godin as well and in his emails if you subscribe as email list there like sometimes or a sentence some of their three sentences but you know last little nuggets <mark>to</mark> kind of kick off your day on that note if you guys have not subscribed <mark>to</mark> the Jimmy Scott Fitness email newsletter hit me up I'm happy <mark>to</mark> add you we send at least three emails per week every single week 52 weeks a year some weeks we do five six or seven emails depending on what's going on in my brain but", "Start Time (s)": 2623.0, "End Time (s)": 2742.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Maxwell. Jhansi Maxwell has like a trillion bucks. A lot of them are really good the 15 laws of growth. I found <mark>to</mark> be educational. So I do think that's a good read if you want <mark>to</mark> pick that up. Next one Seth Godin Seth actually sends out a ton of emails probably more emails than me Seth has written a shit ton of books. The two books Seth has written that I would recommend off the top are linchpin. If you work for a company or organization, your goal would be <mark>to</mark> come the linchpin the person that is indispensable the person that if they got rid of them the company would I'm not saying fold like a lawn. not sure but they would struggle <mark>to</mark> replace you because you're so awesome and that can be for any organization whether it be a family school setting a team or obviously a corporation so linchpin by Seth Godin is a great read and also tribes by Seth Godin as well and in his emails if you subscribe as email list there like sometimes or a sentence some of their three sentences but you know last little nuggets <mark>to</mark> kind of kick off your day on that note if you guys have not subscribed <mark>to</mark> the Jimmy Scott Fitness email newsletter hit me up I'm happy <mark>to</mark> add you we send at least three emails per week every single week 52 weeks a year some weeks we do five six or seven emails depending on what's going on in my brain but that is available <mark>to</mark> you all as well and the last two books here let's go with it starts with Y by Simon sinek he does a lot of comparison stuff of you know in terms of business right like people don't buy what you do they buy why you do it people don't buy what you do they buy why you do it and I do believe this is well we talked a lot about branding talks about Apple a lot through Google in there I've applied a lot of the things <mark>to</mark> my business as well. And yeah people by what we do here, you know, it's Fitness. It's coaching. It's nutrition. It's being a good person but it's why we do it and I think it's the passion behind it and <mark>how</mark> we identify with it as ourselves. And so if we can identify with the person in a business or more likely <mark>to</mark> do business with them and deal with them and talk with them and see things the way that they see things because they're part of our tribe, right? They're part of our group. It's like, you know where the", "Start Time (s)": 2675.1, "End Time (s)": 2794.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "some of their three sentences but you know last little nuggets <mark>to</mark> kind of kick off your day on that note if you guys have not subscribed <mark>to</mark> the Jimmy Scott Fitness email newsletter hit me up I'm happy <mark>to</mark> add you we send at least three emails per week every single week 52 weeks a year some weeks we do five six or seven emails depending on what's going on in my brain but that is available <mark>to</mark> you all as well and the last two books here let's go with it starts with Y by Simon sinek he does a lot of comparison stuff of you know in terms of business right like people don't buy what you do they buy why you do it people don't buy what you do they buy why you do it and I do believe this is well we talked a lot about branding talks about Apple a lot through Google in there I've applied a lot of the things <mark>to</mark> my business as well. And yeah people by what we do here, you know, it's Fitness. It's coaching. It's nutrition. It's being a good person but it's why we do it and I think it's the passion behind it and <mark>how</mark> we identify with it as ourselves. And so if we can identify with the person in a business or more likely <mark>to</mark> do business with them and deal with them and talk with them and see things the way that they see things because they're part of our tribe, right? They're part of our group. It's like, you know where the Misfits if you will and that's kind of like that's why they do so much of the Apple stuff because apples kind of a trendsetter in the space if you will it. So, you know, you see people waiting outside for an iPhone, you know, 80 people deep at six o'clock in the morning. Like that's insane. You never seen people wait 60 people deep outside of the you know Dell store for a Dell computer. Like you just said there's certain things that we do in in the world that kind of defy logic like they just don't make any sense and that's because they're not buying just the iPhone they're buying like why Apple does it and What it stands for inside of that the last book will share here is Wizard of ads by Roy H. Williams is a super old book for sure. But if you're a person out there in business and you're looking <mark>to</mark> sell or Market or View and their person you're trying <mark>to</mark> get a", "Start Time (s)": 2726.1, "End Time (s)": 2845.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "And so if we can identify with the person in a business or more likely <mark>to</mark> do business with them and deal with them and talk with them and see things the way that they see things because they're part of our tribe, right? They're part of our group. It's like, you know where the Misfits if you will and that's kind of like that's why they do so much of the Apple stuff because apples kind of a trendsetter in the space if you will it. So, you know, you see people waiting outside for an iPhone, you know, 80 people deep at six o'clock in the morning. Like that's insane. You never seen people wait 60 people deep outside of the you know Dell store for a Dell computer. Like you just said there's certain things that we do in in the world that kind of defy logic like they just don't make any sense and that's because they're not buying just the iPhone they're buying like why Apple does it and What it stands for inside of that the last book will share here is Wizard of ads by Roy H. Williams is a super old book for sure. But if you're a person out there in business and you're looking <mark>to</mark> sell or Market or View and their person you're trying <mark>to</mark> get a job and you're trying <mark>to</mark> sell and Market yourself and you want <mark>to</mark> understand more about that process the wizard of ads by Roy H. Williams is a super old book and read and listen, but it's a great one as well. also hope you guys enjoyed that list again I can't go through all the books that I have ever you know read and listened <mark>to</mark> over the past couple years but I thought that's a decent list at least get you guys started in on the right track and again whether you're a book person or a podcast person it really doesn't matter as long as you're consuming things that are adding value <mark>to</mark> your life and you know helping you and your family and the people around you I think you're on the right track and again some people don't learn that way I'm not a Huge like looking at print and read if it's super long if it shorter stuff I tend <mark>to</mark> do better like articles and blogs and things that are under probably like, you know, a couple thousand words, but the audible stuff has really changed the", "Start Time (s)": 2781.9, "End Time (s)": 2901.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Wizard of ads by Roy H. Williams is a super old book for sure. But if you're a person out there in business and you're looking <mark>to</mark> sell or Market or View and their person you're trying <mark>to</mark> get a job and you're trying <mark>to</mark> sell and Market yourself and you want <mark>to</mark> understand more about that process the wizard of ads by Roy H. Williams is a super old book and read and listen, but it's a great one as well. also hope you guys enjoyed that list again I can't go through all the books that I have ever you know read and listened <mark>to</mark> over the past couple years but I thought that's a decent list at least get you guys started in on the right track and again whether you're a book person or a podcast person it really doesn't matter as long as you're consuming things that are adding value <mark>to</mark> your life and you know helping you and your family and the people around you I think you're on the right track and again some people don't learn that way I'm not a Huge like looking at print and read if it's super long if it shorter stuff I tend <mark>to</mark> do better like articles and blogs and things that are under probably like, you know, a couple thousand words, but the audible stuff has really changed the game for me, especially when I'm standing, you know in line at the grocery store or for have <mark>to</mark> go <mark>to</mark> the post office or I'm at like a doctor's appointment or I'm just literally like at the airport waiting anytime. I can kill two birds with one stone and not just be commuting and just be sitting somewhere. Like having <mark>to</mark> listen <mark>to</mark> the shit people are talking about around me because I don't watch the news. I don't consume a lot of those things but I do consume these things and I do think and just change the scope of who I am and <mark>how</mark> I live my life and <mark>how</mark> I think about stuff and you know at the time when my car radio had died, I was super pissed and irritated that I couldn't you know, listen <mark>to</mark> you know, Mobb Deep and Jay-Z anymore on the way <mark>to</mark> work, but it really, you know, End up being the best thing for me and that's why I say, you know, sometimes these things that seem like their", "Start Time (s)": 2835.0, "End Time (s)": 2954.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and again some people don't learn that way I'm not a Huge like looking at print and read if it's super long if it shorter stuff I tend <mark>to</mark> do better like articles and blogs and things that are under probably like, you know, a couple thousand words, but the audible stuff has really changed the game for me, especially when I'm standing, you know in line at the grocery store or for have <mark>to</mark> go <mark>to</mark> the post office or I'm at like a doctor's appointment or I'm just literally like at the airport waiting anytime. I can kill two birds with one stone and not just be commuting and just be sitting somewhere. Like having <mark>to</mark> listen <mark>to</mark> the shit people are talking about around me because I don't watch the news. I don't consume a lot of those things but I do consume these things and I do think and just change the scope of who I am and <mark>how</mark> I live my life and <mark>how</mark> I think about stuff and you know at the time when my car radio had died, I was super pissed and irritated that I couldn't you know, listen <mark>to</mark> you know, Mobb Deep and Jay-Z anymore on the way <mark>to</mark> work, but it really, you know, End up being the best thing for me and that's why I say, you know, sometimes these things that seem like their negatives in your life, they end up being a positive and so if I didn't do that, who knows if I would have listened <mark>to</mark> you know, 600 plus books in the past six years or so and be able <mark>to</mark> speak <mark>to</mark> you guys today and talk <mark>to</mark> you and do the things I'm doing or have the ideas for certain programs and or just be able just <mark>to</mark> speak <mark>to</mark> my friends and family or my wife the way that I do because I've heard it from somebody else and you beg borrow and steal. Some of the best practices and you see if it's applicable <mark>to</mark> your life and your situation. That's what I've been able <mark>to</mark> do, especially in terms of like the finance and money because again all of us were not all born Geniuses, at least I wasn't for sure but through hard work and over time. I've acquired a certain amount of knowledge in certain areas of things and enough <mark>to</mark> be dangerous and you know, I'm good at what I'm good at and I can Outsource we need <mark>to</mark> Outsource, but if you want <mark>to</mark> be awesome at something if you want <mark>to</mark> learn", "Start Time (s)": 2885.8, "End Time (s)": 3004.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I was super pissed and irritated that I couldn't you know, listen <mark>to</mark> you know, Mobb Deep and Jay-Z anymore on the way <mark>to</mark> work, but it really, you know, End up being the best thing for me and that's why I say, you know, sometimes these things that seem like their negatives in your life, they end up being a positive and so if I didn't do that, who knows if I would have listened <mark>to</mark> you know, 600 plus books in the past six years or so and be able <mark>to</mark> speak <mark>to</mark> you guys today and talk <mark>to</mark> you and do the things I'm doing or have the ideas for certain programs and or just be able just <mark>to</mark> speak <mark>to</mark> my friends and family or my wife the way that I do because I've heard it from somebody else and you beg borrow and steal. Some of the best practices and you see if it's applicable <mark>to</mark> your life and your situation. That's what I've been able <mark>to</mark> do, especially in terms of like the finance and money because again all of us were not all born Geniuses, at least I wasn't for sure but through hard work and over time. I've acquired a certain amount of knowledge in certain areas of things and enough <mark>to</mark> be dangerous and you know, I'm good at what I'm good at and I can Outsource we need <mark>to</mark> Outsource, but if you want <mark>to</mark> be awesome at something if you want <mark>to</mark> learn something Model Behavior and consume the information from the people who have done it before you longer than you and are more successful than you and even if you suck at it but you try <mark>to</mark> do exactly what some of the most successful people did in the field odds. Are you're going <mark>to</mark> be pretty far along like that's what this is all about like us trying <mark>to</mark> improve our lives and I do think auditory books and watching human behavior are probably the two best ways for us <mark>to</mark> do that. So, hopefully you guys enjoyed it. Not the most exciting. Podcast for the sexiest but I know a lot of you guys asked for it. If you've been looking for some good reads in terms of books. Those would be my go-to and get them a try <mark>to</mark> throw them up in the German stuff in his blog here sooner than later, but forgive me if it doesn't happen in the next week or so short of that reminder if you guys are not subscribe <mark>to</mark> us on YouTube again, all the podcasts now are on the Jimmy's got finished", "Start Time (s)": 2938.1, "End Time (s)": 3057.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I've acquired a certain amount of knowledge in certain areas of things and enough <mark>to</mark> be dangerous and you know, I'm good at what I'm good at and I can Outsource we need <mark>to</mark> Outsource, but if you want <mark>to</mark> be awesome at something if you want <mark>to</mark> learn something Model Behavior and consume the information from the people who have done it before you longer than you and are more successful than you and even if you suck at it but you try <mark>to</mark> do exactly what some of the most successful people did in the field odds. Are you're going <mark>to</mark> be pretty far along like that's what this is all about like us trying <mark>to</mark> improve our lives and I do think auditory books and watching human behavior are probably the two best ways for us <mark>to</mark> do that. So, hopefully you guys enjoyed it. Not the most exciting. Podcast for the sexiest but I know a lot of you guys asked for it. If you've been looking for some good reads in terms of books. Those would be my go-to and get them a try <mark>to</mark> throw them up in the German stuff in his blog here sooner than later, but forgive me if it doesn't happen in the next week or so short of that reminder if you guys are not subscribe <mark>to</mark> us on YouTube again, all the podcasts now are on the Jimmy's got finished YouTube page. I think we have over a thousand videos now on the YouTube page in terms of podcasts Mobility full workouts finishers. Nutrition videos recipes full Q&A series basically anything we're doing now 90% of it were filming and we're throwing it on YouTube. So it's a high percent free subscribe. You'll never miss a video and if you want <mark>to</mark> see something holler at me, I'm happy <mark>to</mark> film it if we can and if you're on iTunes right now stop don't be a lazy ass open up your podcast app scroll all the way down in your iPhone. Click five-star drop us a comment under ratings and reviews a true would appreciate if you have a friend who loves Books and they want <mark>to</mark> dig into some other books. Please share this podcast with them <mark>to</mark> share the list of them. So hopefully they can, you know educate themselves and maybe you know level up their life of a certain area. They want <mark>to</mark> be a little bit better at now. Obviously if you're on iTunes or your MacBook or MacBook Pro and your iPad click the iTunes", "Start Time (s)": 2993.1, "End Time (s)": 3113.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but forgive me if it doesn't happen in the next week or so short of that reminder if you guys are not subscribe <mark>to</mark> us on YouTube again, all the podcasts now are on the Jimmy's got finished YouTube page. I think we have over a thousand videos now on the YouTube page in terms of podcasts Mobility full workouts finishers. Nutrition videos recipes full Q&A series basically anything we're doing now 90% of it were filming and we're throwing it on YouTube. So it's a high percent free subscribe. You'll never miss a video and if you want <mark>to</mark> see something holler at me, I'm happy <mark>to</mark> film it if we can and if you're on iTunes right now stop don't be a lazy ass open up your podcast app scroll all the way down in your iPhone. Click five-star drop us a comment under ratings and reviews a true would appreciate if you have a friend who loves Books and they want <mark>to</mark> dig into some other books. Please share this podcast with them <mark>to</mark> share the list of them. So hopefully they can, you know educate themselves and maybe you know level up their life of a certain area. They want <mark>to</mark> be a little bit better at now. Obviously if you're on iTunes or your MacBook or MacBook Pro and your iPad click the iTunes icon hit range reviews 5 Star commented I truly would appreciate it. And if there's anything else you guys want <mark>to</mark> hear on the podcast, please send me requests shoot me a message. I'm happy <mark>to</mark> record if I can speak on I have a huge. Ageless already and we keep just kind of a little Library here and slowly over time. We'll get <mark>to</mark> everybody's request and hopefully get your question answered. So about <mark>to</mark> jump into this most awful leg workout here and get on with my night. So thank you guys. I appreciate all the positive feedback in the message. You guys are leaving us a truly does mean the world <mark>to</mark> me. I can't thank you enough. I know I say that all the time and obviously I can't pay my bills with with thank using your kind. But they do mean, you know more <mark>to</mark> me than just dollars in the bank. It really does. It's the oxygen that keeps this machine going and I'm happy, you know, I can take what I've learned over the years and all my", "Start Time (s)": 3046.7, "End Time (s)": 3166.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Please share this podcast with them <mark>to</mark> share the list of them. So hopefully they can, you know educate themselves and maybe you know level up their life of a certain area. They want <mark>to</mark> be a little bit better at now. Obviously if you're on iTunes or your MacBook or MacBook Pro and your iPad click the iTunes icon hit range reviews 5 Star commented I truly would appreciate it. And if there's anything else you guys want <mark>to</mark> hear on the podcast, please send me requests shoot me a message. I'm happy <mark>to</mark> record if I can speak on I have a huge. Ageless already and we keep just kind of a little Library here and slowly over time. We'll get <mark>to</mark> everybody's request and hopefully get your question answered. So about <mark>to</mark> jump into this most awful leg workout here and get on with my night. So thank you guys. I appreciate all the positive feedback in the message. You guys are leaving us a truly does mean the world <mark>to</mark> me. I can't thank you enough. I know I say that all the time and obviously I can't pay my bills with with thank using your kind. But they do mean, you know more <mark>to</mark> me than just dollars in the bank. It really does. It's the oxygen that keeps this machine going and I'm happy, you know, I can take what I've learned over the years and all my fuck-ups and struggles and somehow help you, you know, just little bit better life and if that's what's happening. I'm happy <mark>to</mark> do it. So thank you guys. I appreciate you for everything. You've done keeps your in the podcast and we'll keep cranking out the episode. So until next time eat well trained hard be nice <mark>to</mark> people and please you guys keep doing it. That you love people you enjoy because your life is too short not <mark>to</mark> I'll talk <mark>to</mark> you guys soon. Peace.", "Start Time (s)": 3098.2, "End Time (s)": 3190.0, "Clip Length (min)": 1.53, "show_uri": "spotify:show:39O5btNcHOIekSuqi6HOha", "show_name": "Jeremy Scott Fitness ", "show_description": "Author, Coach, Speaker & Certified Fitness Junkie Jeremy Scott owns Jeremy Scott Fitness in beautiful Scottsdale, AZ. Jeremy is a certified personal trainer who leads by example sharing hacks, tips, education and advice on all things health, fitness, & lifestyle related. Jeremy has worked with some of the biggest brands in fitness such as Men\u2019s Health, Reebok and Vitamin Shoppe. Want a topic covered? Just send us a message and we will make it happen. ", "publisher": "Jeremy Scott Fitness ", "episode_uri": "spotify:episode:4f77NE84uoy852WPcUOlES", "episode_name": "Books I Recommend", "episode_description": "Quick list of books I have read over the years that might help you level up areas of your life you are looking to improve.  ", "score": 3.810402, "explanation": "{\n  \"value\": 3.810402,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.3915936,\n      \"description\": \"weight(word_list:how in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.3915936,\n          \"description\": \"score(LMDirichletSimilarity, freq=41.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.2051146,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 41.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.044470426,\n      \"description\": \"weight(word_list:to in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.044470426,\n          \"description\": \"score(LMDirichletSimilarity, freq=295.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8579913,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 295.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5241766,\n      \"description\": \"weight(word_list:become in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5241766,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.3376975,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.8501612,\n      \"description\": \"weight(word_list:rich in 9) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.8501612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.8135209,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 10264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "The great doll clothes everywhere both <mark>to</mark> the left and <mark>to</mark> the right it loves and nourishes all things but does not Lord it over and when merits are accomplished it lays no claim Namaste world. I'm so grateful <mark>to</mark> welcome you <mark>to</mark> another episode of the real you a podcast about finding your true self for strengthening your mind taking care of your body listening <mark>to</mark> your soul and cultivating your spirit. My name is Caleb and this your boy Events will be your guides the real you. And today in episode 2 Our intention is going <mark>to</mark> be helping each other and you are audience develop an indomitable mindset by understanding the power of why why is the foundation that will keep you going when you want <mark>to</mark> quit sure. Why is a greatest tool for success? I just want <mark>to</mark> give a quick shout-out <mark>to</mark> everyone who had a chance <mark>to</mark> listen", "Start Time (s)": 0.3, "End Time (s)": 62.0, "Clip Length (min)": 1.03, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "The great doll clothes everywhere both <mark>to</mark> the left and <mark>to</mark> the right it loves and nourishes all things but does not Lord it over and when merits are accomplished it lays no claim Namaste world. I'm so grateful <mark>to</mark> welcome you <mark>to</mark> another episode of the real you a podcast about finding your true self for strengthening your mind taking care of your body listening <mark>to</mark> your soul and cultivating your spirit. My name is Caleb and this your boy Events will be your guides the real you. And today in episode 2 Our intention is going <mark>to</mark> be helping each other and you are audience develop an indomitable mindset by understanding the power of why why is the foundation that will keep you going when you want <mark>to</mark> quit sure. Why is a greatest tool for success? I just want <mark>to</mark> give a quick shout-out <mark>to</mark> everyone who had a chance <mark>to</mark> listen <mark>to</mark> episode 1 we're honestly so grateful and appreciative and we just want <mark>to</mark> express that so thanks <mark>to</mark> all of you beautiful souls out there. We hope you continue <mark>to</mark> listen. Joy, as you follow us on our journey and as always <mark>to</mark> begin, I will open up with meditation by American writer and entrepreneur Mark Twain. The two most important days in your life are the day you are born and the day you find out. Why what is your why what is important about your why what is it that drives you <mark>to</mark> wake up every morning. What do you living for? If you have no purpose or goal? What's the point <mark>to</mark> quote Socrates Socrates once said an unexamined life is not worth living. He's basically trying <mark>to</mark> say that worth is what people use <mark>to</mark> define their reason for living if their life has worth they will continue <mark>to</mark> Enjoy life, but on the flip side, if you", "Start Time (s)": 0.3, "End Time (s)": 115.5, "Clip Length (min)": 1.92, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is going <mark>to</mark> be helping each other and you are audience develop an indomitable mindset by understanding the power of why why is the foundation that will keep you going when you want <mark>to</mark> quit sure. Why is a greatest tool for success? I just want <mark>to</mark> give a quick shout-out <mark>to</mark> everyone who had a chance <mark>to</mark> listen <mark>to</mark> episode 1 we're honestly so grateful and appreciative and we just want <mark>to</mark> express that so thanks <mark>to</mark> all of you beautiful souls out there. We hope you continue <mark>to</mark> listen. Joy, as you follow us on our journey and as always <mark>to</mark> begin, I will open up with meditation by American writer and entrepreneur Mark Twain. The two most important days in your life are the day you are born and the day you find out. Why what is your why what is important about your why what is it that drives you <mark>to</mark> wake up every morning. What do you living for? If you have no purpose or goal? What's the point <mark>to</mark> quote Socrates Socrates once said an unexamined life is not worth living. He's basically trying <mark>to</mark> say that worth is what people use <mark>to</mark> define their reason for living if their life has worth they will continue <mark>to</mark> Enjoy life, but on the flip side, if you don't examine life, there's no reason <mark>to</mark> want <mark>to</mark> live the day you figure out your why is the most important day in your life because that's a day you <mark>become</mark> unstoppable. That's the day you find your purpose. Nothing is going <mark>to</mark> be able <mark>to</mark> stop you from achieving your dreams and your passions. If you really understand why you're doing it if your why is strong enough your <mark>how</mark> will reveal itself hundred percent? And because our thoughts have so much power. I just want <mark>to</mark> share a quote by British author David chamel. Don't speak badly of yourself for the warrior within here's your words and his lesson by them. Think about it every thought feeling and emotion that we feel is shaped by our beliefs and values. Our whole lives are basically set up based on all our decisions all the little things that", "Start Time (s)": 46.0, "End Time (s)": 165.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is what people use <mark>to</mark> define their reason for living if their life has worth they will continue <mark>to</mark> Enjoy life, but on the flip side, if you don't examine life, there's no reason <mark>to</mark> want <mark>to</mark> live the day you figure out your why is the most important day in your life because that's a day you <mark>become</mark> unstoppable. That's the day you find your purpose. Nothing is going <mark>to</mark> be able <mark>to</mark> stop you from achieving your dreams and your passions. If you really understand why you're doing it if your why is strong enough your <mark>how</mark> will reveal itself hundred percent? And because our thoughts have so much power. I just want <mark>to</mark> share a quote by British author David chamel. Don't speak badly of yourself for the warrior within here's your words and his lesson by them. Think about it every thought feeling and emotion that we feel is shaped by our beliefs and values. Our whole lives are basically set up based on all our decisions all the little things that you've decided got you <mark>to</mark> where you are today. The beauty and this is realizing that wherever it is that you are now whether you're perfectly content or you're totally disappointed you ultimately have the power <mark>to</mark> change it. It's so important <mark>to</mark> be mindful of our thoughts because our mind makes her reality. Our minds are the center of our own Universe. Our thoughts are real and powerful and what you think directly influences <mark>how</mark> you feel <mark>how</mark> you behave and your beliefs can influence other people's behavior. Remember guys, nothing is going <mark>to</mark> change unless you do and that all begins with our thoughts. So farts are powerful because fotz is a form of energy mix. I just want <mark>to</mark> share a story about why it's so important. We got <mark>to</mark> be careful what we say <mark>to</mark> our family friends and ourselves, but I will always have this vivid memory when I was 13 years old. I remember when I was 13, I just moved from the", "Start Time (s)": 107.2, "End Time (s)": 227.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "emotion that we feel is shaped by our beliefs and values. Our whole lives are basically set up based on all our decisions all the little things that you've decided got you <mark>to</mark> where you are today. The beauty and this is realizing that wherever it is that you are now whether you're perfectly content or you're totally disappointed you ultimately have the power <mark>to</mark> change it. It's so important <mark>to</mark> be mindful of our thoughts because our mind makes her reality. Our minds are the center of our own Universe. Our thoughts are real and powerful and what you think directly influences <mark>how</mark> you feel <mark>how</mark> you behave and your beliefs can influence other people's behavior. Remember guys, nothing is going <mark>to</mark> change unless you do and that all begins with our thoughts. So farts are powerful because fotz is a form of energy mix. I just want <mark>to</mark> share a story about why it's so important. We got <mark>to</mark> be careful what we say <mark>to</mark> our family friends and ourselves, but I will always have this vivid memory when I was 13 years old. I remember when I was 13, I just moved from the West Coast Vancouver <mark>to</mark> the east coast Toronto and it was a totally different culture from the clothes. I wore the slang I use no one in Toronto seen that For like I was a total Outcast and that was super confusing for me because I just I was like a normal guy had friends at my old school and then I came here wearing the same baggy clothes like well, everyone was wearing tight jeans. I just did not fit in. This is why if you listen <mark>to</mark> episode 1 I referred <mark>to</mark> Caleb as this cool Street hipster. Now you guys have a background of why tough time I'd absolutely no friends. And so what I would do is I would try <mark>to</mark> learn <mark>how</mark> <mark>to</mark> dance. I'm at home. I put the cardboard down on the floor and I'll just roll around on the floor. So I remember one day my dad saw me. He told me he just saw me and told me", "Start Time (s)": 157.4, "End Time (s)": 277.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "friends and ourselves, but I will always have this vivid memory when I was 13 years old. I remember when I was 13, I just moved from the West Coast Vancouver <mark>to</mark> the east coast Toronto and it was a totally different culture from the clothes. I wore the slang I use no one in Toronto seen that For like I was a total Outcast and that was super confusing for me because I just I was like a normal guy had friends at my old school and then I came here wearing the same baggy clothes like well, everyone was wearing tight jeans. I just did not fit in. This is why if you listen <mark>to</mark> episode 1 I referred <mark>to</mark> Caleb as this cool Street hipster. Now you guys have a background of why tough time I'd absolutely no friends. And so what I would do is I would try <mark>to</mark> learn <mark>how</mark> <mark>to</mark> dance. I'm at home. I put the cardboard down on the floor and I'll just roll around on the floor. So I remember one day my dad saw me. He told me he just saw me and told me son. You're trying <mark>to</mark> learn <mark>how</mark> <mark>to</mark> dance you're completely wasting your time. Your uncoordinated. You have no musicality and just you just stick <mark>to</mark> math. So basically, it's like your typical Asian Dad. I absolutely love my dad, but I'll never forget that comment. I didn't say anything back <mark>to</mark> him at the time because he was probably right. But at that point I made a choice <mark>to</mark> myself I decided I'm going <mark>to</mark> work even harder <mark>to</mark> prove them wrong because deep down. I knew I could dance like deep down. I just knew I could and that was one of the best decisions I've ever made and dance made me uncomfortable and through that discomfort. I grew so much. I made so many valuable connections through dance and helped me gain so much confidence at those critical years of my life when I entered High School the following The year, I started practicing at the local college with college students. These old students are Role Models gave me advice. They kept me out of trouble and it gave me so much confidence,", "Start Time (s)": 218.2, "End Time (s)": 337.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you're completely wasting your time. Your uncoordinated. You have no musicality and just you just stick <mark>to</mark> math. So basically, it's like your typical Asian Dad. I absolutely love my dad, but I'll never forget that comment. I didn't say anything back <mark>to</mark> him at the time because he was probably right. But at that point I made a choice <mark>to</mark> myself I decided I'm going <mark>to</mark> work even harder <mark>to</mark> prove them wrong because deep down. I knew I could dance like deep down. I just knew I could and that was one of the best decisions I've ever made and dance made me uncomfortable and through that discomfort. I grew so much. I made so many valuable connections through dance and helped me gain so much confidence at those critical years of my life when I entered High School the following The year, I started practicing at the local college with college students. These old students are Role Models gave me advice. They kept me out of trouble and it gave me so much confidence, especially if I'm learning <mark>how</mark> <mark>to</mark> do a backflip. So just from watching YouTube videos and practicing them backyards learning <mark>how</mark> <mark>to</mark> backflip help me gain so much Social rank in school just because I could backflip on command at the end of high school. I could dance in front of the whole school of 800 900 students confidently one money. Some competitions and Just Dance kept me out of trouble. I don't know where I would be without dance. So imagine if I stop the day, my dad said those comments he would have been right I wouldn't have been able <mark>to</mark> dance. So from there. I learned if you fight for your limitations, you will keep them. So please be careful what you say <mark>to</mark> your friends. What do you say <mark>to</mark> your family and most importantly what you say <mark>to</mark> yourself? Because whether you think you can or you can't you're right. So more of the story don't listen <mark>to</mark> your parents. I don't know that's the whole moral of story that can be generalized like that. But no, but seriously", "Start Time (s)": 279.4, "End Time (s)": 398.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "These old students are Role Models gave me advice. They kept me out of trouble and it gave me so much confidence, especially if I'm learning <mark>how</mark> <mark>to</mark> do a backflip. So just from watching YouTube videos and practicing them backyards learning <mark>how</mark> <mark>to</mark> backflip help me gain so much Social rank in school just because I could backflip on command at the end of high school. I could dance in front of the whole school of 800 900 students confidently one money. Some competitions and Just Dance kept me out of trouble. I don't know where I would be without dance. So imagine if I stop the day, my dad said those comments he would have been right I wouldn't have been able <mark>to</mark> dance. So from there. I learned if you fight for your limitations, you will keep them. So please be careful what you say <mark>to</mark> your friends. What do you say <mark>to</mark> your family and most importantly what you say <mark>to</mark> yourself? Because whether you think you can or you can't you're right. So more of the story don't listen <mark>to</mark> your parents. I don't know that's the whole moral of story that can be generalized like that. But no, but seriously don't let other people's opinions affect you because opinions are literally the cheapest commodity in the world literally, everyone has one facts opinions and talk or both cheap the biggest takeaway from just learning <mark>how</mark> <mark>to</mark> dance is the power of self belief in the power. Our positive thinking because ultimately it's because I believed that I could dance that's what motivated me <mark>to</mark> practice more myself belief influence my behavior. And then when I practice some more the better, I got it just reinforced my belief that I could dance everything is interrelated. So be mindful of what you think and believe again if you fight for your limitations, you will keep them. Nothing is going <mark>to</mark> change unless you do and not all begins with your thoughts. It's all Interrelated you are what you think and <mark>to</mark> be honest people don't actually think that", "Start Time (s)": 332.0, "End Time (s)": 451.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "more of the story don't listen <mark>to</mark> your parents. I don't know that's the whole moral of story that can be generalized like that. But no, but seriously don't let other people's opinions affect you because opinions are literally the cheapest commodity in the world literally, everyone has one facts opinions and talk or both cheap the biggest takeaway from just learning <mark>how</mark> <mark>to</mark> dance is the power of self belief in the power. Our positive thinking because ultimately it's because I believed that I could dance that's what motivated me <mark>to</mark> practice more myself belief influence my behavior. And then when I practice some more the better, I got it just reinforced my belief that I could dance everything is interrelated. So be mindful of what you think and believe again if you fight for your limitations, you will keep them. Nothing is going <mark>to</mark> change unless you do and not all begins with your thoughts. It's all Interrelated you are what you think and <mark>to</mark> be honest people don't actually think that often they don't use their conscious decision making skills as often as one would think for example 40% of people's there's a 40% 40% or more of our day is spent by habitual routine. The mind is a creature of habit and we are the sum of those habits. So everything you think and you do That's being communicated <mark>to</mark> your subconscious everything that you think is being recorded by your subconscious. And what's so interesting about the subconscious in our brain is that positive and negative emotions cannot occupy the mind at the same time and what people don't realize is positive thinking is a choice that becomes a habit positive thinking is a muscle that needs <mark>to</mark> be exercised <mark>to</mark> <mark>become</mark> a strong in this podcast. You're going <mark>to</mark> hear us talk about <mark>how</mark> So a lot and you're going <mark>to</mark> hear us talk about discipline because", "Start Time (s)": 388.7, "End Time (s)": 508.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "going <mark>to</mark> change unless you do and not all begins with your thoughts. It's all Interrelated you are what you think and <mark>to</mark> be honest people don't actually think that often they don't use their conscious decision making skills as often as one would think for example 40% of people's there's a 40% 40% or more of our day is spent by habitual routine. The mind is a creature of habit and we are the sum of those habits. So everything you think and you do That's being communicated <mark>to</mark> your subconscious everything that you think is being recorded by your subconscious. And what's so interesting about the subconscious in our brain is that positive and negative emotions cannot occupy the mind at the same time and what people don't realize is positive thinking is a choice that becomes a habit positive thinking is a muscle that needs <mark>to</mark> be exercised <mark>to</mark> <mark>become</mark> a strong in this podcast. You're going <mark>to</mark> hear us talk about <mark>how</mark> So a lot and you're going <mark>to</mark> hear us talk about discipline because from my experiences it takes discipline <mark>to</mark> find out who you really are being able <mark>to</mark> get yourself <mark>to</mark> do. The things you don't want <mark>to</mark> do is ultimately Freedom being able <mark>to</mark> control your thoughts this freedom and it's from just allowing allowing your thoughts <mark>to</mark> wander listening <mark>to</mark> your thoughts listening <mark>to</mark> your heart as <mark>how</mark> you're going <mark>to</mark> <mark>become</mark> who you really are if you're going through autopilot constantly on your phone. Never have any alone time and he faking time. You never you never going <mark>to</mark> <mark>become</mark> the real you. Let me ask you this. When was the last time you actually sat down and thought <mark>to</mark> yourself? Who am I? We all think we know who we are in reality. We are basically running on scripts. So for those who've watched The Matrix, it's basically like we're stuck in The Matrix, but in reality we have the ability", "Start Time (s)": 440.3, "End Time (s)": 560.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>to</mark> be exercised <mark>to</mark> <mark>become</mark> a strong in this podcast. You're going <mark>to</mark> hear us talk about <mark>how</mark> So a lot and you're going <mark>to</mark> hear us talk about discipline because from my experiences it takes discipline <mark>to</mark> find out who you really are being able <mark>to</mark> get yourself <mark>to</mark> do. The things you don't want <mark>to</mark> do is ultimately Freedom being able <mark>to</mark> control your thoughts this freedom and it's from just allowing allowing your thoughts <mark>to</mark> wander listening <mark>to</mark> your thoughts listening <mark>to</mark> your heart as <mark>how</mark> you're going <mark>to</mark> <mark>become</mark> who you really are if you're going through autopilot constantly on your phone. Never have any alone time and he faking time. You never you never going <mark>to</mark> <mark>become</mark> the real you. Let me ask you this. When was the last time you actually sat down and thought <mark>to</mark> yourself? Who am I? We all think we know who we are in reality. We are basically running on scripts. So for those who've watched The Matrix, it's basically like we're stuck in The Matrix, but in reality we have the ability <mark>to</mark> think for ourselves. We have the ability <mark>to</mark> make conscious decisions. Everything we do is up <mark>to</mark> us. Meaning we're responsible for everything that we do. The next time something bad happens <mark>to</mark> you. Don't blame everyone else literally people blame everything but themselves <mark>to</mark> blame the economy the blame society <mark>to</mark> blame their neighbor, like people need <mark>to</mark> wake up and realize that everything that happens <mark>to</mark> them when sue them for a reason everything that happens <mark>to</mark> them is shaped by them. So you have the power <mark>to</mark> shape your life in any way you want it <mark>to</mark> be it's all up <mark>to</mark> you. Yeah. I just like in The Matrix Morpheus offers Neo you want <mark>to</mark> take the red pill or the blue pill? You can take the blue pill and just go back <mark>to</mark> your ordinary life and just live in the social contracts. You were taught go <mark>to</mark> school putting you get a job have a wife have some kids and then just died, but don't worry. Your life's going <mark>to</mark> start after retire. Just living miserably now and then when you save up enough money and when you're tired life's going <mark>to</mark> be", "Start Time (s)": 500.3, "End Time (s)": 620.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "The Matrix, it's basically like we're stuck in The Matrix, but in reality we have the ability <mark>to</mark> think for ourselves. We have the ability <mark>to</mark> make conscious decisions. Everything we do is up <mark>to</mark> us. Meaning we're responsible for everything that we do. The next time something bad happens <mark>to</mark> you. Don't blame everyone else literally people blame everything but themselves <mark>to</mark> blame the economy the blame society <mark>to</mark> blame their neighbor, like people need <mark>to</mark> wake up and realize that everything that happens <mark>to</mark> them when sue them for a reason everything that happens <mark>to</mark> them is shaped by them. So you have the power <mark>to</mark> shape your life in any way you want it <mark>to</mark> be it's all up <mark>to</mark> you. Yeah. I just like in The Matrix Morpheus offers Neo you want <mark>to</mark> take the red pill or the blue pill? You can take the blue pill and just go back <mark>to</mark> your ordinary life and just live in the social contracts. You were taught go <mark>to</mark> school putting you get a job have a wife have some kids and then just died, but don't worry. Your life's going <mark>to</mark> start after retire. Just living miserably now and then when you save up enough money and when you're tired life's going <mark>to</mark> be lit. Like or you can take the red pill and just live in reality. Everything's about perspective and perspective is a choice. Like you can choose <mark>to</mark> be a victim or you can choose <mark>to</mark> take control of your life. You are in control you choosing not <mark>to</mark> believe in yourself. That's going <mark>to</mark> <mark>become</mark> a reality. Thank God you kind of reference the movie there because I actually didn't watch the movie. So y'all as a frickin nerd. I love Matrix Fight Club <mark>to</mark> bangs now. We understand the importance of your why. You're probably wondering <mark>how</mark> do I find my y what's my why what a what's my purpose in life and that's for you <mark>to</mark> figure out but but we're here <mark>to</mark> give you some tips on", "Start Time (s)": 554.0, "End Time (s)": 673.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a wife have some kids and then just died, but don't worry. Your life's going <mark>to</mark> start after retire. Just living miserably now and then when you save up enough money and when you're tired life's going <mark>to</mark> be lit. Like or you can take the red pill and just live in reality. Everything's about perspective and perspective is a choice. Like you can choose <mark>to</mark> be a victim or you can choose <mark>to</mark> take control of your life. You are in control you choosing not <mark>to</mark> believe in yourself. That's going <mark>to</mark> <mark>become</mark> a reality. Thank God you kind of reference the movie there because I actually didn't watch the movie. So y'all as a frickin nerd. I love Matrix Fight Club <mark>to</mark> bangs now. We understand the importance of your why. You're probably wondering <mark>how</mark> do I find my y what's my why what a what's my purpose in life and that's for you <mark>to</mark> figure out but but we're here <mark>to</mark> give you some tips on Guiding you on <mark>how</mark> <mark>to</mark> find your why I like finding your why is an ongoing process even a year ago. If you ask me Caleb, what's your number one goal. I would tell you without even blinking <mark>to</mark> <mark>become</mark> a millionaire before 30. And what I did because from my mentors, they told me <mark>to</mark> follow the Warren Buffett 525 rule. I wrote down my top 25 goals and I circled my top five and number one was <mark>become</mark> a millionaire before 30. I started making my smart goals and start planning on <mark>how</mark> I was going <mark>to</mark> <mark>become</mark> a millionaire before 30 develop multiple Paths of sources of income invest in real estate and do all these things. Right but it's pretty funny because like six months after I when I reflect on my goals again that goal actually fell way Lauren Listen, it's through a lot of introspection. Maybe a little psilocybin. I realized in myself that you let's go was not even for myself. Like if I'm not happy now on my process <mark>to</mark> <mark>become</mark> a", "Start Time (s)": 609.9, "End Time (s)": 729.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that's for you <mark>to</mark> figure out but but we're here <mark>to</mark> give you some tips on Guiding you on <mark>how</mark> <mark>to</mark> find your why I like finding your why is an ongoing process even a year ago. If you ask me Caleb, what's your number one goal. I would tell you without even blinking <mark>to</mark> <mark>become</mark> a millionaire before 30. And what I did because from my mentors, they told me <mark>to</mark> follow the Warren Buffett 525 rule. I wrote down my top 25 goals and I circled my top five and number one was <mark>become</mark> a millionaire before 30. I started making my smart goals and start planning on <mark>how</mark> I was going <mark>to</mark> <mark>become</mark> a millionaire before 30 develop multiple Paths of sources of income invest in real estate and do all these things. Right but it's pretty funny because like six months after I when I reflect on my goals again that goal actually fell way Lauren Listen, it's through a lot of introspection. Maybe a little psilocybin. I realized in myself that you let's go was not even for myself. Like if I'm not happy now on my process <mark>to</mark> <mark>become</mark> a millionaire. <mark>How</mark> am I going <mark>to</mark> be happy if a million dollars? And from there, I really revised my goal. I realized some things I absolutely had <mark>to</mark> do with my bucket list and it's from practicing gratitude and realize I can't take life for granted. Like life is precious. If I was <mark>to</mark> die today, I don't want <mark>to</mark> I don't want my memories <mark>to</mark> just be working 9:00 <mark>to</mark> 5:00 and always saving up for you know, when I retire that's when I'll travel the world. No, I like everything is a choice and we accept it. Yeah, if you want <mark>to</mark> be a millionaire. You're by 30. That's up <mark>to</mark> you. You want <mark>to</mark> put in the work? You want <mark>to</mark> make that money? You want <mark>to</mark> make that bread that's up <mark>to</mark> you. Not not your neighbor. Not the economy not Society. Not your dog. It's up <mark>to</mark> you man. And a quick disclaimer disclaimer becoming a millionaire before 30 still on my bucket list or my top 25 list, but it's just my reason why <mark>become</mark> becoming a millionaire has changed", "Start Time (s)": 669.1, "End Time (s)": 788.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "even for myself. Like if I'm not happy now on my process <mark>to</mark> <mark>become</mark> a millionaire. <mark>How</mark> am I going <mark>to</mark> be happy if a million dollars? And from there, I really revised my goal. I realized some things I absolutely had <mark>to</mark> do with my bucket list and it's from practicing gratitude and realize I can't take life for granted. Like life is precious. If I was <mark>to</mark> die today, I don't want <mark>to</mark> I don't want my memories <mark>to</mark> just be working 9:00 <mark>to</mark> 5:00 and always saving up for you know, when I retire that's when I'll travel the world. No, I like everything is a choice and we accept it. Yeah, if you want <mark>to</mark> be a millionaire. You're by 30. That's up <mark>to</mark> you. You want <mark>to</mark> put in the work? You want <mark>to</mark> make that money? You want <mark>to</mark> make that bread that's up <mark>to</mark> you. Not not your neighbor. Not the economy not Society. Not your dog. It's up <mark>to</mark> you man. And a quick disclaimer disclaimer becoming a millionaire before 30 still on my bucket list or my top 25 list, but it's just my reason why <mark>become</mark> becoming a millionaire has changed before is more just like, oh I wanted <mark>to</mark> buy a house for my parents I want <mark>to</mark> do. Do by my dad and M3. Like I had all these goals that were I needed money <mark>to</mark> accomplish and not saying that money is evil money is not evil money's just a tool. It's our relationship with money and <mark>how</mark> we use it. That's when it became <mark>become</mark> evil, but by Nature, I genuinely believe money is a good thing. That's a tool that can just help us it can just be a tool for us <mark>to</mark> accomplish our goals. It can help us be more generous <mark>to</mark> help other people now, that's that's one way. I like <mark>to</mark> think about it is That money is kind of like a enhancer. So if you're like an asshole and you got money, it's just going <mark>to</mark> enhance your douchebag Enos the whole just get bigger exactly the whole just gets bigger, but on the other hand, if you're like not the asshole just the whole thing, but on the other hand", "Start Time (s)": 725.8, "End Time (s)": 845.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "like, oh I wanted <mark>to</mark> buy a house for my parents I want <mark>to</mark> do. Do by my dad and M3. Like I had all these goals that were I needed money <mark>to</mark> accomplish and not saying that money is evil money is not evil money's just a tool. It's our relationship with money and <mark>how</mark> we use it. That's when it became <mark>become</mark> evil, but by Nature, I genuinely believe money is a good thing. That's a tool that can just help us it can just be a tool for us <mark>to</mark> accomplish our goals. It can help us be more generous <mark>to</mark> help other people now, that's that's one way. I like <mark>to</mark> think about it is That money is kind of like a enhancer. So if you're like an asshole and you got money, it's just going <mark>to</mark> enhance your douchebag Enos the whole just get bigger exactly the whole just gets bigger, but on the other hand, if you're like not the asshole just the whole thing, but on the other hand if you're kind caring compassionate and you got money that's just going <mark>to</mark> multiply it even more you can just have a bigger impact on the world exactly money is Not evil people are going a little bit on a tangent. Just know that your goals can change over time like everything else or just takes practice like figure out your why figuring your goals, you know, sit down have some alone time write down journal in your book make a conscious effort. That's <mark>how</mark> you figure out who you are and that's <mark>how</mark> you figure out where you want <mark>to</mark> be and that's <mark>how</mark> you don't waste your life or moment of it. Yeah. Honestly life is too short <mark>to</mark> be stressing out over trivial things that don't really matter. Why it's important <mark>to</mark> stay present and focused on the things that do matter the thing <mark>to</mark> think about when you're trying <mark>to</mark> find your why try and think about very significant times in your life something that made you feel really emotional because when things are very emotional your it's easier <mark>to</mark> remember Clarity. Yeah think of times. I'm got you emotionally charged what caused those motion what about that", "Start Time (s)": 791.2, "End Time (s)": 909.4, "Clip Length (min)": 1.97, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but on the other hand if you're kind caring compassionate and you got money that's just going <mark>to</mark> multiply it even more you can just have a bigger impact on the world exactly money is Not evil people are going a little bit on a tangent. Just know that your goals can change over time like everything else or just takes practice like figure out your why figuring your goals, you know, sit down have some alone time write down journal in your book make a conscious effort. That's <mark>how</mark> you figure out who you are and that's <mark>how</mark> you figure out where you want <mark>to</mark> be and that's <mark>how</mark> you don't waste your life or moment of it. Yeah. Honestly life is too short <mark>to</mark> be stressing out over trivial things that don't really matter. Why it's important <mark>to</mark> stay present and focused on the things that do matter the thing <mark>to</mark> think about when you're trying <mark>to</mark> find your why try and think about very significant times in your life something that made you feel really emotional because when things are very emotional your it's easier <mark>to</mark> remember Clarity. Yeah think of times. I'm got you emotionally charged what caused those motion what about that experience made you feel that way when you dive deeper into these questions you start <mark>to</mark> figure out Your beliefs deep down not societal beliefs and just <mark>to</mark> wrap it all together <mark>to</mark> the importance of figure out your why is that's an important step of finding out who you are something that blows my mind is like when you talk <mark>to</mark> a kid and ask them what they want <mark>to</mark> be when they grow up kids want <mark>to</mark> be doctors astronauts or superheroes. I change the world, but every year growing up their goals gets smaller and smaller <mark>to</mark> the point. We're at the point of graduation there. Just I'll take any job. So this brings me back <mark>to</mark> our previous. Point don't care about others opinions because at the end of the day, it's all about you. It's about what you think and what you feel now about what others think if you don't know what you want. You can't possibly know who you're meant <mark>to</mark> be. I think everyone wants <mark>to</mark> be great. Everyone wants <mark>to</mark> change the world and that's a good thing. What's not good", "Start Time (s)": 844.2, "End Time (s)": 962.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that made you feel really emotional because when things are very emotional your it's easier <mark>to</mark> remember Clarity. Yeah think of times. I'm got you emotionally charged what caused those motion what about that experience made you feel that way when you dive deeper into these questions you start <mark>to</mark> figure out Your beliefs deep down not societal beliefs and just <mark>to</mark> wrap it all together <mark>to</mark> the importance of figure out your why is that's an important step of finding out who you are something that blows my mind is like when you talk <mark>to</mark> a kid and ask them what they want <mark>to</mark> be when they grow up kids want <mark>to</mark> be doctors astronauts or superheroes. I change the world, but every year growing up their goals gets smaller and smaller <mark>to</mark> the point. We're at the point of graduation there. Just I'll take any job. So this brings me back <mark>to</mark> our previous. Point don't care about others opinions because at the end of the day, it's all about you. It's about what you think and what you feel now about what others think if you don't know what you want. You can't possibly know who you're meant <mark>to</mark> be. I think everyone wants <mark>to</mark> be great. Everyone wants <mark>to</mark> change the world and that's a good thing. What's not good as <mark>how</mark> our education system our society is shutting people down and saying that oh, no, you can't be you just got <mark>to</mark> work a safe 905 and it's the best thing you could do for your family. Yeah, I remember. Like I told my dad I wanted <mark>to</mark> be a professional gamer. I know that sounds impossible. I know that if I worked hard at it if I dedicated my life <mark>to</mark> that I definitely could have done it but it is because my dad told me what kind of a profession is that go <mark>to</mark> university get a real profession. That's what you're going <mark>to</mark> need in life not games we go back <mark>to</mark> this this reoccurring theme don't listen <mark>to</mark> your dad. I think the main takeaway is just <mark>to</mark> be critical you got <mark>to</mark> be critical of everything because yes us our parents have good intentions, but they grew up in a different world in a different time where the same rules may not apply. So yes everything <mark>to</mark> telling you is out of pure love but you", "Start Time (s)": 896.7, "End Time (s)": 1016.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "if you don't know what you want. You can't possibly know who you're meant <mark>to</mark> be. I think everyone wants <mark>to</mark> be great. Everyone wants <mark>to</mark> change the world and that's a good thing. What's not good as <mark>how</mark> our education system our society is shutting people down and saying that oh, no, you can't be you just got <mark>to</mark> work a safe 905 and it's the best thing you could do for your family. Yeah, I remember. Like I told my dad I wanted <mark>to</mark> be a professional gamer. I know that sounds impossible. I know that if I worked hard at it if I dedicated my life <mark>to</mark> that I definitely could have done it but it is because my dad told me what kind of a profession is that go <mark>to</mark> university get a real profession. That's what you're going <mark>to</mark> need in life not games we go back <mark>to</mark> this this reoccurring theme don't listen <mark>to</mark> your dad. I think the main takeaway is just <mark>to</mark> be critical you got <mark>to</mark> be critical of everything because yes us our parents have good intentions, but they grew up in a different world in a different time where the same rules may not apply. So yes everything <mark>to</mark> telling you is out of pure love but you got <mark>to</mark> be critical and think for yourself. That's the important thing right there is <mark>to</mark> be critical and always questioned. Why have faith <mark>to</mark> when your why is strong enough your <mark>how</mark> will reveal itself? It's only when you know, that's your why that's your goal and you keep working <mark>to</mark> it. That's <mark>how</mark> it's going <mark>to</mark> <mark>become</mark> a reality. But right then and there if you accept whatever you choose <mark>to</mark> believe your mind will make that a reality and that has power the thoughts have power and your mind is the center of our own Universe. Don't wait until something terrible happens <mark>to</mark> change your life. Take the time now <mark>to</mark> ask yourself. Who am I and remember nothing is going <mark>to</mark> change unless you do. I know I know so many people who are expecting their lives <mark>to</mark> change and do nothing about it. Like you want <mark>to</mark> win the lottery yet. You're too fucking lazy <mark>to</mark> even buy a fucking lottery ticket or people say, you know, I want <mark>to</mark>", "Start Time (s)": 953.3, "End Time (s)": 1073.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "have good intentions, but they grew up in a different world in a different time where the same rules may not apply. So yes everything <mark>to</mark> telling you is out of pure love but you got <mark>to</mark> be critical and think for yourself. That's the important thing right there is <mark>to</mark> be critical and always questioned. Why have faith <mark>to</mark> when your why is strong enough your <mark>how</mark> will reveal itself? It's only when you know, that's your why that's your goal and you keep working <mark>to</mark> it. That's <mark>how</mark> it's going <mark>to</mark> <mark>become</mark> a reality. But right then and there if you accept whatever you choose <mark>to</mark> believe your mind will make that a reality and that has power the thoughts have power and your mind is the center of our own Universe. Don't wait until something terrible happens <mark>to</mark> change your life. Take the time now <mark>to</mark> ask yourself. Who am I and remember nothing is going <mark>to</mark> change unless you do. I know I know so many people who are expecting their lives <mark>to</mark> change and do nothing about it. Like you want <mark>to</mark> win the lottery yet. You're too fucking lazy <mark>to</mark> even buy a fucking lottery ticket or people say, you know, I want <mark>to</mark> travel but I don't have the time. I don't have the money. I want <mark>to</mark> learn this. I want <mark>to</mark> learn that bro make money make the time you can do anything you want in this life. This is all up <mark>to</mark> you. Don't wish things were easier. Wish that you were better and stronger <mark>to</mark> take on the challenges life has <mark>to</mark> offer if you do what is easy, you will live a hard life. If you do what is hard you live an easy life. What kind of Life do you want <mark>to</mark> live? Do you want <mark>to</mark> do what is easy and just barely scrape by what you want <mark>to</mark> do the hard things develop your skills and the tenacity <mark>to</mark> take on any challenge life throws your way. Seems like a pretty obvious choice <mark>to</mark> me, but it's not up <mark>to</mark> me. It's up <mark>to</mark> you. So what are you guys going <mark>to</mark> choose? So if you guys are asking, <mark>how</mark> can I find my Y, <mark>how</mark> can I build positive thinking <mark>how</mark> can I build those habits? Well", "Start Time (s)": 1005.0, "End Time (s)": 1124.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Who am I and remember nothing is going <mark>to</mark> change unless you do. I know I know so many people who are expecting their lives <mark>to</mark> change and do nothing about it. Like you want <mark>to</mark> win the lottery yet. You're too fucking lazy <mark>to</mark> even buy a fucking lottery ticket or people say, you know, I want <mark>to</mark> travel but I don't have the time. I don't have the money. I want <mark>to</mark> learn this. I want <mark>to</mark> learn that bro make money make the time you can do anything you want in this life. This is all up <mark>to</mark> you. Don't wish things were easier. Wish that you were better and stronger <mark>to</mark> take on the challenges life has <mark>to</mark> offer if you do what is easy, you will live a hard life. If you do what is hard you live an easy life. What kind of Life do you want <mark>to</mark> live? Do you want <mark>to</mark> do what is easy and just barely scrape by what you want <mark>to</mark> do the hard things develop your skills and the tenacity <mark>to</mark> take on any challenge life throws your way. Seems like a pretty obvious choice <mark>to</mark> me, but it's not up <mark>to</mark> me. It's up <mark>to</mark> you. So what are you guys going <mark>to</mark> choose? So if you guys are asking, <mark>how</mark> can I find my Y, <mark>how</mark> can I build positive thinking <mark>how</mark> can I build those habits? Well just start small. So my challenge for you guys is for the next week or until our next episode. I want you <mark>to</mark> be extremely mindful pay attention <mark>to</mark> what you think about and every time you have that negative thought come <mark>to</mark> your mind. People anything the moment you get that negative thought you have <mark>to</mark> text that <mark>to</mark> your accountability partner send it <mark>to</mark> them in a message what the negative thought is and just get their feedback. Most often like you're probably going <mark>to</mark> see that your accountability partner is going <mark>to</mark> see in a different light that you see and they're just going <mark>to</mark> tell you it's straight irrational. It's good <mark>to</mark> see things from a different perspective as well doing this. You're building the habit of being mindful of your thoughts being positive a positive habit and you're building your tribe tribe. I like that humans are social", "Start Time (s)": 1057.0, "End Time (s)": 1176.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>how</mark> can I build positive thinking <mark>how</mark> can I build those habits? Well just start small. So my challenge for you guys is for the next week or until our next episode. I want you <mark>to</mark> be extremely mindful pay attention <mark>to</mark> what you think about and every time you have that negative thought come <mark>to</mark> your mind. People anything the moment you get that negative thought you have <mark>to</mark> text that <mark>to</mark> your accountability partner send it <mark>to</mark> them in a message what the negative thought is and just get their feedback. Most often like you're probably going <mark>to</mark> see that your accountability partner is going <mark>to</mark> see in a different light that you see and they're just going <mark>to</mark> tell you it's straight irrational. It's good <mark>to</mark> see things from a different perspective as well doing this. You're building the habit of being mindful of your thoughts being positive a positive habit and you're building your tribe tribe. I like that humans are social creatures. So it's only natural that we live in tribes people who try <mark>to</mark> do. Everything themselves. It's inefficient. We've been social creatures for thousands of years and it's not going <mark>to</mark> change now. Don't try and do things yourself. We're meant <mark>to</mark> work together. We are meant <mark>to</mark> unite we are all powerful Divine Spiritual Beings living a human existence that have the power <mark>to</mark> achieve anything and being in control for life means making very conscious and critical decisions. Who you spend your time with? Because I'm sure we all heard of the law of averages which is what the average of the 5 people we spend the most time. You're hanging out with a bunch of bums. Guess who the fifth bum is those you that's right asshole. So it's kind of just like a reality check take a look around you look at your environment. See what is useful take. What is useful absorb what you can reject what? Useless and add what is essentially your own exactly now, I just want <mark>to</mark>", "Start Time (s)": 1120.6, "End Time (s)": 1240.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>to</mark> do. Everything themselves. It's inefficient. We've been social creatures for thousands of years and it's not going <mark>to</mark> change now. Don't try and do things yourself. We're meant <mark>to</mark> work together. We are meant <mark>to</mark> unite we are all powerful Divine Spiritual Beings living a human existence that have the power <mark>to</mark> achieve anything and being in control for life means making very conscious and critical decisions. Who you spend your time with? Because I'm sure we all heard of the law of averages which is what the average of the 5 people we spend the most time. You're hanging out with a bunch of bums. Guess who the fifth bum is those you that's right asshole. So it's kind of just like a reality check take a look around you look at your environment. See what is useful take. What is useful absorb what you can reject what? Useless and add what is essentially your own exactly now, I just want <mark>to</mark> mention one more thing before we go here is listening <mark>to</mark> a self-development. Speech by Jim Rohn. He used the analogy that life is like changing season. You cannot change the season but you can change yourself and with every season there's a lesson <mark>to</mark> learn though Winters Winters always come after fall and Winters whether they're Financial Winters personal Winters motional Winters. So your hearts been broken into a thousand pieces. That's a Sir, but we have <mark>to</mark> learn <mark>how</mark> <mark>to</mark> handle the winters. They're always going <mark>to</mark> come <mark>to</mark> always be there but it's up <mark>to</mark> us <mark>to</mark> decide <mark>how</mark> we want <mark>to</mark> react <mark>to</mark> them. Can't remember. We can't change the seasons, but we can change ourselves and I just thought that was really cool. And I wanted <mark>to</mark> share that with you guys. That's beautiful beautiful analogy. I think that is all we have for you guys today Caleb. Is there anything you want <mark>to</mark> add before we go now, that's pretty much it just Remember your father important your thoughts are real protect your energy protect your thoughts choose who <mark>to</mark> surround yourself with choose <mark>how</mark> you respond <mark>to</mark> life. Just remember you're in", "Start Time (s)": 1180.2, "End Time (s)": 1299.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Useless and add what is essentially your own exactly now, I just want <mark>to</mark> mention one more thing before we go here is listening <mark>to</mark> a self-development. Speech by Jim Rohn. He used the analogy that life is like changing season. You cannot change the season but you can change yourself and with every season there's a lesson <mark>to</mark> learn though Winters Winters always come after fall and Winters whether they're Financial Winters personal Winters motional Winters. So your hearts been broken into a thousand pieces. That's a Sir, but we have <mark>to</mark> learn <mark>how</mark> <mark>to</mark> handle the winters. They're always going <mark>to</mark> come <mark>to</mark> always be there but it's up <mark>to</mark> us <mark>to</mark> decide <mark>how</mark> we want <mark>to</mark> react <mark>to</mark> them. Can't remember. We can't change the seasons, but we can change ourselves and I just thought that was really cool. And I wanted <mark>to</mark> share that with you guys. That's beautiful beautiful analogy. I think that is all we have for you guys today Caleb. Is there anything you want <mark>to</mark> add before we go now, that's pretty much it just Remember your father important your thoughts are real protect your energy protect your thoughts choose who <mark>to</mark> surround yourself with choose <mark>how</mark> you respond <mark>to</mark> life. Just remember you're in control. So find your why one last thing guys, if you did enjoy this episode or the last please leave a review on whatever platform you're listening <mark>to</mark> Spotify Stitcher iTunes Apple podcast, whatever it is leave us there. You leave us some feedback. Let us know what you think. But we definitely felt a lot more comfortable recording episode 2. It's all a process. Remember guys. Yeah. So once again, thanks for listening guys much love much appreciated until next time peace and love peace the real you.", "Start Time (s)": 1235.6, "End Time (s)": 1337.6, "Clip Length (min)": 1.7, "show_uri": "spotify:show:2lRMymrbWMi2tpwrA45eZD", "show_name": "The Real You", "show_description": "A curated collection of life experiences to guide the listener to self discovery through holistic well living. Created by two friends that awakened their souls by standing up for their beliefs even when it meant challenging their parents, school and social norms.  Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram  Support us:  http://paypal.me/therealyoupodcast", "publisher": "Caleb & Vince", "episode_uri": "spotify:episode:6GkMo84lpcM4pwA46A25R6", "episode_name": "02 TRY: The Power of Why", "episode_description": "It all starts with why. Join Caleb and Vince as they enter the matrix of why. Exploring the ideas of passion, money, limitations, and reasons for being. Contact Us: realyoupodcast@gmail.com and @realyoupodcast on Instagram Help us get a third mic! www.paypal.me/therealyoupodcast ", "score": 3.6902578, "explanation": "{\n  \"value\": 3.6902578,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.76728106,\n      \"description\": \"weight(word_list:how in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.76728106,\n          \"description\": \"score(LMDirichletSimilarity, freq=27.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.8429658,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 27.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.4845797,\n      \"description\": \"weight(word_list:to in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.4845797,\n          \"description\": \"score(LMDirichletSimilarity, freq=205.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.5602645,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 205.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.438397,\n      \"description\": \"weight(word_list:become in 105) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.438397,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Wealth from get-rich-quick schemes quickly disappears. Well from hard work grows over time Proverbs 13 11. I read a story recently about a 24 year old who went <mark>to</mark> visit a financial planner the financial planner asked <mark>to</mark> see her spending habits the author of the article shared that through <mark>to</mark> over the phone sessions in a couple of weeks of financial reflection. She found that she didn't have <mark>to</mark> give up things. She really loved <mark>to</mark> save money that realization helped her get past Financial anxiety and helped her <mark>to</mark> make productive spending cuts during the sessions. Which each lasted about an hour they discussed her background shared screens <mark>to</mark> look at a monthly credit card statement and addressed goals for the week. The financial accountability was intended <mark>to</mark> help her prepare and save for the future. It's encouraging <mark>to</mark> know that the Bible is full of wise advice on <mark>how</mark> <mark>to</mark> handle and <mark>how</mark> <mark>to</mark> view Money In fact money is mentioned hundreds of times in the Bible including the verse from Proverbs we heard today. Let's hear it again wealth from get-rich-quick schemes quickly disappears. Well from hard work grows over time. It's also important <mark>to</mark> remember Words of Jesus <mark>to</mark> when I plan for my financial future <mark>to</mark> invest in things of the Kingdom that will reap and eternal reward. Not just an Earthly one as I go", "Start Time (s)": 0.2, "End Time (s)": 69.8, "Clip Length (min)": 1.16, "show_uri": "spotify:show:7otatnsw98FDMc6kcMPvjG", "show_name": "Daily Bible Verse", "show_description": "Volley.FM presents Daily Bible Verse  Cory's daily podcast brings you an inspiring bible verse and some words of encouragement to help start every day on the right foot.  It is easy to lose sight of what is most important in the hustle of everyday life. Starting your day by focusing on a great verse of the Bible, some ideas of how to put it into action can help keep things on track.  Let this positive encouragement and bible study help guide your day.", "publisher": "Daily Bible Verse", "episode_uri": "spotify:episode:44CnUZ2v4d6IWR1juH2I2F", "episode_name": "Wealth And Wisdom", "episode_description": "Volley.FM - Click here for more great shows! ", "score": 3.6345057, "explanation": "{\n  \"value\": 3.6345057,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34011418,\n      \"description\": \"weight(word_list:how in 5) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34011418,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.46410015,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.12398598,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.14742304,\n      \"description\": \"weight(word_list:to in 5) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.14742304,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.27140903,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.12398598,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.1469686,\n      \"description\": \"weight(word_list:rich in 5) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.1469686,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.12398598,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "schemes quickly disappears. Well from hard work grows over time Proverbs 13 11. I read a story recently about a 24 year old who went <mark>to</mark> visit a financial planner the financial planner asked <mark>to</mark> see her spending habits the author of the article shared that through <mark>to</mark> over the phone sessions in a couple of weeks of financial reflection. She found that she didn't have <mark>to</mark> give up things. She really loved <mark>to</mark> save money that realization helped her get past Financial anxiety and helped her <mark>to</mark> make productive spending cuts during the sessions. Which each lasted about an hour they discussed her background shared screens <mark>to</mark> look at a monthly credit card statement and addressed goals for the week. The financial accountability was intended <mark>to</mark> help her prepare and save for the future. It's encouraging <mark>to</mark> know that the Bible is full of wise advice on <mark>how</mark> <mark>to</mark> handle and <mark>how</mark> <mark>to</mark> view Money In fact money is mentioned hundreds of times in the Bible including the verse from Proverbs we heard today. Let's hear it again wealth from get-rich-quick schemes quickly disappears. Well from hard work grows over time. It's also important <mark>to</mark> remember Words of Jesus <mark>to</mark> when I plan for my financial future <mark>to</mark> invest in things of the Kingdom that will reap and eternal reward. Not just an Earthly one as I go throughout my day <mark>to</mark> day. I'm going <mark>to</mark> pay closer attention <mark>to</mark> <mark>how</mark> I'm spending the money. The father has blessed me with I hope you'll join me. Have a blessed day.", "Start Time (s)": 1.5, "End Time (s)": 76.9, "Clip Length (min)": 1.26, "show_uri": "spotify:show:7otatnsw98FDMc6kcMPvjG", "show_name": "Daily Bible Verse", "show_description": "Volley.FM presents Daily Bible Verse  Cory's daily podcast brings you an inspiring bible verse and some words of encouragement to help start every day on the right foot.  It is easy to lose sight of what is most important in the hustle of everyday life. Starting your day by focusing on a great verse of the Bible, some ideas of how to put it into action can help keep things on track.  Let this positive encouragement and bible study help guide your day.", "publisher": "Daily Bible Verse", "episode_uri": "spotify:episode:44CnUZ2v4d6IWR1juH2I2F", "episode_name": "Wealth And Wisdom", "episode_description": "Volley.FM - Click here for more great shows! ", "score": 3.6345057, "explanation": "{\n  \"value\": 3.6345057,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.34011418,\n      \"description\": \"weight(word_list:how in 5) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.34011418,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.46410015,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.12398598,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.14742304,\n      \"description\": \"weight(word_list:to in 5) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.14742304,\n          \"description\": \"score(LMDirichletSimilarity, freq=17.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.27140903,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 17.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.12398598,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 3.1469686,\n      \"description\": \"weight(word_list:rich in 5) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 3.1469686,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -0.12398598,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 264.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "All right, one, two, three, four five little bow walk fresh it down. Yes. How's the big man? I don't know 90 job that will spot you suspected of mind has been on the minds <mark>to</mark> working for real until right. Now you off social media. What's their apart? You're going straight into it. It's a whole bunch of things. But I think for me the most important thing is just <mark>to</mark> like get focused packable and I thought in the beginning I thought I'll take it back. But then I realize it sounds like they really I need <mark>to</mark> eat your because life has now came <mark>to</mark> revolve around it. And what intrapreneurship does is that it takes you away from so many things takes away from family takes you away from your spirituality takes away from your emotions and you getting that back like has <mark>to</mark> be bird effort like Milli Milli be nice when it's scheduled <mark>to</mark> King Lionel engine rattling at the sun along energy and for me in being able <mark>to</mark> try <mark>to</mark> get all of that back. I don't find space for social media and I still have people find me for that say people need <mark>to</mark> hear", "Start Time (s)": 7.7, "End Time (s)": 83.7, "Clip Length (min)": 1.27, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "man? I don't know 90 job that will spot you suspected of mind has been on the minds <mark>to</mark> working for real until right. Now you off social media. What's their apart? You're going straight into it. It's a whole bunch of things. But I think for me the most important thing is just <mark>to</mark> like get focused packable and I thought in the beginning I thought I'll take it back. But then I realize it sounds like they really I need <mark>to</mark> eat your because life has now came <mark>to</mark> revolve around it. And what intrapreneurship does is that it takes you away from so many things takes away from family takes you away from your spirituality takes away from your emotions and you getting that back like has <mark>to</mark> be bird effort like Milli Milli be nice when it's scheduled <mark>to</mark> King Lionel engine rattling at the sun along energy and for me in being able <mark>to</mark> try <mark>to</mark> get all of that back. I don't find space for social media and I still have people find me for that say people need <mark>to</mark> hear what you say that but I think I'm choosing my life over that you choosing a laugh over that and social the social media. I mean intrapreneurship and is it not been your life? I mean, I'm sure you at some point. It would say this is everything but right now you you just you sound like you're saying or two. It's actually intrapreneurship is not your entire life. I think I think until you get <mark>to</mark> a point where you almost lose your life because of Entrepreneurship. You realize it's no actually I don't like I don't think this is worth dying for because if I die I have siblings. I family who Be Like A Cholo McLeod body and that's it. And when you're talking about dying and talking about isn't this find a way Austrian yeah, yeah. Yeah, like when I when I when I know you maybe I should explain the when I say dying there's different ways <mark>to</mark> time and there's people who are dead spiritually those people are dead", "Start Time (s)": 15.8, "End Time (s)": 135.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "along energy and for me in being able <mark>to</mark> try <mark>to</mark> get all of that back. I don't find space for social media and I still have people find me for that say people need <mark>to</mark> hear what you say that but I think I'm choosing my life over that you choosing a laugh over that and social the social media. I mean intrapreneurship and is it not been your life? I mean, I'm sure you at some point. It would say this is everything but right now you you just you sound like you're saying or two. It's actually intrapreneurship is not your entire life. I think I think until you get <mark>to</mark> a point where you almost lose your life because of Entrepreneurship. You realize it's no actually I don't like I don't think this is worth dying for because if I die I have siblings. I family who Be Like A Cholo McLeod body and that's it. And when you're talking about dying and talking about isn't this find a way Austrian yeah, yeah. Yeah, like when I when I when I know you maybe I should explain the when I say dying there's different ways <mark>to</mark> time and there's people who are dead spiritually those people are dead emotionally. There's people are dated my friend was shot on Sunday Saturday nights and he was almost dead. You know what I'm saying? So for me it was it was just that good see in as much as I love intrapreneurship with once you bite that Apple you've person and you know, but I'm not willing <mark>to</mark> die for it. There's more <mark>to</mark> life and in as much as intrapreneurship is life is my life right now. Wake up for that I live for that. But what intrapreneurship teaches you anyone who's a true entrepreneur will tell you what see the one lesson you learn as you go is that it stopped being about your long time ago. And it's also me dying is actually a cost. Oh, yes student. People are robbing people around me <mark>to</mark> see people that are depending on me, you know, so I have <mark>to</mark> stay alive. Yeah. So is that why you've been working on? Yeah. Yeah.", "Start Time (s)": 72.6, "End Time (s)": 183.7, "Clip Length (min)": 1.85, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "entrepreneur will tell you what see the one lesson you learn as you go is that it stopped being about your long time ago. And it's also me dying is actually a cost. Oh, yes student. People are robbing people around me <mark>to</mark> see people that are depending on me, you know, so I have <mark>to</mark> stay alive. Yeah. So is that why you've been working on? Yeah. Yeah. and and Black ball joint angry white people they've killed us have done this and I was really angry and and I think entrepreneurship brings that <mark>to</mark> your face because there's so many doors that are closed and you get frustrated with it. If I was white, I would have done this article and opportunity. So it pulls that anger and she says <mark>to</mark> me right now, you're like a hand grenade you and I can only be impactful <mark>to</mark> probably five kilometers around you you impact will only be around five kilometers. The trick is <mark>to</mark> live long. The longer you live the more you'll be able <mark>to</mark> do <mark>to</mark> fight that we should angry about. So if Cordelia Angie you're going <mark>to</mark> do something stupid. Yeah, and you want <mark>to</mark> die. Yeah. Yeah. Yeah focused, you know because now I'm able <mark>to</mark> think differently I'm able <mark>to</mark> take myself out of poverty because so many entrepreneurs are broke because we prioritize the people that depend on us but <mark>to</mark> Lutheran shyly Jakarta, but then when you when you are now you you're focusing on yourself. Then you also able <mark>to</mark> take yourself out of that situation", "Start Time (s)": 164.8, "End Time (s)": 284.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Black ball joint angry white people they've killed us have done this and I was really angry and and I think entrepreneurship brings that <mark>to</mark> your face because there's so many doors that are closed and you get frustrated with it. If I was white, I would have done this article and opportunity. So it pulls that anger and she says <mark>to</mark> me right now, you're like a hand grenade you and I can only be impactful <mark>to</mark> probably five kilometers around you you impact will only be around five kilometers. The trick is <mark>to</mark> live long. The longer you live the more you'll be able <mark>to</mark> do <mark>to</mark> fight that we should angry about. So if Cordelia Angie you're going <mark>to</mark> do something stupid. Yeah, and you want <mark>to</mark> die. Yeah. Yeah. Yeah focused, you know because now I'm able <mark>to</mark> think differently I'm able <mark>to</mark> take myself out of poverty because so many entrepreneurs are broke because we prioritize the people that depend on us but <mark>to</mark> Lutheran shyly Jakarta, but then when you when you are now you you're focusing on yourself. Then you also able <mark>to</mark> take yourself out of that situation and and eat better and understand and start reading more things that bring life back <mark>to</mark> you are honest and so I started working out like Joe and and working hard. It's not just about physically it's just like that escaped <mark>to</mark> be by yourself and set certain goals. I see you running you set goals for yourself, you know. Yeah set goals achieve those goals. So for me right now, it's really about <mark>how</mark> do I then live longer because the longer I live the more Impact I'm able <mark>to</mark> <mark>to</mark> have okay, I see so now you you you you taking yourself out of poverty. So obviously right now you were running you having a gym membership you eating right? It's not good. Here. We are, you know, we are floor Supremacy. Now you eating salmon just you choose <mark>to</mark> eat salmon because it's good for you and you're trying <mark>to</mark> live long. So we've been seeing these things have been done by other people that we don't who don't know you", "Start Time (s)": 217.1, "End Time (s)": 336.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "differently I'm able <mark>to</mark> take myself out of poverty because so many entrepreneurs are broke because we prioritize the people that depend on us but <mark>to</mark> Lutheran shyly Jakarta, but then when you when you are now you you're focusing on yourself. Then you also able <mark>to</mark> take yourself out of that situation and and eat better and understand and start reading more things that bring life back <mark>to</mark> you are honest and so I started working out like Joe and and working hard. It's not just about physically it's just like that escaped <mark>to</mark> be by yourself and set certain goals. I see you running you set goals for yourself, you know. Yeah set goals achieve those goals. So for me right now, it's really about <mark>how</mark> do I then live longer because the longer I live the more Impact I'm able <mark>to</mark> <mark>to</mark> have okay, I see so now you you you you taking yourself out of poverty. So obviously right now you were running you having a gym membership you eating right? It's not good. Here. We are, you know, we are floor Supremacy. Now you eating salmon just you choose <mark>to</mark> eat salmon because it's good for you and you're trying <mark>to</mark> live long. So we've been seeing these things have been done by other people that we don't who don't know you Win this because you're rich. Yeah, are you doing this? Because your floors are going <mark>to</mark> actually know you trying <mark>to</mark> get back you trying <mark>to</mark> get yourself together? Yeah. Yeah. So now you've taken yourself out of poverty and you inspire a lot of people you're not the first person <mark>to</mark> static business that's model <mark>to</mark> MIT because you did it differently. Yeah. What what does what and I know what you went <mark>to</mark> school, you know, and it's cool then Plays an important in any important part in in <mark>how</mark> you did your business you have <mark>to</mark> okay. Can you then tell me what was what do you think was the biggest contribution of Education in a business that is done by a lot of young people are gassing. I want a muffin dollar my name often. Do you lie and", "Start Time (s)": 269.1, "End Time (s)": 387.2, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "been done by other people that we don't who don't know you Win this because you're rich. Yeah, are you doing this? Because your floors are going <mark>to</mark> actually know you trying <mark>to</mark> get back you trying <mark>to</mark> get yourself together? Yeah. Yeah. So now you've taken yourself out of poverty and you inspire a lot of people you're not the first person <mark>to</mark> static business that's model <mark>to</mark> MIT because you did it differently. Yeah. What what does what and I know what you went <mark>to</mark> school, you know, and it's cool then Plays an important in any important part in in <mark>how</mark> you did your business you have <mark>to</mark> okay. Can you then tell me what was what do you think was the biggest contribution of Education in a business that is done by a lot of young people are gassing. I want a muffin dollar my name often. Do you lie and what made it what made your business, you know <mark>become</mark> the way it is we was it really schooling was it was the schooling was it also kind of looks Concentrated solution. Yeah your coordinate. So what was it? I generally believe it's a mixture of both but more than that. It's it's <mark>how</mark> I've done it and <mark>how</mark> I've done it is not because I have special talent, but it's because I'm able <mark>to</mark> <mark>to</mark> <mark>to</mark> view the world from different from two parts <mark>how</mark> so so long in cars and people want <mark>to</mark> say that as if some some of a badge with young Jessica's for me. It's like when I say that I'm saying this is my back. Ground, this is my piston Balaji. That's <mark>how</mark> I make sense of life from that land. So using it on a cigar see Mona. Is he moving a meeting in as much as you know, this is the CEO. This is the ca but for my interaction able <mark>to</mark> go <mark>to</mark> college every layer it clever meaning that they shot caller. Yeah. He might be the CFO. This might be the C part actually that and there's no I can't tell you <mark>how</mark> I know that. Yeah, but I know it because I'm gonna take us", "Start Time (s)": 332.8, "End Time (s)": 452.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it what made your business, you know <mark>become</mark> the way it is we was it really schooling was it was the schooling was it also kind of looks Concentrated solution. Yeah your coordinate. So what was it? I generally believe it's a mixture of both but more than that. It's it's <mark>how</mark> I've done it and <mark>how</mark> I've done it is not because I have special talent, but it's because I'm able <mark>to</mark> <mark>to</mark> <mark>to</mark> view the world from different from two parts <mark>how</mark> so so long in cars and people want <mark>to</mark> say that as if some some of a badge with young Jessica's for me. It's like when I say that I'm saying this is my back. Ground, this is my piston Balaji. That's <mark>how</mark> I make sense of life from that land. So using it on a cigar see Mona. Is he moving a meeting in as much as you know, this is the CEO. This is the ca but for my interaction able <mark>to</mark> go <mark>to</mark> college every layer it clever meaning that they shot caller. Yeah. He might be the CFO. This might be the C part actually that and there's no I can't tell you <mark>how</mark> I know that. Yeah, but I know it because I'm gonna take us because of <mark>how</mark> we make sense of things, you know, and what education did Don't want not lie <mark>to</mark> people and say your I took what I learnt at school, and I've not the technicalities of it. Like they <mark>how</mark> <mark>to</mark> build a brand steps that it of keep cool. But what's what's good did <mark>to</mark> me it taught me <mark>how</mark> <mark>to</mark> think bigger. Okay, it taught me <mark>how</mark> <mark>to</mark> <mark>to</mark> see things in a very big of you because now I understood go see your job like a French has a thing because I did campaigns for franchises. So when I start the business, I'm not And my love will on a TV show nice coat. I'm thinking yo franchise because I want what I've seen in internal circuit. The reason why it was awfully short hair and you shop for five years or I will cover shining because he has never seen anything else out of that. So <mark>to</mark> him <mark>to</mark> be able <mark>to</mark> run that for five years. It's a crazy Milestone. Oh, okay, so I get you so you find Richie and there you have a", "Start Time (s)": 389.6, "End Time (s)": 509.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "college every layer it clever meaning that they shot caller. Yeah. He might be the CFO. This might be the C part actually that and there's no I can't tell you <mark>how</mark> I know that. Yeah, but I know it because I'm gonna take us because of <mark>how</mark> we make sense of things, you know, and what education did Don't want not lie <mark>to</mark> people and say your I took what I learnt at school, and I've not the technicalities of it. Like they <mark>how</mark> <mark>to</mark> build a brand steps that it of keep cool. But what's what's good did <mark>to</mark> me it taught me <mark>how</mark> <mark>to</mark> think bigger. Okay, it taught me <mark>how</mark> <mark>to</mark> <mark>to</mark> see things in a very big of you because now I understood go see your job like a French has a thing because I did campaigns for franchises. So when I start the business, I'm not And my love will on a TV show nice coat. I'm thinking yo franchise because I want what I've seen in internal circuit. The reason why it was awfully short hair and you shop for five years or I will cover shining because he has never seen anything else out of that. So <mark>to</mark> him <mark>to</mark> be able <mark>to</mark> run that for five years. It's a crazy Milestone. Oh, okay, so I get you so you find Richie and there you have a business that's been running for five years pure and it doesn't it doesn't grow. Yeah, but it sort of is They there's lunge tivity <mark>to</mark> it. But there is an expansion that they all say, so that's what slick here. So when expansion so now we know we're teaching education gave you the the I actually now see things in an expanded Way by so doing you you then. Well, it's sort of like you made sure go <mark>to</mark> these other guys that were not that do not go too. School basically through you now what all actually it business. I can actually expand instead of instead of so now <mark>how</mark> did you expand because you spent your spending on a crazy rate. I know it's been five years and", "Start Time (s)": 440.7, "End Time (s)": 560.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and you shop for five years or I will cover shining because he has never seen anything else out of that. So <mark>to</mark> him <mark>to</mark> be able <mark>to</mark> run that for five years. It's a crazy Milestone. Oh, okay, so I get you so you find Richie and there you have a business that's been running for five years pure and it doesn't it doesn't grow. Yeah, but it sort of is They there's lunge tivity <mark>to</mark> it. But there is an expansion that they all say, so that's what slick here. So when expansion so now we know we're teaching education gave you the the I actually now see things in an expanded Way by so doing you you then. Well, it's sort of like you made sure go <mark>to</mark> these other guys that were not that do not go too. School basically through you now what all actually it business. I can actually expand instead of instead of so now <mark>how</mark> did you expand because you spent your spending on a crazy rate. I know it's been five years and the business but now there's three. Yeah, <mark>how</mark> the fuck did you get into a sentence? I can't I can't I can't find them and I can't I can't fathom that, you know much respect <mark>to</mark> that word because look it's not an easy thing would be innocent in any Situation what do anything it takes? Yeah. Yeah. Yeah. Yeah. Yeah <mark>to</mark> go there <mark>how</mark> what's the steps there? What's really the steps there <mark>to</mark> go there? You can befor before we open sense and I posted on Facebook. I was like look and I hadn't announced with Sevilla sensing and I said the next move I'm going <mark>to</mark> make there's going <mark>to</mark> be so many people ask me. <mark>How</mark> did you do it? <mark>How</mark> do you speak <mark>to</mark> because kids especially in front of a cigar? I see we have a cardiac fagin about okay, I'll leave my family. Oh, I see who we can have a needle.", "Start Time (s)": 494.8, "End Time (s)": 613.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "on a crazy rate. I know it's been five years and the business but now there's three. Yeah, <mark>how</mark> the fuck did you get into a sentence? I can't I can't I can't find them and I can't I can't fathom that, you know much respect <mark>to</mark> that word because look it's not an easy thing would be innocent in any Situation what do anything it takes? Yeah. Yeah. Yeah. Yeah. Yeah <mark>to</mark> go there <mark>how</mark> what's the steps there? What's really the steps there <mark>to</mark> go there? You can befor before we open sense and I posted on Facebook. I was like look and I hadn't announced with Sevilla sensing and I said the next move I'm going <mark>to</mark> make there's going <mark>to</mark> be so many people ask me. <mark>How</mark> did you do it? <mark>How</mark> do you speak <mark>to</mark> because kids especially in front of a cigar? I see we have a cardiac fagin about okay, I'll leave my family. Oh, I see who we can have a needle. That's that's that's what we know and that's just <mark>how</mark> the nature of the piece like for you <mark>to</mark> get <mark>to</mark> sensing equipment like millivolts in Canada ceco ugly property. Only Sensei, you know. Yeah, but for me, it's like for you <mark>to</mark> do anything that is spectacularly son of the created exactly, but that wasn't the case. It's still not my kids for me. We have one. We have a couple of philosophies but one of the philosophies that we have <mark>to</mark> our creation is that we don't go <mark>to</mark> them. We come <mark>to</mark> they come <mark>to</mark> us. What does it mean? So that means we're willing <mark>to</mark> put in so much work. Consistently for months and four years that you as put seen your first recognizers like we're willing <mark>to</mark> make so much noise and putting so much work that Joe. If you're not working with us is like what are you doing? Everyone else is looking at you. Like what are you doing Global is looking at you like sports scene. <mark>How</mark> are they do we know about these kids and you haven't worked with them. That's the current thing that we dealing with such a big brand we want <mark>to</mark> do a big campaign with them. We drove all had <mark>to</mark> call them", "Start Time (s)": 557.8, "End Time (s)": 677.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a cardiac fagin about okay, I'll leave my family. Oh, I see who we can have a needle. That's that's that's what we know and that's just <mark>how</mark> the nature of the piece like for you <mark>to</mark> get <mark>to</mark> sensing equipment like millivolts in Canada ceco ugly property. Only Sensei, you know. Yeah, but for me, it's like for you <mark>to</mark> do anything that is spectacularly son of the created exactly, but that wasn't the case. It's still not my kids for me. We have one. We have a couple of philosophies but one of the philosophies that we have <mark>to</mark> our creation is that we don't go <mark>to</mark> them. We come <mark>to</mark> they come <mark>to</mark> us. What does it mean? So that means we're willing <mark>to</mark> put in so much work. Consistently for months and four years that you as put seen your first recognizers like we're willing <mark>to</mark> make so much noise and putting so much work that Joe. If you're not working with us is like what are you doing? Everyone else is looking at you. Like what are you doing Global is looking at you like sports scene. <mark>How</mark> are they do we know about these kids and you haven't worked with them. That's the current thing that we dealing with such a big brand we want <mark>to</mark> do a big campaign with them. We drove all had <mark>to</mark> call them and say <mark>how</mark> is it that we know working with these kids but in as well when it's like land on Nina episode of organization why you not approaching these boys so our formula from Jen beehive Jane beehives have sought were doing So Tina, Tina Tina simple even say that <mark>to</mark> the team Jen's must have a valid measure sarcoma saucepan. It's a natural principle. Its natural principle what you put in it comes back. They're gonna eat the only the only stress about it that you never know when they'll come. Yeah, so now <mark>become</mark> a long game now, but that's yeah fantastic Governor motion. I think then you speaking <mark>to</mark> the vector routing we know very well we have been there. You've been there way you would you think what would you actually put in? The work yeah and in then you start feeling with okay, it's time now, they need <mark>to</mark> recognize any doesn't happen. It doesn't happen. So now", "Start Time (s)": 607.8, "End Time (s)": 726.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "looking at you. Like what are you doing Global is looking at you like sports scene. <mark>How</mark> are they do we know about these kids and you haven't worked with them. That's the current thing that we dealing with such a big brand we want <mark>to</mark> do a big campaign with them. We drove all had <mark>to</mark> call them and say <mark>how</mark> is it that we know working with these kids but in as well when it's like land on Nina episode of organization why you not approaching these boys so our formula from Jen beehive Jane beehives have sought were doing So Tina, Tina Tina simple even say that <mark>to</mark> the team Jen's must have a valid measure sarcoma saucepan. It's a natural principle. Its natural principle what you put in it comes back. They're gonna eat the only the only stress about it that you never know when they'll come. Yeah, so now <mark>become</mark> a long game now, but that's yeah fantastic Governor motion. I think then you speaking <mark>to</mark> the vector routing we know very well we have been there. You've been there way you would you think what would you actually put in? The work yeah and in then you start feeling with okay, it's time now, they need <mark>to</mark> recognize any doesn't happen. It doesn't happen. So now someone listening <mark>to</mark> this they need <mark>to</mark> know which look you putting down your head and forget a Spanish. Yeah when you feel like it's time for them <mark>to</mark> come. It's not yet time. Yeah. Yeah, because when it's time for them <mark>to</mark> come you will it's at a point where you would want <mark>to</mark> give a like the burner and Criminal Minds and it's you gonna do work with them. Literally when we spoke. Oh, but see him. Okay, give us a wish list of what you want. And I said <mark>to</mark> them, I mean, I don't want anything from you. Okay, I'll let you don't want there's nothing I want from you. What does that mean? When you say I don't want anything from it means I made a point where I've waited. Like you said I've waited for them <mark>to</mark> come and they didn't come in. I was like no actually need <mark>to</mark> do this by myself. So I said <mark>to</mark> them now it's a matter of you guys now tell me what you need and I can tell you if I can plug into it or not because now as a company, I have my own strategy. I have my own calendar. So if mean I'm getting Nani in my calendar shoot I did not think of you guys", "Start Time (s)": 663.8, "End Time (s)": 783.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So now someone listening <mark>to</mark> this they need <mark>to</mark> know which look you putting down your head and forget a Spanish. Yeah when you feel like it's time for them <mark>to</mark> come. It's not yet time. Yeah. Yeah, because when it's time for them <mark>to</mark> come you will it's at a point where you would want <mark>to</mark> give a like the burner and Criminal Minds and it's you gonna do work with them. Literally when we spoke. Oh, but see him. Okay, give us a wish list of what you want. And I said <mark>to</mark> them, I mean, I don't want anything from you. Okay, I'll let you don't want there's nothing I want from you. What does that mean? When you say I don't want anything from it means I made a point where I've waited. Like you said I've waited for them <mark>to</mark> come and they didn't come in. I was like no actually need <mark>to</mark> do this by myself. So I said <mark>to</mark> them now it's a matter of you guys now tell me what you need and I can tell you if I can plug into it or not because now as a company, I have my own strategy. I have my own calendar. So if mean I'm getting Nani in my calendar shoot I did not think of you guys just <mark>to</mark> be less philosophical about <mark>how</mark> did I do it in terms of <mark>how</mark> did I get suppose see now that get into sensing in putting the work you don't put you don't put in the work blindfold early. You don't fish it's not fishing in <mark>how</mark> you <mark>how</mark> we position the brand we've been specific in the communication that we send out. The brand has <mark>to</mark> look a certain way. The CI has looked at a certain way the quality of the work that we put out is corporate. Covid ITT identity its palaces. Keep are you it has <mark>to</mark> be spun with one in the magazine Sharon Sharon was really time. We share a MOBA <mark>to</mark> listen <mark>to</mark> him. He I want <mark>to</mark> look good. Yeah. Yeah. Yeah exactly. I came before the hard work and then it becomes hard work. I'm willing <mark>to</mark> put in the work but what kind of work so it's been CI it's been it's been covid identity as a brand. It's been positioning has been communication the messages that you send out. What brings WordPress look for.", "Start Time (s)": 725.7, "End Time (s)": 845.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in <mark>how</mark> you <mark>how</mark> we position the brand we've been specific in the communication that we send out. The brand has <mark>to</mark> look a certain way. The CI has looked at a certain way the quality of the work that we put out is corporate. Covid ITT identity its palaces. Keep are you it has <mark>to</mark> be spun with one in the magazine Sharon Sharon was really time. We share a MOBA <mark>to</mark> listen <mark>to</mark> him. He I want <mark>to</mark> look good. Yeah. Yeah. Yeah exactly. I came before the hard work and then it becomes hard work. I'm willing <mark>to</mark> put in the work but what kind of work so it's been CI it's been it's been covid identity as a brand. It's been positioning has been communication the messages that you send out. What brings WordPress look for. They don't look for someone who just says Tina isn't just a cigar see you can be part about that. But then it's does a brain aligned with it doesn't make Financial sense for them <mark>to</mark> <mark>to</mark> <mark>to</mark> bring you in because I'm sure I'm up friends when they want <mark>to</mark> fuck with you is because they see Woody there's money <mark>to</mark> be made friends will never come <mark>to</mark> you if they don't see value and what kind of values is. Only financial or also. Is it so so so for big Brands, here's <mark>how</mark> it works for big Brands. There's no money. You can give spot seen as well crash. Okay, there's literally no man. I can give them and there's no money. I can make them that they haven't made as put seed but then when you're dealing with Brands like that Brands like that till they don't have money problems. They have experienced problems experience. I have a customer experience customer experience now the value they see news like this guy's adding value <mark>to</mark> our customer experience because now They playing the game. They playing the game at a very high level that they understand the Matrix of <mark>how</mark> they converted into money. Uh-huh. Okay, Justin. So now you come in there and adding that experience. You could see Joy taking pylons will be saluted washer. When as a child. It's an experience for you,", "Start Time (s)": 797.2, "End Time (s)": 917.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>to</mark> bring you in because I'm sure I'm up friends when they want <mark>to</mark> fuck with you is because they see Woody there's money <mark>to</mark> be made friends will never come <mark>to</mark> you if they don't see value and what kind of values is. Only financial or also. Is it so so so for big Brands, here's <mark>how</mark> it works for big Brands. There's no money. You can give spot seen as well crash. Okay, there's literally no man. I can give them and there's no money. I can make them that they haven't made as put seed but then when you're dealing with Brands like that Brands like that till they don't have money problems. They have experienced problems experience. I have a customer experience customer experience now the value they see news like this guy's adding value <mark>to</mark> our customer experience because now They playing the game. They playing the game at a very high level that they understand the Matrix of <mark>how</mark> they converted into money. Uh-huh. Okay, Justin. So now you come in there and adding that experience. You could see Joy taking pylons will be saluted washer. When as a child. It's an experience for you, which I don't even have <mark>to</mark> worry about this. But once you start feeling like that, it means you don't even mind buying again. That's why in this is this is something that you did not you did not plan what you wanted <mark>to</mark> do was watch a mataji make money out of it. Yeah. And along the way you like in fact if I'm gonna watch a material and have a company was traumatic it then I'm going <mark>to</mark> look into <mark>how</mark> it looks <mark>how</mark> it feels <mark>how</mark> I communicate it so that I come out <mark>to</mark> the best within the people that are competing. I mean, I mean, I mean, I also goes back <mark>to</mark> its scale and done. Okay, because back <mark>to</mark> scalar after scalar. I worked I will <mark>to</mark> agency. Okay, I got with Isaac and when I built when I'm building the company I'm saying I want this <mark>to</mark> be a company that agency want <mark>to</mark> I work with because also not much take us about understand with most potent and I cannot necessarily working with Nike you working with the agency that has the account and the people that agency look at things differently compared <mark>to</mark> Nike. Okay in like you will look at the expel the stone lintel a specialist or less. This is for my agents will look at the metrics", "Start Time (s)": 857.8, "End Time (s)": 977.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "adding that experience. You could see Joy taking pylons will be saluted washer. When as a child. It's an experience for you, which I don't even have <mark>to</mark> worry about this. But once you start feeling like that, it means you don't even mind buying again. That's why in this is this is something that you did not you did not plan what you wanted <mark>to</mark> do was watch a mataji make money out of it. Yeah. And along the way you like in fact if I'm gonna watch a material and have a company was traumatic it then I'm going <mark>to</mark> look into <mark>how</mark> it looks <mark>how</mark> it feels <mark>how</mark> I communicate it so that I come out <mark>to</mark> the best within the people that are competing. I mean, I mean, I mean, I also goes back <mark>to</mark> its scale and done. Okay, because back <mark>to</mark> scalar after scalar. I worked I will <mark>to</mark> agency. Okay, I got with Isaac and when I built when I'm building the company I'm saying I want this <mark>to</mark> be a company that agency want <mark>to</mark> I work with because also not much take us about understand with most potent and I cannot necessarily working with Nike you working with the agency that has the account and the people that agency look at things differently compared <mark>to</mark> Nike. Okay in like you will look at the expel the stone lintel a specialist or less. This is for my agents will look at the metrics <mark>to</mark> say does this tool fits? My sister was the longevity of the story that it is are you know, so then when we work when I position the brand I'm actually selling <mark>to</mark> agency. I'm not selling <mark>to</mark> neck I'm sorry agency because that's who decides. They can pinpoint what you're telling me now now it is something that you you understand from a perspective of having having studied. Yeah, and and having worked a bit into agency. So there was a bit of background. So you use that yeah, tu-tu-tu-tu-tu-tu creates the brand that you've created we are so the next person would be then they need <mark>to</mark> look towards <mark>how</mark> you did the things. Yeah, and then they could then sort of copy that so now tell me In in terms of the business is the business itself. I'm not going <mark>to</mark> ask you a question about you sir. <mark>How</mark> did you start and right now? I'm sure you've had a lot of", "Start Time (s)": 910.2, "End Time (s)": 1030.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the account and the people that agency look at things differently compared <mark>to</mark> Nike. Okay in like you will look at the expel the stone lintel a specialist or less. This is for my agents will look at the metrics <mark>to</mark> say does this tool fits? My sister was the longevity of the story that it is are you know, so then when we work when I position the brand I'm actually selling <mark>to</mark> agency. I'm not selling <mark>to</mark> neck I'm sorry agency because that's who decides. They can pinpoint what you're telling me now now it is something that you you understand from a perspective of having having studied. Yeah, and and having worked a bit into agency. So there was a bit of background. So you use that yeah, tu-tu-tu-tu-tu-tu creates the brand that you've created we are so the next person would be then they need <mark>to</mark> look towards <mark>how</mark> you did the things. Yeah, and then they could then sort of copy that so now tell me In in terms of the business is the business itself. I'm not going <mark>to</mark> ask you a question about you sir. <mark>How</mark> did you start and right now? I'm sure you've had a lot of interviews. I'll be anonymous. But yeah, so now the they this is sort of intimidation in terms of before not knowing who <mark>to</mark> speak to, you know in terms of a my parents. So you think <mark>to</mark> a my parents put in the work, I'm Appliance as Rosa go away but manager told me about setting the price. It's not the same as setting the price with it take she can say what she take it out of 120. But now when you're talking with a friend Brent comes and say we want <mark>to</mark> work with you and you know that they need <mark>to</mark> pay you your <mark>how</mark> do you know <mark>how</mark> much you need <mark>to</mark> be paid? So let me pick up <mark>to</mark> questions from that. So the one that <mark>how</mark> much is this last question the first question Donna in terms of who you sell <mark>to</mark> here's and I generally write like speaking about them because I'm a businesses in the township, you know, the mistake that we do have some Japan Japan is that we want <mark>to</mark> solve <mark>to</mark> people outside the township. Is that a mistake one mistake we do. Okay, because", "Start Time (s)": 966.2, "End Time (s)": 1086.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "terms of the business is the business itself. I'm not going <mark>to</mark> ask you a question about you sir. <mark>How</mark> did you start and right now? I'm sure you've had a lot of interviews. I'll be anonymous. But yeah, so now the they this is sort of intimidation in terms of before not knowing who <mark>to</mark> speak to, you know in terms of a my parents. So you think <mark>to</mark> a my parents put in the work, I'm Appliance as Rosa go away but manager told me about setting the price. It's not the same as setting the price with it take she can say what she take it out of 120. But now when you're talking with a friend Brent comes and say we want <mark>to</mark> work with you and you know that they need <mark>to</mark> pay you your <mark>how</mark> do you know <mark>how</mark> much you need <mark>to</mark> be paid? So let me pick up <mark>to</mark> questions from that. So the one that <mark>how</mark> much is this last question the first question Donna in terms of who you sell <mark>to</mark> here's and I generally write like speaking about them because I'm a businesses in the township, you know, the mistake that we do have some Japan Japan is that we want <mark>to</mark> solve <mark>to</mark> people outside the township. Is that a mistake one mistake we do. Okay, because once you start wanting <mark>to</mark> sell outside the township the people are set the township can resonate with what you say the way you look is somewhat <mark>how</mark> you say what you saying? Once you step out of the township <mark>to</mark> the sitting image that's expected of you as a business whether we like <mark>to</mark> admit that or not. Okay, what we've done I call it. I call it the coat and one dealer weight will ocean culture set this <mark>to</mark> me said they are Needs <mark>to</mark> live with the LED must serve the masses. Okay, what we're doing at sonship brands that all the big brands are coming into the Township tennis. Look fi the manage your brand pick subtraction from Google shopping my bony, you know, what we've done is said <mark>to</mark> we want <mark>to</mark> sell <mark>to</mark> the masses. We want <mark>to</mark> sell <mark>to</mark> the masses Zone colossal Spider-Man plank. Those are they spending my parents? Don't let the spanner in my insurance companies dynamical 7/8 Geet because when Assurance wants <mark>to</mark> speak <mark>to</mark> these guys, Guys these guys are", "Start Time (s)": 1021.8, "End Time (s)": 1141.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that we do have some Japan Japan is that we want <mark>to</mark> solve <mark>to</mark> people outside the township. Is that a mistake one mistake we do. Okay, because once you start wanting <mark>to</mark> sell outside the township the people are set the township can resonate with what you say the way you look is somewhat <mark>how</mark> you say what you saying? Once you step out of the township <mark>to</mark> the sitting image that's expected of you as a business whether we like <mark>to</mark> admit that or not. Okay, what we've done I call it. I call it the coat and one dealer weight will ocean culture set this <mark>to</mark> me said they are Needs <mark>to</mark> live with the LED must serve the masses. Okay, what we're doing at sonship brands that all the big brands are coming into the Township tennis. Look fi the manage your brand pick subtraction from Google shopping my bony, you know, what we've done is said <mark>to</mark> we want <mark>to</mark> sell <mark>to</mark> the masses. We want <mark>to</mark> sell <mark>to</mark> the masses Zone colossal Spider-Man plank. Those are they spending my parents? Don't let the spanner in my insurance companies dynamical 7/8 Geet because when Assurance wants <mark>to</mark> speak <mark>to</mark> these guys, Guys these guys are Australia Pakistani helices. Okay. How's Josh was going <mark>to</mark> reach those guys. They must do a campaign with Rockfish because we interact with these guys. We have these guys numbers. We know where their children weekends. We know <mark>how</mark> many has they have so healing insights now now now it's inside now, it's in size now. We then I had <mark>to</mark> say <mark>to</mark> see in Jen's Noir eating a banana being a pansy Cassie. Nobody named Angela as Focus then <mark>to</mark> be technical with you in terms of the pricing. I always Squishing <mark>to</mark> say that among these way photographers photographers use as mean among shoot hourly in Chattanooga economic utility ideas. I captured the same price for me. We are not told me a 60% margin rule. Whatever you doing. The margin your profit margin has <mark>to</mark> be a minimum 60 percent. I said cost whatever it goes in if we spend a two-run cost a chunk into a spend I <mark>to</mark> do whatever they ask you <mark>to</mark> do participation markup on it. Okay, that's the trick. I'm gonna sell so", "Start Time (s)": 1079.6, "End Time (s)": 1199.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "insurance companies dynamical 7/8 Geet because when Assurance wants <mark>to</mark> speak <mark>to</mark> these guys, Guys these guys are Australia Pakistani helices. Okay. How's Josh was going <mark>to</mark> reach those guys. They must do a campaign with Rockfish because we interact with these guys. We have these guys numbers. We know where their children weekends. We know <mark>how</mark> many has they have so healing insights now now now it's inside now, it's in size now. We then I had <mark>to</mark> say <mark>to</mark> see in Jen's Noir eating a banana being a pansy Cassie. Nobody named Angela as Focus then <mark>to</mark> be technical with you in terms of the pricing. I always Squishing <mark>to</mark> say that among these way photographers photographers use as mean among shoot hourly in Chattanooga economic utility ideas. I captured the same price for me. We are not told me a 60% margin rule. Whatever you doing. The margin your profit margin has <mark>to</mark> be a minimum 60 percent. I said cost whatever it goes in if we spend a two-run cost a chunk into a spend I <mark>to</mark> do whatever they ask you <mark>to</mark> do participation markup on it. Okay, that's the trick. I'm gonna sell so if you cross the detail and And it's 60 percent that is here. And that's what you put and if you feel like you can put 70 percent you have <mark>to</mark> be able <mark>to</mark> justify the minimum the minimum minimum principle of minimum 60 percent that way even if you are loser least 50% recovery were a profit on top of your course. So that's that's <mark>how</mark> I do it. And then if if you if you're not feeling confident enough <mark>to</mark> put in <mark>to</mark> say, okay, I'm going <mark>to</mark> do 60% Should you leave the deal should you leave the table? Should you contact a good friend of mine who Fri paranormal or not going <mark>to</mark> business training? Then he said <mark>to</mark> me, you know, you never leave the room without the deal so well because because what they do means what the deal means that even if they pay you below 60% you've built a relationship that you've worked with that brand we ever comes after you can still get that because you have a reference and that builds a relationship and I could see X when monthly purchase order for nuclear and we'll ask you have you worked with those guys before once", "Start Time (s)": 1134.1, "End Time (s)": 1254.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0CPd4sMfZkY47t8sfI8y3P", "show_name": "The General Podcast with Banele Rewo", "show_description": "Businessman, Entrepreneur and Writer Banele Rewo speaks to high impact individuals weekly in a no-prepared-questions conversation on the person behind the work. The listener is inspired by learning the 'How- To's' of starting, maintaining and growing a business or career. No poverty fetishes and life struggle selling on this show.", "publisher": "Banele Rewo", "episode_uri": "spotify:episode:5WeGGurhgoXNbWPsI50WpW", "episode_name": "Lethabo Mokoena Walk Fresh ", "episode_description": "In the first of two episodes, Lethabo Mokoena takes us through social media fatigue, how entrepreneurs can negotiate with big brands, how to price yourself in the boardroom and stay alive and not die for entrepreneurship. The episode had to be cut short and we promise to deliver the full length one. For now, there is still plenty you will learn inside. \u00a0  ---   Send in a voice message: https://anchor.fm/banele-rewo/message", "score": 3.5955257, "explanation": "{\n  \"value\": 3.5955257,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 1.0145714,\n      \"description\": \"weight(word_list:how in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0145714,\n          \"description\": \"score(LMDirichletSimilarity, freq=36.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.0902562,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 36.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.2561433,\n      \"description\": \"weight(word_list:to in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2561433,\n          \"description\": \"score(LMDirichletSimilarity, freq=152.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.3318281,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 152.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.7854213,\n      \"description\": \"weight(word_list:become in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.7854213,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.861106,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.5393896,\n      \"description\": \"weight(word_list:rich in 446) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.5393896,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "You're listening <mark>to</mark> phenomenology Club radio. Hello, and thank you for listening <mark>to</mark> this audio podcast. I am buttress the host of phenomenology club, which is an interactive online community of artists and thinkers centered around this content that I create and curate online for us <mark>to</mark> talk about which is why both our tagline for phenomenology club and the subtitle for this discussion series is talk about it. Most of these uploads are originally stream live on our YouTube page. If you're interested in interacting with those as they happen live, please go subscribe and turn on the notifications at youtube.com phenomenology club and in general <mark>to</mark> learn more about our club what we do and <mark>how</mark> you can <mark>become</mark> a member for only one dollar a month, please visit our website at www.ge.com Club. Thank you for listening. Stay trippy.", "Start Time (s)": 2.0, "End Time (s)": 61.3, "Clip Length (min)": 0.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "what we do and <mark>how</mark> you can <mark>become</mark> a member for only one dollar a month, please visit our website at www.ge.com Club. Thank you for listening. Stay trippy. Hello, it's me buttress and this is talk about it. The official podcast series of phenomenology Club this is it guys. This is a this is the upload. We're in 25 years. When I am running for Supreme Leader of the New World Order also known as Pangaea 3000 they will dig up this episode from the archives and say we can't elect buttresses Supreme world leader of Pangaea 3000 look, What this bitch said, look what she said, but you know what? I'm from, New Jersey, so I do what I want <mark>how</mark> y'all doing <mark>how</mark> y'all doing on this beautiful Sunday evening? Because it's Sunday. Did you know that I say, it's Sunday, so it's Sunday. It's actually not Sunday. And if you're listening <mark>to</mark> this not when it's happening now, you'll never ever know when this actually happened ha ha ha. Hey Dad, this is Rachel Johnson. Do I look like a dad bitch? Maybe maybe I am a dad Thanks High Offspring <mark>how</mark> relevant because today. We're going <mark>to</mark> discuss eugenics. I said a few episodes ago that I wanted <mark>to</mark> discuss Eugenics because one of the last times I logged into social media. I saw a lot of people talking about some hot take Richard Dawkins dropped up. I'm coming in a little hot going <mark>to</mark> turn down my levels a bit. Sorry.", "Start Time (s)": 49.4, "End Time (s)": 166.4, "Clip Length (min)": 1.95, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but you know what? I'm from, New Jersey, so I do what I want <mark>how</mark> y'all doing <mark>how</mark> y'all doing on this beautiful Sunday evening? Because it's Sunday. Did you know that I say, it's Sunday, so it's Sunday. It's actually not Sunday. And if you're listening <mark>to</mark> this not when it's happening now, you'll never ever know when this actually happened ha ha ha. Hey Dad, this is Rachel Johnson. Do I look like a dad bitch? Maybe maybe I am a dad Thanks High Offspring <mark>how</mark> relevant because today. We're going <mark>to</mark> discuss eugenics. I said a few episodes ago that I wanted <mark>to</mark> discuss Eugenics because one of the last times I logged into social media. I saw a lot of people talking about some hot take Richard Dawkins dropped up. I'm coming in a little hot going <mark>to</mark> turn down my levels a bit. Sorry. Who's Beth Renato? I know no Beth. My name is Bethany also. I mean Bethany meaning House of poverty. Um, what was I saying? Oh, yeah Richard Dawkins drop some hot take as he's often known <mark>to</mark> drop on Twitter talking about Eugenics which raised a lot of hubbub and I thought it was interesting because Eugenics and the ethics of medicine in general and what kind of Technology we use in our processes of human reproduction these So I think really raised a lot of super controversial super hard <mark>to</mark> navigate philosophical problems, and I do not have a solution but I do have some thoughts", "Start Time (s)": 104.8, "End Time (s)": 224.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I logged into social media. I saw a lot of people talking about some hot take Richard Dawkins dropped up. I'm coming in a little hot going <mark>to</mark> turn down my levels a bit. Sorry. Who's Beth Renato? I know no Beth. My name is Bethany also. I mean Bethany meaning House of poverty. Um, what was I saying? Oh, yeah Richard Dawkins drop some hot take as he's often known <mark>to</mark> drop on Twitter talking about Eugenics which raised a lot of hubbub and I thought it was interesting because Eugenics and the ethics of medicine in general and what kind of Technology we use in our processes of human reproduction these So I think really raised a lot of super controversial super hard <mark>to</mark> navigate philosophical problems, and I do not have a solution but I do have some thoughts that I know many of my peers find <mark>to</mark> be scary and they're scary <mark>to</mark> me as well. I'm going <mark>to</mark> share some of them with you and you're going <mark>to</mark> use it <mark>to</mark> get me now. Not elected as Supreme world leader of Pangaea 3000 but fuck it. Let's go for it. Let's do it. So let's use Richard Dawkins tweet as are launching pad for tonight's discussion. I'm going <mark>to</mark> read the one I think he had a series of tweets because you know, he was going on and on but I'm going <mark>to</mark> read the one that as far as I understand was the source the beginning of this controversy that arose on social media when he dropped it ready. Is from Richard Dawkins, this is what he said.", "Start Time (s)": 156.5, "End Time (s)": 275.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "problems, and I do not have a solution but I do have some thoughts that I know many of my peers find <mark>to</mark> be scary and they're scary <mark>to</mark> me as well. I'm going <mark>to</mark> share some of them with you and you're going <mark>to</mark> use it <mark>to</mark> get me now. Not elected as Supreme world leader of Pangaea 3000 but fuck it. Let's go for it. Let's do it. So let's use Richard Dawkins tweet as are launching pad for tonight's discussion. I'm going <mark>to</mark> read the one I think he had a series of tweets because you know, he was going on and on but I'm going <mark>to</mark> read the one that as far as I understand was the source the beginning of this controversy that arose on social media when he dropped it ready. Is from Richard Dawkins, this is what he said. He said it's one thing <mark>to</mark> deplore Eugenics on ideological political moral grounds. It's quite another <mark>to</mark> conclude that it wouldn't work in practice. Of course, it would it works for cows horses pigs dogs and Roses. Why on Earth wouldn't it work for humans facts ignore Ideology Now let me just say Say first and foremost. I think Richard Dawkins is an asshole. I think he's racist and he's a provocateur. I think he's still high off of his Glory Days when people gave a fuck about listening <mark>to</mark> Christians and atheists fight on stages for hours on end about creationism. And we've all moved past that thankfully not all of us. Really. I mean atheist YouTube is still doing it. They're never going <mark>to</mark> stop there just compared <mark>to</mark> still going having fun, too. Get in the fucking creation myth with Christians all day long. Like aren't you guys fucking bored? So I do not like Richard Dawkins. He", "Start Time (s)": 219.2, "End Time (s)": 338.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "moral grounds. It's quite another <mark>to</mark> conclude that it wouldn't work in practice. Of course, it would it works for cows horses pigs dogs and Roses. Why on Earth wouldn't it work for humans facts ignore Ideology Now let me just say Say first and foremost. I think Richard Dawkins is an asshole. I think he's racist and he's a provocateur. I think he's still high off of his Glory Days when people gave a fuck about listening <mark>to</mark> Christians and atheists fight on stages for hours on end about creationism. And we've all moved past that thankfully not all of us. Really. I mean atheist YouTube is still doing it. They're never going <mark>to</mark> stop there just compared <mark>to</mark> still going having fun, too. Get in the fucking creation myth with Christians all day long. Like aren't you guys fucking bored? So I do not like Richard Dawkins. He sucks. And I think that he wants <mark>to</mark> still be this guy that people are like whoa, <mark>how</mark> can you <mark>how</mark> can you be out here obliterating people with your harsh truths bra so fuck him and at face value <mark>to</mark> this tweet, I think just makes no real sense for one. I mean he says, It's one thing <mark>to</mark> deploy Eugenics and ideological political moral grounds. And I don't even really see the difference between any of these things necessarily especially comparing ideology and morality. I mean morality is in and of itself ideology. I would say so I'm already confused after the first phrase but then he says it's quite another <mark>to</mark> conclude that it wouldn't work in practice and he doesn't even defined what he means by work, but then he gives the example of Was horses pigs and dogs. I don't and Roses. I'm not sure exactly what's up where roses I don't know shit about plants. But all these", "Start Time (s)": 282.4, "End Time (s)": 401.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "be this guy that people are like whoa, <mark>how</mark> can you <mark>how</mark> can you be out here obliterating people with your harsh truths bra so fuck him and at face value <mark>to</mark> this tweet, I think just makes no real sense for one. I mean he says, It's one thing <mark>to</mark> deploy Eugenics and ideological political moral grounds. And I don't even really see the difference between any of these things necessarily especially comparing ideology and morality. I mean morality is in and of itself ideology. I would say so I'm already confused after the first phrase but then he says it's quite another <mark>to</mark> conclude that it wouldn't work in practice and he doesn't even defined what he means by work, but then he gives the example of Was horses pigs and dogs. I don't and Roses. I'm not sure exactly what's up where roses I don't know shit about plants. But all these animals that he lives like it's no secret <mark>to</mark> anybody that dogs out of I think any other species have the most health problems and the most genetically passed on diseases and shit because of all of the Eugenics we have done with cross breeding dogs and breeding dogs for this or that specific purpose. Purpose, you know, so it's like really has this work for any of these things and all the livestock that he mentions these animals that we eat. It's like did it really work for them? I mean, I don't think that they're like at their healthiest I would imagine that they were much healthier before we decided <mark>to</mark> put them into these fucking factories and shoot them up with steroids and breed this one because it's bigger and fatter and all this, you know, so I don't really know what the fuck this man's is talking about. Okay. So Renato says, is that the guy who pose Is with cigarettes, I don't know maybe who knows maybe it's possible sounds sounds like it could be. Um, but anyway, a lot of people were very upset by this", "Start Time (s)": 343.7, "End Time (s)": 463.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "have the most health problems and the most genetically passed on diseases and shit because of all of the Eugenics we have done with cross breeding dogs and breeding dogs for this or that specific purpose. Purpose, you know, so it's like really has this work for any of these things and all the livestock that he mentions these animals that we eat. It's like did it really work for them? I mean, I don't think that they're like at their healthiest I would imagine that they were much healthier before we decided <mark>to</mark> put them into these fucking factories and shoot them up with steroids and breed this one because it's bigger and fatter and all this, you know, so I don't really know what the fuck this man's is talking about. Okay. So Renato says, is that the guy who pose Is with cigarettes, I don't know maybe who knows maybe it's possible sounds sounds like it could be. Um, but anyway, a lot of people were very upset by this tweet. I saw some of the responses <mark>to</mark> it and it raised within me a lot of a lot of thoughts and questions and when thinking about Eugenics, I think that and I think that some interesting problems arise because what is it exactly that we the general human public are critical of and wary of when discussions about Eugenics and especially discussions Like Richard Dawkins is trying <mark>to</mark> start about <mark>how</mark> about <mark>how</mark> potentially Eugenics might not necessarily be some morally corrupt practice at its core. What what is it exactly that we are being critical of and what is eugenics let's ask Merriam-Webster because this is what we do. So Miriam Webster says eugenics", "Start Time (s)": 406.9, "End Time (s)": 525.0, "Clip Length (min)": 1.97, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "some interesting problems arise because what is it exactly that we the general human public are critical of and wary of when discussions about Eugenics and especially discussions Like Richard Dawkins is trying <mark>to</mark> start about <mark>how</mark> about <mark>how</mark> potentially Eugenics might not necessarily be some morally corrupt practice at its core. What what is it exactly that we are being critical of and what is eugenics let's ask Merriam-Webster because this is what we do. So Miriam Webster says eugenics Eugenics Eugenics Eugenics Eugenics the practice or advocacy of controlled selective breeding of human populations in parentheses as by sterilization <mark>to</mark> improve the populations genetic composition. So that's interesting. I've also pulled up Wikipedia because I liked their little definition. I'm going <mark>to</mark> read it really quick. Yeah. Janek's from Wikipedia from the Greek you Janice Wellborn Eugenics is a set of beliefs and practices that aim <mark>to</mark> improve the genetic quality of a human population typically by excluding people and groups judged <mark>to</mark> be inferior and promoting those judge <mark>to</mark> be superior. So in both of these definitions about Eugenics, it's clear that Eugenics is not only the practice of selectively picking and breeding populations for qualities that are perceived <mark>to</mark> be superior, but also by excluding certain populations or variables that would result in some offspring that could be", "Start Time (s)": 483.2, "End Time (s)": 601.9, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "practice or advocacy of controlled selective breeding of human populations in parentheses as by sterilization <mark>to</mark> improve the populations genetic composition. So that's interesting. I've also pulled up Wikipedia because I liked their little definition. I'm going <mark>to</mark> read it really quick. Yeah. Janek's from Wikipedia from the Greek you Janice Wellborn Eugenics is a set of beliefs and practices that aim <mark>to</mark> improve the genetic quality of a human population typically by excluding people and groups judged <mark>to</mark> be inferior and promoting those judge <mark>to</mark> be superior. So in both of these definitions about Eugenics, it's clear that Eugenics is not only the practice of selectively picking and breeding populations for qualities that are perceived <mark>to</mark> be superior, but also by excluding certain populations or variables that would result in some offspring that could be understood as inferior in some capacity and thinking about this has me thinking. Well not just now this has been a thought in my mind for a while, but isn't it true that we already? Practice eugenics in a pretty extreme way and I think the most obvious example I could think of right now is what about <mark>how</mark> often women? Well not just women couples selectively abort offspring that might suffer from some serious health complications. Do we think that this is any different from what's being Dist with Eugenics. What do you guys think? Is this a", "Start Time (s)": 533.0, "End Time (s)": 652.0, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but also by excluding certain populations or variables that would result in some offspring that could be understood as inferior in some capacity and thinking about this has me thinking. Well not just now this has been a thought in my mind for a while, but isn't it true that we already? Practice eugenics in a pretty extreme way and I think the most obvious example I could think of right now is what about <mark>how</mark> often women? Well not just women couples selectively abort offspring that might suffer from some serious health complications. Do we think that this is any different from what's being Dist with Eugenics. What do you guys think? Is this a process of eugenics <mark>to</mark> abort a fetus that quite possibly, you know as confirmed by things like sonograms is going <mark>to</mark> be less healthy than some other Offspring. What do you guys think? Let's get some discussion going in the chat. Boom boom boom answer me. Say something you fucking cowards. I'll tell you what, I think I think that There really is no cord difference between a boarding some fetus that you know might suffer from some health", "Start Time (s)": 594.6, "End Time (s)": 713.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a fetus that quite possibly, you know as confirmed by things like sonograms is going <mark>to</mark> be less healthy than some other Offspring. What do you guys think? Let's get some discussion going in the chat. Boom boom boom answer me. Say something you fucking cowards. I'll tell you what, I think I think that There really is no cord difference between a boarding some fetus that you know might suffer from some health problem as it is <mark>to</mark> selectively breed for any other reason, you know, but at the same time I'm not saying that I necessarily mentally treat this practice with with <mark>how</mark> I perceive Eugenics as a historical thing and quote-unquote. Shin in my mind Edward says yes, it's pretty similar F CK. You says fuck. I mean, yeah, I don't think that there really is a difference. So it makes me wonder exactly what is it then that we are so opposed by when we see taste such as Richard Dawkins. I mean, I'm just appalled by the fucking guys need <mark>to</mark> boost. Oh be relevant in 2020. You should have just let your history speak for itself and maybe people would forget that you're an asshole, but Edward has followed up. However, when people talk about Eugenics, I think they", "Start Time (s)": 656.3, "End Time (s)": 775.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "specific history and the way that it's been implemented. specific groups of people most notably the Nazis, you know, but also in all types of way in American history, you know, we see the US government doing things like allowing the for sterilization of black women in certain communities and other demographics, you know, there's been all types of fucked up shit that is called Eugenics and that we associate the history of with Eugenics the word, you know, but from an idea Logical consideration do we think that the very concept of breeding selectively for traits is in and of itself unethical. What do we think about this? Do we think that <mark>to</mark> breed selectively is in and of itself unethical? Ronaldo again as is he the cigarette guy. He is the cigarette guy Ela. Oh, please post this picture of the cigarette or a link <mark>to</mark> it because now I'm intrigued what do you guys think? Do you think that selective breeding is unethical? I mean, I personally think like I just said we already balls deep in selective breeding and in fact from an evolutionary standpoint, which I'm sure somebody like Richard Dawkins really appreciates because I'm pretty sure he's one of these these fuck and what are they called? Social darwinists types the fucking thinks that everything has its foundations and like evolutionary bullshit. But um, you know, it's undeniable. I think that historically humans reproduce for for reasons that have very much <mark>to</mark> do", "Start Time (s)": 796.1, "End Time (s)": 915.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>to</mark> breed selectively is in and of itself unethical? Ronaldo again as is he the cigarette guy. He is the cigarette guy Ela. Oh, please post this picture of the cigarette or a link <mark>to</mark> it because now I'm intrigued what do you guys think? Do you think that selective breeding is unethical? I mean, I personally think like I just said we already balls deep in selective breeding and in fact from an evolutionary standpoint, which I'm sure somebody like Richard Dawkins really appreciates because I'm pretty sure he's one of these these fuck and what are they called? Social darwinists types the fucking thinks that everything has its foundations and like evolutionary bullshit. But um, you know, it's undeniable. I think that historically humans reproduce for for reasons that have very much <mark>to</mark> do with things like selective breeding, you know. Oh, I'm going <mark>to</mark> reproduce with the VIN. I love my tribe because he is so brolic and manly and can protect our Offspring. He also seems so virile actually. No, he's balding somebody else. I don't know the guy who plays Aquaman he has a lot of hair and he's brolic and so Macho I want <mark>to</mark> have my Offspring with him. He can protect them. And also I think he has millions and millions of sperm per CC which I'm judging by his long beautiful fucking hair. And Jessica person just spoke <mark>to</mark> this when you said I mean, that's just choosing a partner. Right? Right. I would say so Wiley says as long as you're not making sure that other groups are being stepped on I think selective breeding might be okay Edward. No, it isn't we kind of do it when looking for a partner <mark>to</mark> reproduce with", "Start Time (s)": 855.9, "End Time (s)": 973.9, "Clip Length (min)": 1.97, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "for reasons that have very much <mark>to</mark> do with things like selective breeding, you know. Oh, I'm going <mark>to</mark> reproduce with the VIN. I love my tribe because he is so brolic and manly and can protect our Offspring. He also seems so virile actually. No, he's balding somebody else. I don't know the guy who plays Aquaman he has a lot of hair and he's brolic and so Macho I want <mark>to</mark> have my Offspring with him. He can protect them. And also I think he has millions and millions of sperm per CC which I'm judging by his long beautiful fucking hair. And Jessica person just spoke <mark>to</mark> this when you said I mean, that's just choosing a partner. Right? Right. I would say so Wiley says as long as you're not making sure that other groups are being stepped on I think selective breeding might be okay Edward. No, it isn't we kind of do it when looking for a partner <mark>to</mark> reproduce with Jessica liking someone for their eye color physicality is a normal thing. and Edward says once human rights are being impeded on then it becomes unethical but when our human rights becoming impeded on I think that this is just this is really interesting because like I said a moment ago, I think that as medicine moves forward and Technology of medicine moves forward or moral landscape is being completely transformed and really amazing hard <mark>to</mark> navigate ways from a philosophical perspective because look already technology of medicine has done two things like moral arguments as far as survivability and sustainability of people, you know in the past I would say it would be much more considered ethical or at least understood why someone might consider it ethical things like Mercy", "Start Time (s)": 913.7, "End Time (s)": 1032.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "when our human rights becoming impeded on I think that this is just this is really interesting because like I said a moment ago, I think that as medicine moves forward and Technology of medicine moves forward or moral landscape is being completely transformed and really amazing hard <mark>to</mark> navigate ways from a philosophical perspective because look already technology of medicine has done two things like moral arguments as far as survivability and sustainability of people, you know in the past I would say it would be much more considered ethical or at least understood why someone might consider it ethical things like Mercy killings, you know or euthanizing certain people because they have some sort of illness that cannot be be helped or you know, something like this and this is something I think we still extend sympathy <mark>to</mark> and our various conversations. I mean, there's a lot of people that advocate for things like euthanasia, you know, the idea that if people are suffering they should be allowed <mark>to</mark> end their own lives and we should be allowed <mark>to</mark> help them do this, you know, and I think that a similar idea is found in the general public sympathy for people who decide <mark>to</mark> abort their fetuses that might have some sort of genetic problem or some other health disorder, you know, but I feel like this kind of idea is becoming more and more controversial and certain incarnations the more medicine improves, you know, because in the past it might be considered it might be considered merciful in our caveman tribe <mark>to</mark> you know, push the guy with a broken Egg off the cave like no hard feelings, you know, but we think it's like the nice thing <mark>to</mark> do,", "Start Time (s)": 985.7, "End Time (s)": 1105.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "some sort of illness that cannot be be helped or you know, something like this and this is something I think we still extend sympathy <mark>to</mark> and our various conversations. I mean, there's a lot of people that advocate for things like euthanasia, you know, the idea that if people are suffering they should be allowed <mark>to</mark> end their own lives and we should be allowed <mark>to</mark> help them do this, you know, and I think that a similar idea is found in the general public sympathy for people who decide <mark>to</mark> abort their fetuses that might have some sort of genetic problem or some other health disorder, you know, but I feel like this kind of idea is becoming more and more controversial and certain incarnations the more medicine improves, you know, because in the past it might be considered it might be considered merciful in our caveman tribe <mark>to</mark> you know, push the guy with a broken Egg off the cave like no hard feelings, you know, but we think it's like the nice thing <mark>to</mark> do, but now you would never you know, if somebody has some medical ailment if we have technology <mark>to</mark> help you survive. Anyway, then of course now, it seems much more moral <mark>to</mark> use technology <mark>to</mark> help you and it's really interesting because this kind of flies in the face of all that we've come <mark>to</mark> think we know about Evolution, right? And what seems Arie and ideas about Only the Strong Survive and shit. Now it almost seems like the opposite is true. It's more moral <mark>to</mark> you know, promote the sustainability of more vulnerable populations. And I think that this is really interesting when thinking about a thing like IDs, you know in vitro fertilization. I personally", "Start Time (s)": 1037.6, "End Time (s)": 1156.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "kind of flies in the face of all that we've come <mark>to</mark> think we know about Evolution, right? And what seems Arie and ideas about Only the Strong Survive and shit. Now it almost seems like the opposite is true. It's more moral <mark>to</mark> you know, promote the sustainability of more vulnerable populations. And I think that this is really interesting when thinking about a thing like IDs, you know in vitro fertilization. I personally think that IV a IVF Is really kind of some eugenic shit like hardcore. I mean and I think that people have a hard time conceptualizing it this way because the idea is that oh I have problems conceiving or maybe there's like a homosexual couple or something, you know, and so it's seen as like overcoming a disadvantage <mark>to</mark> get IVF. And in that sense. I think a lot of people would not see it as something that aligns with Eugenics, but it totally is I'm a first of all you have Have <mark>to</mark> be wealthy <mark>to</mark> afford such a thing. Right? It's kind of like the upper class is basically just fucking enforcing their right <mark>to</mark> reproduce and in America, if you're wealthy, even if you have some sort of reproductive problems, you can still reproduce Anyway by hiring out the body of some woman probably that lives in India and is getting paid 10% of what an American surrogate would get paid which is still fucking nothing and then getting <mark>to</mark> Deuce you know because you're <mark>rich</mark> and because you're <mark>rich</mark> you can afford this insanely technologically advanced procedure and let me just stay for the record. I mean I am against surrogacy period I think that it's a completely unethical practice. I don't believe that it should be", "Start Time (s)": 1122.1, "End Time (s)": 1240.5, "Clip Length (min)": 1.97, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "And in that sense. I think a lot of people would not see it as something that aligns with Eugenics, but it totally is I'm a first of all you have Have <mark>to</mark> be wealthy <mark>to</mark> afford such a thing. Right? It's kind of like the upper class is basically just fucking enforcing their right <mark>to</mark> reproduce and in America, if you're wealthy, even if you have some sort of reproductive problems, you can still reproduce Anyway by hiring out the body of some woman probably that lives in India and is getting paid 10% of what an American surrogate would get paid which is still fucking nothing and then getting <mark>to</mark> Deuce you know because you're <mark>rich</mark> and because you're <mark>rich</mark> you can afford this insanely technologically advanced procedure and let me just stay for the record. I mean I am against surrogacy period I think that it's a completely unethical practice. I don't believe that it should be allowed for women <mark>to</mark> hire out their bodies for something that can literally kill them. I think people forget <mark>how</mark> risky pregnancy She is <mark>to</mark> Women's Health women died in childbirth all the time and especially are more vulnerable populations black women died in childbirth at a much higher rate than white women in America. And if you look up where surrogates are most often hired from the vast majority of them are in India and an Eastern European countries. I don't think it's right that <mark>rich</mark> wealthy people from America can go into these other countries. Is higher up these women that are really vulnerable really desperate for money pay them still barely anything, you know <mark>to</mark> basically rent out their fucking bodies for a thing that they could very well die from and even women who exist in more first world quote-unquote won't quote country still die from surrogacy", "Start Time (s)": 1182.5, "End Time (s)": 1302.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in childbirth at a much higher rate than white women in America. And if you look up where surrogates are most often hired from the vast majority of them are in India and an Eastern European countries. I don't think it's right that <mark>rich</mark> wealthy people from America can go into these other countries. Is higher up these women that are really vulnerable really desperate for money pay them still barely anything, you know <mark>to</mark> basically rent out their fucking bodies for a thing that they could very well die from and even women who exist in more first world quote-unquote won't quote country still die from surrogacy a surrogate just died. I think she was in the UK. It happens. So that's my Fucking hot take about surrogacy. So this is also why I'm against IVF. I think that I might be more open <mark>to</mark> it in another context, but the fact that it requires surrogacy in many instances. I'm against but I do think also that it's very very classist. Fuck it. I said it Wiley, <mark>how</mark> did these fucking videos always make me think I agree with shit. Like Eugenics. Hey, hey, nothing. Nothing has been said yet. But where was I going before? I went off into my surrogacy tantrum. Yeah. It's interesting <mark>how</mark> medicine I think has completely transformed the moral landscape now, it's almost I mean it's very confusing because okay, we think I think that like all of these arguments are so mediated by the various contexts, you know like a thing. like a thing like like what we were saying a moment ago, you know Eugenics is ideologically perhaps not a thing that is", "Start Time (s)": 1258.3, "End Time (s)": 1377.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "but I do think also that it's very very classist. Fuck it. I said it Wiley, <mark>how</mark> did these fucking videos always make me think I agree with shit. Like Eugenics. Hey, hey, nothing. Nothing has been said yet. But where was I going before? I went off into my surrogacy tantrum. Yeah. It's interesting <mark>how</mark> medicine I think has completely transformed the moral landscape now, it's almost I mean it's very confusing because okay, we think I think that like all of these arguments are so mediated by the various contexts, you know like a thing. like a thing like like what we were saying a moment ago, you know Eugenics is ideologically perhaps not a thing that is morally corrupt or or wrong at its most fundamental level, but were critical of eugenics because of things like <mark>how</mark> it's been used <mark>to</mark> promote racist agendas, you know, the Nazis love it white supremacist love it, you know, it has a history that aligns very much with these institutions of scientific racism and Such, you know, but the very idea of breeding selectively I mean is it wrong because you also have <mark>to</mark> think now that we are on the brink of things like super genetic editing and shit, what about that? You know because right now these conversations are still some mediated by our current reality. We're only this or that is possible, but think about this Chinese scientists who Who recently made these twin girls with all of these genetic edits, you know, I think that it wasn't even revealed <mark>to</mark> the public exactly what he did <mark>to</mark> them. But I know that one of the genetic edits that he did on them was supposed <mark>to</mark>", "Start Time (s)": 1327.1, "End Time (s)": 1446.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "morally corrupt or or wrong at its most fundamental level, but were critical of eugenics because of things like <mark>how</mark> it's been used <mark>to</mark> promote racist agendas, you know, the Nazis love it white supremacist love it, you know, it has a history that aligns very much with these institutions of scientific racism and Such, you know, but the very idea of breeding selectively I mean is it wrong because you also have <mark>to</mark> think now that we are on the brink of things like super genetic editing and shit, what about that? You know because right now these conversations are still some mediated by our current reality. We're only this or that is possible, but think about this Chinese scientists who Who recently made these twin girls with all of these genetic edits, you know, I think that it wasn't even revealed <mark>to</mark> the public exactly what he did <mark>to</mark> them. But I know that one of the genetic edits that he did on them was supposed <mark>to</mark> be that they were I think immune <mark>to</mark> HIV which obviously I mean he did not do because he really felt there was some true fear of these girls Contracting it it was just Basically using their bodies as some sort of fucking lab rat thing so he could test out this thing he was doing you know, what about things like this? What about humans wanting <mark>to</mark> have I don't know longer legs or fucking bigger titties or Wings, even you know, like as technology advances, which it has already done and is going <mark>to</mark> can keep is going <mark>to</mark> keep doing what about this. Is it ethical <mark>to</mark> <mark>To</mark> use medicine and Technology <mark>to</mark> advance", "Start Time (s)": 1377.9, "End Time (s)": 1496.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Who recently made these twin girls with all of these genetic edits, you know, I think that it wasn't even revealed <mark>to</mark> the public exactly what he did <mark>to</mark> them. But I know that one of the genetic edits that he did on them was supposed <mark>to</mark> be that they were I think immune <mark>to</mark> HIV which obviously I mean he did not do because he really felt there was some true fear of these girls Contracting it it was just Basically using their bodies as some sort of fucking lab rat thing so he could test out this thing he was doing you know, what about things like this? What about humans wanting <mark>to</mark> have I don't know longer legs or fucking bigger titties or Wings, even you know, like as technology advances, which it has already done and is going <mark>to</mark> can keep is going <mark>to</mark> keep doing what about this. Is it ethical <mark>to</mark> <mark>To</mark> use medicine and Technology <mark>to</mark> advance quote-unquote our bodies. What do we think about this? Because this is what I think I think that as a stands right now. Like I just said medicine has transformed our current understanding of ethics. And right now we're at a popular idea and I think one that we all pretty much subscribe <mark>to</mark> is we are morally obligated <mark>to</mark> use medicine and Technology <mark>to</mark> help people. Who are Vanish if someone is dying on the street, and we know that we could use a defibrillator or a shot of epinephrine <mark>to</mark> revive them and let them survive <mark>to</mark> throw them in", "Start Time (s)": 1430.2, "End Time (s)": 1549.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>to</mark> keep doing what about this. Is it ethical <mark>to</mark> <mark>To</mark> use medicine and Technology <mark>to</mark> advance quote-unquote our bodies. What do we think about this? Because this is what I think I think that as a stands right now. Like I just said medicine has transformed our current understanding of ethics. And right now we're at a popular idea and I think one that we all pretty much subscribe <mark>to</mark> is we are morally obligated <mark>to</mark> use medicine and Technology <mark>to</mark> help people. Who are Vanish if someone is dying on the street, and we know that we could use a defibrillator or a shot of epinephrine <mark>to</mark> revive them and let them survive <mark>to</mark> throw them in an ambulance and bring him <mark>to</mark> the ER. If it's true that it's morally incumbent on us <mark>to</mark> use medicine in these kinds of scenarios, then wouldn't it also be morally incumbent on us <mark>to</mark> also promote and Advance the health of Our Offspring with our technology if it's our moral responsibility <mark>to</mark> use medicine and ethical matters <mark>to</mark> promote survivability than wouldn't that also be true for future outcomes. Mmm-hmm. but we thank Wiley where my big tittied Wing It bitches at Right here, baby. Did you guys watch that show on natural selection", "Start Time (s)": 1485.4, "End Time (s)": 1605.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "on us <mark>to</mark> use medicine in these kinds of scenarios, then wouldn't it also be morally incumbent on us <mark>to</mark> also promote and Advance the health of Our Offspring with our technology if it's our moral responsibility <mark>to</mark> use medicine and ethical matters <mark>to</mark> promote survivability than wouldn't that also be true for future outcomes. Mmm-hmm. but we thank Wiley where my big tittied Wing It bitches at Right here, baby. Did you guys watch that show on natural selection on Netflix? That was really fascinating and also really fucking scary because I personally had no idea <mark>how</mark> far we had comb in genetic engineering and ever since watching that series. I've been researching it and I really am kind of floored and kind of shook because you know, if you saw that show, you know that they're already doing things like releasing entire populations of genetically modified mice into certain. Areas <mark>to</mark> do things like, you know combat the spread of certain tick populations and shit, you know, they're trying <mark>to</mark> use genetically modified animal populations <mark>to</mark> help with various like ecological problems, which I just find <mark>to</mark> be scary because as all of this technology is still so new and untested, you know, I just I feel like so many things could probably go wrong that we don't even understand yet. You know, what if one of these mice has some in after Contracting this or that disease and the disease has <mark>become</mark> super fucking disease and then it's", "Start Time (s)": 1554.1, "End Time (s)": 1673.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "fucking scary because I personally had no idea <mark>how</mark> far we had comb in genetic engineering and ever since watching that series. I've been researching it and I really am kind of floored and kind of shook because you know, if you saw that show, you know that they're already doing things like releasing entire populations of genetically modified mice into certain. Areas <mark>to</mark> do things like, you know combat the spread of certain tick populations and shit, you know, they're trying <mark>to</mark> use genetically modified animal populations <mark>to</mark> help with various like ecological problems, which I just find <mark>to</mark> be scary because as all of this technology is still so new and untested, you know, I just I feel like so many things could probably go wrong that we don't even understand yet. You know, what if one of these mice has some in after Contracting this or that disease and the disease has <mark>become</mark> super fucking disease and then it's fucking a monkey and then Dustin Hoffman and a fucking helicopter and fucking shit while he says Eugenics is about raising the elite and oppressing the inferior, but we are able <mark>to</mark> improve the inferior with our medicines. Jessica it's going in that direction. So we might as well hop on the train. Hmm Edward. Well if Eugenics prevents only bad things from being passed on sure but doing Eugenics probably prevents other things from being passed on along that way. I assume I am no scientist. Well, I mean it's interesting because I think in this conversation, especially it really all has <mark>to</mark> do with what people think is bad. You know, it's easy for us all <mark>to</mark> agree that a thing like, you know, A", "Start Time (s)": 1610.8, "End Time (s)": 1730.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "You know, what if one of these mice has some in after Contracting this or that disease and the disease has <mark>become</mark> super fucking disease and then it's fucking a monkey and then Dustin Hoffman and a fucking helicopter and fucking shit while he says Eugenics is about raising the elite and oppressing the inferior, but we are able <mark>to</mark> improve the inferior with our medicines. Jessica it's going in that direction. So we might as well hop on the train. Hmm Edward. Well if Eugenics prevents only bad things from being passed on sure but doing Eugenics probably prevents other things from being passed on along that way. I assume I am no scientist. Well, I mean it's interesting because I think in this conversation, especially it really all has <mark>to</mark> do with what people think is bad. You know, it's easy for us all <mark>to</mark> agree that a thing like, you know, A congenital deformity is bad, you know, but there's other people like the scientific races of the early 19th century, that would also say this or that race is bad. It's biologically inferior and they would also Say this isn't some moral argument or stance. It's it has nothing <mark>to</mark> do with anything except that science says that you know, this is a biological disadvantage don't blame us, you know, so, who are we really <mark>to</mark> say what Easter is not bad? Because we know that institutions like science themselves are biased, you know, maybe it's wrong that we interfere at all. But then if it's wrong that we interfere at all then <mark>how</mark> can we also feel as if it is our Our moral duty <mark>to</mark> use medicine <mark>to</mark> help disadvantaged populations. Hmm.", "Start Time (s)": 1664.0, "End Time (s)": 1783.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "scientist. Well, I mean it's interesting because I think in this conversation, especially it really all has <mark>to</mark> do with what people think is bad. You know, it's easy for us all <mark>to</mark> agree that a thing like, you know, A congenital deformity is bad, you know, but there's other people like the scientific races of the early 19th century, that would also say this or that race is bad. It's biologically inferior and they would also Say this isn't some moral argument or stance. It's it has nothing <mark>to</mark> do with anything except that science says that you know, this is a biological disadvantage don't blame us, you know, so, who are we really <mark>to</mark> say what Easter is not bad? Because we know that institutions like science themselves are biased, you know, maybe it's wrong that we interfere at all. But then if it's wrong that we interfere at all then <mark>how</mark> can we also feel as if it is our Our moral duty <mark>to</mark> use medicine <mark>to</mark> help disadvantaged populations. Hmm. What do we fucking do? It's Tricky it's very tricky because on the one hand. Yeah, if we're going <mark>to</mark> do things like allow for abortion when you know, well we should allow for abortion in any circumstance. Okay. This is my moral ideological position. So It ultimately doesn't really matter. But if we are going <mark>to</mark> publicly approve of from a moral stance the idea of aborting. fetuses that have some sort of deformity or you know some sort of health problem if that's true then I have <mark>to</mark> wonder", "Start Time (s)": 1715.1, "End Time (s)": 1831.5, "Clip Length (min)": 1.94, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "interfere at all. But then if it's wrong that we interfere at all then <mark>how</mark> can we also feel as if it is our Our moral duty <mark>to</mark> use medicine <mark>to</mark> help disadvantaged populations. Hmm. What do we fucking do? It's Tricky it's very tricky because on the one hand. Yeah, if we're going <mark>to</mark> do things like allow for abortion when you know, well we should allow for abortion in any circumstance. Okay. This is my moral ideological position. So It ultimately doesn't really matter. But if we are going <mark>to</mark> publicly approve of from a moral stance the idea of aborting. fetuses that have some sort of deformity or you know some sort of health problem if that's true then I have <mark>to</mark> wonder Why because what's the justification the justification is that this being will suffer right? So if that's morally acceptable right then is it morally acceptable <mark>to</mark> allow people <mark>to</mark> have that Offspring. Anyway, if it's morally acceptable for somebody <mark>to</mark> say, okay. This child has some sort of A congenital deformity even though I know that they could be sustained what modern medicine I'm going <mark>to</mark> choose to. Or instead if that's morally righteous. Let's say then wouldn't it be morally wrong <mark>to</mark> allow people <mark>to</mark> say actually, you know what? I know. This child is going <mark>to</mark> have a deformity but I'm going <mark>to</mark> have it. Anyway Hmm. This is where it gets really controversial, huh? Because both of these", "Start Time (s)": 1770.8, "End Time (s)": 1890.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "fetuses that have some sort of deformity or you know some sort of health problem if that's true then I have <mark>to</mark> wonder Why because what's the justification the justification is that this being will suffer right? So if that's morally acceptable right then is it morally acceptable <mark>to</mark> allow people <mark>to</mark> have that Offspring. Anyway, if it's morally acceptable for somebody <mark>to</mark> say, okay. This child has some sort of A congenital deformity even though I know that they could be sustained what modern medicine I'm going <mark>to</mark> choose to. Or instead if that's morally righteous. Let's say then wouldn't it be morally wrong <mark>to</mark> allow people <mark>to</mark> say actually, you know what? I know. This child is going <mark>to</mark> have a deformity but I'm going <mark>to</mark> have it. Anyway Hmm. This is where it gets really controversial, huh? Because both of these things can't be simultaneously true. but I think that As it stands right now. They're kind of considered <mark>to</mark> be simultaneously true and why? Because ultimately we are in a mode. I think we're basically the desire of the parents is ultimately seen as the thing that should be venerated, you know, and this is why I think personally we put so much. Well, we don't we're never really allowed <mark>to</mark> be critical of Institutions like IVF, you know, and people will cry they're fucking eyes out on television and stuff talking about <mark>how</mark> they had <mark>to</mark> do this or that IVF when I don't give a fuck", "Start Time (s)": 1823.0, "End Time (s)": 1941.8, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>to</mark> say actually, you know what? I know. This child is going <mark>to</mark> have a deformity but I'm going <mark>to</mark> have it. Anyway Hmm. This is where it gets really controversial, huh? Because both of these things can't be simultaneously true. but I think that As it stands right now. They're kind of considered <mark>to</mark> be simultaneously true and why? Because ultimately we are in a mode. I think we're basically the desire of the parents is ultimately seen as the thing that should be venerated, you know, and this is why I think personally we put so much. Well, we don't we're never really allowed <mark>to</mark> be critical of Institutions like IVF, you know, and people will cry they're fucking eyes out on television and stuff talking about <mark>how</mark> they had <mark>to</mark> do this or that IVF when I don't give a fuck cancel me Pangaea 3000 but it's like dude. There's so many kids in the fucking world without parents. You think I'm gonna sit here and cry for you because your wealthiest like fucking Dollar IVF procedure is having complications. I don't give a fuck. I think you're kind of a sociopath but this is kind of where we're at right now. And I think where we've always been at upholding this social norm and ideal that it is everybody's god-given right <mark>to</mark> reproduce, you know, and especially women because this is our role as women in the world, right? This is my one. This is my one thing. I was born <mark>to</mark> do <mark>to</mark> have a fucking baby. Be so of course people are going <mark>to</mark> justify whatever I need <mark>to</mark> do <mark>to</mark> have my own baby. Even if it's paying thousands and thousands of dollars <mark>to</mark>", "Start Time (s)": 1878.9, "End Time (s)": 1995.4, "Clip Length (min)": 1.94, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "of Institutions like IVF, you know, and people will cry they're fucking eyes out on television and stuff talking about <mark>how</mark> they had <mark>to</mark> do this or that IVF when I don't give a fuck cancel me Pangaea 3000 but it's like dude. There's so many kids in the fucking world without parents. You think I'm gonna sit here and cry for you because your wealthiest like fucking Dollar IVF procedure is having complications. I don't give a fuck. I think you're kind of a sociopath but this is kind of where we're at right now. And I think where we've always been at upholding this social norm and ideal that it is everybody's god-given right <mark>to</mark> reproduce, you know, and especially women because this is our role as women in the world, right? This is my one. This is my one thing. I was born <mark>to</mark> do <mark>to</mark> have a fucking baby. Be so of course people are going <mark>to</mark> justify whatever I need <mark>to</mark> do <mark>to</mark> have my own baby. Even if it's paying thousands and thousands of dollars <mark>to</mark> get this incredibly Advanced medical procedure that I can afford because I am wealthy and affluent in the United States of America, you know, I mean, I I try <mark>to</mark> understand <mark>how</mark> I can like excess of you point where I feel safe. Add when I just see these people crying about IVF friendship, but I don't like dude. Uh, you would rather go through all this shit then just fucking adopt a kid and we know for a fact that there's so many fucking kids without parents. Like what are you doing? I don't think that she should I don't think that she should be legal. That's <mark>how</mark> I feel, but it's because of our contextual reality, you know, I think that if it were not true Ooh that there were thousands and thousands of children in foster care", "Start Time (s)": 1929.5, "End Time (s)": 2048.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "medical procedure that I can afford because I am wealthy and affluent in the United States of America, you know, I mean, I I try <mark>to</mark> understand <mark>how</mark> I can like excess of you point where I feel safe. Add when I just see these people crying about IVF friendship, but I don't like dude. Uh, you would rather go through all this shit then just fucking adopt a kid and we know for a fact that there's so many fucking kids without parents. Like what are you doing? I don't think that she should I don't think that she should be legal. That's <mark>how</mark> I feel, but it's because of our contextual reality, you know, I think that if it were not true Ooh that there were thousands and thousands of children in foster care and thousands and thousands of children without parents and perhaps we had some sort of reproduction crisis where you know, we needed IVF <mark>to</mark> reproduce. I don't know what I would think in that scenario. I would probably think that we got there because we fucked ourselves up by doing all this gene splicing for the centuries that lead us <mark>to</mark> that point or something. So I would probably just be like fuck it. This point but yeah, if that weren't true than maybe I'm in another context. I would think IVF is totally good and reasonable and we need it <mark>to</mark> continue the great human race, but as it stands right now contextually, I don't really see any moral justification for a thing like IVF. What are you guys talking about? If someone wanted autism <mark>to</mark> not be passed on with that be morally or ethically wrong. Mmm. Well that is a really interesting question and also one that I think brings us", "Start Time (s)": 2000.5, "End Time (s)": 2119.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I don't know what I would think in that scenario. I would probably think that we got there because we fucked ourselves up by doing all this gene splicing for the centuries that lead us <mark>to</mark> that point or something. So I would probably just be like fuck it. This point but yeah, if that weren't true than maybe I'm in another context. I would think IVF is totally good and reasonable and we need it <mark>to</mark> continue the great human race, but as it stands right now contextually, I don't really see any moral justification for a thing like IVF. What are you guys talking about? If someone wanted autism <mark>to</mark> not be passed on with that be morally or ethically wrong. Mmm. Well that is a really interesting question and also one that I think brings us back a little bit <mark>to</mark> a moment ago when we're thinking about things like what is bad what is considered bad and for what reasons, you know? someone else just said is autism genetic. Anyway, I mean my I'm not a scientist either, you know, but I have I don't like <mark>to</mark> get conspiratorial. Okay, but if I get conspiratorial on any topic, I would say maybe it's my feelings about autism where I feel as if maybe autism itself is some sort of evolutionary mutation, you know, because really a lot of are autistic population I think has really Traits that could be understood as super desirable. You know, I mean, look at autistic savants like the kind of computational abilities. These people have is just incredible,", "Start Time (s)": 2061.5, "End Time (s)": 2180.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "my I'm not a scientist either, you know, but I have I don't like <mark>to</mark> get conspiratorial. Okay, but if I get conspiratorial on any topic, I would say maybe it's my feelings about autism where I feel as if maybe autism itself is some sort of evolutionary mutation, you know, because really a lot of are autistic population I think has really Traits that could be understood as super desirable. You know, I mean, look at autistic savants like the kind of computational abilities. These people have is just incredible, you know, but we also know that evolution is not really necessarily an intentional or conscious process and evolution misfires all the time populations have had evolutionary mutations where the mutation ended up hurting them, you know, so it stands <mark>to</mark> reason that these kinds of things can still exist in human populations and I didn't make this up either. Well, I actually did make it up and then I Googled it <mark>to</mark> see if anyone else thought the same thing and there are scientists that are pursuing this Theory. Okay, so it's not totally stupid but shit, I'm open <mark>to</mark> the idea, you know, because why is the prevalent so high and you know, I'm not a scientist. I'm not even going <mark>to</mark> go that way but it's an interesting question Edward, you know asking is it is it a if you knew that your child had autism. Is it morally right or wrong <mark>to</mark> abort? What do you guys think about that?", "Start Time (s)": 2138.7, "End Time (s)": 2242.5, "Clip Length (min)": 1.73, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it up and then I Googled it <mark>to</mark> see if anyone else thought the same thing and there are scientists that are pursuing this Theory. Okay, so it's not totally stupid but shit, I'm open <mark>to</mark> the idea, you know, because why is the prevalent so high and you know, I'm not a scientist. I'm not even going <mark>to</mark> go that way but it's an interesting question Edward, you know asking is it is it a if you knew that your child had autism. Is it morally right or wrong <mark>to</mark> abort? What do you guys think about that? Jessica says it does get tricky with bodily autonomy pushing for the right <mark>to</mark> abortion and getting faced with the need for IVF is weird. What do you mean by that? Yeah. I mean, I'm somebody who I really wish that in all of these abortion debates people just brought up the fact that pregnancy is literally a risk <mark>to</mark> your life and that as far as I think as far as I'm concerned is all that needs <mark>to</mark> Be said yeah, I never see it said you know if we push this idea more because it's so true. I mean childbirth has killed millions and millions of women throughout the history of humanity. I'm pretty sure that childbirth was like the number one cause of death among women until like last century or maybe the one previous, you know, childbirth is risky as fuck pregnancy is risky as fuck, you know, and that shit even when you don't die completely transforms your body, you know, but like I said, Said people have no empathy. So we don't even have <mark>to</mark> go <mark>to</mark> that next Point. All that needs <mark>to</mark> be said is it's a life.", "Start Time (s)": 2204.4, "End Time (s)": 2323.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "does get tricky with bodily autonomy pushing for the right <mark>to</mark> abortion and getting faced with the need for IVF is weird. What do you mean by that? Yeah. I mean, I'm somebody who I really wish that in all of these abortion debates people just brought up the fact that pregnancy is literally a risk <mark>to</mark> your life and that as far as I think as far as I'm concerned is all that needs <mark>to</mark> Be said yeah, I never see it said you know if we push this idea more because it's so true. I mean childbirth has killed millions and millions of women throughout the history of humanity. I'm pretty sure that childbirth was like the number one cause of death among women until like last century or maybe the one previous, you know, childbirth is risky as fuck pregnancy is risky as fuck, you know, and that shit even when you don't die completely transforms your body, you know, but like I said, Said people have no empathy. So we don't even have <mark>to</mark> go <mark>to</mark> that next Point. All that needs <mark>to</mark> be said is it's a life. It's a risk <mark>to</mark> your life. That should be enough that should be enough <mark>to</mark> let people abort for whatever reason they fucking want. You know, I think it should be a woman's Choice obviously and this is really all that needs <mark>to</mark> be said, of course, there's all types of reasons. Why else you might support abortion, especially in our specific context, but I think that that's really all that needs <mark>to</mark> be stated. What else could be stated? You know, why do I have <mark>to</mark> risk my life for somebody else? I don't you know, no one can make you jump in front of a moving train <mark>to</mark> save somebody on the tracks because this is what people are saying, you know, like oh well. Well doesn't matter. Let me continue. Nobody can make you push somebody off of a of a train platform with a train moving towards you guys on the tracks, even if maybe", "Start Time (s)": 2260.4, "End Time (s)": 2379.2, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "It's a risk <mark>to</mark> your life. That should be enough that should be enough <mark>to</mark> let people abort for whatever reason they fucking want. You know, I think it should be a woman's Choice obviously and this is really all that needs <mark>to</mark> be said, of course, there's all types of reasons. Why else you might support abortion, especially in our specific context, but I think that that's really all that needs <mark>to</mark> be stated. What else could be stated? You know, why do I have <mark>to</mark> risk my life for somebody else? I don't you know, no one can make you jump in front of a moving train <mark>to</mark> save somebody on the tracks because this is what people are saying, you know, like oh well. Well doesn't matter. Let me continue. Nobody can make you push somebody off of a of a train platform with a train moving towards you guys on the tracks, even if maybe maybe you could both survive, even if it seems like you probably could bolt survive. Nobody's going <mark>to</mark> hold it against you or criminalize you for not getting on that fucking train platform and saving this person. That's <mark>how</mark> we should think about abortion. You know, it might be true that yeah. Like maybe they're seems like a good possibility that all survive I'll be fine, but the fact remains that I can die, so I should not be criminalized for choosing not <mark>to</mark> participate in this thing case fucking clothes Jersey. Mmm, Caitlin I don't think there is a need for abortion just because your child is autistic. But I mean if someone were <mark>to</mark> do it, I don't know if I'd be mad or anything. Well, I'm not sure if you could tell whether or not I'm pretty positive you can't actually no you cannot because autism I believe is measured right based on like social variables and <mark>how</mark> they interact with others and their speech patterns and all this so you can't tell but you know people already do things like a board for other quote unquote", "Start Time (s)": 2324.1, "End Time (s)": 2443.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "with a train moving towards you guys on the tracks, even if maybe maybe you could both survive, even if it seems like you probably could bolt survive. Nobody's going <mark>to</mark> hold it against you or criminalize you for not getting on that fucking train platform and saving this person. That's <mark>how</mark> we should think about abortion. You know, it might be true that yeah. Like maybe they're seems like a good possibility that all survive I'll be fine, but the fact remains that I can die, so I should not be criminalized for choosing not <mark>to</mark> participate in this thing case fucking clothes Jersey. Mmm, Caitlin I don't think there is a need for abortion just because your child is autistic. But I mean if someone were <mark>to</mark> do it, I don't know if I'd be mad or anything. Well, I'm not sure if you could tell whether or not I'm pretty positive you can't actually no you cannot because autism I believe is measured right based on like social variables and <mark>how</mark> they interact with others and their speech patterns and all this so you can't tell but you know people already do things like a board for other quote unquote mental disabilities. You know, I think that autism personally is seen as a much more controversial thing than some of these other things that we call mental disabilities or whatever because so many normally functioning quote-unquote people have autism, you know, I think that's really why people are a pole. I don't know if that's controversial but I think that that's true, you know, and that's kind of fucked up when you think about it, you know, because if you if you are more upset by people by this idea that like, oh maybe people will abort their fetus because it might be autistic then you would be for somebody aborting their fetus because you know, they have some other mental handicap that isn't that really fucked up because the only difference really is that if you're", "Start Time (s)": 2374.4, "End Time (s)": 2494.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the whole moral justification for any of this. The idea that you would abort a fetus because you know, it has less of a chance of doing okay, I guess without let without assistance in society. I don't know it's fucked up. This is like a philosophical fucking landmine. Yes, just like Jessica just said also the autism spectrum is so broad includes those with very low functioning as well as people Asperger's. Yeah, I mean, I personally think that the the spectrum is way way wider than it probably will end up being a in the realm of clinical diagnosis. You know, I think that as time goes on because really autism is only a thing that has been named and research within the past I don't know <mark>how</mark> many years you know I imagine that the classification systems that exist for it will change dramatically you know and I suspect that a lot of people on the autism spectrum really have nothing in common you know I think that right now I mean Psychiatry and psychology as institutions really are held <mark>to</mark> no meaningful standard at all fuck it they just like suck and they both still have so much pseudoscience within them I would not be surprised if within even the next decade they tell us actually everyone that we said was on the autism spectrum like the people on opposite poles really have absolutely nothing in common you know I wouldn't be surprised at all right now they're still just kind of grouping these people based on like General perceived characteristics you know Yeah, Edward Edward says okay, maybe not autism. But what about Down", "Start Time (s)": 2502.4, "End Time (s)": 2621.9, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I mean Psychiatry and psychology as institutions really are held <mark>to</mark> no meaningful standard at all fuck it they just like suck and they both still have so much pseudoscience within them I would not be surprised if within even the next decade they tell us actually everyone that we said was on the autism spectrum like the people on opposite poles really have absolutely nothing in common you know I wouldn't be surprised at all right now they're still just kind of grouping these people based on like General perceived characteristics you know Yeah, Edward Edward says okay, maybe not autism. But what about Down syndrome, there are functioning quote-unquote people with Down Syndrome. Exactly. You know, I think that down syndrome is just generally seen by the public as the thing that is more of a handicap, you know, and this is why people would probably be much more empathetic with a couple that chooses <mark>to</mark> abort if they find out that their fetus has Down syndrome versus if they find out the fetus has autism, you know, because autism is much more prevalent and we see a lot of more hi, Let him or function in quote unquote people with Autism, you know, but I think that's also just due <mark>to</mark> social stigma and taboo because I think a lot of people probably don't even realize that a lot of people with Down Syndrome do things like live totally on their own and are self-sufficient and some of them even raise their own families, you know, so this has very much <mark>to</mark> do with I think social stigma and taboos, too. And this is why we have <mark>to</mark> talk about the underlying ideology. So it's been about 43 minutes. I'm not going <mark>to</mark> go much longer but <mark>to</mark> conclude I think that this is really something that is not. Really well defined or articulated in any meaningful way as", "Start Time (s)": 2579.6, "End Time (s)": 2698.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "and we see a lot of more hi, Let him or function in quote unquote people with Autism, you know, but I think that's also just due <mark>to</mark> social stigma and taboo because I think a lot of people probably don't even realize that a lot of people with Down Syndrome do things like live totally on their own and are self-sufficient and some of them even raise their own families, you know, so this has very much <mark>to</mark> do with I think social stigma and taboos, too. And this is why we have <mark>to</mark> talk about the underlying ideology. So it's been about 43 minutes. I'm not going <mark>to</mark> go much longer but <mark>to</mark> conclude I think that this is really something that is not. Really well defined or articulated in any meaningful way as it stands right now, you know, what is our moral obligation as humans as far as it relates <mark>to</mark> things like medicine, you know, because I think that the dissidents arises from multiple things appearing <mark>to</mark> be simultaneously true on the one hand. We still Foster this attitude where We feel as if it is morally acceptable and perhaps even morally righteous <mark>to</mark> not <mark>to</mark> basically not bring people into the world that we know or as close <mark>to</mark> definitively knowing as you can get that we know will likely suffer for this or that reason, right? but at the same time We also feel as if it is morally wrong. <mark>To</mark>", "Start Time (s)": 2646.1, "End Time (s)": 2765.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "far as it relates <mark>to</mark> things like medicine, you know, because I think that the dissidents arises from multiple things appearing <mark>to</mark> be simultaneously true on the one hand. We still Foster this attitude where We feel as if it is morally acceptable and perhaps even morally righteous <mark>to</mark> not <mark>to</mark> basically not bring people into the world that we know or as close <mark>to</mark> definitively knowing as you can get that we know will likely suffer for this or that reason, right? but at the same time We also feel as if it is morally wrong. <mark>To</mark> not put all of our best efforts into using medicine <mark>to</mark> promote the survivability and sustainability of these same exact populations, you know, so <mark>how</mark> can both of these things be simultaneously true? What are we really promoting here? If not, what seems like <mark>to</mark> me in this moment some brilli nebulous. kind of ill-defined moral relativism subjectivism really you know the idea that well whatever the parent wants or whatever this person wants or whatever is right for you is right is that really all we have <mark>to</mark> go on I feel like especially as things like genetic engineering <mark>become</mark> more and more complex and are being utilized more and more that we should", "Start Time (s)": 2705.1, "End Time (s)": 2825.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "We also feel as if it is morally wrong. <mark>To</mark> not put all of our best efforts into using medicine <mark>to</mark> promote the survivability and sustainability of these same exact populations, you know, so <mark>how</mark> can both of these things be simultaneously true? What are we really promoting here? If not, what seems like <mark>to</mark> me in this moment some brilli nebulous. kind of ill-defined moral relativism subjectivism really you know the idea that well whatever the parent wants or whatever this person wants or whatever is right for you is right is that really all we have <mark>to</mark> go on I feel like especially as things like genetic engineering <mark>become</mark> more and more complex and are being utilized more and more that we should really try <mark>to</mark> form some sort of premises that we And use <mark>to</mark> look <mark>to</mark> you when all types of problems will arise undoubtedly because they will very soon, you know, and I think I think that if we don't start delineating some sort of clear arguments and what we think exactly then we're fucked. Caitlin says damn this is so interesting. I'm so sad. I missed 90% of this life. Well lucky for you. I'm about <mark>to</mark> get out of here and you can listen <mark>to</mark> it in full. I hope you meditate on these Concepts and maybe that you can come back and we can talk some more about where they lead you maybe you could see this as a", "Start Time (s)": 2757.9, "End Time (s)": 2877.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "will arise undoubtedly because they will very soon, you know, and I think I think that if we don't start delineating some sort of clear arguments and what we think exactly then we're fucked. Caitlin says damn this is so interesting. I'm so sad. I missed 90% of this life. Well lucky for you. I'm about <mark>to</mark> get out of here and you can listen <mark>to</mark> it in full. I hope you meditate on these Concepts and maybe that you can come back and we can talk some more about where they lead you maybe you could see this as a homework assignment because this is a homework assignment that exist for myself, especially in the past few months. Because I've been thinking on it heavily. What I think about medicines role is in what we come up with for systems of morality. You know, <mark>how</mark> do we integrate medicine into our ideas about morality in a way that is philosophically coherent because right now is a stands right now this idea that whatever this or that person wants is the righteous thing <mark>to</mark> do. I don't think is working currently. But it's kind of okay at the moment since the stakes are not super high yet, you know, but I think that this is just going <mark>to</mark> <mark>become</mark> more and more complex for future generations of people so we should all think about it deeply so I want you <mark>to</mark> do this and then I want you <mark>to</mark> tell me your fucking thoughts. Okay, because you're all so fucking smart and I love all of your stupid fucking brains. If you want <mark>to</mark> talk more about this with me, by the way, it's only $1 <mark>to</mark> join our Discord in via the patreon in the links. So go do that. If you want you could come into the Discord. We're always", "Start Time (s)": 2838.1, "End Time (s)": 2957.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "role is in what we come up with for systems of morality. You know, <mark>how</mark> do we integrate medicine into our ideas about morality in a way that is philosophically coherent because right now is a stands right now this idea that whatever this or that person wants is the righteous thing <mark>to</mark> do. I don't think is working currently. But it's kind of okay at the moment since the stakes are not super high yet, you know, but I think that this is just going <mark>to</mark> <mark>become</mark> more and more complex for future generations of people so we should all think about it deeply so I want you <mark>to</mark> do this and then I want you <mark>to</mark> tell me your fucking thoughts. Okay, because you're all so fucking smart and I love all of your stupid fucking brains. If you want <mark>to</mark> talk more about this with me, by the way, it's only $1 <mark>to</mark> join our Discord in via the patreon in the links. So go do that. If you want you could come into the Discord. We're always in there talking and fighting about what a chair is what a punch is what is punching is eugenics ethical yada yada. So also, please give me a thumbs up because when I asked for one I get more, so please do that. Thank you everybody and I'll be back. Soon. I'll talk <mark>to</mark> you later. Happy motherfucking Sunday evening. Soon. I'll talk <mark>to</mark> you later. Happy motherfucking Sunday evening.", "Start Time (s)": 2889.8, "End Time (s)": 2980.4, "Clip Length (min)": 1.51, "show_uri": "spotify:show:4iax1kbINZW0YbQmoNwysd", "show_name": "Phenomenology Club", "show_description": "Phenomenology Club is an interactive set of learning materials designed to pinpoint & harness our phenomenological abilities. Join us!   Learn more about our club and how you can become a member at https://www.phenomenology.club Patreon: www.patreon.com/phenomenologyclub Follow us on twitter @phenomenologyCL ", "publisher": "Phenomenology Club", "episode_uri": "spotify:episode:0HxDPGN2OG9ZtkOwdLZkpL", "episode_name": "The Ethics of Eugenics ", "episode_description": "What is Eugenics? What kind of ethical concerns does it raise & are these concerns philosophically consistent? Let's Talk About It. Learn more about our club at http://www.phenomenology.club and how you can become a member via our patreon for only $1 a month at http://www.patreon.com/phenomenologyclub Twitter @phenomenologycl ", "score": 3.4781559, "explanation": "{\n  \"value\": 3.4781559,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.2769085,\n      \"description\": \"weight(word_list:how in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.2769085,\n          \"description\": \"score(LMDirichletSimilarity, freq=24.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.7447828,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 24.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=179.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.4546984,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 179.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.0054396,\n      \"description\": \"weight(word_list:become in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.0054396,\n          \"description\": \"score(LMDirichletSimilarity, freq=4.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.473314,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 4.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1958077,\n      \"description\": \"weight(word_list:rich in 360) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1958077,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.6636822,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Right this podcast is going <mark>to</mark> be focused on the first lesson of Richard and John which is looking at life in a medieval village. Now what needs <mark>to</mark> be understood about a medieval village, is that obviously in the medieval period things were very different in regards <mark>to</mark> <mark>how</mark> people lived. So most people in England lived and worked on the land in the Middle Ages, and unless you were <mark>rich</mark> life was at actually a pretty big struggle Ordinary People did face a constant struggle <mark>to</mark> survive and live tended <mark>to</mark> be very short for so for those people within a medieval village, you're looking at a life expectancy as low as 25 and if you're lucky as high as 40 So a medieval village was all based around one concept and that was Agriculture and agriculture means Farm. Now the main types of people that lived on a medieval", "Start Time (s)": 1.6, "End Time (s)": 62.3, "Clip Length (min)": 1.01, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "looking at life in a medieval village. Now what needs <mark>to</mark> be understood about a medieval village, is that obviously in the medieval period things were very different in regards <mark>to</mark> <mark>how</mark> people lived. So most people in England lived and worked on the land in the Middle Ages, and unless you were <mark>rich</mark> life was at actually a pretty big struggle Ordinary People did face a constant struggle <mark>to</mark> survive and live tended <mark>to</mark> be very short for so for those people within a medieval village, you're looking at a life expectancy as low as 25 and if you're lucky as high as 40 So a medieval village was all based around one concept and that was Agriculture and agriculture means Farm. Now the main types of people that lived on a medieval village were peasants. Now you're going <mark>to</mark> look at this later on but in medieval Society there was a hierarchy of importance called the feudal system and at the very bottom of this system where the peasants now overall there were around Types of peasants you had one peasant that actually had an element of Freedom. They were called Freeman now, they were very free types of peasants because they could do as they pleased because they paid rent just because we're saying the word peasant doesn't mean they're totally poor. Another type of peasant would be a Kotter. Now a cotter would work from one <mark>to</mark> two days a week working the Lord's land and the worst off kind of peasant was a villain of the line would work around five days a week. They were the property of the Lord and the Lord could do anything. He wanted <mark>to</mark> them apart from kill or injure them. He could sell them he could find them he could treat them pretty awfully now in", "Start Time (s)": 6.1, "End Time (s)": 126.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Another type of peasant would be a Kotter. Now a cotter would work from one <mark>to</mark> two days a week working the Lord's land and the worst off kind of peasant was a villain of the line would work around five days a week. They were the property of the Lord and the Lord could do anything. He wanted <mark>to</mark> them apart from kill or injure them. He could sell them he could find them he could treat them pretty awfully now in terms of the picture of a medieval village. It's known as a manorial estate now most peasants did live and work on these manorial Estates and they were made up of one or several Villages which surrounded a manor house and the manor house would be where the Lord lived now if the Lord was away which was very common because a lord could have been a night which again we'll look at later. Then a bailiff would look after it now Bayless job was <mark>to</mark> look after the Lord's land. His Lords held lands in different parts of the countries bailiffs were really important <mark>to</mark> look after their land while the Lord's were away. So the Lord kept some of the land for himself and then he divided it up amongst the peasants so he could have it farmed so we could make some profit. Now the next really important individual so you have the Lord who was in charge of the land the bailiff who would watch over the land then you'd have a Reeve or a Reeve would basically supervise the peasants and they would watch over the peasants work now. He divided out the work. He kept the the accounts of what was sold and he also collect the rents from the Freeman. So what needs <mark>to</mark> be understood as if you were of the line if you were a peasant you had <mark>to</mark> work there was no", "Start Time (s)": 96.1, "End Time (s)": 215.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "which again we'll look at later. Then a bailiff would look after it now Bayless job was <mark>to</mark> look after the Lord's land. His Lords held lands in different parts of the countries bailiffs were really important <mark>to</mark> look after their land while the Lord's were away. So the Lord kept some of the land for himself and then he divided it up amongst the peasants so he could have it farmed so we could make some profit. Now the next really important individual so you have the Lord who was in charge of the land the bailiff who would watch over the land then you'd have a Reeve or a Reeve would basically supervise the peasants and they would watch over the peasants work now. He divided out the work. He kept the the accounts of what was sold and he also collect the rents from the Freeman. So what needs <mark>to</mark> be understood as if you were of the line if you were a peasant you had <mark>to</mark> work there was no disagreement. It was your part in society. It was your place in society <mark>to</mark> work. But if you were a Freeman as I said previously you would only you wouldn't have <mark>to</mark> work you'd only work as often as you want. Because you paid rent for your land. As this course goes on the whole definition of a villain was changing because as time went on more people were paying rent, but what needs <mark>to</mark> be understood the first thing who were the people that lived on this land they were the peasants that had people overseeing them. So the next thing you need <mark>to</mark> really understand is what sort of jobs did people do on the farm now each piece of farming land. We'll split up into three sections. One of these pieces of lime has always left fallow and follow means empty. The reason for this was <mark>to</mark> allow that piece of", "Start Time (s)": 150.4, "End Time (s)": 270.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So what needs <mark>to</mark> be understood as if you were of the line if you were a peasant you had <mark>to</mark> work there was no disagreement. It was your part in society. It was your place in society <mark>to</mark> work. But if you were a Freeman as I said previously you would only you wouldn't have <mark>to</mark> work you'd only work as often as you want. Because you paid rent for your land. As this course goes on the whole definition of a villain was changing because as time went on more people were paying rent, but what needs <mark>to</mark> be understood the first thing who were the people that lived on this land they were the peasants that had people overseeing them. So the next thing you need <mark>to</mark> really understand is what sort of jobs did people do on the farm now each piece of farming land. We'll split up into three sections. One of these pieces of lime has always left fallow and follow means empty. The reason for this was <mark>to</mark> allow that piece of land <mark>to</mark> recover in time for the next Harvest. That's really important because the one thing people didn't couldn't have in those days was a bad Harvest because of the potential of starvation. Now the three pieces of land was split in two strips of land each peasant, including Freeman had strips of land in different fields, so they had some really good land and they had some really bad land a problem with this was is that some peasants land might be miles apart. So if I wanted <mark>to</mark> work their land that The walk quite a distance <mark>to</mark> be able <mark>to</mark> do it effectively. Now as a farmer the sort of jobs you would do you'd be plowing the fields where you'll be digging digging the field up <mark>to</mark> make sure that it was ready <mark>to</mark> sow your seeds. So plowing digging it up the weeding the ground sewing planting your seats and then by the time of", "Start Time (s)": 209.7, "End Time (s)": 328.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "That's really important because the one thing people didn't couldn't have in those days was a bad Harvest because of the potential of starvation. Now the three pieces of land was split in two strips of land each peasant, including Freeman had strips of land in different fields, so they had some really good land and they had some really bad land a problem with this was is that some peasants land might be miles apart. So if I wanted <mark>to</mark> work their land that The walk quite a distance <mark>to</mark> be able <mark>to</mark> do it effectively. Now as a farmer the sort of jobs you would do you'd be plowing the fields where you'll be digging digging the field up <mark>to</mark> make sure that it was ready <mark>to</mark> sow your seeds. So plowing digging it up the weeding the ground sewing planting your seats and then by the time of around summer time, you'd be harvesting the land taking the crops up ready <mark>to</mark> take it <mark>to</mark> a male <mark>to</mark> make things such as bread. Now the type of crop really did depend on the soil that you had now. This is obviously quite in-depth and it's sort of like farming understanding but then the different types of crops would be things like barley wheat Rye oats, they were all grown in England during the Middle Ages and when the lines are harvested the land they would take the crops <mark>to</mark> the Village Mill <mark>to</mark> be ground and they'd have <mark>to</mark> pay a fee <mark>to</mark> use the mill. Now farming was very profitable in England overall. It wasn't just your bog-standard crops that would be grown. So what needs <mark>to</mark> be understood that in the 13th century the most profitable product in terms of farming was wool and made England one of the richest countries in the world some areas of the country especially areas, like the north were really ideally suited <mark>to</mark> things like sheep farming", "Start Time (s)": 274.5, "End Time (s)": 393.1, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "harvesting the land taking the crops up ready <mark>to</mark> take it <mark>to</mark> a male <mark>to</mark> make things such as bread. Now the type of crop really did depend on the soil that you had now. This is obviously quite in-depth and it's sort of like farming understanding but then the different types of crops would be things like barley wheat Rye oats, they were all grown in England during the Middle Ages and when the lines are harvested the land they would take the crops <mark>to</mark> the Village Mill <mark>to</mark> be ground and they'd have <mark>to</mark> pay a fee <mark>to</mark> use the mill. Now farming was very profitable in England overall. It wasn't just your bog-standard crops that would be grown. So what needs <mark>to</mark> be understood that in the 13th century the most profitable product in terms of farming was wool and made England one of the richest countries in the world some areas of the country especially areas, like the north were really ideally suited <mark>to</mark> things like sheep farming which links perfectly into the next bit. So just as a summary of that and you know, the type of people that lived within a village, you know, the types of jobs that people have <mark>to</mark> do with in a medieval village. And now the next thing really is <mark>to</mark> understand what was peasants life like On the majority. It was pretty tough. It was hot. The types of places so the peasants would live within the village and they live in a very small house with a thatched roof like a straw like roof, and these were known as crack houses. The walls were made of wooden strips woven together and they were plastered not with cement but with manual and this was known as wattle and daub so mixture of mud and dung. But a woman <mark>to</mark> live in very little", "Start Time (s)": 331.5, "End Time (s)": 451.4, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "ideally suited <mark>to</mark> things like sheep farming which links perfectly into the next bit. So just as a summary of that and you know, the type of people that lived within a village, you know, the types of jobs that people have <mark>to</mark> do with in a medieval village. And now the next thing really is <mark>to</mark> understand what was peasants life like On the majority. It was pretty tough. It was hot. The types of places so the peasants would live within the village and they live in a very small house with a thatched roof like a straw like roof, and these were known as crack houses. The walls were made of wooden strips woven together and they were plastered not with cement but with manual and this was known as wattle and daub so mixture of mud and dung. But a woman <mark>to</mark> live in very little Furniture floors would be covered with straw which was you know, quite easy <mark>to</mark> clean but it could <mark>become</mark> very dirty and invested quite easily and within these houses it was very likely they were going <mark>to</mark> be very cold in the winter. Another thing that the peasants would have <mark>to</mark> share their home with is their animal if they had one. So if they kept an animal in the daytime the animal will be outside grazing. So eating the grass but night time that had <mark>to</mark> be put in their house <mark>to</mark> keep them safe from people who would steal them or wild animals who potentially could kill them now in terms of the actual job farming was very very difficult. They didn't have the same technology that we had today. So when you were Having the land that had <mark>to</mark> be done manually with a tools that weren't really good enough. If you didn't have proper tools, then the work was very physically demanding. If you are a peasant", "Start Time (s)": 390.1, "End Time (s)": 509.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the peasants would have <mark>to</mark> share their home with is their animal if they had one. So if they kept an animal in the daytime the animal will be outside grazing. So eating the grass but night time that had <mark>to</mark> be put in their house <mark>to</mark> keep them safe from people who would steal them or wild animals who potentially could kill them now in terms of the actual job farming was very very difficult. They didn't have the same technology that we had today. So when you were Having the land that had <mark>to</mark> be done manually with a tools that weren't really good enough. If you didn't have proper tools, then the work was very physically demanding. If you are a peasant women basically you had no rights. They were controlled by the men firstly they be controlled by their father secondly their husband when a woman married a medieval England, she became the property of her husband and basically this meant that her main duty was Static she had <mark>to</mark> stay at home caring for the children cooking spinning wall weaving. She grew a very small vegetable patch in the garden <mark>to</mark> look after animals <mark>to</mark> look after the children. Then also look talk <mark>to</mark> the animals. She would also help in time of harvest. Now. What what you'll notice is that peasants work together when obviously it was really important especially Harvest Time. So a daughter will be expected <mark>to</mark> help her mother obviously if you were You were a boy you'd be expected <mark>to</mark> work the farm. Just like your dad would the children thinking back <mark>to</mark> that didn't go <mark>to</mark> school. Once they're old enough. They join their father in the fields. They wouldn't carry out the hard tasks straight away, but they would clear the fields of stones scare away the birds and the older they got the more physically demanding their jobs got now the opal one of the main positive. So this is it wasn't all ridiculously hard work. Some of the peasants", "Start Time (s)": 468.8, "End Time (s)": 588.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "<mark>to</mark> look after the children. Then also look talk <mark>to</mark> the animals. She would also help in time of harvest. Now. What what you'll notice is that peasants work together when obviously it was really important especially Harvest Time. So a daughter will be expected <mark>to</mark> help her mother obviously if you were You were a boy you'd be expected <mark>to</mark> work the farm. Just like your dad would the children thinking back <mark>to</mark> that didn't go <mark>to</mark> school. Once they're old enough. They join their father in the fields. They wouldn't carry out the hard tasks straight away, but they would clear the fields of stones scare away the birds and the older they got the more physically demanding their jobs got now the opal one of the main positive. So this is it wasn't all ridiculously hard work. Some of the peasants also could focus on merrymaking basically means times where they could enjoy themselves and these were usually linked <mark>to</mark> either Pagan or Christian festivals and on these days villagers would gather and enjoy things like wrestling different types of sports that archery they'd be drinking ale which is a title you had type of drink And that have sort of games. So in those days in a village if you were a man that could drink the most ale you might get yourself an award, but the problem was this didn't happen very often because L was very expensive. So when they did enjoy themselves then obviously they must have saved up for quite a long time. So in summary life in the medieval town was not the easiest opportunity for people unless you could escape <mark>to</mark> a town for one year and one day you would have spent most of your life in a medieval Town. Therefore. It was something where your life expectancy wasn't expected <mark>to</mark> be very high. And if you were born into peasantry the likelihood likelihood is you would die in peasantry.", "Start Time (s)": 539.0, "End Time (s)": 655.9, "Clip Length (min)": 1.95, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "could focus on merrymaking basically means times where they could enjoy themselves and these were usually linked <mark>to</mark> either Pagan or Christian festivals and on these days villagers would gather and enjoy things like wrestling different types of sports that archery they'd be drinking ale which is a title you had type of drink And that have sort of games. So in those days in a village if you were a man that could drink the most ale you might get yourself an award, but the problem was this didn't happen very often because L was very expensive. So when they did enjoy themselves then obviously they must have saved up for quite a long time. So in summary life in the medieval town was not the easiest opportunity for people unless you could escape <mark>to</mark> a town for one year and one day you would have spent most of your life in a medieval Town. Therefore. It was something where your life expectancy wasn't expected <mark>to</mark> be very high. And if you were born into peasantry the likelihood likelihood is you would die in peasantry. Why this podcast can be focusing on medieval towns, which is the second lesson in the Richard and John scheme of learning. So towns were vastly different <mark>to</mark> a village now there were aspects of similarities, but on the whole they were a very different area in the 12th century the period that were looking at in this course, the town's went through what some historians call a golden period old towns grew massively and New Towns were met were found because of something called tray. And as I've said towns would be very they wouldn't be massively different in terms of their appearance farming would have still taken place. But a majority of the things about towns would have been very very different due <mark>to</mark> the importance that they played in raising money for the king. So firstly <mark>how</mark> we're", "Start Time (s)": 589.1, "End Time (s)": 708.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a medieval Town. Therefore. It was something where your life expectancy wasn't expected <mark>to</mark> be very high. And if you were born into peasantry the likelihood likelihood is you would die in peasantry. Why this podcast can be focusing on medieval towns, which is the second lesson in the Richard and John scheme of learning. So towns were vastly different <mark>to</mark> a village now there were aspects of similarities, but on the whole they were a very different area in the 12th century the period that were looking at in this course, the town's went through what some historians call a golden period old towns grew massively and New Towns were met were found because of something called tray. And as I've said towns would be very they wouldn't be massively different in terms of their appearance farming would have still taken place. But a majority of the things about towns would have been very very different due <mark>to</mark> the importance that they played in raising money for the king. So firstly <mark>how</mark> we're towns form <mark>to</mark> most of the towns were established by Royal Charter now a royal Charter could only be given <mark>to</mark> a from <mark>to</mark> a town from the King. NG and in return they will get their freedom from the local Lord, which means that the town had the right <mark>to</mark> self govern itself. They would have their own Law Court and their own mini government within the town Richard and John would have charged vast monies fast amounts of money for this privilege. And one of the biggest towns in England was London, it had its own officials and these men were called Alderman who played important important role in King off <mark>to</mark> the town in Law Courts. Each Oldman was responsible for an area of London. So because London was so big. They need <mark>to</mark> separate these men into separate little parts <mark>to</mark> look after the law and make sure it didn't <mark>become</mark>", "Start Time (s)": 642.9, "End Time (s)": 762.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "taken place. But a majority of the things about towns would have been very very different due <mark>to</mark> the importance that they played in raising money for the king. So firstly <mark>how</mark> we're towns form <mark>to</mark> most of the towns were established by Royal Charter now a royal Charter could only be given <mark>to</mark> a from <mark>to</mark> a town from the King. NG and in return they will get their freedom from the local Lord, which means that the town had the right <mark>to</mark> self govern itself. They would have their own Law Court and their own mini government within the town Richard and John would have charged vast monies fast amounts of money for this privilege. And one of the biggest towns in England was London, it had its own officials and these men were called Alderman who played important important role in King off <mark>to</mark> the town in Law Courts. Each Oldman was responsible for an area of London. So because London was so big. They need <mark>to</mark> separate these men into separate little parts <mark>to</mark> look after the law and make sure it didn't <mark>become</mark> Lawless which means there was a lot of crime. And London was a special case because in 1215 they could elect their own mayor of London. So they really did get given extra Power by the king and the king at that time would have been King jump. Let's hounds also were renowned for the different jobs that you could do now in a town. You have <mark>to</mark> be part of a guild GUI LD and what these were they were basically groups of workers who did the same job so you can only you have <mark>to</mark> be part of a guild <mark>to</mark> so you could have unrestricted trade <mark>to</mark> I'm actually trade within the town and if you weren't a member you couldn't do your job and you couldn't earn money for it. Now in return are being part of a guild you have <mark>to</mark> promise that you pay your taxes as well, which is really important because the tax money in those days", "Start Time (s)": 696.7, "End Time (s)": 816.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Oldman was responsible for an area of London. So because London was so big. They need <mark>to</mark> separate these men into separate little parts <mark>to</mark> look after the law and make sure it didn't <mark>become</mark> Lawless which means there was a lot of crime. And London was a special case because in 1215 they could elect their own mayor of London. So they really did get given extra Power by the king and the king at that time would have been King jump. Let's hounds also were renowned for the different jobs that you could do now in a town. You have <mark>to</mark> be part of a guild GUI LD and what these were they were basically groups of workers who did the same job so you can only you have <mark>to</mark> be part of a guild <mark>to</mark> so you could have unrestricted trade <mark>to</mark> I'm actually trade within the town and if you weren't a member you couldn't do your job and you couldn't earn money for it. Now in return are being part of a guild you have <mark>to</mark> promise that you pay your taxes as well, which is really important because the tax money in those days would have gone <mark>to</mark> the king and that was a big way in which the king made money something called tala judge, which was a tax. Now one of the most important guilds in the 12th century and was basically the the cloth industry anyone that manufactured cloth because the population was growing so significantly it became one of the richest Industries because people needed clothing and top of this the trade England traded a lot with the Low Country. So countries like Belgium today in the Netherlands. Not made the England a lot richer because they were trading with other people. Now a big question you might get is why would town so important <mark>to</mark> the economy? Why were town so important <mark>to</mark> the revenue the money of the king. There's a few things you could talk about", "Start Time (s)": 751.9, "End Time (s)": 871.1, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a member you couldn't do your job and you couldn't earn money for it. Now in return are being part of a guild you have <mark>to</mark> promise that you pay your taxes as well, which is really important because the tax money in those days would have gone <mark>to</mark> the king and that was a big way in which the king made money something called tala judge, which was a tax. Now one of the most important guilds in the 12th century and was basically the the cloth industry anyone that manufactured cloth because the population was growing so significantly it became one of the richest Industries because people needed clothing and top of this the trade England traded a lot with the Low Country. So countries like Belgium today in the Netherlands. Not made the England a lot richer because they were trading with other people. Now a big question you might get is why would town so important <mark>to</mark> the economy? Why were town so important <mark>to</mark> the revenue the money of the king. There's a few things you could talk about firstly trade was controlled by tolls. Now whenever someone made a sale or purchase tolls were collected which meant that there'd be money added on top. I mean a modern-day example is if we have v8e added on top of our items. This money will go <mark>to</mark> the king and on top of that the king would benefit more the bigger the town was for example, London. Also tolls were collected when people use certain roads and bridges <mark>to</mark> get <mark>to</mark> towns and <mark>to</mark> get through town Gates. They had <mark>to</mark> collect tolls for them <mark>to</mark> get through and also on top of this any item that sort of came into the country and went out of the country also had a toll put on it all of this money would go <mark>to</mark> the king of England which means they're going <mark>to</mark> financially benefit significantly. On top of this buying and selling was also carried out in a", "Start Time (s)": 805.3, "End Time (s)": 925.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the England a lot richer because they were trading with other people. Now a big question you might get is why would town so important <mark>to</mark> the economy? Why were town so important <mark>to</mark> the revenue the money of the king. There's a few things you could talk about firstly trade was controlled by tolls. Now whenever someone made a sale or purchase tolls were collected which meant that there'd be money added on top. I mean a modern-day example is if we have v8e added on top of our items. This money will go <mark>to</mark> the king and on top of that the king would benefit more the bigger the town was for example, London. Also tolls were collected when people use certain roads and bridges <mark>to</mark> get <mark>to</mark> towns and <mark>to</mark> get through town Gates. They had <mark>to</mark> collect tolls for them <mark>to</mark> get through and also on top of this any item that sort of came into the country and went out of the country also had a toll put on it all of this money would go <mark>to</mark> the king of England which means they're going <mark>to</mark> financially benefit significantly. On top of this buying and selling was also carried out in a local market now every Sunday that be a market in a town and this meant that Traders Traders would sell Goods on open table. So if we think about car boot sales in today's society that's sort of similar but markets and a lot more money. So the stall holders the people that had a area <mark>to</mark> sell they kept records of what they sold and people went around officials for the king went around collecting rent off the table based on <mark>how</mark> much they earn and they also charge people for the use of official weights and measures so if you were a baker and you were selling a certain weight edge of bread for example markets were huge booster towns income and allowed some towns <mark>to</mark> <mark>become</mark> ridiculously wealthy which in turn is going <mark>to</mark> benefit the king due <mark>to</mark> the fact that they were", "Start Time (s)": 856.1, "End Time (s)": 975.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that sort of came into the country and went out of the country also had a toll put on it all of this money would go <mark>to</mark> the king of England which means they're going <mark>to</mark> financially benefit significantly. On top of this buying and selling was also carried out in a local market now every Sunday that be a market in a town and this meant that Traders Traders would sell Goods on open table. So if we think about car boot sales in today's society that's sort of similar but markets and a lot more money. So the stall holders the people that had a area <mark>to</mark> sell they kept records of what they sold and people went around officials for the king went around collecting rent off the table based on <mark>how</mark> much they earn and they also charge people for the use of official weights and measures so if you were a baker and you were selling a certain weight edge of bread for example markets were huge booster towns income and allowed some towns <mark>to</mark> <mark>become</mark> ridiculously wealthy which in turn is going <mark>to</mark> benefit the king due <mark>to</mark> the fact that they were going <mark>to</mark> charge extra rent for the people who earned extra money now, The trade of towns also required building of roads and bridges and tell governments became responsible for looking after these roads in and around the towns, but roads did Flood very often and they did collapse making travel slow. So this could affect trade. You know, again, it's similar <mark>to</mark> today's that today's society. If you get flooding in a town, then the business in that town is going <mark>to</mark> go down. It's very similar <mark>to</mark> the Middle Ages. Now the town's that really benefitted as well ones with Points now a port is where ships can come into the country and these were crucial <mark>to</mark> England's trade because they allow Goods <mark>to</mark> be bought in and sold <mark>to</mark> foreign countries. It helps speed up train at speed up trade between circles and coastal towns,", "Start Time (s)": 909.1, "End Time (s)": 1028.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "so if you were a baker and you were selling a certain weight edge of bread for example markets were huge booster towns income and allowed some towns <mark>to</mark> <mark>become</mark> ridiculously wealthy which in turn is going <mark>to</mark> benefit the king due <mark>to</mark> the fact that they were going <mark>to</mark> charge extra rent for the people who earned extra money now, The trade of towns also required building of roads and bridges and tell governments became responsible for looking after these roads in and around the towns, but roads did Flood very often and they did collapse making travel slow. So this could affect trade. You know, again, it's similar <mark>to</mark> today's that today's society. If you get flooding in a town, then the business in that town is going <mark>to</mark> go down. It's very similar <mark>to</mark> the Middle Ages. Now the town's that really benefitted as well ones with Points now a port is where ships can come into the country and these were crucial <mark>to</mark> England's trade because they allow Goods <mark>to</mark> be bought in and sold <mark>to</mark> foreign countries. It helps speed up train at speed up trade between circles and coastal towns, which meant that trade could be done quicker with in the country because it was a lot trick quicker <mark>to</mark> travel by sea rather than Road. And the last reason why they tell made lots of money for the King was an annual Fair now some towns hosted at the annual fairs a yearly fair and they were usually held on important years of on the Christian calendar important day. Sorry of the Christian calendar and there's usually lasted several days and got Traders from other towns and even foreign country. So it was a big deal with made lots of money and the purpose the main purpose of this was merry making sports like archery all the taverns would sell Mead which was an alcoholic Drink made from honey Andale and after all is very making the business occurred trade was carried out including trading luxury goods like wine and", "Start Time (s)": 959.7, "End Time (s)": 1078.4, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "up train at speed up trade between circles and coastal towns, which meant that trade could be done quicker with in the country because it was a lot trick quicker <mark>to</mark> travel by sea rather than Road. And the last reason why they tell made lots of money for the King was an annual Fair now some towns hosted at the annual fairs a yearly fair and they were usually held on important years of on the Christian calendar important day. Sorry of the Christian calendar and there's usually lasted several days and got Traders from other towns and even foreign country. So it was a big deal with made lots of money and the purpose the main purpose of this was merry making sports like archery all the taverns would sell Mead which was an alcoholic Drink made from honey Andale and after all is very making the business occurred trade was carried out including trading luxury goods like wine and silk and the key thing about these annual fairs where you could only do it. If you paid the king for a license <mark>to</mark> hold it and this raised a huge amount of money for the King on tolls and rents for stalls and trade so the king really benefited from this. Then the next aspect is what was life in a town really like so life in a town. The key difference <mark>to</mark> the countryside was not all townspeople were free. And even if you are from a village if you ran away from one year and one day without being caught then you could also <mark>become</mark> free this meant that you were choose. You are free <mark>to</mark> choose where you work rather than being tied <mark>to</mark> the land as like a farmer like the the lines were in a village. Now back <mark>to</mark> the job aspect. I'm like the countryside the population of the towns were employed in many different jobs. For example, people became blacksmith butchers Weaver's Builders and the way you do this is by becoming an apprentice. Now, you would be apprenticed <mark>to</mark> a Master Craftsman. So you basically learn from someone who was really high up in their trade and you <mark>become</mark> an", "Start Time (s)": 1024.1, "End Time (s)": 1143.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "like wine and silk and the key thing about these annual fairs where you could only do it. If you paid the king for a license <mark>to</mark> hold it and this raised a huge amount of money for the King on tolls and rents for stalls and trade so the king really benefited from this. Then the next aspect is what was life in a town really like so life in a town. The key difference <mark>to</mark> the countryside was not all townspeople were free. And even if you are from a village if you ran away from one year and one day without being caught then you could also <mark>become</mark> free this meant that you were choose. You are free <mark>to</mark> choose where you work rather than being tied <mark>to</mark> the land as like a farmer like the the lines were in a village. Now back <mark>to</mark> the job aspect. I'm like the countryside the population of the towns were employed in many different jobs. For example, people became blacksmith butchers Weaver's Builders and the way you do this is by becoming an apprentice. Now, you would be apprenticed <mark>to</mark> a Master Craftsman. So you basically learn from someone who was really high up in their trade and you <mark>become</mark> an apprentice at the age of 14 train between five and nine years and then you'd be allowed <mark>to</mark> practice the trade yourself. It was a real good opportunity for children <mark>to</mark> work in different occupations and women could also do this but women also had domestic duties <mark>to</mark> fulfill women did support their husbands. So for example, if a man was a baker women might support them in the bakery or that although their skilled occupation, like weaving very rarely. Some women were allowed <mark>to</mark> join guilds, but it was very unusual. Now as we know from the medicine course towns were very dirty. Dirty crowded people entered their chamber pots into the street and rain wash the waste into the wells, which would have caused things like cholera housing was built on narrow streets with shops at the front and those days the shop signs would have been pictures because people couldn't read", "Start Time (s)": 1077.7, "End Time (s)": 1196.7, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "It was a real good opportunity for children <mark>to</mark> work in different occupations and women could also do this but women also had domestic duties <mark>to</mark> fulfill women did support their husbands. So for example, if a man was a baker women might support them in the bakery or that although their skilled occupation, like weaving very rarely. Some women were allowed <mark>to</mark> join guilds, but it was very unusual. Now as we know from the medicine course towns were very dirty. Dirty crowded people entered their chamber pots into the street and rain wash the waste into the wells, which would have caused things like cholera housing was built on narrow streets with shops at the front and those days the shop signs would have been pictures because people couldn't read town would have got busy from around 5 a.m. Shops opened at 6 and stayed open until 3 p.m. Some did continue till 9:00, but at the end of the night a curfew Bell would ring which means that people had <mark>to</mark> leave the town would be Shop fair amount of town was surrounded by a wall and the Watchman would look after the town overnight for any criminals that might be doing things. They shouldn't be doing so that's an overview of the medieval town. Right. Okay. This podcast is less than 3 I'm Richard and John the role of a king. Now the first thing you need <mark>to</mark> understand what this course at the role of a king was very different <mark>to</mark> today's Monarch and medieval Monarch was a powerful ruler who had complete responsibility for looking after the country and the kingdom this meant that the character of the King was really really important. If you had a weak King then potentially your government and your country could fall apart the king needed <mark>to</mark> be strong <mark>to</mark> control the people. <mark>To</mark> enforce the laws <mark>to</mark> keep Justice and also <mark>to</mark> stop the Kingdom from being attacked from other countries the whole nation very much depended on the king and this was", "Start Time (s)": 1151.6, "End Time (s)": 1269.9, "Clip Length (min)": 1.97, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Shops opened at 6 and stayed open until 3 p.m. Some did continue till 9:00, but at the end of the night a curfew Bell would ring which means that people had <mark>to</mark> leave the town would be Shop fair amount of town was surrounded by a wall and the Watchman would look after the town overnight for any criminals that might be doing things. They shouldn't be doing so that's an overview of the medieval town. Right. Okay. This podcast is less than 3 I'm Richard and John the role of a king. Now the first thing you need <mark>to</mark> understand what this course at the role of a king was very different <mark>to</mark> today's Monarch and medieval Monarch was a powerful ruler who had complete responsibility for looking after the country and the kingdom this meant that the character of the King was really really important. If you had a weak King then potentially your government and your country could fall apart the king needed <mark>to</mark> be strong <mark>to</mark> control the people. <mark>To</mark> enforce the laws <mark>to</mark> keep Justice and also <mark>to</mark> stop the Kingdom from being attacked from other countries the whole nation very much depended on the king and this was vitally important now in this course, obviously Richard the first is looked as the hero and King John is looked at as the the incompetent King who really did destroy the country. Now, <mark>how</mark> would you <mark>become</mark> a king would have one of the main ideas was that in the 11th century than the Norman? Fans who were in power because of William of Normandy after the Battle of Hastings introduced the principle of primogeniture. This idea means that the eldest son inherits all of the father's titles and his land the in this case. It meant that basically the eldest son would have the throne so a legitimate child means basically if they were born <mark>to</mark> the queen while she was married <mark>to</mark> the king if they won't All right, then I", "Start Time (s)": 1200.6, "End Time (s)": 1320.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "could fall apart the king needed <mark>to</mark> be strong <mark>to</mark> control the people. <mark>To</mark> enforce the laws <mark>to</mark> keep Justice and also <mark>to</mark> stop the Kingdom from being attacked from other countries the whole nation very much depended on the king and this was vitally important now in this course, obviously Richard the first is looked as the hero and King John is looked at as the the incompetent King who really did destroy the country. Now, <mark>how</mark> would you <mark>become</mark> a king would have one of the main ideas was that in the 11th century than the Norman? Fans who were in power because of William of Normandy after the Battle of Hastings introduced the principle of primogeniture. This idea means that the eldest son inherits all of the father's titles and his land the in this case. It meant that basically the eldest son would have the throne so a legitimate child means basically if they were born <mark>to</mark> the queen while she was married <mark>to</mark> the king if they won't All right, then I couldn't <mark>become</mark> the king and because he would be known as illegitimate. Now this idea didn't really follow through in history in the idea of kingship. But Richard the first was the first king for more than a hundred years <mark>to</mark> get the throne from his father this concept of primogeniture. And this is why you know having sons in those days were really important for people <mark>to</mark> have a clear succession pathway. Now prior <mark>to</mark> this obviously people have been nominated, but this is different which at the first earned his way <mark>to</mark> the Ship under primogeniture if the succession wasn't done properly, then it could lead <mark>to</mark> a civil war. So it's important that the king knew who was going <mark>to</mark> be next in line. Now when the king when the person is identified as the next king, they will go through this process called a coronation", "Start Time (s)": 1255.9, "End Time (s)": 1375.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "this idea didn't really follow through in history in the idea of kingship. But Richard the first was the first king for more than a hundred years <mark>to</mark> get the throne from his father this concept of primogeniture. And this is why you know having sons in those days were really important for people <mark>to</mark> have a clear succession pathway. Now prior <mark>to</mark> this obviously people have been nominated, but this is different which at the first earned his way <mark>to</mark> the Ship under primogeniture if the succession wasn't done properly, then it could lead <mark>to</mark> a civil war. So it's important that the king knew who was going <mark>to</mark> be next in line. Now when the king when the person is identified as the next king, they will go through this process called a coronation now from the moment a king was anointed with holy oils. It is coronation. So that combination is where he's crowned becomes official. Once he's Anointed with holy oil <mark>to</mark> prove that he's been taking a chosen by God. He took the title of wrecks or king and the King was given a Divine authority meaning he was chosen by God and his subjects could not question his authority. Obviously that causes problems when the pope wants <mark>to</mark> be a bit more powerful than the King which happens later in the course now up until in this course the Kings Authority was very much accepted until 12:15 when King John was presented with the Magna Carta which <mark>To</mark> limit his situation as king limit his power and this caused the Civil War when he went against it. So what we need <mark>to</mark> understand this court is what were the duties of the king? What did he have <mark>to</mark> do and what sort of things did he do for display? So the duties well as we've mentioned the King was the biggest decision maker in the whole of the kingdom and he had <mark>to</mark> decide on foreign policy, which was what he did with other countries and domestic policy what he did with in our country, but the king", "Start Time (s)": 1326.3, "End Time (s)": 1445.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "anointed with holy oils. It is coronation. So that combination is where he's crowned becomes official. Once he's Anointed with holy oil <mark>to</mark> prove that he's been taking a chosen by God. He took the title of wrecks or king and the King was given a Divine authority meaning he was chosen by God and his subjects could not question his authority. Obviously that causes problems when the pope wants <mark>to</mark> be a bit more powerful than the King which happens later in the course now up until in this course the Kings Authority was very much accepted until 12:15 when King John was presented with the Magna Carta which <mark>To</mark> limit his situation as king limit his power and this caused the Civil War when he went against it. So what we need <mark>to</mark> understand this court is what were the duties of the king? What did he have <mark>to</mark> do and what sort of things did he do for display? So the duties well as we've mentioned the King was the biggest decision maker in the whole of the kingdom and he had <mark>to</mark> decide on foreign policy, which was what he did with other countries and domestic policy what he did with in our country, but the king can do exactly what he pleased. So during the coronation the king asked <mark>to</mark> make a promise that he would protect the people now that basically means the king card abuse his power and it is her in his oath he promises <mark>to</mark> say for example <mark>to</mark> keep the peace promises <mark>to</mark> protect the People by making sure they're not greedy and also <mark>to</mark> maintain Justice <mark>to</mark> make sure that people who commit crimes are punished now the king made the laws he was the supreme law maker and he had a duty show fairness if he showed favoritism that could cause problems so <mark>to</mark> fulfill his oath his promise the King needed <mark>to</mark> travel around the country here in cases basically a royal traveling court and that's an itinerant kingship. This helps the king build relationships with the most important people in society", "Start Time (s)": 1377.4, "End Time (s)": 1497.0, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a promise that he would protect the people now that basically means the king card abuse his power and it is her in his oath he promises <mark>to</mark> say for example <mark>to</mark> keep the peace promises <mark>to</mark> protect the People by making sure they're not greedy and also <mark>to</mark> maintain Justice <mark>to</mark> make sure that people who commit crimes are punished now the king made the laws he was the supreme law maker and he had a duty show fairness if he showed favoritism that could cause problems so <mark>to</mark> fulfill his oath his promise the King needed <mark>to</mark> travel around the country here in cases basically a royal traveling court and that's an itinerant kingship. This helps the king build relationships with the most important people in society the Nobles Barons tenants in Chief and he would stay in their castles and basically the more he showed his fairness the more people would respect him. Another really important duty of the King was <mark>to</mark> protect his kingdom and the people from foreign attacks and Civil Wars one of the biggest threats <mark>to</mark> the king of England would obviously be Philip II of France. So a king needed <mark>to</mark> have effective military skills. He needs <mark>to</mark> be able <mark>to</mark> plan campaigns direct his armies <mark>to</mark> choose the most capable leaders and most of the time the king actually led the Army himself Richard. The first is one of the most standout examples of a great warrior. He led his men into Crusade. He led his men into many battles against Philip II <mark>to</mark> try and reclaim parts of land that were lost while he was away. Whereas John on the other hand failed spectacularly in campaigns in Normandy. Therefore he received the name a nickname soft sword. So this shows he wasn't as capable as Richard but also didn't fulfill his coronation oath his promise <mark>to</mark> look after the land. Now a medieval King needed <mark>to</mark> be seen by a", "Start Time (s)": 1450.9, "End Time (s)": 1570.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the more people would respect him. Another really important duty of the King was <mark>to</mark> protect his kingdom and the people from foreign attacks and Civil Wars one of the biggest threats <mark>to</mark> the king of England would obviously be Philip II of France. So a king needed <mark>to</mark> have effective military skills. He needs <mark>to</mark> be able <mark>to</mark> plan campaigns direct his armies <mark>to</mark> choose the most capable leaders and most of the time the king actually led the Army himself Richard. The first is one of the most standout examples of a great warrior. He led his men into Crusade. He led his men into many battles against Philip II <mark>to</mark> try and reclaim parts of land that were lost while he was away. Whereas John on the other hand failed spectacularly in campaigns in Normandy. Therefore he received the name a nickname soft sword. So this shows he wasn't as capable as Richard but also didn't fulfill his coronation oath his promise <mark>to</mark> look after the land. Now a medieval King needed <mark>to</mark> be seen by a subject. That's his key thing. If you're not if you're not seeing then then people are going <mark>to</mark> doubt your Authority and this was <mark>to</mark> reinforce the power that he had within his kingdom. So formal occasions were arranged <mark>to</mark> enable the king <mark>to</mark> show his face basically and the greatest ritual was the coronation where the King was anointed with holy oil and crowned in front of the most important Noble than clerics religious people. That was the most important ritual the king went through because it made it official but more regular displays of the Kings power will also needed so the itinerant kingship was also important. So people could see him people could learn some respect him and also the king shows his power another key thing was the crown wearing now. Basically, that means that the King has <mark>to</mark> be seen in public wearing his crown <mark>to</mark> reinforce his authority.", "Start Time (s)": 1505.3, "End Time (s)": 1623.8, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "capable as Richard but also didn't fulfill his coronation oath his promise <mark>to</mark> look after the land. Now a medieval King needed <mark>to</mark> be seen by a subject. That's his key thing. If you're not if you're not seeing then then people are going <mark>to</mark> doubt your Authority and this was <mark>to</mark> reinforce the power that he had within his kingdom. So formal occasions were arranged <mark>to</mark> enable the king <mark>to</mark> show his face basically and the greatest ritual was the coronation where the King was anointed with holy oil and crowned in front of the most important Noble than clerics religious people. That was the most important ritual the king went through because it made it official but more regular displays of the Kings power will also needed so the itinerant kingship was also important. So people could see him people could learn some respect him and also the king shows his power another key thing was the crown wearing now. Basically, that means that the King has <mark>to</mark> be seen in public wearing his crown <mark>to</mark> reinforce his authority. Now the king would be seen wearing his crown on three occasions throughout the year. And this is this happened since the start of William the Conqueror and these would be an important times of the year. So for example, our Easter the king would wear his crown in Winchester Christmas. He'd wear it in Gloucester and at Whitson. He'd wear it in Westminster. These Crown weddings were imported as they were like, they had feasts and they had a big get together afterwards, but the key thing is it encouraged people <mark>to</mark> be loyal <mark>to</mark> the monarch. As they reminded people of his power his authority and his sheer determination <mark>to</mark> be an outstanding King. So the king had many many jobs <mark>to</mark> do and what we need <mark>to</mark> assess during this course is <mark>how</mark> well Richard did it and <mark>how</mark> well John did it. So the next podcast is going <mark>to</mark> be focusing on the white religion was important then we're going <mark>to</mark> look at the feudal system and then we're going <mark>to</mark> look into a bit more detail", "Start Time (s)": 1560.4, "End Time (s)": 1679.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "power another key thing was the crown wearing now. Basically, that means that the King has <mark>to</mark> be seen in public wearing his crown <mark>to</mark> reinforce his authority. Now the king would be seen wearing his crown on three occasions throughout the year. And this is this happened since the start of William the Conqueror and these would be an important times of the year. So for example, our Easter the king would wear his crown in Winchester Christmas. He'd wear it in Gloucester and at Whitson. He'd wear it in Westminster. These Crown weddings were imported as they were like, they had feasts and they had a big get together afterwards, but the key thing is it encouraged people <mark>to</mark> be loyal <mark>to</mark> the monarch. As they reminded people of his power his authority and his sheer determination <mark>to</mark> be an outstanding King. So the king had many many jobs <mark>to</mark> do and what we need <mark>to</mark> assess during this course is <mark>how</mark> well Richard did it and <mark>how</mark> well John did it. So the next podcast is going <mark>to</mark> be focusing on the white religion was important then we're going <mark>to</mark> look at the feudal system and then we're going <mark>to</mark> look into a bit more detail about the actual family themselves. Right. Okay. Now this podcast is focused on the feudal system. Now the feudal system was a way in which the king of England in the medieval period basically controlled their land it was a way of ensuring that there was a control over land but also that the king had people doing jobs for him in able <mark>to</mark> enable him <mark>to</mark> make sure the country ran as smoothly as possible now, we've got <mark>to</mark> understand the This time period was a bit different compared <mark>to</mark> today. It was a really strange and foreign Land There was nearly no real understanding of equality and these attitudes would obviously cause some problems in the 12th century, but basically as an", "Start Time (s)": 1612.6, "End Time (s)": 1732.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "a bit more detail about the actual family themselves. Right. Okay. Now this podcast is focused on the feudal system. Now the feudal system was a way in which the king of England in the medieval period basically controlled their land it was a way of ensuring that there was a control over land but also that the king had people doing jobs for him in able <mark>to</mark> enable him <mark>to</mark> make sure the country ran as smoothly as possible now, we've got <mark>to</mark> understand the This time period was a bit different compared <mark>to</mark> today. It was a really strange and foreign Land There was nearly no real understanding of equality and these attitudes would obviously cause some problems in the 12th century, but basically as an overview the feudal system organized Society into a hierarchy, it means the most important down <mark>to</mark> the least important and these people would be judged based on <mark>how</mark> much land they held remember in this period the more land the more power the more importance and when was it introduced when it was introduced in 1066 after William of Normandy won the Battle of Hastings. That's not important <mark>to</mark> this course for what is important is that you understand <mark>how</mark> it works. So there's four strands <mark>to</mark> the feudal system firstly at the top obviously got the king. Now the king technically owns a hundred percent of the land, but he can't look after it all. It's a bit like going <mark>to</mark> school when a head teacher is in charge. They can't look after the whole school without help as they'll be just too much <mark>to</mark> do. Just like the king in this period but the king would keep 20% of his land and this was known as The Royal Land the world the mezzanine and this was an area", "Start Time (s)": 1678.9, "End Time (s)": 1798.6, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "based on <mark>how</mark> much land they held remember in this period the more land the more power the more importance and when was it introduced when it was introduced in 1066 after William of Normandy won the Battle of Hastings. That's not important <mark>to</mark> this course for what is important is that you understand <mark>how</mark> it works. So there's four strands <mark>to</mark> the feudal system firstly at the top obviously got the king. Now the king technically owns a hundred percent of the land, but he can't look after it all. It's a bit like going <mark>to</mark> school when a head teacher is in charge. They can't look after the whole school without help as they'll be just too much <mark>to</mark> do. Just like the king in this period but the king would keep 20% of his land and this was known as The Royal Land the world the mezzanine and this was an area where the Kings will animal with Rome and the king would also like <mark>to</mark> hunt in this period the king would really hunt like hunting deer. Now. What did the king do now the king obviously is at the top of the hierarchy he is the most powerful person in the country and this is something we've looked at. Previous podcast lessons as a king as a good King you'd expect your people <mark>to</mark> be obedient and in return under his coronation oath, he would protect his people but there's a problem <mark>to</mark> do this <mark>to</mark> protect the people the king needs an army and it was really expensive <mark>to</mark> raise a an army of soldiers in these days, especially as they needed paying and they needed horses and weapons. So what does The king get out of this feudal system now he gives land and tax concessions. That means that they don't pay as much that they changed compared <mark>to</mark> normal people. He provides peace law protection", "Start Time (s)": 1742.6, "End Time (s)": 1861.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "this was an area where the Kings will animal with Rome and the king would also like <mark>to</mark> hunt in this period the king would really hunt like hunting deer. Now. What did the king do now the king obviously is at the top of the hierarchy he is the most powerful person in the country and this is something we've looked at. Previous podcast lessons as a king as a good King you'd expect your people <mark>to</mark> be obedient and in return under his coronation oath, he would protect his people but there's a problem <mark>to</mark> do this <mark>to</mark> protect the people the king needs an army and it was really expensive <mark>to</mark> raise a an army of soldiers in these days, especially as they needed paying and they needed horses and weapons. So what does The king get out of this feudal system now he gives land and tax concessions. That means that they don't pay as much that they changed compared <mark>to</mark> normal people. He provides peace law protection and in return he will give land <mark>to</mark> a group of people called the tenants in Chief. Now these tenants in Chief will also known as Barons and as we looked at in real in the religion lesson Bishops and Abbot's So these tenants in chiefs were highly respected the king would divide his land up and he granted some of his land <mark>to</mark> these people and they held land but in return they had <mark>to</mark> do a job for the king. So the tenants in Chief's job mainly was <mark>to</mark> get get the king of England a an army their job was <mark>to</mark> provide the king with a quota a number of soldiers and <mark>to</mark> be able <mark>to</mark> allow the country <mark>to</mark> be protected. They also did provide the king with advice and especially in regards <mark>to</mark> chant the chancellor one", "Start Time (s)": 1797.5, "End Time (s)": 1916.5, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "The king get out of this feudal system now he gives land and tax concessions. That means that they don't pay as much that they changed compared <mark>to</mark> normal people. He provides peace law protection and in return he will give land <mark>to</mark> a group of people called the tenants in Chief. Now these tenants in Chief will also known as Barons and as we looked at in real in the religion lesson Bishops and Abbot's So these tenants in chiefs were highly respected the king would divide his land up and he granted some of his land <mark>to</mark> these people and they held land but in return they had <mark>to</mark> do a job for the king. So the tenants in Chief's job mainly was <mark>to</mark> get get the king of England a an army their job was <mark>to</mark> provide the king with a quota a number of soldiers and <mark>to</mark> be able <mark>to</mark> allow the country <mark>to</mark> be protected. They also did provide the king with advice and especially in regards <mark>to</mark> chant the chancellor one of the keep the Kings main advisors that would usually come from the LeBaron or Bishop group. They were very important <mark>to</mark> the king. They would give advice they were very high-ranking members of society such as the church archbishop's would also be a tenant in Chief. They weren't just there <mark>to</mark> raise an army. They were important people who helped the king run. the government But the key thing with those individuals were is that they got land they became a vassal of land in return for providing the king with a night service and advice. So just <mark>to</mark> summarize so far. You've got the king and then the tenants in Chief. Underneath the tenants in Chief. You've got the knights now the knights as I've produced", "Start Time (s)": 1846.6, "End Time (s)": 1966.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "king with advice and especially in regards <mark>to</mark> chant the chancellor one of the keep the Kings main advisors that would usually come from the LeBaron or Bishop group. They were very important <mark>to</mark> the king. They would give advice they were very high-ranking members of society such as the church archbishop's would also be a tenant in Chief. They weren't just there <mark>to</mark> raise an army. They were important people who helped the king run. the government But the key thing with those individuals were is that they got land they became a vassal of land in return for providing the king with a night service and advice. So just <mark>to</mark> summarize so far. You've got the king and then the tenants in Chief. Underneath the tenants in Chief. You've got the knights now the knights as I've produced mentioned will raised by the tenants in Chief and tenants in Chief had <mark>to</mark> do that <mark>to</mark> keep their lap. Now the knights were also known as the under tenants and what they had <mark>to</mark> do was they had <mark>to</mark> work or they had <mark>to</mark> fight on Horseback in the king's Army whenever the king demanded night <mark>to</mark> his tenants and cheap. So the king would go <mark>to</mark> his tenants in Chief and say I need an army. Under that promise <mark>to</mark> their tenant in Chief. They had <mark>to</mark> fight they had <mark>to</mark> fight for 40 days a year also had <mark>to</mark> help protect the Kings castles for up <mark>to</mark> two <mark>to</mark> three months of their reign. In return they would get land. Now there was a problem that the king faced obviously it was very expensive paying soldiers. Well, <mark>how</mark> did he mainly pain? We paid them in land. They would have received money from that land. But he also got the knights <mark>to</mark> pay for that own horses and their own weapons now in a lesson", "Start Time (s)": 1911.0, "End Time (s)": 2031.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "now the knights as I've produced mentioned will raised by the tenants in Chief and tenants in Chief had <mark>to</mark> do that <mark>to</mark> keep their lap. Now the knights were also known as the under tenants and what they had <mark>to</mark> do was they had <mark>to</mark> work or they had <mark>to</mark> fight on Horseback in the king's Army whenever the king demanded night <mark>to</mark> his tenants and cheap. So the king would go <mark>to</mark> his tenants in Chief and say I need an army. Under that promise <mark>to</mark> their tenant in Chief. They had <mark>to</mark> fight they had <mark>to</mark> fight for 40 days a year also had <mark>to</mark> help protect the Kings castles for up <mark>to</mark> two <mark>to</mark> three months of their reign. In return they would get land. Now there was a problem that the king faced obviously it was very expensive paying soldiers. Well, <mark>how</mark> did he mainly pain? We paid them in land. They would have received money from that land. But he also got the knights <mark>to</mark> pay for that own horses and their own weapons now in a lesson that we previously looked at the nights were usually Nords of manorial Estates. Now manorial Estates would be the village. So the knights would also be in charge of a villager. Eight making sure that the peasants were doing their job and they were providing enough income and economy and food for the country. So the knights really important in many many different ways the peasants now the last group okay the last group in the feudal system were the peasants so the knights provided land <mark>to</mark> The Peasants and The Peasants would not have ownership of this land The Peasants would be lent this land and their job was <mark>to</mark> work on it. Now there were three types of peasants which we've looked at in our village lashing. You've got the other", "Start Time (s)": 1965.0, "End Time (s)": 2084.5, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "soldiers. Well, <mark>how</mark> did he mainly pain? We paid them in land. They would have received money from that land. But he also got the knights <mark>to</mark> pay for that own horses and their own weapons now in a lesson that we previously looked at the nights were usually Nords of manorial Estates. Now manorial Estates would be the village. So the knights would also be in charge of a villager. Eight making sure that the peasants were doing their job and they were providing enough income and economy and food for the country. So the knights really important in many many different ways the peasants now the last group okay the last group in the feudal system were the peasants so the knights provided land <mark>to</mark> The Peasants and The Peasants would not have ownership of this land The Peasants would be lent this land and their job was <mark>to</mark> work on it. Now there were three types of peasants which we've looked at in our village lashing. You've got the other villains you've go which is your everyday everyday peasant would work three <mark>to</mark> five days a week. You've got caught ours who would work one <mark>to</mark> two days a week and then you've also got Freeman who were the while off peasant? Why well because they they paid rent. Now The Peasants were at the very bottom of the hierarchy they were a huge class so numbering around a million people. They really didn't have any power they work the land for their nights and the tendency in Chief and in return they would protect them. So if anything The Peasants got very little out of this agreement, but they did get a piece of land they did get a lamb piece of laminate had <mark>to</mark> work. They didn't have the best life and we'll look at that in a little. Bit of detail in just a second. Now in", "Start Time (s)": 2017.9, "End Time (s)": 2137.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "provided land <mark>to</mark> The Peasants and The Peasants would not have ownership of this land The Peasants would be lent this land and their job was <mark>to</mark> work on it. Now there were three types of peasants which we've looked at in our village lashing. You've got the other villains you've go which is your everyday everyday peasant would work three <mark>to</mark> five days a week. You've got caught ours who would work one <mark>to</mark> two days a week and then you've also got Freeman who were the while off peasant? Why well because they they paid rent. Now The Peasants were at the very bottom of the hierarchy they were a huge class so numbering around a million people. They really didn't have any power they work the land for their nights and the tendency in Chief and in return they would protect them. So if anything The Peasants got very little out of this agreement, but they did get a piece of land they did get a lamb piece of laminate had <mark>to</mark> work. They didn't have the best life and we'll look at that in a little. Bit of detail in just a second. Now in terms of <mark>how</mark> the land was given out as I've mentioned the king couldn't do it on his own go back <mark>to</mark> the analogy of a head teacher in a school. They cannot do it on their own. So the king of England divided his land into fiefs fi EFS. What a thief was it was a piece of land that was granted <mark>to</mark> a landowner now when the person gets given a piece of land they Of the Pledge homage. It's basically means that they have <mark>to</mark> declare loyalty <mark>to</mark> their Lord by swearing an oath of fealty or loyalty. Now when that person swears that loyalty they <mark>become</mark> a vassal. Okay, so just go over that one more time. If you want <mark>to</mark> <mark>become</mark> a", "Start Time (s)": 2068.2, "End Time (s)": 2187.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "little out of this agreement, but they did get a piece of land they did get a lamb piece of laminate had <mark>to</mark> work. They didn't have the best life and we'll look at that in a little. Bit of detail in just a second. Now in terms of <mark>how</mark> the land was given out as I've mentioned the king couldn't do it on his own go back <mark>to</mark> the analogy of a head teacher in a school. They cannot do it on their own. So the king of England divided his land into fiefs fi EFS. What a thief was it was a piece of land that was granted <mark>to</mark> a landowner now when the person gets given a piece of land they Of the Pledge homage. It's basically means that they have <mark>to</mark> declare loyalty <mark>to</mark> their Lord by swearing an oath of fealty or loyalty. Now when that person swears that loyalty they <mark>become</mark> a vassal. Okay, so just go over that one more time. If you want <mark>to</mark> <mark>become</mark> a land owner of a thief you'd have <mark>to</mark> pledge homage <mark>to</mark> your Lord by swearing an oath of fealty. LT out of loyalty and once you've done all that you would then <mark>become</mark> a vassal a vassal is someone who simply holds land someone who has done homage <mark>to</mark> their lord for that piece of land now when you did homage you had <mark>to</mark> do it in public and the reason for that is It shows that if you don't do your job for that land that it could be a pun attend a an action which is punishable by death because it's treason <mark>to</mark> break the oath now as I mentioned the king did keep land and most of the land was divided up amongst his tenants in Chief and then they would be passed down", "Start Time (s)": 2122.0, "End Time (s)": 2241.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "by swearing an oath of fealty. LT out of loyalty and once you've done all that you would then <mark>become</mark> a vassal a vassal is someone who simply holds land someone who has done homage <mark>to</mark> their lord for that piece of land now when you did homage you had <mark>to</mark> do it in public and the reason for that is It shows that if you don't do your job for that land that it could be a pun attend a an action which is punishable by death because it's treason <mark>to</mark> break the oath now as I mentioned the king did keep land and most of the land was divided up amongst his tenants in Chief and then they would be passed down the land. The fiefs were scattered across England. The Barons did keep some land for their liver their own and then I did the rest between their nights. Now. This did becomes some little it could <mark>become</mark> a problem <mark>to</mark> a degree. The reason for this is because if a Barren had a lot of land they could have quite a large night and they could <mark>become</mark> something known as an over-mighty subject. This could be very problematic for the king if a Barren decides <mark>to</mark> overthrow and rebel. If someone doesn't do their job, then they have <mark>to</mark> Forfeit their land now, this is where the this is where the feudal system works properly. If a vassal didn't do that oath, then the Lord could take their land away. So for if a night didn't turn up <mark>to</mark> fight, then he would lose his land. He would forfeit was known as forfeiture Okay, so Just <mark>to</mark> go back <mark>to</mark> the two groups the two biggest groups at an exam board might ask you about other the knights and The Peasants. So the knights as we mentioned the knights would get their land from the tenants in Chief and this was", "Start Time (s)": 2194.3, "End Time (s)": 2314.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "The reason for this is because if a Barren had a lot of land they could have quite a large night and they could <mark>become</mark> something known as an over-mighty subject. This could be very problematic for the king if a Barren decides <mark>to</mark> overthrow and rebel. If someone doesn't do their job, then they have <mark>to</mark> Forfeit their land now, this is where the this is where the feudal system works properly. If a vassal didn't do that oath, then the Lord could take their land away. So for if a night didn't turn up <mark>to</mark> fight, then he would lose his land. He would forfeit was known as forfeiture Okay, so Just <mark>to</mark> go back <mark>to</mark> the two groups the two biggest groups at an exam board might ask you about other the knights and The Peasants. So the knights as we mentioned the knights would get their land from the tenants in Chief and this was known as the knight's fee and the Knights have <mark>to</mark> do a range of jobs. Serving the Army for two months at their own expense. They got their own horse. They got their own armor. They've got their own weapons. And if they conflict lasted for more than two months, then the king would have <mark>to</mark> pay. For today service in protecting the king's castles castles were very important <mark>to</mark> keep be kept hold of. And help pay money. If a lord was captured help pay a ransom fee never really important. Lord was captured in the medieval period part of something known as chivalric values meant that they would be well that a ransom could be paid instead of them dying. Now <mark>how</mark> many nights were needed. So if you're a tent in Chief the amount of nights that you got the king depending on <mark>how</mark> much you land. Now, this was known as the surbiton debatin. The big eagle and the mold nightshirt <mark>to</mark> have so some tenants in", "Start Time (s)": 2257.1, "End Time (s)": 2376.8, "Clip Length (min)": 2.0, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So the knights as we mentioned the knights would get their land from the tenants in Chief and this was known as the knight's fee and the Knights have <mark>to</mark> do a range of jobs. Serving the Army for two months at their own expense. They got their own horse. They got their own armor. They've got their own weapons. And if they conflict lasted for more than two months, then the king would have <mark>to</mark> pay. For today service in protecting the king's castles castles were very important <mark>to</mark> keep be kept hold of. And help pay money. If a lord was captured help pay a ransom fee never really important. Lord was captured in the medieval period part of something known as chivalric values meant that they would be well that a ransom could be paid instead of them dying. Now <mark>how</mark> many nights were needed. So if you're a tent in Chief the amount of nights that you got the king depending on <mark>how</mark> much you land. Now, this was known as the surbiton debatin. The big eagle and the mold nightshirt <mark>to</mark> have so some tenants in Chief had <mark>to</mark> raise 50 <mark>to</mark> 60 nights. Some of them had <mark>to</mark> just raise a handful it all really depended on the amount of land. They would they had under the feudal system. Overall. There were about 5000 nights in England. So that shows that the feudal system was absolutely vital in gaining this protection for the country. The last thing <mark>to</mark> look at is the peasants. Now as I mentioned that was three types, which I won't go over again, but these individuals had <mark>to</mark> work for their land they have <mark>to</mark> work for their lord and their usual work was known as week work the plowing the sewing the harvesting the everyday farm work <mark>to</mark> make sure that the Harvest was successful. In a time of extra work a peasant might have <mark>to</mark> do bun work which is extra work and that would be", "Start Time (s)": 2307.4, "End Time (s)": 2426.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "So if you're a tent in Chief the amount of nights that you got the king depending on <mark>how</mark> much you land. Now, this was known as the surbiton debatin. The big eagle and the mold nightshirt <mark>to</mark> have so some tenants in Chief had <mark>to</mark> raise 50 <mark>to</mark> 60 nights. Some of them had <mark>to</mark> just raise a handful it all really depended on the amount of land. They would they had under the feudal system. Overall. There were about 5000 nights in England. So that shows that the feudal system was absolutely vital in gaining this protection for the country. The last thing <mark>to</mark> look at is the peasants. Now as I mentioned that was three types, which I won't go over again, but these individuals had <mark>to</mark> work for their land they have <mark>to</mark> work for their lord and their usual work was known as week work the plowing the sewing the harvesting the everyday farm work <mark>to</mark> make sure that the Harvest was successful. In a time of extra work a peasant might have <mark>to</mark> do bun work which is extra work and that would be around of extra work around the Harvest Time. Freeman didn't need <mark>to</mark> work on the land because they paid rent and the one thing that peasants did not owe was military service. It was the duty of their night <mark>to</mark> protect them. So a peasant was never expected <mark>to</mark> do military service under the feudal system. So overall the feudal system helped significantly in development of sharing land out making sure the king could control this country and if he was away, which Richard was for quite a long time he could still have I structure which worked.", "Start Time (s)": 2363.7, "End Time (s)": 2464.6, "Clip Length (min)": 1.68, "show_uri": "spotify:show:0U4InYuSUM932j4exqjz5o", "show_name": "History Hall Park Academy ", "show_description": "All things related to GCSE History", "publisher": "Charlie", "episode_uri": "spotify:episode:4r1Y8TxG9I3eSykOoOPdK9", "episode_name": "Paper 2 - Richard and John - Key Topic 1 - Life in Medieval England ", "episode_description": "Key Topic 1 - Richard and John  ", "score": 3.3742466, "explanation": "{\n  \"value\": 3.3742466,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:how in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.2126338,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.180839,\n      \"description\": \"weight(word_list:to in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.180839,\n          \"description\": \"score(LMDirichletSimilarity, freq=229.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.6487134,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 229.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.0462074,\n      \"description\": \"weight(word_list:become in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.0462074,\n          \"description\": \"score(LMDirichletSimilarity, freq=12.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.5140817,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 12.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1472001,\n      \"description\": \"weight(word_list:rich in 138) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1472001,\n          \"description\": \"score(LMDirichletSimilarity, freq=1.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.6150744,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 1.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.4678743,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 6680.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Hello everyone. This is Adam Meister the bitcoinmeister the disrupt Meister. Welcome <mark>to</mark> the one Bitcoin show. Today is March the first 2020 strong hand golden age of the 2020s baby had. Height we're going <mark>to</mark> talk about that some 80 percenters were talking about it in motion value your wealth in Bitcoin be a unique beast on confiscated Bible low my Elite friends marches here. Oh my hey this week in Bitcoin. The last one in February or was legendary ugly old goat was on there and Phil was on there and Brady Swenson. Of a citizen Bitcoin fill as of course unchain Capital check it out yesterday. There were two shows. One of them was a caped presentation. I did for an Iowa Bitcoin group. I did it from here in LA, but", "Start Time (s)": 7.3, "End Time (s)": 80.8, "Clip Length (min)": 1.23, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "is March the first 2020 strong hand golden age of the 2020s baby had. Height we're going <mark>to</mark> talk about that some 80 percenters were talking about it in motion value your wealth in Bitcoin be a unique beast on confiscated Bible low my Elite friends marches here. Oh my hey this week in Bitcoin. The last one in February or was legendary ugly old goat was on there and Phil was on there and Brady Swenson. Of a citizen Bitcoin fill as of course unchain Capital check it out yesterday. There were two shows. One of them was a caped presentation. I did for an Iowa Bitcoin group. I did it from here in LA, but they were in Iowa when I did for them on Thursday, it's pretty cool watch it. It's linked <mark>to</mark> below of course and the be on bitcoin show. We were talking about the current events the Panic. Oh my God the people out there. Come on. Mine the Golden Age you guys are just falling into this 80% or mainstream media hype about this. God all right, so I can't even say what I'm talking about. But you all know what's been in the news lately. It's ridiculous. I'm not going <mark>to</mark> spend on a stuff because of course. This is the one Bitcoin show. Oh, yeah, San Francisco. I'll be at the event at the end of the month. That's linked <mark>to</mark> below Tel Aviv. Oh, yeah. I'm still going <mark>to</mark> Tel Aviv. Of course. The having party will be made 21st best having party on Earth that's linked <mark>to</mark> below and We will talk about the having in a second. Jay doorman says this stem the stimulus is coming possibly as early as today. What do", "Start Time (s)": 26.3, "End Time (s)": 146.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "the Panic. Oh my God the people out there. Come on. Mine the Golden Age you guys are just falling into this 80% or mainstream media hype about this. God all right, so I can't even say what I'm talking about. But you all know what's been in the news lately. It's ridiculous. I'm not going <mark>to</mark> spend on a stuff because of course. This is the one Bitcoin show. Oh, yeah, San Francisco. I'll be at the event at the end of the month. That's linked <mark>to</mark> below Tel Aviv. Oh, yeah. I'm still going <mark>to</mark> Tel Aviv. Of course. The having party will be made 21st best having party on Earth that's linked <mark>to</mark> below and We will talk about the having in a second. Jay doorman says this stem the stimulus is coming possibly as early as today. What do you think Bitcoin does when more insane amounts of free money are created. I've got <mark>to</mark> say I agree with Jay doorman on this one that the FED may be coordinated with some of the other. Western Nations and <mark>rich</mark> Asian Nations like Japan will have some coordinated stimulus of some sort lowering rates suddenly. Maybe it won't be coordinated. Maybe it will but I don't think Trump can and it will pump all the markets again including Bitcoin. So be prepared for that. Am IA fan of that kind of stuff of the fed. The FED is going <mark>to</mark> do with the fence going <mark>to</mark> do it's not my I don't care anymore. That's why I own Bitcoin. I don't care what the think that's that that when you own Bitcoin you really don't care what the FED does. I'm just pointing it out. For those of you who think also beginning of a horrible recession. Oh the 2020 is going be so terrible for the economy and", "Start Time (s)": 93.4, "End Time (s)": 213.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "doorman on this one that the FED may be coordinated with some of the other. Western Nations and <mark>rich</mark> Asian Nations like Japan will have some coordinated stimulus of some sort lowering rates suddenly. Maybe it won't be coordinated. Maybe it will but I don't think Trump can and it will pump all the markets again including Bitcoin. So be prepared for that. Am IA fan of that kind of stuff of the fed. The FED is going <mark>to</mark> do with the fence going <mark>to</mark> do it's not my I don't care anymore. That's why I own Bitcoin. I don't care what the think that's that that when you own Bitcoin you really don't care what the FED does. I'm just pointing it out. For those of you who think also beginning of a horrible recession. Oh the 2020 is going be so terrible for the economy and Ever want <mark>to</mark> jump back in every when the crack is flowing again when the heroine is Flowing that monetary hair and everyone will be partying it up. Like it's freaking 1999 and it's Prince pound that like button. All right. So Moon capital, what's this? Oh, this is good. Unpopular take Bitcoin is so much bigger than Bitcoin Twitter. We are a small part of the Bitcoin community. And if we all disappeared Bitcoin would be fine pound that like button dude. I agree. You can learn a lot from Bitcoin Twitter, but 80% of it of course of it is gossip and a waste of time and people screaming at each other and complete nonsense even 20% probably is good. I do encourage people <mark>to</mark> <mark>to</mark> read the the Twitter feeds of the people I have on the show and and the Twitter feeds of people that I retweet but not <mark>to</mark> get into the ludicrous arguments. It's now", "Start Time (s)": 155.3, "End Time (s)": 275.3, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "economy and Ever want <mark>to</mark> jump back in every when the crack is flowing again when the heroine is Flowing that monetary hair and everyone will be partying it up. Like it's freaking 1999 and it's Prince pound that like button. All right. So Moon capital, what's this? Oh, this is good. Unpopular take Bitcoin is so much bigger than Bitcoin Twitter. We are a small part of the Bitcoin community. And if we all disappeared Bitcoin would be fine pound that like button dude. I agree. You can learn a lot from Bitcoin Twitter, but 80% of it of course of it is gossip and a waste of time and people screaming at each other and complete nonsense even 20% probably is good. I do encourage people <mark>to</mark> <mark>to</mark> read the the Twitter feeds of the people I have on the show and and the Twitter feeds of people that I retweet but not <mark>to</mark> get into the ludicrous arguments. It's now when you do get into this ludicrous arguments and when you start <mark>to</mark> put these people on pedestals, you forget that there's so many entities in this Ace who's never been on Twitter before have just bought a lot of Bitcoin because it's it's Bitcoin because they want <mark>to</mark> preserve their wealth because they wanted a they want gold 2.0 limited Supply type of monetary. I mean that it's so it's a good reminder. Sometimes you have <mark>to</mark> get out of a little bubble and it's a thing with YouTube Bitcoin YouTubers like me if we all disappeared. It wouldn't matter at all. Would it matter at all for Bitcoin Bitcoin is so much bigger Bitcoin is the honey badger. It doesn't matter what the YouTubers do and I'm not a YouTuber. I'm a bit coiner, but you know what? I mean the Twitter people do so if you ever if you ever start <mark>to</mark> take that don't", "Start Time (s)": 212.3, "End Time (s)": 331.8, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "retweet but not <mark>to</mark> get into the ludicrous arguments. It's now when you do get into this ludicrous arguments and when you start <mark>to</mark> put these people on pedestals, you forget that there's so many entities in this Ace who's never been on Twitter before have just bought a lot of Bitcoin because it's it's Bitcoin because they want <mark>to</mark> preserve their wealth because they wanted a they want gold 2.0 limited Supply type of monetary. I mean that it's so it's a good reminder. Sometimes you have <mark>to</mark> get out of a little bubble and it's a thing with YouTube Bitcoin YouTubers like me if we all disappeared. It wouldn't matter at all. Would it matter at all for Bitcoin Bitcoin is so much bigger Bitcoin is the honey badger. It doesn't matter what the YouTubers do and I'm not a YouTuber. I'm a bit coiner, but you know what? I mean the Twitter people do so if you ever if you ever start <mark>to</mark> take that don't overreact <mark>to</mark> social media Okay, there is a benefit <mark>to</mark> it there. You can learn it does not make Bitcoin. It does not make or bake make-or-break Bitcoin it helps you as an individual <mark>become</mark> a more efficient manager of your finances if you properly read and listen <mark>to</mark> the so shut up in shouting mouth matches waited wasting their time and on Twitter or and comment sections just trolling which is not Being in motion at all now all we got questions here. Hey before we move on <mark>to</mark> this and I can't say that word there Daniel. That's not a very nice thing. You're a bit coiner riot. You're a big koiner. Not a you not a YouTuber for sure. I don't know where I still write it from. Thanks, Daniel. I'm a I'm a big point or not a YouTuber for sure.", "Start Time (s)": 270.7, "End Time (s)": 390.5, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "read and listen <mark>to</mark> the so shut up in shouting mouth matches waited wasting their time and on Twitter or and comment sections just trolling which is not Being in motion at all now all we got questions here. Hey before we move on <mark>to</mark> this and I can't say that word there Daniel. That's not a very nice thing. You're a bit coiner riot. You're a big koiner. Not a you not a YouTuber for sure. I don't know where I still write it from. Thanks, Daniel. I'm a I'm a big point or not a YouTuber for sure. Okay. Good. All right Bitcoin or Ted says here on Twitter bitcoiners deserve every single Cent their portfolio appreciates. Your Bitcoins being well-preserved is an effort. Still very few are ready <mark>to</mark> learn. I agree but it will change over time Bitcoin is going <mark>to</mark> create lesions of cybersecurity experts. Hmm regions of cyber Security Experts. I think it'll make some people more aware of the cybersecurity risk out there when you're dealing with your finances when you're dealing with your private key. I think it's going <mark>to</mark> send some people <mark>to</mark> third parties. I think it's going <mark>to</mark> help some Bitcoin Banks out. I would say the bitcoiners do deserve every single cent of their that their portfolio appreciates if they are properly managing the private key on their treasure on their Ledger or whatever their Hardware device. Okay, but I don't I don't think it's going <mark>to</mark> wake up everyone <mark>to</mark> properly controlling their private key. It will wake up some people but you say Legions will <mark>become</mark> cyber Security", "Start Time (s)": 351.6, "End Time (s)": 471.3, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "their portfolio appreciates. Your Bitcoins being well-preserved is an effort. Still very few are ready <mark>to</mark> learn. I agree but it will change over time Bitcoin is going <mark>to</mark> create lesions of cybersecurity experts. Hmm regions of cyber Security Experts. I think it'll make some people more aware of the cybersecurity risk out there when you're dealing with your finances when you're dealing with your private key. I think it's going <mark>to</mark> send some people <mark>to</mark> third parties. I think it's going <mark>to</mark> help some Bitcoin Banks out. I would say the bitcoiners do deserve every single cent of their that their portfolio appreciates if they are properly managing the private key on their treasure on their Ledger or whatever their Hardware device. Okay, but I don't I don't think it's going <mark>to</mark> wake up everyone <mark>to</mark> properly controlling their private key. It will wake up some people but you say Legions will <mark>become</mark> cyber Security Experts. I think it's wishful thinking dude. I think we got a lot of bad stories ahead of us for some individuals that do not take personal responsibility. Seriously now on that note. Hello everyone. If you haven't heard about anchor it's the easiest way <mark>to</mark> make a podcast. That's <mark>how</mark> I make mine. Let me explain it's free. There's creation tools that allow you <mark>to</mark> record and edit your podcast right from your phone or your computer like like I do anchor will distribute your podcast for you. So it can be heard on Spotify Apple podcast and many more you can make money just like I do from your podcast with no minimum listenership. It's everything you need <mark>to</mark> make a podcast in one place. I love the convenience download the free anchor app or go <mark>to</mark>", "Start Time (s)": 401.8, "End Time (s)": 521.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Ledger or whatever their Hardware device. Okay, but I don't I don't think it's going <mark>to</mark> wake up everyone <mark>to</mark> properly controlling their private key. It will wake up some people but you say Legions will <mark>become</mark> cyber Security Experts. I think it's wishful thinking dude. I think we got a lot of bad stories ahead of us for some individuals that do not take personal responsibility. Seriously now on that note. Hello everyone. If you haven't heard about anchor it's the easiest way <mark>to</mark> make a podcast. That's <mark>how</mark> I make mine. Let me explain it's free. There's creation tools that allow you <mark>to</mark> record and edit your podcast right from your phone or your computer like like I do anchor will distribute your podcast for you. So it can be heard on Spotify Apple podcast and many more you can make money just like I do from your podcast with no minimum listenership. It's everything you need <mark>to</mark> make a podcast in one place. I love the convenience download the free anchor app or go <mark>to</mark> Anchor dot. F m-- <mark>to</mark> get started. Anchor dot f m here's a story about a guy. Who's apparently bidding cryptocurrency for quite some time and owns a lot of be cash and Bitcoin he had $60,000 60,000 bees cash worth around 20 million dollars stolen from his phone. Oh, yes. He wasn't keeping his be cash. He was those cyber security expert was he as the excuse me as the Tweet before Alito alluded <mark>to</mark> he did become. Um cyber security expert yet. He's been in the space for a very long time. It's linked <mark>to</mark> below the entire crazy story, but he was either keeping his be cached on a phone or keeping his be cash at blockchain dot info God forbid and it was stolen from him.", "Start Time (s)": 456.3, "End Time (s)": 575.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "love the convenience download the free anchor app or go <mark>to</mark> Anchor dot. F m-- <mark>to</mark> get started. Anchor dot f m here's a story about a guy. Who's apparently bidding cryptocurrency for quite some time and owns a lot of be cash and Bitcoin he had $60,000 60,000 bees cash worth around 20 million dollars stolen from his phone. Oh, yes. He wasn't keeping his be cash. He was those cyber security expert was he as the excuse me as the Tweet before Alito alluded <mark>to</mark> he did become. Um cyber security expert yet. He's been in the space for a very long time. It's linked <mark>to</mark> below the entire crazy story, but he was either keeping his be cached on a phone or keeping his be cash at blockchain dot info God forbid and it was stolen from him. All we had <mark>to</mark> do. All he had <mark>to</mark> do was keep it at a Tresor. I mean if you've got like a million dollars Dude, I can't believe in you have a million dollars worth of be cash or keeping on the phone. Let alone 20 million dollars worth of it. Now some people think well, he he's not a very smart guy because he's got his wealth and be cash. He doesn't understand what bit that Bitcoin is the next Bitcoin and that you got a value your wealth in Bitcoin and not be cash. That's for sure. I think it's really unfortunate that he got his fortune stolen from him because Been an honor phone or keeping it on a blockchain done in for we're not keeping it on a hardware wallet clearly, but that's linked <mark>to</mark> below that story a few people are talking about it. Some people some be cashiers are worried because the hacker is going <mark>to</mark> sell it all and maybe that'll crash", "Start Time (s)": 518.1, "End Time (s)": 638.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "be cash at blockchain dot info God forbid and it was stolen from him. All we had <mark>to</mark> do. All he had <mark>to</mark> do was keep it at a Tresor. I mean if you've got like a million dollars Dude, I can't believe in you have a million dollars worth of be cash or keeping on the phone. Let alone 20 million dollars worth of it. Now some people think well, he he's not a very smart guy because he's got his wealth and be cash. He doesn't understand what bit that Bitcoin is the next Bitcoin and that you got a value your wealth in Bitcoin and not be cash. That's for sure. I think it's really unfortunate that he got his fortune stolen from him because Been an honor phone or keeping it on a blockchain done in for we're not keeping it on a hardware wallet clearly, but that's linked <mark>to</mark> below that story a few people are talking about it. Some people some be cashiers are worried because the hacker is going <mark>to</mark> sell it all and maybe that'll crash damn right? I wouldn't worry about that aspect of it. I'm more so would worry about people who keep that much money on a phone. Or on blockchain that info and somehow by losing access <mark>to</mark> their phone by getting their phone hacked. Maybe he had some password listed there. Maybe he had some private key listed there. It's not exactly clear but he did something really wrong and you can avoid all of that first and you know, that that's probably reason I don't have a phone. I don't even have a phone if I had a phone I would not keep any of cryptocurrency there at all. No. What else is he who keeps his kind of money with only a phone as protection never heard of a hardware while and never heard of a hardware", "Start Time (s)": 569.0, "End Time (s)": 688.9, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "talking about it. Some people some be cashiers are worried because the hacker is going <mark>to</mark> sell it all and maybe that'll crash damn right? I wouldn't worry about that aspect of it. I'm more so would worry about people who keep that much money on a phone. Or on blockchain that info and somehow by losing access <mark>to</mark> their phone by getting their phone hacked. Maybe he had some password listed there. Maybe he had some private key listed there. It's not exactly clear but he did something really wrong and you can avoid all of that first and you know, that that's probably reason I don't have a phone. I don't even have a phone if I had a phone I would not keep any of cryptocurrency there at all. No. What else is he who keeps his kind of money with only a phone as protection never heard of a hardware while and never heard of a hardware while it's when will people learn <mark>how</mark> <mark>to</mark> secure their coins. <mark>How</mark> many horror stories must we see? Well, we're going <mark>to</mark> see we're going <mark>to</mark> hear quite quite a few more here. So guys, don't be the next Horror Story and all right. Remember if you guys got questions I can answer. I see people talk in there. You see just type in Bitcoin Meister do it super cat. And what is next on the agenda here? Oh, well, let's talk about cash real quick. We're talking about Bitcoin which is digital cash digital gold. Whatever you want <mark>to</mark> call it much better than a bringing that cash in on your in your suitcase. And yes Bitcoin fixes the following problem that this on this unfortunate individual has the FED sees $39,000 from this guy's carry-on bags. He sues the get it back when the feds asked where he got the money. He invoked his Fifth Amendment rights against", "Start Time (s)": 630.7, "End Time (s)": 750.6, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "quite quite a few more here. So guys, don't be the next Horror Story and all right. Remember if you guys got questions I can answer. I see people talk in there. You see just type in Bitcoin Meister do it super cat. And what is next on the agenda here? Oh, well, let's talk about cash real quick. We're talking about Bitcoin which is digital cash digital gold. Whatever you want <mark>to</mark> call it much better than a bringing that cash in on your in your suitcase. And yes Bitcoin fixes the following problem that this on this unfortunate individual has the FED sees $39,000 from this guy's carry-on bags. He sues the get it back when the feds asked where he got the money. He invoked his Fifth Amendment rights against self-incrimination. The sixth Circuit Court says that means he doesn't have standing <mark>to</mark> challenge the seizure because he can't show it's his money. So yeah, if you got thirty nine thousand dollars laying around in cash. And it can be easily taken away from you. Okay easily confiscated. You might think you're getting it back, but you're going <mark>to</mark> get into some bureaucracy there as as this. Tweet shows. It's his money. He doesn't want <mark>to</mark> say where he got the money. They stole it from him the TSA stole the money from it was in his possession. He doesn't want <mark>to</mark> say it is his right not <mark>to</mark> say where he got the money from but now the court said well, if you can't say where he got it from it's not really his money. So they stole his money. Yeah, Bitcoin definitely solves that issue right there because they can't just come at you and take your Bitcoin unless you have your freaking private key ring down there. Yeah, if you're like the guy men. Above it. That's pretty bad. But if you've got it on a Tresor if you've got it on a ledger", "Start Time (s)": 697.1, "End Time (s)": 816.4, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "it from you right away. They cannot get it from Uruguay. If you've if you know that thing's been stolen you got your private key. You you've first of all you move it at that point and you're in good shape. Now, I doubt if the government stole suddenly stole your treasure at this point, they would have the proper and of course. If you just even if they stole it and they had the proper specialized device and specialized person that could get into your Treasurer if you had the freaking. The was it the passphrase or whatever not the not the code not your password, but you're special 25th word. Basically you'd be fine for a while at least and again you would know if they stole your treasure and you would have your private key. And of course you would move it <mark>to</mark> a new you would move the Bitcoin <mark>to</mark> a new private key at that point. You'll be fine. But anyway going back <mark>to</mark> the whole darn point of this it and you. So off moberg ask have you seen Daniel Kravitz talk about fake Toshi and Michael Hudson, it's hilarious. Well II I've unfortunately during its people retweet Daniel Kravitz worship of just blind worship of fake Toshi. So I've seen that I don't know who Michael hugs Hudson is but it's it's really like cringe-worthy that the stuff that Daniel tweets out there. I mean, he's not like The most socially skilled guy out there obviously and there's nothing wrong with with that but he does take it <mark>to</mark> a", "Start Time (s)": 824.3, "End Time (s)": 944.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you would move it <mark>to</mark> a new you would move the Bitcoin <mark>to</mark> a new private key at that point. You'll be fine. But anyway going back <mark>to</mark> the whole darn point of this it and you. So off moberg ask have you seen Daniel Kravitz talk about fake Toshi and Michael Hudson, it's hilarious. Well II I've unfortunately during its people retweet Daniel Kravitz worship of just blind worship of fake Toshi. So I've seen that I don't know who Michael hugs Hudson is but it's it's really like cringe-worthy that the stuff that Daniel tweets out there. I mean, he's not like The most socially skilled guy out there obviously and there's nothing wrong with with that but he does take it <mark>to</mark> a new level in his weird belief in bsv. But again, it just shows you that anyone can fall into a into a cult. All right, so yes 25th word baby. You gotta love the 25th word now. What do we have here? We see. I see Richie riches in the house too. I got <mark>to</mark> meet Richie Rich. All right, and people are saying they want <mark>to</mark> see the Daniel per hour. It's think dude. It is a waste of your fricking time that <mark>to</mark> listen <mark>to</mark> a word that dude even says I again I just stumble upon stuff. He says it's noise at this point. It's really embarrassing noise. And so I know some people like <mark>to</mark> be entertained by people who are not, you know, the the most socially Who can be socially awkward or whatever, but that dudes a waste your time. You're not learning anything from that guy.", "Start Time (s)": 883.6, "End Time (s)": 1002.3, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "see Richie riches in the house too. I got <mark>to</mark> meet Richie Rich. All right, and people are saying they want <mark>to</mark> see the Daniel per hour. It's think dude. It is a waste of your fricking time that <mark>to</mark> listen <mark>to</mark> a word that dude even says I again I just stumble upon stuff. He says it's noise at this point. It's really embarrassing noise. And so I know some people like <mark>to</mark> be entertained by people who are not, you know, the the most socially Who can be socially awkward or whatever, but that dudes a waste your time. You're not learning anything from that guy. It's like the stroke so. Literally talked about the Dead the cash Heist by the government. They don't carry cash in your in your bags when you're going on a plane not a good idea and it's just unfortunate. We live in this world where you you should be able <mark>to</mark> And there's been a few people that have lost their cash that way. So the lovely a TSA agents. Alright, so here's an interesting trolling example from a woman who likes likes <mark>to</mark> troll a lot. Her name is Angela watch vault. And this probably shows she doesn't really know too much about Bitcoin and that's not the point of me sharing this. I think it again is foreshadowing the next big social attack on bitcoin which will create a fork of Bitcoin. She said if tomorrow I submitted a technically sound pull request that would lift the 21 million cap in Bitcoin. What stops it from being included in the next release of Bitcoin core All right, so that's it's a pretty ridiculous question. And but and she's probably just trying <mark>to</mark> stir people up or she", "Start Time (s)": 967.3, "End Time (s)": 1087.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "you should be able <mark>to</mark> And there's been a few people that have lost their cash that way. So the lovely a TSA agents. Alright, so here's an interesting trolling example from a woman who likes likes <mark>to</mark> troll a lot. Her name is Angela watch vault. And this probably shows she doesn't really know too much about Bitcoin and that's not the point of me sharing this. I think it again is foreshadowing the next big social attack on bitcoin which will create a fork of Bitcoin. She said if tomorrow I submitted a technically sound pull request that would lift the 21 million cap in Bitcoin. What stops it from being included in the next release of Bitcoin core All right, so that's it's a pretty ridiculous question. And but and she's probably just trying <mark>to</mark> stir people up or she wants new followers because it generated a lot of retweets and a lot of people yelling at her. Okay great. But look what she specifically trolled with their the theme or <mark>how</mark> would you raise it by 21 million? <mark>How</mark> would you raise the 21 million cap? And it's people like her that once that becomes. The more popular little mean among the no coiners or whoever she'll Jump Right In on it and just say yeah, why not? Let's have a big coin with 21 million. And you know what? I will say go ahead make my day create that crypto dividend go for it. It's Bitcoin is the next big coin. You guys are trying <mark>to</mark> be the next be cash and please by give up your precious Bitcoin <mark>to</mark> buy this for 82 million proposed Bitcoin whatever you want <mark>to</mark> call it's not Bitcoin but 42 million proposed altcoin and yeah", "Start Time (s)": 1026.2, "End Time (s)": 1145.7, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "core All right, so that's it's a pretty ridiculous question. And but and she's probably just trying <mark>to</mark> stir people up or she wants new followers because it generated a lot of retweets and a lot of people yelling at her. Okay great. But look what she specifically trolled with their the theme or <mark>how</mark> would you raise it by 21 million? <mark>How</mark> would you raise the 21 million cap? And it's people like her that once that becomes. The more popular little mean among the no coiners or whoever she'll Jump Right In on it and just say yeah, why not? Let's have a big coin with 21 million. And you know what? I will say go ahead make my day create that crypto dividend go for it. It's Bitcoin is the next big coin. You guys are trying <mark>to</mark> be the next be cash and please by give up your precious Bitcoin <mark>to</mark> buy this for 82 million proposed Bitcoin whatever you want <mark>to</mark> call it's not Bitcoin but 42 million proposed altcoin and yeah by what I get for free, but she I'm just I'm just throwing this out there. She's trolling with this theme of the future. Let's say this trolling theme of the future. It's a little for Shatter there for you people. I know I've talked about it quite a bit lately, but this next having period between 2020 and 2024. That's my that's my prediction of the next. Big B cash type of fork off of Bitcoin unfriendly for one that will involve inflation. For the impatient for the people for the complainers. Okay. What do we got here? All right, so I still for some reason one of my email accounts my numerous email accounts. I don't have a phone but I have numerous email accounts. I gotta get a nice shirt on today.", "Start Time (s)": 1076.7, "End Time (s)": 1196.7, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "million proposed Bitcoin whatever you want <mark>to</mark> call it's not Bitcoin but 42 million proposed altcoin and yeah by what I get for free, but she I'm just I'm just throwing this out there. She's trolling with this theme of the future. Let's say this trolling theme of the future. It's a little for Shatter there for you people. I know I've talked about it quite a bit lately, but this next having period between 2020 and 2024. That's my that's my prediction of the next. Big B cash type of fork off of Bitcoin unfriendly for one that will involve inflation. For the impatient for the people for the complainers. Okay. What do we got here? All right, so I still for some reason one of my email accounts my numerous email accounts. I don't have a phone but I have numerous email accounts. I gotta get a nice shirt on today. You cannot get shirts like this link <mark>to</mark> below I still get I still get the Doug Casey. I get some free free newsletter thing from him and occasionally, he'll have someone writes. I usually just erase them because usually the titles are just like gold gold. The or Trump destroying economy or end of world about <mark>to</mark> happen. You know, it's just there's such clickbait nonsense. But I'll occasionally check the ones that I think Mike deal with Bitcoin and sure enough. He's got a he's got a guy who appeals <mark>to</mark> the 80 percenters writing for him talking about the having so anyone hyping the having okay. I like having hype use the hashtag having hype. I think I forgot <mark>to</mark> in my in the tweet. I forgot <mark>to</mark> hashtag it up my bad, but here it is. I'm going <mark>to</mark> read you. Are you prepared? May 20 2011 is a message from our colleagues over at Palm", "Start Time (s)": 1138.5, "End Time (s)": 1258.2, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "I don't have a phone but I have numerous email accounts. I gotta get a nice shirt on today. You cannot get shirts like this link <mark>to</mark> below I still get I still get the Doug Casey. I get some free free newsletter thing from him and occasionally, he'll have someone writes. I usually just erase them because usually the titles are just like gold gold. The or Trump destroying economy or end of world about <mark>to</mark> happen. You know, it's just there's such clickbait nonsense. But I'll occasionally check the ones that I think Mike deal with Bitcoin and sure enough. He's got a he's got a guy who appeals <mark>to</mark> the 80 percenters writing for him talking about the having so anyone hyping the having okay. I like having hype use the hashtag having hype. I think I forgot <mark>to</mark> in my in the tweet. I forgot <mark>to</mark> hashtag it up my bad, but here it is. I'm going <mark>to</mark> read you. Are you prepared? May 20 2011 is a message from our colleagues over at Palm Beach research group that we found particularly interesting. We urge you <mark>to</mark> continue reading Casey dispatch reader a big event is happening in the world of cryptocurrencies in May. It happens every four years. You could call it the big coil Olympics. If you like this event is called the having those first two bull runs work. Great, and I believe this will happen again with Bitcoin and other cryptocurrencies in 2020. That's from teeka tiwari sheath and Analyst at Palm Beach research Group, which of course pumps all sorts of 50 or altcoins again my point in sharing this is that if you think it's hot, if you think it's priced in when this guy is just educate educating his 80%", "Start Time (s)": 1191.6, "End Time (s)": 1311.2, "Clip Length (min)": 1.99, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "May. It happens every four years. You could call it the big coil Olympics. If you like this event is called the having those first two bull runs work. Great, and I believe this will happen again with Bitcoin and other cryptocurrencies in 2020. That's from teeka tiwari sheath and Analyst at Palm Beach research Group, which of course pumps all sorts of 50 or altcoins again my point in sharing this is that if you think it's hot, if you think it's priced in when this guy is just educate educating his 80% followers about it now. Dead wrong. And yeah, so as I said I predict I predicted in 2016 I predicted in for 2020 as we get closer more and more people whether they be sketching individuals like that or the mainstream media are going <mark>to</mark> be bringing it <mark>to</mark> the attention of the 80 percenters. It will be fomo etcetera, etc. Etc. Price will go up. Then price will go down and then by the End by the start of 2021, we'll have our I real. Real movement again. Okay, but no it's not posting yet because people like that haven't heard about it yet. <mark>How</mark> many people do you think have at least one Bitcoin? There was an a story I did on this a few weeks ago Jeff. And I forgot the exact numbers the person broke it down by entities. <mark>How</mark> many entities have at least one Bitcoin and now I forgot what it was. It's not that many if you have like 10, you're in such good shape. It's unbelievable, but I don't I don't remember the number now. They have at least one Bitcoin it", "Start Time (s)": 1271.1, "End Time (s)": 1391.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "by the End by the start of 2021, we'll have our I real. Real movement again. Okay, but no it's not posting yet because people like that haven't heard about it yet. <mark>How</mark> many people do you think have at least one Bitcoin? There was an a story I did on this a few weeks ago Jeff. And I forgot the exact numbers the person broke it down by entities. <mark>How</mark> many entities have at least one Bitcoin and now I forgot what it was. It's not that many if you have like 10, you're in such good shape. It's unbelievable, but I don't I don't remember the number now. They have at least one Bitcoin it maybe it was like 200,000 or something like that. It's quite a small number. It's quite a small number of entities. You know, what I'll try <mark>to</mark> do Jeff is I'll link <mark>to</mark> the video after the show. I'll find the video and it'll be linked <mark>to</mark> below and we'll say <mark>how</mark> many entities have at least one Bitcoin but very good question and I'd like so I'm going with the this The testicles that I talked about in that video that I cannot remember right now that were in that article, I think that guy wrote the article did a good job of figuring out <mark>how</mark> many entities have one Bitcoin at Penn Bitcoin have a hundred Bitcoin is cetera and because it's some companies that share it there their exchanges that okay. Hello Bitcoin presentation people should understand Bitcoin if you're a Bitcoin ER with an interest in educating Aguilar people about big <mark>how</mark> Bitcoin works and why it's important. They consider giving this intro presentation in your local community and I link <mark>to</mark> the tweet that links <mark>to</mark>", "Start Time (s)": 1340.2, "End Time (s)": 1460.0, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "Bitcoin it maybe it was like 200,000 or something like that. It's quite a small number. It's quite a small number of entities. You know, what I'll try <mark>to</mark> do Jeff is I'll link <mark>to</mark> the video after the show. I'll find the video and it'll be linked <mark>to</mark> below and we'll say <mark>how</mark> many entities have at least one Bitcoin but very good question and I'd like so I'm going with the this The testicles that I talked about in that video that I cannot remember right now that were in that article, I think that guy wrote the article did a good job of figuring out <mark>how</mark> many entities have one Bitcoin at Penn Bitcoin have a hundred Bitcoin is cetera and because it's some companies that share it there their exchanges that okay. Hello Bitcoin presentation people should understand Bitcoin if you're a Bitcoin ER with an interest in educating Aguilar people about big <mark>how</mark> Bitcoin works and why it's important. They consider giving this intro presentation in your local community and I link <mark>to</mark> the tweet that links <mark>to</mark> the presentation. I also link <mark>to</mark> hello Bitcoin. And I actually went through the entire presentation. I thought it was very good. There was a little there was a couple high level things in there that some people might not get but in terms of talking about scarcity and why it's valuable and what it is. I thought it was a good thing. It had it had fancy sets and Graphics in it. Well not too fancy. But stuff that people can can get a hold of and be happy about and if you're a if you want <mark>to</mark> show your Club your church group or whatever. You want <mark>to</mark> give a little bit coin presentation. There it is these guys at hello bit. When it had made something that you can share with many people so check that out. I thought it was a cool little tool. So in motion that that entity is in", "Start Time (s)": 1390.1, "End Time (s)": 1510.1, "Clip Length (min)": 2.0, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "in your local community and I link <mark>to</mark> the tweet that links <mark>to</mark> the presentation. I also link <mark>to</mark> hello Bitcoin. And I actually went through the entire presentation. I thought it was very good. There was a little there was a couple high level things in there that some people might not get but in terms of talking about scarcity and why it's valuable and what it is. I thought it was a good thing. It had it had fancy sets and Graphics in it. Well not too fancy. But stuff that people can can get a hold of and be happy about and if you're a if you want <mark>to</mark> show your Club your church group or whatever. You want <mark>to</mark> give a little bit coin presentation. There it is these guys at hello bit. When it had made something that you can share with many people so check that out. I thought it was a cool little tool. So in motion that that entity is in motion pound that like fun finally it's happened <mark>to</mark> me. All right, baby named says You don't wait for insurance premiums <mark>to</mark> go down the buy life insurance. You don't wait for insurance premiums <mark>to</mark> go down the buy fire insurance and you shouldn't wait for Bitcoin prices <mark>to</mark> go down <mark>to</mark> have some insurance again. Socio economic disruptions. Well, that is a good way of looking at things. Mr. Doar David nage actually said that I hope I said they've an aide said that yes, you can consider Bitcoin insurance against really horrible situations happening in your country. And so you really shouldn't wait <mark>to</mark> have that insurance against your your country. Perhaps printing your wealth away, etc, etc. Okay, I'm Adam Meister the bitcoinmeister the disrupt Meister remember <mark>to</mark> subscribe this channel like this video share this video check out the links", "Start Time (s)": 1456.1, "End Time (s)": 1574.6, "Clip Length (min)": 1.98, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}, {"Clip Text": "that like fun finally it's happened <mark>to</mark> me. All right, baby named says You don't wait for insurance premiums <mark>to</mark> go down the buy life insurance. You don't wait for insurance premiums <mark>to</mark> go down the buy fire insurance and you shouldn't wait for Bitcoin prices <mark>to</mark> go down <mark>to</mark> have some insurance again. Socio economic disruptions. Well, that is a good way of looking at things. Mr. Doar David nage actually said that I hope I said they've an aide said that yes, you can consider Bitcoin insurance against really horrible situations happening in your country. And so you really shouldn't wait <mark>to</mark> have that insurance against your your country. Perhaps printing your wealth away, etc, etc. Okay, I'm Adam Meister the bitcoinmeister the disrupt Meister remember <mark>to</mark> subscribe this channel like this video share this video check out the links below. Pound it bang the belly button and I will say hi <mark>to</mark> everybody in the chat right now this late night in La see you soon new show every day conviction.", "Start Time (s)": 1510.8, "End Time (s)": 1590.8, "Clip Length (min)": 1.33, "show_uri": "spotify:show:3h2R3XyV2GQFB0uV7bD0mp", "show_name": "BitcoinMeister- Bitcoin, Cryptocurrency, Altcoins", "show_description": "For all the strong hand Bitcoin fans of the world! Adam Meister brings you original BTC content. Cryptocurrency news that you will get at no other site! A new show every day! Personal responsibility is the new counterculture!  Support this podcast: https://anchor.fm/bitcoinmeister/support", "publisher": "Adam Meister", "episode_uri": "spotify:episode:4Ip6tumAJ6VL26bojRxQVl", "episode_name": "The 1 Bitcoin Show- BTC Twitter is not BTC! Government stimulus on the way? Bcash wallet hack, 80%er halving hype!", "episode_description": "Welcome to the 1 Bitcoin Show! A major Bcash hack from a phone wallet shows that some people STILL take too many chances. How soon will the masses learn about proper BTC security? Will the Fed (USA) be lowering rates soon? Bitcoin Twitter is NOT BTC! Cash can be confiscated easily and then the legal nonsense begins- avoid it with BTC! \u00a0Some 80%er halving hype! \u00a0BTC is insurance, lift the 21million cap noise, more! Recorded in Los Angeles, CA! Question from video about entities- The article- https://medium.com/glassnode-insights/how-many-entities-hold-bitcoin-e945ecc5d0a1 Watch the show here- https://www.youtube.com/watch?v=RCpmS_4K4cM Follow Adam on Twitter- https://twitter.com/TechBalt All of the BitcoinMeister videos are here at- \u00a0http://DisruptMeister.com Financially support the podcast here- https://anchor.fm/bitcoinmeister/support  ---   This episode is sponsored by  \u00b7 Anchor: The easiest way to make a podcast.  https://anchor.fm/app  Support this podcast: https://anchor.fm/bitcoinmeister/support", "score": 3.3453393, "explanation": "{\n  \"value\": 3.3453393,\n  \"description\": \"sum of:\",\n  \"details\": [\n    {\n      \"value\": 0.012408213,\n      \"description\": \"weight(word_list:how in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.012408213,\n          \"description\": \"score(LMDirichletSimilarity, freq=10.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 1.088093,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 10.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.0025398664,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.0025398664,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 0.0,\n      \"description\": \"weight(word_list:to in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 0.0,\n          \"description\": \"score(LMDirichletSimilarity, freq=90.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.974849,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 90.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.027260058,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.027260058,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 1.1376612,\n      \"description\": \"weight(word_list:become in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 1.1376612,\n          \"description\": \"score(LMDirichletSimilarity, freq=3.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 2.213346,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 3.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 0.00018413337,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 0.00018413337,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"value\": 2.1952698,\n      \"description\": \"weight(word_list:rich in 43) [PerFieldSimilarity], result of:\",\n      \"details\": [\n        {\n          \"value\": 2.1952698,\n          \"description\": \"score(LMDirichletSimilarity, freq=2.0), computed as boost * (term weight + document norm) from:\",\n          \"details\": [\n            {\n              \"value\": 2000.0,\n              \"description\": \"mu\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.2709546,\n              \"description\": \"term weight, computed as log(1 + freq /(mu * P)) from:\",\n              \"details\": [\n                {\n                  \"value\": 2.0,\n                  \"description\": \"freq, number of occurrences of term in the document\",\n                  \"details\": []\n                },\n                {\n                  \"value\": 3.9468803e-05,\n                  \"description\": \"P, probability that the current term is generated by the collection\",\n                  \"details\": []\n                }\n              ]\n            },\n            {\n              \"value\": -1.0756848,\n              \"description\": \"document norm, computed as log(mu / (dl + mu))\",\n              \"details\": []\n            },\n            {\n              \"value\": 3864.0,\n              \"description\": \"dl, length of field\",\n              \"details\": []\n            },\n            {\n              \"value\": 3.9468803e-05,\n              \"description\": \"collection probability\",\n              \"details\": []\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}"}]}